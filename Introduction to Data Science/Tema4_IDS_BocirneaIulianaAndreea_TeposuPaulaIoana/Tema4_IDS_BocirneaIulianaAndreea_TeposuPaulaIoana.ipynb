{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.19.2\n",
      "Pandas version: 1.1.3\n",
      "Sklearn version: 0.23.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'Sklearn version: {sklearn.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercitiul 1\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 6. Cel putin un set de date sa fie cu valori lipsa; pentru un alt set de date care are initial toate valorile, introduceti dvs. in mod artificial valori lipsa, suprascriind un anumit procent din valorile initiale (ex. `p=5%`, `p` parametru) cu `numpy.nan`. \n",
    "\n",
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; documentati metoda folosita.\n",
    "*Resurse*: Pentru missing value imputation, puteti urmari [Imputation of missing values](https://scikit-learn.org/stable/modules/impute.html), [How to Handle Missing Data with Python](https://machinelearningmastery.com/handle-missing-data-python/), [fancyimpute](https://github.com/iskandr/fancyimpute), [missingpy](https://github.com/epsilon-machine/missingpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Wine\"\n",
    "\n",
    "- It doesn't have missing values, but we insert them artificially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4.875433939146417\n"
     ]
    }
   ],
   "source": [
    "wine_df:pd.DataFrame = pd.read_csv(\"data/winequality-white.csv\",sep=\";\", header=None)\n",
    "wine_df:pd.DataFrame = wine_df.drop(0, axis = 0)\n",
    "assert wine_df.isnull().sum().sum() == 0\n",
    "\n",
    "wine_df:pd.DataFrame = wine_df.values\n",
    "wine_df_copy:pd.DataFrame = wine_df.copy()\n",
    "\n",
    "def add_missing_values(dataset:pd.DataFrame, p:int = 5)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function changes p% values from data farme into np.nan\n",
    "    :param dataset:the dataframe to bi changed\n",
    "    :param p:the percent of values from dataframe\n",
    "    :return:the dataframe with p% values changed into np.nan\n",
    "    \"\"\"\n",
    "    assert (p>= 0 and p<100)\n",
    "  \n",
    "    nrOfValuesToBeChanged:int = int((p/100) * dataset.shape[0] * dataset.shape[1])\n",
    "    lines:np.ndarray = np.random.choice(dataset.shape[0], nrOfValuesToBeChanged)\n",
    "    columns :np.ndarray= np.random.choice(dataset.shape[1], nrOfValuesToBeChanged)\n",
    "    dataset[lines, columns] = np.nan\n",
    "    return dataset\n",
    "        \n",
    "wine_df:pd.DataFrame = add_missing_values(wine_df)\n",
    "print(np.isnan(wine_df.sum()))\n",
    "assert np.isnan(wine_df.sum()) == True\n",
    "percent_of_missing_values:float = len(np.where(np.isnan(wine_df))[0]) /wine_df.shape[0]/wine_df.shape[1]*100\n",
    "print(percent_of_missing_values )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing value imputaion for wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp:sklearn.impute._base.SimpleImputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "wine_df_imp:np.ndarray = imp.fit_transform(wine_df)\n",
    "\n",
    "\n",
    "assert np.isnan(wine_df_imp.sum()) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"CSM\"\n",
    "- Missing value imputation for csm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csm_df:pd.DataFrame = pd.read_excel(\"data/2014 and 2015 CSM dataset.xlsx\", header = None)\n",
    "csm_df:pd.DataFrame = csm_df.drop(0, axis = 0)\n",
    "csm_df:pd.DataFrame = csm_df.drop(0, axis = 1)\n",
    "\n",
    "assert csm_df.isnull().sum().sum() != 0\n",
    "\n",
    "imp:sklearn.impute._base.SimpleImputer  = SimpleImputer(strategy=\"most_frequent\")\n",
    "csm_df_imp:np.ndarray = imp.fit_transform(csm_df)\n",
    "\n",
    "assert np.isnan(csm_df_imp.sum()) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Glass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1      2     3     4      5     6     7    8    9   10\n",
       "0   1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   1\n",
       "1   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   1\n",
       "2   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   1\n",
       "3   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   1\n",
       "4   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_df:pd.DataFrame = pd.read_csv(\"data/glass.data\", header = None)\n",
    "assert glass_df.isnull().sum().sum() == 0\n",
    "glass_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Segmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>140.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.062963</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>6.185185</td>\n",
       "      <td>7.333334</td>\n",
       "      <td>7.666666</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>4.444445</td>\n",
       "      <td>-7.888889</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.545635</td>\n",
       "      <td>-1.121818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>188.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>8.333334</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-8.333333</td>\n",
       "      <td>8.444445</td>\n",
       "      <td>0.538580</td>\n",
       "      <td>-0.924817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>105.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.107407</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>7.555555</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-7.666666</td>\n",
       "      <td>7.555555</td>\n",
       "      <td>0.532628</td>\n",
       "      <td>-0.965946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>34.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>5.851852</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>6.444445</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>-7.555555</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.573633</td>\n",
       "      <td>-0.744272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRICKFACE</td>\n",
       "      <td>39.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.374074</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.429629</td>\n",
       "      <td>6.037037</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.666666</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>-7.777778</td>\n",
       "      <td>7.888889</td>\n",
       "      <td>0.562919</td>\n",
       "      <td>-1.175773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2   3    4    5         6         7         8   \\\n",
       "0  BRICKFACE  140.0  125.0   9  0.0  0.0  0.277778  0.062963  0.666667   \n",
       "1  BRICKFACE  188.0  133.0   9  0.0  0.0  0.333333  0.266667  0.500000   \n",
       "2  BRICKFACE  105.0  139.0   9  0.0  0.0  0.277778  0.107407  0.833333   \n",
       "3  BRICKFACE   34.0  137.0   9  0.0  0.0  0.500000  0.166667  1.111111   \n",
       "4  BRICKFACE   39.0  111.0   9  0.0  0.0  0.722222  0.374074  0.888889   \n",
       "\n",
       "         9         10        11        12        13        14        15  \\\n",
       "0  0.311111  6.185185  7.333334  7.666666  3.555556  3.444444  4.444445   \n",
       "1  0.077778  6.666666  8.333334  7.777778  3.888889  5.000000  3.333333   \n",
       "2  0.522222  6.111111  7.555555  7.222222  3.555556  4.333334  3.333333   \n",
       "3  0.474074  5.851852  7.777778  6.444445  3.333333  5.777778  1.777778   \n",
       "4  0.429629  6.037037  7.000000  7.666666  3.444444  2.888889  4.888889   \n",
       "\n",
       "         16        17        18        19  \n",
       "0 -7.888889  7.777778  0.545635 -1.121818  \n",
       "1 -8.333333  8.444445  0.538580 -0.924817  \n",
       "2 -7.666666  7.555555  0.532628 -0.965946  \n",
       "3 -7.555555  7.777778  0.573633 -0.744272  \n",
       "4 -7.777778  7.888889  0.562919 -1.175773  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_df:pd.DataFrame = pd.read_csv(\"data/segmentation.data\", header = None)\n",
    "assert segmentation_df.isnull().sum().sum() == 0\n",
    "segmentation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 20 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       210 non-null    int8   \n",
      " 1   1       210 non-null    float64\n",
      " 2   2       210 non-null    float64\n",
      " 3   3       210 non-null    int64  \n",
      " 4   4       210 non-null    float64\n",
      " 5   5       210 non-null    float64\n",
      " 6   6       210 non-null    float64\n",
      " 7   7       210 non-null    float64\n",
      " 8   8       210 non-null    float64\n",
      " 9   9       210 non-null    float64\n",
      " 10  10      210 non-null    float64\n",
      " 11  11      210 non-null    float64\n",
      " 12  12      210 non-null    float64\n",
      " 13  13      210 non-null    float64\n",
      " 14  14      210 non-null    float64\n",
      " 15  15      210 non-null    float64\n",
      " 16  16      210 non-null    float64\n",
      " 17  17      210 non-null    float64\n",
      " 18  18      210 non-null    float64\n",
      " 19  19      210 non-null    float64\n",
      "dtypes: float64(18), int64(1), int8(1)\n",
      "memory usage: 31.5 KB\n"
     ]
    }
   ],
   "source": [
    "#Categorical encoding first column that contains text, using Label-Encoding to use for next exercise\n",
    "segmentation_df[0] = segmentation_df[0].astype('category')\n",
    "segmentation_df[0] = segmentation_df[0].cat.codes\n",
    "assert segmentation_df.isnull().sum().sum() == 0\n",
    "segmentation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercitiul 2\n",
    "2. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, precision, recall, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics), [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "from  sklearn import model_selection\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from typing import Union\n",
    "\n",
    "ClassifierModel = Union[KNeighborsClassifier, SVC, RandomForestClassifier, DecisionTreeClassifier, GaussianNB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_macro(classifier:ClassifierModel, x:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    This function prints accuracy,precision,recall,F1 score\n",
    "    :param classifier: the model classifier\n",
    "    :param x: the train dataset for the model\n",
    "    :param y: the test dataset for the model\n",
    "    \n",
    "    \"\"\"\n",
    "    scores:dict = model_selection.cross_validate(classifier, x, y,cv=5, scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], return_train_score=True)\n",
    "    train_acurracy:np.float64 = np.mean(scores['train_accuracy'])\n",
    "    print(f'Train accuracy: {train_acurracy}')\n",
    "    test_accuracy:np.float64 = np.mean(scores['test_accuracy'])\n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "    train_precision_macro:np.float64 = np.mean(scores['train_precision_macro'])\n",
    "    print(f'Train precision_macro: {train_precision_macro}')\n",
    "    test_precision_macro:np.float64 = np.mean(scores['test_precision_macro'])\n",
    "    print(f'Test precision_macro: {test_precision_macro}')\n",
    "    train_recall_macro:np.float64 = np.mean(scores['train_recall_macro'])\n",
    "    print(f'Train recall_macro: {train_recall_macro}')\n",
    "    test_recall_macro:np.float64 = np.mean(scores['test_recall_macro'])\n",
    "    print(f'Test recall_macro: {test_recall_macro}')\n",
    "    train_f1_macro:np.float64 = np.mean(scores['train_f1_macro'])\n",
    "    print(f'Train f1_macro: {train_f1_macro}')\n",
    "    test_f1_macro:np.float64 = np.mean(scores['test_f1_macro'])\n",
    "    print(f'Test f1_macro: {test_f1_macro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Glass\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9941520467836256\n",
      "Test accuracy: 0.8492801771871539\n",
      "Train precision_macro: 0.9876190476190476\n",
      "Test precision_macro: 0.8764141414141415\n",
      "Train recall_macro: 0.9828138528138528\n",
      "Test recall_macro: 0.8655555555555555\n",
      "Train f1_macro: 0.9845673595522356\n",
      "Test f1_macro: 0.8345941925252269\n"
     ]
    }
   ],
   "source": [
    "x_glass:pd.DataFrame = glass_df.iloc[:, :-1]\n",
    "y_glass:pd.Series = glass_df.iloc[:, -1]\n",
    "\n",
    "clf:sklearn.neighbors._classification.KNeighborsClassifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "scores_macro(clf, x_glass, y_glass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9532707738338093\n",
      "Test accuracy: 0.8261351052048728\n",
      "Train precision_macro: 0.7498856209150327\n",
      "Test precision_macro: 0.6862121212121212\n",
      "Train recall_macro: 0.8206060606060607\n",
      "Test recall_macro: 0.7344444444444445\n",
      "Train f1_macro: 0.7786844062706132\n",
      "Test f1_macro: 0.6871793021793022\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.tree._classes.DecisionTreeClassifier = DecisionTreeClassifier(max_depth = 5, min_samples_leaf = 15)\n",
    "scores_macro(clf,x_glass,y_glass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8188290493676051\n",
      "Test accuracy: 0.7233665559246955\n",
      "Train precision_macro: 0.4398240877945523\n",
      "Test precision_macro: 0.39947596263385743\n",
      "Train recall_macro: 0.5259367681498829\n",
      "Test recall_macro: 0.4822222222222223\n",
      "Train f1_macro: 0.47564585936863696\n",
      "Test f1_macro: 0.42316124638639846\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.svm._classes.SVC = SVC(class_weight = None, random_state = 10)\n",
    "scores_macro(clf,x_glass, y_glass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8212770297837617\n",
      "Test accuracy: 0.7332225913621262\n",
      "Train precision_macro: 0.5178516980235017\n",
      "Test precision_macro: 0.4173280423280423\n",
      "Train recall_macro: 0.5218204983422374\n",
      "Test recall_macro: 0.4644444444444445\n",
      "Train f1_macro: 0.49365948777343754\n",
      "Test f1_macro: 0.4267987167987167\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.ensemble._forest.RandomForestClassifier = RandomForestClassifier(max_depth = 5, min_samples_leaf = 15)\n",
    "scores_macro(clf,x_glass, y_glass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***GaussianNB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8948320413436692\n",
      "Test accuracy: 0.724141749723145\n",
      "Train precision_macro: 0.9311893600704595\n",
      "Test precision_macro: 0.7898060552465587\n",
      "Train recall_macro: 0.9361429217808406\n",
      "Test recall_macro: 0.724484126984127\n",
      "Train f1_macro: 0.9257393310508603\n",
      "Test f1_macro: 0.7216786328348195\n"
     ]
    }
   ],
   "source": [
    " clf:sklearn.naive_bayes.GaussianNB = GaussianNB()\n",
    "\n",
    "scores_macro(clf,x_glass, y_glass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8785714285714284\n",
      "Test accuracy: 0.7619047619047619\n",
      "Train precision_macro: 0.8989624555548925\n",
      "Test precision_macro: 0.7958039579468151\n",
      "Train recall_macro: 0.8785714285714284\n",
      "Test recall_macro: 0.7619047619047619\n",
      "Train f1_macro: 0.8795108948515061\n",
      "Test f1_macro: 0.7569531215749703\n"
     ]
    }
   ],
   "source": [
    "x_segmentation:pd.DataFrame = segmentation_df.iloc[:, 1:]\n",
    "y_segmentation:pd.Series = segmentation_df.iloc[:, 0]\n",
    "assert segmentation_df.isnull().sum().sum() == 0\n",
    "clf:sklearn.neighbors._classification.KNeighborsClassifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "scores_macro(clf, x_segmentation, y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8261904761904763\n",
      "Test accuracy: 0.8047619047619048\n",
      "Train precision_macro: 0.745250978729087\n",
      "Test precision_macro: 0.7235609628466771\n",
      "Train recall_macro: 0.8261904761904761\n",
      "Test recall_macro: 0.8047619047619048\n",
      "Train f1_macro: 0.7754520049702844\n",
      "Test f1_macro: 0.7533077073302639\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.tree._classes.DecisionTreeClassifier = DecisionTreeClassifier(max_depth = 5, min_samples_leaf = 15)\n",
    "scores_macro(clf,x_segmentation,y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SVC***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7785714285714286\n",
      "Test accuracy: 0.7380952380952381\n",
      "Train precision_macro: 0.813844405291934\n",
      "Test precision_macro: 0.7192900750043607\n",
      "Train recall_macro: 0.7785714285714286\n",
      "Test recall_macro: 0.7380952380952381\n",
      "Train f1_macro: 0.7626452253777287\n",
      "Test f1_macro: 0.7161843336279425\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.svm._classes.SVC = SVC(class_weight = None, random_state = 10)\n",
    "\n",
    "        \n",
    "scores_macro(clf,x_segmentation, y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9035714285714287\n",
      "Test accuracy: 0.8761904761904761\n",
      "Train precision_macro: 0.9090621251194199\n",
      "Test precision_macro: 0.8854761904761904\n",
      "Train recall_macro: 0.9035714285714285\n",
      "Test recall_macro: 0.8761904761904761\n",
      "Train f1_macro: 0.9001712463009082\n",
      "Test f1_macro: 0.8702716331287761\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.ensemble._forest.RandomForestClassifier = RandomForestClassifier(max_depth = 5, min_samples_leaf = 15)\n",
    "\n",
    "scores_macro(clf,x_segmentation, y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***GaussianNB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8345238095238094\n",
      "Test accuracy: 0.7714285714285716\n",
      "Train precision_macro: 0.8615450004878149\n",
      "Test precision_macro: 0.7675283446712019\n",
      "Train recall_macro: 0.8345238095238094\n",
      "Test recall_macro: 0.7714285714285715\n",
      "Train f1_macro: 0.8244809513985449\n",
      "Test f1_macro: 0.7525553018410163\n"
     ]
    }
   ],
   "source": [
    " clf:sklearn.naive_bayes.GaussianNB = GaussianNB()\n",
    "    \n",
    "scores_macro(clf,x_segmentation, y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Wine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6578197394638052\n",
      "Test accuracy: 0.39669508661482983\n",
      "Train precision_macro: 0.4928820250191551\n",
      "Test precision_macro: 0.17932900611572694\n",
      "Train recall_macro: 0.37957009300375555\n",
      "Test recall_macro: 0.17348941485041863\n",
      "Train f1_macro: 0.41172933127836453\n",
      "Test f1_macro: 0.1717784679161612\n"
     ]
    }
   ],
   "source": [
    "wine_df:pd.DataFrame = pd.read_csv(\"data/winequality-white.csv\",sep=\";\", header=None)\n",
    "wine_df:pd.DataFrame = wine_df.drop(0, axis = 0)\n",
    "x_wine:pd.DataFrame = wine_df.iloc[:, :-1]\n",
    "y_wine:pd.Series = wine_df.iloc[:, -1]\n",
    "\n",
    "clf:sklearn.neighbors._classification.KNeighborsClassifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "scores_macro(clf, x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5702844911656031\n",
      "Test accuracy: 0.5153282191323926\n",
      "Train precision_macro: 0.33832046342222216\n",
      "Test precision_macro: 0.2491534999196466\n",
      "Train recall_macro: 0.2527554581787645\n",
      "Test recall_macro: 0.2141161565667969\n",
      "Train f1_macro: 0.2601181853232906\n",
      "Test f1_macro: 0.20955234329465294\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.tree._classes.DecisionTreeClassifier = DecisionTreeClassifier(max_depth = 5, min_samples_leaf = 15)\n",
    "scores_macro(clf,x_wine,y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.455543619968476\n",
      "Test accuracy: 0.4434483333680766\n",
      "Train precision_macro: 0.25402664498736544\n",
      "Test precision_macro: 0.10734393785582164\n",
      "Train recall_macro: 0.15661869617210092\n",
      "Test recall_macro: 0.14598938507620957\n",
      "Train f1_macro: 0.12043695877122554\n",
      "Test f1_macro: 0.10425229023787745\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.svm._classes.SVC = SVC(class_weight = None, random_state = 10)\n",
    "\n",
    "        \n",
    "scores_macro(clf,x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***GaussianNB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.45411400669582525\n",
      "Test accuracy: 0.4346598986887911\n",
      "Train precision_macro: 0.36687511471487916\n",
      "Test precision_macro: 0.2553729250260153\n",
      "Train recall_macro: 0.36883415451682533\n",
      "Test recall_macro: 0.2883453601069523\n",
      "Train f1_macro: 0.3265808174582711\n",
      "Test f1_macro: 0.25222199802636813\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.naive_bayes.GaussianNB = GaussianNB()\n",
    "    \n",
    "scores_macro(clf,x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5898838409908873\n",
      "Test accuracy: 0.5202167976485793\n",
      "Train precision_macro: 0.2693971658436799\n",
      "Test precision_macro: 0.22304998755905786\n",
      "Train recall_macro: 0.23719306019856842\n",
      "Test recall_macro: 0.20500591397821832\n",
      "Train f1_macro: 0.23458094652215683\n",
      "Test f1_macro: 0.19460469450145826\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.ensemble._forest.RandomForestClassifier = RandomForestClassifier(max_depth = 5, min_samples_leaf = 15)\n",
    "\n",
    "scores_macro(clf,x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"CSM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5021562867215041\n",
      "Test accuracy: 0.26373728029602217\n",
      "Train precision_macro: 0.31879723118177933\n",
      "Test precision_macro: 0.11486820106978346\n",
      "Train recall_macro: 0.24383189367755964\n",
      "Test recall_macro: 0.12143140809807478\n",
      "Train f1_macro: 0.2446200759006818\n",
      "Test f1_macro: 0.11011675095772437\n"
     ]
    }
   ],
   "source": [
    "lines:list = list(set(range(0,13))-set([2]))\n",
    "x_csm:np.ndarray = csm_df_imp[:, lines]\n",
    "y_csm:np.ndarray = csm_df_imp[:, 2]\n",
    "y_csm=y_csm.astype('int')\n",
    "\n",
    "\n",
    "clf:sklearn.neighbors._classification.KNeighborsClassifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "scores_macro(clf, x_csm, y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4999882491186839\n",
      "Test accuracy: 0.3371877890841813\n",
      "Train precision_macro: 0.2024682720736964\n",
      "Test precision_macro: 0.1555411020199462\n",
      "Train recall_macro: 0.26385180231903277\n",
      "Test recall_macro: 0.20468445135111804\n",
      "Train f1_macro: 0.22248654479863433\n",
      "Test f1_macro: 0.1628335092040855\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.tree._classes.DecisionTreeClassifier = DecisionTreeClassifier(max_depth = 5, min_samples_leaf = 15)\n",
    "scores_macro(clf,x_csm,y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.37444770857814336\n",
      "Test accuracy: 0.35485661424606846\n",
      "Train precision_macro: 0.0811805861179447\n",
      "Test precision_macro: 0.09132759869829872\n",
      "Train recall_macro: 0.1374467972459516\n",
      "Test recall_macro: 0.1524561857895191\n",
      "Train f1_macro: 0.09888316636243455\n",
      "Test f1_macro: 0.1092041575104927\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.svm._classes.SVC = SVC(class_weight = None, random_state = 10)\n",
    "\n",
    "        \n",
    "scores_macro(clf,x_csm, y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5043478260869565\n",
      "Test accuracy: 0.36336725254394076\n",
      "Train precision_macro: 0.14059507905006657\n",
      "Test precision_macro: 0.11557248307248306\n",
      "Train recall_macro: 0.19257072356438107\n",
      "Test recall_macro: 0.1606146939480273\n",
      "Train f1_macro: 0.16148507587472719\n",
      "Test f1_macro: 0.1318468012699112\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.ensemble._forest.RandomForestClassifier = RandomForestClassifier(max_depth = 5, min_samples_leaf = 15)\n",
    "\n",
    "scores_macro(clf,x_csm, y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***GaussianNB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.2683783783783784\n",
      "Test accuracy: 0.1689176688251619\n",
      "Train precision_macro: 0.4151112736296918\n",
      "Test precision_macro: 0.15896453254347992\n",
      "Train recall_macro: 0.4523133533894633\n",
      "Test recall_macro: 0.1515678149011482\n",
      "Train f1_macro: 0.3675286974088689\n",
      "Test f1_macro: 0.10825562836977565\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.naive_bayes.GaussianNB = GaussianNB()\n",
    "    \n",
    "scores_macro(clf,x_csm, y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercitiul 3\n",
    "3. (numar de modele * numar de seturi de date * 1 punct = 20 de puncte) Raportati performanta\n",
    "fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati\n",
    "hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca\n",
    "medie a celor 5 rulari. Observatie: la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi,\n",
    "din cauza datelor utilizate pentru antrenare/validar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "def search_hiperparam(classifier:ClassifierModel, param:dict,x:pd.DataFrame,y:pd.Series):\n",
    "    \"\"\"\n",
    "    This function returns the performance for each model\n",
    "    :param classifier:the model classifier\n",
    "    :param param:the params for the classifier \n",
    "    :param x:the train dataset for the model\n",
    "    :param y:the test dataset for the model\n",
    "    \"\"\"\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5)\n",
    "    grid_search:sklearn.model_selection._search.GridSearchCV = GridSearchCV(estimator = classifier, param_grid = param, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "    \n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    y_estimated_train = grid_search.predict(x_train)\n",
    "\n",
    "    print(\"Accuracy train:\", accuracy_score(y_train, y_estimated_train))\n",
    "\n",
    "    y_estimated_test = grid_search.predict(x_test)\n",
    "    \n",
    "    print(\"Accuracy test:\", accuracy_score(y_test, y_estimated_test))\n",
    "\n",
    "    print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "    scores = cross_val_score(grid_search, x, y, cv = 4)\n",
    "    print(\"Scores accuracy:\", scores)\n",
    "    print(\"Mean accuracy:\", scores.mean())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Glass\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.9941520467836257\n",
      "Accuracy test: 0.9767441860465116\n",
      "Best parameter: {'n_neighbors': 5, 'p': 1}\n",
      "Scores accuracy: [0.68518519 1.         1.         0.62264151]\n",
      "Mean accuracy: 0.8269566736547869\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.neighbors._classification.KNeighborsClassifier=KNeighborsClassifier()\n",
    "param:dict = {'n_neighbors': list(range(5, 12)), 'p': [1, 1.5,2,2.5,3]}\n",
    "search_hiperparam(clf,param,x_glass,y_glass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.0\n",
      "Accuracy test: 0.9767441860465116\n",
      "Best parameter: {'C': 1, 'gamma': 'auto'}\n",
      "Scores accuracy: [0.68518519 0.96296296 0.96226415 0.62264151]\n",
      "Mean accuracy: 0.8082634521313767\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.svm._classes.SVC=SVC()\n",
    "param:dict={'C': list(range(1, 5)), 'gamma': ['scale', 'auto']}\n",
    "search_hiperparam(clf,param,x_glass,y_glass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.0\n",
      "Accuracy test: 1.0\n",
      "Best parameter: {'max_depth': 6, 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "Scores accuracy: [0.66666667 0.96296296 0.98113208 0.66037736]\n",
      "Mean accuracy: 0.8177847658979734\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.ensemble._forest.RandomForestClassifier=RandomForestClassifier()\n",
    "param:dict = {'n_estimators' : [15,25,50], 'max_depth' : [2,3,5,6], 'min_samples_leaf' : [1,2,13,15]}\n",
    "\n",
    "search_hiperparam(clf,param,x_glass,y_glass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***GaussianNB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.9707602339181286\n",
      "Accuracy test: 0.9534883720930233\n",
      "Best parameter: {'var_smoothing': 0.0001}\n",
      "Scores accuracy: [0.61111111 0.96296296 1.         0.75471698]\n",
      "Mean accuracy: 0.8321977638015374\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.naive_bayes.GaussianNB=GaussianNB()\n",
    "param:dict = {'var_smoothing' : [1e-4,5e-6,1e-9]}\n",
    "\n",
    "search_hiperparam(clf,param,x_glass,y_glass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.0\n",
      "Accuracy test: 1.0\n",
      "Best parameter: {'max_depth': 7, 'max_leaf_nodes': 25}\n",
      "Scores accuracy: [0.62962963 1.         1.         0.60377358]\n",
      "Mean accuracy: 0.8083508036338225\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.tree._classes.DecisionTreeClassifier = DecisionTreeClassifier()\n",
    "\n",
    "param:dict = {'max_depth': [5, 6, 7, 8, 9] ,'max_leaf_nodes': [5, 10, 15, 20, 25]}\n",
    "\n",
    "search_hiperparam(clf,param,x_glass,y_glass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.8928571428571429\n",
      "Accuracy test: 0.8095238095238095\n",
      "Best parameter: {'n_neighbors': 5, 'p': 1}\n",
      "Scores accuracy: [0.83018868 0.73584906 0.82692308 0.84615385]\n",
      "Mean accuracy: 0.809778664731495\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.neighbors._classification.KNeighborsClassifier=KNeighborsClassifier()\n",
    "param :dict= {'n_neighbors': list(range(5, 12)), 'p': [1, 1.5,2,2.5,3]}\n",
    "search_hiperparam(clf,param,x_segmentation,y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.8273809523809523\n",
      "Accuracy test: 0.7857142857142857\n",
      "Best parameter: {'C': 4, 'gamma': 'scale'}\n",
      "Scores accuracy: [0.81132075 0.81132075 0.76923077 0.84615385]\n",
      "Mean accuracy: 0.8095065312046444\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.svm._classes.SVC=SVC()\n",
    "param:dict={'C': list(range(1, 5)), 'gamma': ['scale', 'auto']}\n",
    "search_hiperparam(clf,param,x_segmentation,y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.9761904761904762\n",
      "Accuracy test: 0.9047619047619048\n",
      "Best parameter: {'max_depth': 6, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "Scores accuracy: [0.9245283  0.9245283  0.88461538 0.94230769]\n",
      "Mean accuracy: 0.9189949201741654\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.ensemble._forest.RandomForestClassifier=RandomForestClassifier()\n",
    "param:dict = {'n_estimators' : [15,25,50], 'max_depth' : [2,3,5,6], 'min_samples_leaf' : [1,2,13,15]}\n",
    "\n",
    "search_hiperparam(clf,param,x_segmentation,y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***GaussianNB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.7738095238095238\n",
      "Accuracy test: 0.8333333333333334\n",
      "Best parameter: {'var_smoothing': 0.0001}\n",
      "Scores accuracy: [0.77358491 0.81132075 0.76923077 0.76923077]\n",
      "Mean accuracy: 0.7808417997097242\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.naive_bayes.GaussianNB=GaussianNB()\n",
    "param:dict = {'var_smoothing' : [1e-4,5e-6,1e-9]}\n",
    "\n",
    "search_hiperparam(clf,param,x_segmentation,y_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.9821428571428571\n",
      "Accuracy test: 0.7857142857142857\n",
      "Best parameter: {'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "Scores accuracy: [0.83018868 0.81132075 0.82692308 0.94230769]\n",
      "Mean accuracy: 0.8526850507982584\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.tree._classes.DecisionTreeClassifier = DecisionTreeClassifier()\n",
    "param:dict = {'max_depth': [5, 6, 7, 8, 9] ,'max_leaf_nodes': [5, 10, 15, 20, 25]}\n",
    "\n",
    "search_hiperparam(clf,param,x_segmentation,y_segmentation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Wine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.0\n",
      "Accuracy test: 0.6010204081632653\n",
      "Best parameter: {'n_neighbors': 1, 'p': 1}\n",
      "Scores accuracy: [0.37714286 0.36734694 0.43627451 0.39787582]\n",
      "Mean accuracy: 0.39466003067893823\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.neighbors._classification.KNeighborsClassifier=KNeighborsClassifier()\n",
    "param:dict = {'n_neighbors': list(range(1, 4)), 'p': [1, 1.5,3]}\n",
    "search_hiperparam(clf,param,x_wine,y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.9109239407861154\n",
      "Accuracy test: 0.5938775510204082\n",
      "Best parameter: {'C': 2, 'gamma': 'auto'}\n",
      "Scores accuracy: [0.42938776 0.42204082 0.44852941 0.44117647]\n",
      "Mean accuracy: 0.43528361344537814\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.svm._classes.SVC=SVC()\n",
    "param:dict={'C': list(range(1, 3)), 'gamma': ['scale', 'auto']}\n",
    "search_hiperparam(clf,param,x_wine,y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.6245533435426238\n",
      "Accuracy test: 0.5918367346938775\n",
      "Best parameter: {'max_depth': 6, 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "Scores accuracy: [0.4955102  0.51510204 0.55392157 0.54738562]\n",
      "Mean accuracy: 0.5279798586101108\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.ensemble._forest.RandomForestClassifier=RandomForestClassifier()\n",
    "param:dict = {'n_estimators' : [15,25,50], 'max_depth' : [2,3,5,6], 'min_samples_leaf' : [1,2,13,15]}\n",
    "\n",
    "search_hiperparam(clf,param,x_wine,y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***GaussianNB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.4920877998979071\n",
      "Accuracy test: 0.4897959183673469\n",
      "Best parameter: {'var_smoothing': 5e-06}\n",
      "Scores accuracy: [0.45714286 0.47265306 0.50898693 0.44281046]\n",
      "Mean accuracy: 0.4703983259970655\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.naive_bayes.GaussianNB=GaussianNB()\n",
    "param:dict = {'var_smoothing' : [1e-4,5e-6,1e-9]}\n",
    "\n",
    "search_hiperparam(clf,param,x_wine,y_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5691679428279734\n",
      "Accuracy test: 0.539795918367347\n",
      "Best parameter: {'max_depth': 7, 'max_leaf_nodes': 25}\n",
      "Scores accuracy: [0.48408163 0.50122449 0.53349673 0.52205882]\n",
      "Mean accuracy: 0.5102154195011338\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.tree._classes.DecisionTreeClassifier = DecisionTreeClassifier()\n",
    "param:dict = {'max_depth': [5, 6, 7, 8, 9] ,'max_leaf_nodes': [5, 10, 15, 20, 25]}\n",
    "\n",
    "search_hiperparam(clf,param,x_wine,y_wine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"CSM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5543478260869565\n",
      "Accuracy test: 0.2765957446808511\n",
      "Best parameter: {'n_neighbors': 3, 'p': 3}\n",
      "Scores accuracy: [0.39655172 0.22413793 0.39655172 0.35087719]\n",
      "Mean accuracy: 0.3420296430732002\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.neighbors._classification.KNeighborsClassifier=KNeighborsClassifier()\n",
    "param:dict = {'n_neighbors': list(range(2, 4)), 'p': [1, 1.5,3]}\n",
    "search_hiperparam(clf,param,x_csm,y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.375\n",
      "Accuracy test: 0.3404255319148936\n",
      "Best parameter: {'C': 1, 'gamma': 'scale'}\n",
      "Scores accuracy: [0.36206897 0.32758621 0.36206897 0.26315789]\n",
      "Mean accuracy: 0.3287205081669691\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.svm._classes.SVC=SVC()\n",
    "param:dict={'C': list(range(1, 3)), 'gamma': ['scale', 'auto']}\n",
    "search_hiperparam(clf,param,x_csm,y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5054347826086957\n",
      "Accuracy test: 0.3829787234042553\n",
      "Best parameter: {'max_depth': 5, 'min_samples_leaf': 15, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "clf:sklearn.ensemble._forest.RandomForestClassifier=RandomForestClassifier()\n",
    "param:dict = {'n_estimators' : [15,25,50], 'max_depth' : [2,3,5,6], 'min_samples_leaf' : [1,2,13,15]}\n",
    "\n",
    "search_hiperparam(clf,param,x_csm,y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***GaussianNB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf:sklearn.naive_bayes.GaussianNB=GaussianNB()\n",
    "param :dict= {'var_smoothing' : [1e-4,5e-6,1e-9]}\n",
    "\n",
    "search_hiperparam(clf,param,x_csm,y_csm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf:sklearn.tree._classes.DecisionTreeClassifier = DecisionTreeClassifier()\n",
    "param:dict = {'max_depth': [5, 6, 7, 8, 9] ,'max_leaf_nodes': [5, 10, 15, 20, 25]}\n",
    "\n",
    "search_hiperparam(clf,param,x_csm,y_csm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN este un model de clasificare si regresie din categoria Case Based Reasoning, un stil de lucru in care deciziile se iau pe baza cautarii intr-o baza de experiente anterioare inregistrate. \n",
    "\n",
    "Algoritmul nu construieste propriu--zis un model. El memoreaza cazurile cunoscute, iar pentru o situatie la care se cere raspuns (clasificare sau regresie) gaseste cele mai apropiate $k$ cazuri si formuleaza raspunsul prin combinarea raspunsurilor de la acestea. Modelul este neparametric: raspunsul nu depinde de vreo presupunere apriorica asupra modului in care raspunsul este format, ci este dat de continutul bazei de cunostinte -- si desigur influentat de numarul de vecini considerati ($k$) si de modul de calcul al distantei.\n",
    "\n",
    "Instruirea propriu-zisa lipseste (include cel mult utilizarea unei structuri de date eficiente de tipul [k-d tree](https://en.wikipedia.org/wiki/K-d_tree), [ball tree](https://en.wikipedia.org/wiki/Ball_tree) pentru structurarea bazei de cunostinte si facilitarea unei cautari rapide). Antrenarea este deci rapida. Pe de alta parte, kNN necesita memorie in cantitate proportionala cu baza de cunostinte utilizata, iar inferenta poate fi lenta, fiind dominata de costul de cautare. \n",
    "\n",
    "Pentru clasificare, principiul de lucru este simplu:\n",
    "1. se gasesc cei mai apropiati $k$ vecini fata de cazul pentru care se solicita clasificarea\n",
    "1. se gaseste clasa majoritara si se considera ca elementul nou face parte din aceasta clasa\n",
    "\n",
    "![GNB](images/KNN.png)\n",
    "\n",
    "Exemplu de clasificare k-NN. Eantionul de testare (cerc interior) trebuie clasificat fie n prima clas de ptrate albastre, fie n a doua clas de triunghiuri roii. Dac k = 3 (cerc exterior) este alocat clasei a doua deoarece exist 2 triunghiuri i doar 1 ptrat n interiorul cercului interior. Dac, de exemplu, k = 5 este atribuit primei clase (3 ptrate vs. 2 triunghiuri n afara cercului exterior).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest algoritm apartine familiei algoritmilor de invatare supravegheati. Poate fi folosit pentru a rezolva atat probleme de clasificare, cat si de regresie. Scopul utilizarii acestui algoritm este crearea unui model de instruire care poate folosi pentru a prezice clasa sau valoarea variabilei tinta reguli simple de decizie deduse din date anterioare(training data).\n",
    "\n",
    "##### Cuvinte cheie\n",
    "- ***Nod radacina*** -reprezinta intregul set de date(sau sample), ce urmeaza sa fie impartit in doua sau mai multe seturi omogene\n",
    "- ***Splitting(Impartire/Despicare)*** -procesul de impartire al unui nod in doua sau mai multe sub-noduri\n",
    "- ***Nod de decizie*** -cand un sub-nod se imparte mai departe in alte sub-noduri este numit un nod de decizie\n",
    "- ***Frunza/Nod terminal*** -nodurile care nu se mai impart\n",
    "- ***Tundere(Prunning)*** -cand indepartam un sub-nod de un nod de decizie, procesul invers pentru splitting\n",
    "- ***Ramura/Subarbore*** -o subsecventa din intregul arbore\n",
    "- ***Nod parinte/copil*** -un nod care se imparte in sub-noduri este numit nodul parinte pentru acestea, iar sub-nodurile sunt nodurile copii pentru parinte\n",
    "![decisionTree](images/decisionTree.png)\n",
    "Arborii decizionali clasifica exemplele sortandu-le intr-un arbore de la radacina catre o anumita frunza/nod terminal, frunza fiind cea care indica si clasificarea pentru exemplu. Fiecare nod din arbore actioneaza ca un caz de testare pentru un atribut anume, iar fiecare muchie ce coboara din nod corespunde raspunsurilor posibile la acest caz. Acest proces este recursiv in natura si se repeta pentru fiecare subarbore atasat noului nod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padurea de arbori decizionali este un algoritm de invatare supravegheat. Poate fi folosit atat pentru probleme de clasificare, cat si pentru cele de regresie. \"Padurea\" pe care o construieste este un ansamblu de arbori decizionali(Decision Trees) antrenati de obicei cu metoda \"ambalarii\". Ideea generala a acestei metode este ca o combinatie de modele de invatare imbunatateste rezultatul final.\n",
    "\n",
    "- Pe scurt, padurea de arbori decizionali construieste mai multi arbori decizionali si ii combina pentru a obtine o predictie mai exacta si mai stabila\n",
    "\n",
    "![randomForest](images/randomForest.jpeg)\n",
    "\n",
    "Corelatia scazuta dintre modele este cheia. Motivul pentru care aceste predictii sunt mai precise/stabile este ca arborii se protejeaza unul pe altul de erori individuale(atata timp cat nu dau eroare toate in mod constant, in aceeasi directie). In timp ce unii arbori pot avea valori gresite, multi altii vor fi corecti, deci, ca grup, arborii pot merge in directia corecta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes este o tehnica de clasificare bazata pe teorema Bayes. este simplu, dar puternic, are o acuratete mai buna si este mai rapid cand avem seturi de date mari.\n",
    "Gaussian Naive Bayes este o varianta pentru Naive Bayes care suport valori continue si presupune ca fiecare clasa este normal distribuita, iar predictorii ar trebui sa fie independenti unii de altii.\n",
    "\n",
    "###### Pasii algoritmului:\n",
    "- Calculez probabilitatea anterioara pentru etichetele de clasa date\n",
    "- Creez un tabel de frecvente din datele istorice date\n",
    "- Gasesc \"likelihood probability\" cu fiecare atribut al fiecarei clase\n",
    "- Pun aceste valori in formula Bayes si calculez probabilitatea posterioara\n",
    "- Clasa cu cea mai mare probabilitate va fi rezultatul\n",
    "\n",
    "###### Formula Bayes:\n",
    "\n",
    "![GNB](images/GNB.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-Support Vector Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC este o clasa capabila sa efectueze clasificarea binaria si multi-clasa pe un set de date. Este similara ca si metoda cu NuSVC, dar accepta ca si parametri seturi de date putin diferite si au formulari matematice diferite.\n",
    "\n",
    "SVC primeste ca si input 2 array-uri: un array x de forma(n_samples,n_features) ce contine datele de antrenare si un array y de etichete de clasa(string-uri sau integer), de forma (n_samples).\n",
    "\n",
    "Implementarea se bazeaz pe libsvm. Timpul de potrivire este cel puin cvadrat cu numrul de probe i poate fi nepractic in momentul in care avem de a face cu zeci de mii de probe.\n",
    "\n",
    "![GNB](images/svc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
