{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "#Number of epochs for training\n",
    "n_epochs = 1000\n",
    "\n",
    "#Batch size\n",
    "size_batch = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.data = []\n",
    "        for img_path in glob.glob(img_dir + \"\\\\*.png\"):\n",
    "            self.data.append(img_path)\n",
    "        #print(self.data)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        image = torchvision.transforms.functional.to_tensor(Image.open(img_path))\n",
    "        #label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        label = np.float32(1)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = CustomImageDataset(img_dir = \"C:\\\\Users\\\\bocir\\\\OneDrive\\\\Desktop\\\\FaceGen\\\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(images, batch_size = size_batch, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([3, 64, 64])\n",
      "shape: torch.Size([3, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2533603f160>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features,_ = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features[0].size()}\")\n",
    "img = train_features[0]\n",
    "print(f\"shape: {img.size()}\")\n",
    "plt.imshow(np.swapaxes(np.swapaxes(img,0,2), 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nc, nz, ngf, ndf):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False)\n",
    "        self.n1 = nn.BatchNorm2d(ngf * 8)\n",
    "        self.conv2 = nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False)\n",
    "        self.n2 = nn.BatchNorm2d(ngf * 4)\n",
    "        self.conv3 = nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False)\n",
    "        self.n3 = nn.BatchNorm2d(ngf * 2)\n",
    "        self.conv4 = nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False)\n",
    "        self.n4 = nn.BatchNorm2d(ngf)\n",
    "        self.conv5 = nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv1(input)\n",
    "        out = self.n1(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.n2(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.n3(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.n4(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.conv5(out)\n",
    "        out = torch.tanh(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, nz, ngf, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)\n",
    "        self.n1 = nn.BatchNorm2d(ndf)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False)\n",
    "        self.n2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)\n",
    "        self.n3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False)\n",
    "        self.n4 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv1(input)\n",
    "        out = self.n1(out)\n",
    "        out = torch.nn.functional.leaky_relu(out, negative_slope=0.02, inplace=True)\n",
    "        out = self.conv2(out)\n",
    "        out = self.n2(out)\n",
    "        out = torch.nn.functional.leaky_relu(out, negative_slope=0.02, inplace=True)\n",
    "        out = self.conv3(out)\n",
    "        out = self.n3(out)\n",
    "        out = torch.nn.functional.leaky_relu(out, negative_slope=0.02, inplace=True)\n",
    "        out = self.conv4(out)\n",
    "        out = self.n4(out)\n",
    "        out = torch.nn.functional.leaky_relu(out, negative_slope=0.02, inplace=True)\n",
    "        out = self.conv5(out)\n",
    "        out = out.flatten()\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator(nc, nz, ngf, ndf)\n",
    "discriminator = Discriminator(nc, nz, ngf, ndf)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    \n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] [Batch 1/168] [D loss: 0.719225] [G loss: 0.594319]\n",
      "[Epoch 1/1000] [Batch 2/168] [D loss: 0.277438] [G loss: 1.076481]\n",
      "[Epoch 1/1000] [Batch 3/168] [D loss: 0.105770] [G loss: 2.568651]\n",
      "[Epoch 1/1000] [Batch 4/168] [D loss: 0.083934] [G loss: 2.402549]\n",
      "[Epoch 1/1000] [Batch 5/168] [D loss: 0.081998] [G loss: 2.287095]\n",
      "[Epoch 1/1000] [Batch 6/168] [D loss: 0.051459] [G loss: 2.779640]\n",
      "[Epoch 1/1000] [Batch 7/168] [D loss: 0.038084] [G loss: 3.355242]\n",
      "[Epoch 1/1000] [Batch 8/168] [D loss: 0.036719] [G loss: 3.202805]\n",
      "[Epoch 1/1000] [Batch 9/168] [D loss: 0.036863] [G loss: 3.475117]\n",
      "[Epoch 1/1000] [Batch 10/168] [D loss: 0.033714] [G loss: 3.635511]\n",
      "[Epoch 1/1000] [Batch 11/168] [D loss: 0.037793] [G loss: 3.591434]\n",
      "[Epoch 1/1000] [Batch 12/168] [D loss: 0.018531] [G loss: 3.811962]\n",
      "[Epoch 1/1000] [Batch 13/168] [D loss: 0.021400] [G loss: 3.745579]\n",
      "[Epoch 1/1000] [Batch 14/168] [D loss: 0.014514] [G loss: 3.990607]\n",
      "[Epoch 1/1000] [Batch 15/168] [D loss: 0.012624] [G loss: 4.183094]\n",
      "[Epoch 1/1000] [Batch 16/168] [D loss: 0.024295] [G loss: 3.626864]\n",
      "[Epoch 1/1000] [Batch 17/168] [D loss: 0.012326] [G loss: 4.849428]\n",
      "[Epoch 1/1000] [Batch 18/168] [D loss: 0.020143] [G loss: 3.703236]\n",
      "[Epoch 1/1000] [Batch 19/168] [D loss: 0.009570] [G loss: 5.312233]\n",
      "[Epoch 1/1000] [Batch 20/168] [D loss: 0.014552] [G loss: 4.085047]\n",
      "[Epoch 1/1000] [Batch 21/168] [D loss: 0.007520] [G loss: 5.124920]\n",
      "[Epoch 1/1000] [Batch 22/168] [D loss: 0.010788] [G loss: 4.279503]\n",
      "[Epoch 1/1000] [Batch 23/168] [D loss: 0.006930] [G loss: 4.968753]\n",
      "[Epoch 1/1000] [Batch 24/168] [D loss: 0.008545] [G loss: 4.387404]\n",
      "[Epoch 1/1000] [Batch 25/168] [D loss: 0.009221] [G loss: 5.169674]\n",
      "[Epoch 1/1000] [Batch 26/168] [D loss: 0.015934] [G loss: 3.885723]\n",
      "[Epoch 1/1000] [Batch 27/168] [D loss: 0.007247] [G loss: 6.775916]\n",
      "[Epoch 1/1000] [Batch 28/168] [D loss: 0.006399] [G loss: 5.033081]\n",
      "[Epoch 1/1000] [Batch 29/168] [D loss: 0.014947] [G loss: 3.760090]\n",
      "[Epoch 1/1000] [Batch 30/168] [D loss: 0.004561] [G loss: 8.425373]\n",
      "[Epoch 1/1000] [Batch 31/168] [D loss: 0.007130] [G loss: 7.216871]\n",
      "[Epoch 1/1000] [Batch 32/168] [D loss: 0.016592] [G loss: 4.008258]\n",
      "[Epoch 1/1000] [Batch 33/168] [D loss: 0.002350] [G loss: 6.667220]\n",
      "[Epoch 1/1000] [Batch 34/168] [D loss: 0.005110] [G loss: 4.899378]\n",
      "[Epoch 1/1000] [Batch 35/168] [D loss: 0.011281] [G loss: 4.373299]\n",
      "[Epoch 1/1000] [Batch 36/168] [D loss: 0.004108] [G loss: 6.437482]\n",
      "[Epoch 1/1000] [Batch 37/168] [D loss: 0.011893] [G loss: 4.373932]\n",
      "[Epoch 1/1000] [Batch 38/168] [D loss: 0.003406] [G loss: 6.075392]\n",
      "[Epoch 1/1000] [Batch 39/168] [D loss: 0.007825] [G loss: 4.672293]\n",
      "[Epoch 1/1000] [Batch 40/168] [D loss: 0.011160] [G loss: 5.790706]\n",
      "[Epoch 1/1000] [Batch 41/168] [D loss: 0.012546] [G loss: 3.898460]\n",
      "[Epoch 1/1000] [Batch 42/168] [D loss: 0.007072] [G loss: 9.627488]\n",
      "[Epoch 1/1000] [Batch 43/168] [D loss: 0.001668] [G loss: 7.993738]\n",
      "[Epoch 1/1000] [Batch 44/168] [D loss: 0.007286] [G loss: 4.460588]\n",
      "[Epoch 1/1000] [Batch 45/168] [D loss: 0.003619] [G loss: 6.019974]\n",
      "[Epoch 1/1000] [Batch 46/168] [D loss: 0.007123] [G loss: 4.722393]\n",
      "[Epoch 1/1000] [Batch 47/168] [D loss: 0.013284] [G loss: 5.454844]\n",
      "[Epoch 1/1000] [Batch 48/168] [D loss: 0.012160] [G loss: 3.887205]\n",
      "[Epoch 1/1000] [Batch 49/168] [D loss: 0.005360] [G loss: 10.595796]\n",
      "[Epoch 1/1000] [Batch 50/168] [D loss: 0.003732] [G loss: 9.530980]\n",
      "[Epoch 1/1000] [Batch 51/168] [D loss: 0.003023] [G loss: 6.228595]\n",
      "[Epoch 1/1000] [Batch 52/168] [D loss: 0.052203] [G loss: 2.409130]\n",
      "[Epoch 1/1000] [Batch 53/168] [D loss: 0.116462] [G loss: 18.411402]\n",
      "[Epoch 1/1000] [Batch 54/168] [D loss: 0.000010] [G loss: 16.446335]\n",
      "[Epoch 1/1000] [Batch 55/168] [D loss: 0.000006] [G loss: 11.997612]\n",
      "[Epoch 1/1000] [Batch 56/168] [D loss: 0.008171] [G loss: 4.341611]\n",
      "[Epoch 1/1000] [Batch 57/168] [D loss: 0.572261] [G loss: 0.478692]\n",
      "[Epoch 1/1000] [Batch 58/168] [D loss: 0.000166] [G loss: 20.343138]\n",
      "[Epoch 1/1000] [Batch 59/168] [D loss: 0.025928] [G loss: 21.183376]\n",
      "[Epoch 1/1000] [Batch 60/168] [D loss: 0.153923] [G loss: 21.005671]\n",
      "[Epoch 1/1000] [Batch 61/168] [D loss: 0.000157] [G loss: 20.049120]\n",
      "[Epoch 1/1000] [Batch 62/168] [D loss: 0.000025] [G loss: 19.221045]\n",
      "[Epoch 1/1000] [Batch 63/168] [D loss: 0.000008] [G loss: 18.471449]\n",
      "[Epoch 1/1000] [Batch 64/168] [D loss: 0.000015] [G loss: 17.718004]\n",
      "[Epoch 1/1000] [Batch 65/168] [D loss: 0.000006] [G loss: 16.905685]\n",
      "[Epoch 1/1000] [Batch 66/168] [D loss: 0.000004] [G loss: 15.944702]\n",
      "[Epoch 1/1000] [Batch 67/168] [D loss: 0.000004] [G loss: 14.708844]\n",
      "[Epoch 1/1000] [Batch 68/168] [D loss: 0.000005] [G loss: 13.102083]\n",
      "[Epoch 1/1000] [Batch 69/168] [D loss: 0.000017] [G loss: 10.916899]\n",
      "[Epoch 1/1000] [Batch 70/168] [D loss: 0.000214] [G loss: 7.827740]\n",
      "[Epoch 1/1000] [Batch 71/168] [D loss: 0.033810] [G loss: 2.892753]\n",
      "[Epoch 1/1000] [Batch 72/168] [D loss: 0.002459] [G loss: 5.422447]\n",
      "[Epoch 1/1000] [Batch 73/168] [D loss: 1.313783] [G loss: 0.084629]\n",
      "[Epoch 1/1000] [Batch 74/168] [D loss: 0.081462] [G loss: 20.971195]\n",
      "[Epoch 1/1000] [Batch 75/168] [D loss: 0.696000] [G loss: 21.337679]\n",
      "[Epoch 1/1000] [Batch 76/168] [D loss: 0.000123] [G loss: 19.939129]\n",
      "[Epoch 1/1000] [Batch 77/168] [D loss: 0.000025] [G loss: 18.903023]\n",
      "[Epoch 1/1000] [Batch 78/168] [D loss: 0.000023] [G loss: 18.026316]\n",
      "[Epoch 1/1000] [Batch 79/168] [D loss: 0.000010] [G loss: 17.173237]\n",
      "[Epoch 1/1000] [Batch 80/168] [D loss: 0.000009] [G loss: 16.274210]\n",
      "[Epoch 1/1000] [Batch 81/168] [D loss: 0.000020] [G loss: 15.182286]\n",
      "[Epoch 1/1000] [Batch 82/168] [D loss: 0.000026] [G loss: 13.686827]\n",
      "[Epoch 1/1000] [Batch 83/168] [D loss: 0.000014] [G loss: 11.615700]\n",
      "[Epoch 1/1000] [Batch 84/168] [D loss: 0.000114] [G loss: 8.508318]\n",
      "[Epoch 1/1000] [Batch 85/168] [D loss: 0.029667] [G loss: 2.883607]\n",
      "[Epoch 1/1000] [Batch 86/168] [D loss: 0.742984] [G loss: 0.267404]\n",
      "[Epoch 1/1000] [Batch 87/168] [D loss: 0.000371] [G loss: 18.588596]\n",
      "[Epoch 1/1000] [Batch 88/168] [D loss: 0.001448] [G loss: 19.565815]\n",
      "[Epoch 1/1000] [Batch 89/168] [D loss: 0.003013] [G loss: 19.471060]\n",
      "[Epoch 1/1000] [Batch 90/168] [D loss: 0.008944] [G loss: 19.082891]\n",
      "[Epoch 1/1000] [Batch 91/168] [D loss: 0.012444] [G loss: 18.548143]\n",
      "[Epoch 1/1000] [Batch 92/168] [D loss: 0.016605] [G loss: 17.865995]\n",
      "[Epoch 1/1000] [Batch 93/168] [D loss: 0.013096] [G loss: 17.058975]\n",
      "[Epoch 1/1000] [Batch 94/168] [D loss: 0.001445] [G loss: 16.198801]\n",
      "[Epoch 1/1000] [Batch 95/168] [D loss: 0.002248] [G loss: 15.135918]\n",
      "[Epoch 1/1000] [Batch 96/168] [D loss: 0.001970] [G loss: 13.722844]\n",
      "[Epoch 1/1000] [Batch 97/168] [D loss: 0.001247] [G loss: 11.362305]\n",
      "[Epoch 1/1000] [Batch 98/168] [D loss: 0.005265] [G loss: 5.162732]\n",
      "[Epoch 1/1000] [Batch 99/168] [D loss: 1.375070] [G loss: 0.070759]\n",
      "[Epoch 1/1000] [Batch 100/168] [D loss: 0.175119] [G loss: 19.114771]\n",
      "[Epoch 1/1000] [Batch 101/168] [D loss: 0.133834] [G loss: 19.496609]\n",
      "[Epoch 1/1000] [Batch 102/168] [D loss: 0.032007] [G loss: 18.297121]\n",
      "[Epoch 1/1000] [Batch 103/168] [D loss: 0.005479] [G loss: 16.411476]\n",
      "[Epoch 1/1000] [Batch 104/168] [D loss: 0.003954] [G loss: 13.942577]\n",
      "[Epoch 1/1000] [Batch 105/168] [D loss: 0.005297] [G loss: 11.514325]\n",
      "[Epoch 1/1000] [Batch 106/168] [D loss: 0.001656] [G loss: 8.682788]\n",
      "[Epoch 1/1000] [Batch 107/168] [D loss: 0.003189] [G loss: 5.392215]\n",
      "[Epoch 1/1000] [Batch 108/168] [D loss: 0.188642] [G loss: 1.178839]\n",
      "[Epoch 1/1000] [Batch 109/168] [D loss: 0.006874] [G loss: 8.420483]\n",
      "[Epoch 1/1000] [Batch 110/168] [D loss: 0.046019] [G loss: 7.819188]\n",
      "[Epoch 1/1000] [Batch 111/168] [D loss: 0.085205] [G loss: 2.246198]\n",
      "[Epoch 1/1000] [Batch 112/168] [D loss: 0.109085] [G loss: 2.375546]\n",
      "[Epoch 1/1000] [Batch 113/168] [D loss: 0.079366] [G loss: 3.817840]\n",
      "[Epoch 1/1000] [Batch 114/168] [D loss: 0.182800] [G loss: 1.397042]\n",
      "[Epoch 1/1000] [Batch 115/168] [D loss: 0.174098] [G loss: 9.527213]\n",
      "[Epoch 1/1000] [Batch 116/168] [D loss: 0.045755] [G loss: 5.224887]\n",
      "[Epoch 1/1000] [Batch 117/168] [D loss: 0.874896] [G loss: 0.204455]\n",
      "[Epoch 1/1000] [Batch 118/168] [D loss: 1.453102] [G loss: 17.553368]\n",
      "[Epoch 1/1000] [Batch 119/168] [D loss: 0.041378] [G loss: 14.698474]\n",
      "[Epoch 1/1000] [Batch 120/168] [D loss: 0.003104] [G loss: 10.518147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] [Batch 121/168] [D loss: 0.003288] [G loss: 5.337857]\n",
      "[Epoch 1/1000] [Batch 122/168] [D loss: 0.735351] [G loss: 0.266258]\n",
      "[Epoch 1/1000] [Batch 123/168] [D loss: 0.070790] [G loss: 10.514451]\n",
      "[Epoch 1/1000] [Batch 124/168] [D loss: 0.190505] [G loss: 10.558645]\n",
      "[Epoch 1/1000] [Batch 125/168] [D loss: 0.072269] [G loss: 7.755351]\n",
      "[Epoch 1/1000] [Batch 126/168] [D loss: 0.065154] [G loss: 3.118405]\n",
      "[Epoch 1/1000] [Batch 127/168] [D loss: 0.845532] [G loss: 0.225566]\n",
      "[Epoch 1/1000] [Batch 128/168] [D loss: 0.945598] [G loss: 11.585881]\n",
      "[Epoch 1/1000] [Batch 129/168] [D loss: 0.222193] [G loss: 9.528223]\n",
      "[Epoch 1/1000] [Batch 130/168] [D loss: 0.018423] [G loss: 5.622384]\n",
      "[Epoch 1/1000] [Batch 131/168] [D loss: 0.226569] [G loss: 1.065726]\n",
      "[Epoch 1/1000] [Batch 132/168] [D loss: 0.033197] [G loss: 3.630134]\n",
      "[Epoch 1/1000] [Batch 133/168] [D loss: 0.078145] [G loss: 2.387159]\n",
      "[Epoch 1/1000] [Batch 134/168] [D loss: 0.275407] [G loss: 1.091338]\n",
      "[Epoch 1/1000] [Batch 135/168] [D loss: 0.346618] [G loss: 5.781466]\n",
      "[Epoch 1/1000] [Batch 136/168] [D loss: 0.237670] [G loss: 1.870899]\n",
      "[Epoch 1/1000] [Batch 137/168] [D loss: 0.676299] [G loss: 0.409091]\n",
      "[Epoch 1/1000] [Batch 138/168] [D loss: 1.623232] [G loss: 12.017197]\n",
      "[Epoch 1/1000] [Batch 139/168] [D loss: 0.114151] [G loss: 7.182877]\n",
      "[Epoch 1/1000] [Batch 140/168] [D loss: 0.249330] [G loss: 0.981148]\n",
      "[Epoch 1/1000] [Batch 141/168] [D loss: 0.042742] [G loss: 3.656038]\n",
      "[Epoch 1/1000] [Batch 142/168] [D loss: 0.118804] [G loss: 2.247197]\n",
      "[Epoch 1/1000] [Batch 143/168] [D loss: 0.303022] [G loss: 1.044011]\n",
      "[Epoch 1/1000] [Batch 144/168] [D loss: 0.379728] [G loss: 6.415455]\n",
      "[Epoch 1/1000] [Batch 145/168] [D loss: 0.138377] [G loss: 2.247139]\n",
      "[Epoch 1/1000] [Batch 146/168] [D loss: 0.656448] [G loss: 0.378423]\n",
      "[Epoch 1/1000] [Batch 147/168] [D loss: 1.066896] [G loss: 12.751934]\n",
      "[Epoch 1/1000] [Batch 148/168] [D loss: 0.163814] [G loss: 8.764889]\n",
      "[Epoch 1/1000] [Batch 149/168] [D loss: 0.052100] [G loss: 2.608633]\n",
      "[Epoch 1/1000] [Batch 150/168] [D loss: 1.103501] [G loss: 0.121194]\n",
      "[Epoch 1/1000] [Batch 151/168] [D loss: 0.298631] [G loss: 9.029827]\n",
      "[Epoch 1/1000] [Batch 152/168] [D loss: 0.375030] [G loss: 9.342925]\n",
      "[Epoch 1/1000] [Batch 153/168] [D loss: 0.050926] [G loss: 6.600711]\n",
      "[Epoch 1/1000] [Batch 154/168] [D loss: 0.031767] [G loss: 3.720841]\n",
      "[Epoch 1/1000] [Batch 155/168] [D loss: 0.232203] [G loss: 1.027297]\n",
      "[Epoch 1/1000] [Batch 156/168] [D loss: 0.035832] [G loss: 3.424246]\n",
      "[Epoch 1/1000] [Batch 157/168] [D loss: 0.077726] [G loss: 2.739867]\n",
      "[Epoch 1/1000] [Batch 158/168] [D loss: 0.341573] [G loss: 0.888509]\n",
      "[Epoch 1/1000] [Batch 159/168] [D loss: 0.451400] [G loss: 7.092372]\n",
      "[Epoch 1/1000] [Batch 160/168] [D loss: 0.138736] [G loss: 4.202277]\n",
      "[Epoch 1/1000] [Batch 161/168] [D loss: 1.115586] [G loss: 0.124942]\n",
      "[Epoch 1/1000] [Batch 162/168] [D loss: 0.869583] [G loss: 15.168289]\n",
      "[Epoch 1/1000] [Batch 163/168] [D loss: 0.309383] [G loss: 12.275190]\n",
      "[Epoch 1/1000] [Batch 164/168] [D loss: 0.045357] [G loss: 7.124899]\n",
      "[Epoch 1/1000] [Batch 165/168] [D loss: 0.098640] [G loss: 1.869653]\n",
      "[Epoch 1/1000] [Batch 166/168] [D loss: 0.494048] [G loss: 0.500699]\n",
      "[Epoch 1/1000] [Batch 167/168] [D loss: 0.138741] [G loss: 5.940521]\n",
      "[Epoch 1/1000] [Batch 168/168] [D loss: 0.188454] [G loss: 6.147469]\n",
      "[Epoch 2/1000] [Batch 1/168] [D loss: 0.087014] [G loss: 4.039889]\n",
      "[Epoch 2/1000] [Batch 2/168] [D loss: 0.166431] [G loss: 1.561629]\n",
      "[Epoch 2/1000] [Batch 3/168] [D loss: 0.167512] [G loss: 1.602744]\n",
      "[Epoch 2/1000] [Batch 4/168] [D loss: 0.154647] [G loss: 2.854336]\n",
      "[Epoch 2/1000] [Batch 5/168] [D loss: 0.188667] [G loss: 2.083785]\n",
      "[Epoch 2/1000] [Batch 6/168] [D loss: 0.188189] [G loss: 1.705203]\n",
      "[Epoch 2/1000] [Batch 7/168] [D loss: 0.183150] [G loss: 3.380695]\n",
      "[Epoch 2/1000] [Batch 8/168] [D loss: 0.214288] [G loss: 1.775035]\n",
      "[Epoch 2/1000] [Batch 9/168] [D loss: 0.186049] [G loss: 2.122309]\n",
      "[Epoch 2/1000] [Batch 10/168] [D loss: 0.221184] [G loss: 2.241554]\n",
      "[Epoch 2/1000] [Batch 11/168] [D loss: 0.304615] [G loss: 1.385331]\n",
      "[Epoch 2/1000] [Batch 12/168] [D loss: 0.252323] [G loss: 4.492015]\n",
      "[Epoch 2/1000] [Batch 13/168] [D loss: 0.819312] [G loss: 0.450034]\n",
      "[Epoch 2/1000] [Batch 14/168] [D loss: 1.568302] [G loss: 8.995524]\n",
      "[Epoch 2/1000] [Batch 15/168] [D loss: 0.192401] [G loss: 2.472935]\n",
      "[Epoch 2/1000] [Batch 16/168] [D loss: 1.111469] [G loss: 0.174271]\n",
      "[Epoch 2/1000] [Batch 17/168] [D loss: 0.325291] [G loss: 4.838474]\n",
      "[Epoch 2/1000] [Batch 18/168] [D loss: 0.259275] [G loss: 4.506916]\n",
      "[Epoch 2/1000] [Batch 19/168] [D loss: 0.216948] [G loss: 1.603327]\n",
      "[Epoch 2/1000] [Batch 20/168] [D loss: 0.361525] [G loss: 0.862435]\n",
      "[Epoch 2/1000] [Batch 21/168] [D loss: 0.192500] [G loss: 3.258817]\n",
      "[Epoch 2/1000] [Batch 22/168] [D loss: 0.237759] [G loss: 2.513470]\n",
      "[Epoch 2/1000] [Batch 23/168] [D loss: 0.418977] [G loss: 0.779830]\n",
      "[Epoch 2/1000] [Batch 24/168] [D loss: 0.303545] [G loss: 3.668365]\n",
      "[Epoch 2/1000] [Batch 25/168] [D loss: 0.228636] [G loss: 1.993072]\n",
      "[Epoch 2/1000] [Batch 26/168] [D loss: 0.453505] [G loss: 0.723030]\n",
      "[Epoch 2/1000] [Batch 27/168] [D loss: 0.502381] [G loss: 6.482508]\n",
      "[Epoch 2/1000] [Batch 28/168] [D loss: 0.140163] [G loss: 3.280285]\n",
      "[Epoch 2/1000] [Batch 29/168] [D loss: 0.779282] [G loss: 0.374786]\n",
      "[Epoch 2/1000] [Batch 30/168] [D loss: 0.605081] [G loss: 7.699708]\n",
      "[Epoch 2/1000] [Batch 31/168] [D loss: 0.199501] [G loss: 4.454216]\n",
      "[Epoch 2/1000] [Batch 32/168] [D loss: 0.658428] [G loss: 0.582561]\n",
      "[Epoch 2/1000] [Batch 33/168] [D loss: 0.251350] [G loss: 3.053966]\n",
      "[Epoch 2/1000] [Batch 34/168] [D loss: 0.260815] [G loss: 1.705503]\n",
      "[Epoch 2/1000] [Batch 35/168] [D loss: 0.457402] [G loss: 1.078369]\n",
      "[Epoch 2/1000] [Batch 36/168] [D loss: 0.443618] [G loss: 2.210874]\n",
      "[Epoch 2/1000] [Batch 37/168] [D loss: 0.615148] [G loss: 0.491475]\n",
      "[Epoch 2/1000] [Batch 38/168] [D loss: 0.618642] [G loss: 6.216224]\n",
      "[Epoch 2/1000] [Batch 39/168] [D loss: 0.150147] [G loss: 2.634749]\n",
      "[Epoch 2/1000] [Batch 40/168] [D loss: 0.688095] [G loss: 0.418286]\n",
      "[Epoch 2/1000] [Batch 41/168] [D loss: 0.244826] [G loss: 4.582426]\n",
      "[Epoch 2/1000] [Batch 42/168] [D loss: 0.217548] [G loss: 3.506719]\n",
      "[Epoch 2/1000] [Batch 43/168] [D loss: 0.372765] [G loss: 1.046617]\n",
      "[Epoch 2/1000] [Batch 44/168] [D loss: 0.249691] [G loss: 1.901047]\n",
      "[Epoch 2/1000] [Batch 45/168] [D loss: 0.259115] [G loss: 2.162579]\n",
      "[Epoch 2/1000] [Batch 46/168] [D loss: 0.322168] [G loss: 1.362110]\n",
      "[Epoch 2/1000] [Batch 47/168] [D loss: 0.236139] [G loss: 1.920611]\n",
      "[Epoch 2/1000] [Batch 48/168] [D loss: 0.269056] [G loss: 1.548822]\n",
      "[Epoch 2/1000] [Batch 49/168] [D loss: 0.270793] [G loss: 1.713376]\n",
      "[Epoch 2/1000] [Batch 50/168] [D loss: 0.270607] [G loss: 1.561306]\n",
      "[Epoch 2/1000] [Batch 51/168] [D loss: 0.277865] [G loss: 1.962001]\n",
      "[Epoch 2/1000] [Batch 52/168] [D loss: 0.386639] [G loss: 0.996892]\n",
      "[Epoch 2/1000] [Batch 53/168] [D loss: 0.385076] [G loss: 4.671154]\n",
      "[Epoch 2/1000] [Batch 54/168] [D loss: 0.535452] [G loss: 0.533743]\n",
      "[Epoch 2/1000] [Batch 55/168] [D loss: 0.616829] [G loss: 6.395815]\n",
      "[Epoch 2/1000] [Batch 56/168] [D loss: 0.112897] [G loss: 2.296465]\n",
      "[Epoch 2/1000] [Batch 57/168] [D loss: 0.733989] [G loss: 0.308351]\n",
      "[Epoch 2/1000] [Batch 58/168] [D loss: 0.678721] [G loss: 6.704914]\n",
      "[Epoch 2/1000] [Batch 59/168] [D loss: 0.111071] [G loss: 4.081968]\n",
      "[Epoch 2/1000] [Batch 60/168] [D loss: 0.405299] [G loss: 0.711468]\n",
      "[Epoch 2/1000] [Batch 61/168] [D loss: 0.155021] [G loss: 3.188917]\n",
      "[Epoch 2/1000] [Batch 62/168] [D loss: 0.178459] [G loss: 2.741257]\n",
      "[Epoch 2/1000] [Batch 63/168] [D loss: 0.274550] [G loss: 1.418314]\n",
      "[Epoch 2/1000] [Batch 64/168] [D loss: 0.198658] [G loss: 2.051319]\n",
      "[Epoch 2/1000] [Batch 65/168] [D loss: 0.199190] [G loss: 2.080629]\n",
      "[Epoch 2/1000] [Batch 66/168] [D loss: 0.288243] [G loss: 1.447096]\n",
      "[Epoch 2/1000] [Batch 67/168] [D loss: 0.322798] [G loss: 2.631170]\n",
      "[Epoch 2/1000] [Batch 68/168] [D loss: 0.475805] [G loss: 0.658946]\n",
      "[Epoch 2/1000] [Batch 69/168] [D loss: 0.513178] [G loss: 5.496918]\n",
      "[Epoch 2/1000] [Batch 70/168] [D loss: 0.124286] [G loss: 2.118452]\n",
      "[Epoch 2/1000] [Batch 71/168] [D loss: 0.557626] [G loss: 0.533497]\n",
      "[Epoch 2/1000] [Batch 72/168] [D loss: 0.469183] [G loss: 5.364884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/1000] [Batch 73/168] [D loss: 0.150371] [G loss: 3.262966]\n",
      "[Epoch 2/1000] [Batch 74/168] [D loss: 0.440307] [G loss: 0.751094]\n",
      "[Epoch 2/1000] [Batch 75/168] [D loss: 0.222012] [G loss: 3.721194]\n",
      "[Epoch 2/1000] [Batch 76/168] [D loss: 0.170145] [G loss: 2.606035]\n",
      "[Epoch 2/1000] [Batch 77/168] [D loss: 0.329870] [G loss: 1.060515]\n",
      "[Epoch 2/1000] [Batch 78/168] [D loss: 0.198593] [G loss: 3.429629]\n",
      "[Epoch 2/1000] [Batch 79/168] [D loss: 0.216337] [G loss: 2.179781]\n",
      "[Epoch 2/1000] [Batch 80/168] [D loss: 0.295204] [G loss: 1.084135]\n",
      "[Epoch 2/1000] [Batch 81/168] [D loss: 0.191231] [G loss: 3.968969]\n",
      "[Epoch 2/1000] [Batch 82/168] [D loss: 0.226549] [G loss: 1.894212]\n",
      "[Epoch 2/1000] [Batch 83/168] [D loss: 0.396954] [G loss: 0.926131]\n",
      "[Epoch 2/1000] [Batch 84/168] [D loss: 0.509131] [G loss: 5.076121]\n",
      "[Epoch 2/1000] [Batch 85/168] [D loss: 0.258132] [G loss: 1.244926]\n",
      "[Epoch 2/1000] [Batch 86/168] [D loss: 0.125018] [G loss: 2.449557]\n",
      "[Epoch 2/1000] [Batch 87/168] [D loss: 0.265928] [G loss: 1.456789]\n",
      "[Epoch 2/1000] [Batch 88/168] [D loss: 0.241688] [G loss: 2.601814]\n",
      "[Epoch 2/1000] [Batch 89/168] [D loss: 0.535463] [G loss: 0.611470]\n",
      "[Epoch 2/1000] [Batch 90/168] [D loss: 1.032978] [G loss: 7.895226]\n",
      "[Epoch 2/1000] [Batch 91/168] [D loss: 0.047609] [G loss: 3.226893]\n",
      "[Epoch 2/1000] [Batch 92/168] [D loss: 0.648891] [G loss: 0.411891]\n",
      "[Epoch 2/1000] [Batch 93/168] [D loss: 0.076079] [G loss: 5.777228]\n",
      "[Epoch 2/1000] [Batch 94/168] [D loss: 0.183260] [G loss: 6.035258]\n",
      "[Epoch 2/1000] [Batch 95/168] [D loss: 0.071417] [G loss: 3.779025]\n",
      "[Epoch 2/1000] [Batch 96/168] [D loss: 0.197944] [G loss: 1.378659]\n",
      "[Epoch 2/1000] [Batch 97/168] [D loss: 0.134771] [G loss: 2.140842]\n",
      "[Epoch 2/1000] [Batch 98/168] [D loss: 0.133865] [G loss: 2.567198]\n",
      "[Epoch 2/1000] [Batch 99/168] [D loss: 0.166932] [G loss: 1.843978]\n",
      "[Epoch 2/1000] [Batch 100/168] [D loss: 0.259819] [G loss: 1.791338]\n",
      "[Epoch 2/1000] [Batch 101/168] [D loss: 0.230068] [G loss: 1.760003]\n",
      "[Epoch 2/1000] [Batch 102/168] [D loss: 0.267843] [G loss: 1.817307]\n",
      "[Epoch 2/1000] [Batch 103/168] [D loss: 0.233656] [G loss: 1.807882]\n",
      "[Epoch 2/1000] [Batch 104/168] [D loss: 0.133992] [G loss: 2.614384]\n",
      "[Epoch 2/1000] [Batch 105/168] [D loss: 0.233757] [G loss: 1.531209]\n",
      "[Epoch 2/1000] [Batch 106/168] [D loss: 0.139397] [G loss: 3.355091]\n",
      "[Epoch 2/1000] [Batch 107/168] [D loss: 0.306508] [G loss: 1.133885]\n",
      "[Epoch 2/1000] [Batch 108/168] [D loss: 0.311624] [G loss: 6.400536]\n",
      "[Epoch 2/1000] [Batch 109/168] [D loss: 0.084234] [G loss: 2.619411]\n",
      "[Epoch 2/1000] [Batch 110/168] [D loss: 0.445393] [G loss: 0.718588]\n",
      "[Epoch 2/1000] [Batch 111/168] [D loss: 0.543021] [G loss: 9.530597]\n",
      "[Epoch 2/1000] [Batch 112/168] [D loss: 0.036423] [G loss: 6.390348]\n",
      "[Epoch 2/1000] [Batch 113/168] [D loss: 0.207222] [G loss: 1.769215]\n",
      "[Epoch 2/1000] [Batch 114/168] [D loss: 0.071222] [G loss: 2.457886]\n",
      "[Epoch 2/1000] [Batch 115/168] [D loss: 0.066622] [G loss: 2.889080]\n",
      "[Epoch 2/1000] [Batch 116/168] [D loss: 0.142904] [G loss: 2.120955]\n",
      "[Epoch 2/1000] [Batch 117/168] [D loss: 0.190439] [G loss: 2.068748]\n",
      "[Epoch 2/1000] [Batch 118/168] [D loss: 0.196770] [G loss: 1.820268]\n",
      "[Epoch 2/1000] [Batch 119/168] [D loss: 0.202994] [G loss: 2.480450]\n",
      "[Epoch 2/1000] [Batch 120/168] [D loss: 0.304410] [G loss: 1.083677]\n",
      "[Epoch 2/1000] [Batch 121/168] [D loss: 0.503788] [G loss: 6.752182]\n",
      "[Epoch 2/1000] [Batch 122/168] [D loss: 0.187974] [G loss: 1.394517]\n",
      "[Epoch 2/1000] [Batch 123/168] [D loss: 0.085175] [G loss: 2.692491]\n",
      "[Epoch 2/1000] [Batch 124/168] [D loss: 0.122468] [G loss: 2.261963]\n",
      "[Epoch 2/1000] [Batch 125/168] [D loss: 0.176391] [G loss: 2.406594]\n",
      "[Epoch 2/1000] [Batch 126/168] [D loss: 0.343944] [G loss: 1.609822]\n",
      "[Epoch 2/1000] [Batch 127/168] [D loss: 0.384940] [G loss: 2.457970]\n",
      "[Epoch 2/1000] [Batch 128/168] [D loss: 1.144158] [G loss: 0.197593]\n",
      "[Epoch 2/1000] [Batch 129/168] [D loss: 2.490499] [G loss: 11.126768]\n",
      "[Epoch 2/1000] [Batch 130/168] [D loss: 0.430063] [G loss: 7.137304]\n",
      "[Epoch 2/1000] [Batch 131/168] [D loss: 0.187910] [G loss: 1.521557]\n",
      "[Epoch 2/1000] [Batch 132/168] [D loss: 0.383478] [G loss: 0.728863]\n",
      "[Epoch 2/1000] [Batch 133/168] [D loss: 0.067050] [G loss: 3.905612]\n",
      "[Epoch 2/1000] [Batch 134/168] [D loss: 0.141551] [G loss: 4.152803]\n",
      "[Epoch 2/1000] [Batch 135/168] [D loss: 0.183108] [G loss: 1.863486]\n",
      "[Epoch 2/1000] [Batch 136/168] [D loss: 0.456372] [G loss: 0.847724]\n",
      "[Epoch 2/1000] [Batch 137/168] [D loss: 0.521798] [G loss: 4.795619]\n",
      "[Epoch 2/1000] [Batch 138/168] [D loss: 0.281272] [G loss: 1.466285]\n",
      "[Epoch 2/1000] [Batch 139/168] [D loss: 0.172856] [G loss: 2.086303]\n",
      "[Epoch 2/1000] [Batch 140/168] [D loss: 0.145153] [G loss: 2.973021]\n",
      "[Epoch 2/1000] [Batch 141/168] [D loss: 0.258093] [G loss: 1.290868]\n",
      "[Epoch 2/1000] [Batch 142/168] [D loss: 0.195240] [G loss: 4.246771]\n",
      "[Epoch 2/1000] [Batch 143/168] [D loss: 0.274798] [G loss: 1.407930]\n",
      "[Epoch 2/1000] [Batch 144/168] [D loss: 0.232721] [G loss: 2.346536]\n",
      "[Epoch 2/1000] [Batch 145/168] [D loss: 0.379195] [G loss: 1.062536]\n",
      "[Epoch 2/1000] [Batch 146/168] [D loss: 0.422769] [G loss: 4.079149]\n",
      "[Epoch 2/1000] [Batch 147/168] [D loss: 0.296992] [G loss: 1.013982]\n",
      "[Epoch 2/1000] [Batch 148/168] [D loss: 0.124928] [G loss: 2.931576]\n",
      "[Epoch 2/1000] [Batch 149/168] [D loss: 0.193155] [G loss: 1.855283]\n",
      "[Epoch 2/1000] [Batch 150/168] [D loss: 0.273125] [G loss: 1.392083]\n",
      "[Epoch 2/1000] [Batch 151/168] [D loss: 0.315371] [G loss: 2.444340]\n",
      "[Epoch 2/1000] [Batch 152/168] [D loss: 0.342390] [G loss: 1.001548]\n",
      "[Epoch 2/1000] [Batch 153/168] [D loss: 0.205073] [G loss: 3.955614]\n",
      "[Epoch 2/1000] [Batch 154/168] [D loss: 0.208248] [G loss: 2.395358]\n",
      "[Epoch 2/1000] [Batch 155/168] [D loss: 0.408178] [G loss: 0.773612]\n",
      "[Epoch 2/1000] [Batch 156/168] [D loss: 0.234221] [G loss: 5.351879]\n",
      "[Epoch 2/1000] [Batch 157/168] [D loss: 0.139699] [G loss: 3.915614]\n",
      "[Epoch 2/1000] [Batch 158/168] [D loss: 0.255997] [G loss: 1.199404]\n",
      "[Epoch 2/1000] [Batch 159/168] [D loss: 0.121008] [G loss: 3.054657]\n",
      "[Epoch 2/1000] [Batch 160/168] [D loss: 0.153237] [G loss: 2.468707]\n",
      "[Epoch 2/1000] [Batch 161/168] [D loss: 0.221582] [G loss: 1.511613]\n",
      "[Epoch 2/1000] [Batch 162/168] [D loss: 0.191406] [G loss: 3.414548]\n",
      "[Epoch 2/1000] [Batch 163/168] [D loss: 0.232187] [G loss: 1.701293]\n",
      "[Epoch 2/1000] [Batch 164/168] [D loss: 0.154490] [G loss: 2.639443]\n",
      "[Epoch 2/1000] [Batch 165/168] [D loss: 0.206532] [G loss: 1.598825]\n",
      "[Epoch 2/1000] [Batch 166/168] [D loss: 0.190327] [G loss: 3.560408]\n",
      "[Epoch 2/1000] [Batch 167/168] [D loss: 0.393753] [G loss: 0.867596]\n",
      "[Epoch 2/1000] [Batch 168/168] [D loss: 0.817198] [G loss: 8.437956]\n",
      "[Epoch 3/1000] [Batch 1/168] [D loss: 0.101710] [G loss: 2.379438]\n",
      "[Epoch 3/1000] [Batch 2/168] [D loss: 0.859679] [G loss: 0.266531]\n",
      "[Epoch 3/1000] [Batch 3/168] [D loss: 0.921855] [G loss: 10.490973]\n",
      "[Epoch 3/1000] [Batch 4/168] [D loss: 0.328987] [G loss: 8.147602]\n",
      "[Epoch 3/1000] [Batch 5/168] [D loss: 0.092389] [G loss: 2.656061]\n",
      "[Epoch 3/1000] [Batch 6/168] [D loss: 0.740624] [G loss: 0.422474]\n",
      "[Epoch 3/1000] [Batch 7/168] [D loss: 0.139548] [G loss: 5.167303]\n",
      "[Epoch 3/1000] [Batch 8/168] [D loss: 0.225320] [G loss: 5.171055]\n",
      "[Epoch 3/1000] [Batch 9/168] [D loss: 0.155114] [G loss: 2.277900]\n",
      "[Epoch 3/1000] [Batch 10/168] [D loss: 0.284603] [G loss: 1.246292]\n",
      "[Epoch 3/1000] [Batch 11/168] [D loss: 0.171625] [G loss: 3.021090]\n",
      "[Epoch 3/1000] [Batch 12/168] [D loss: 0.199305] [G loss: 2.292936]\n",
      "[Epoch 3/1000] [Batch 13/168] [D loss: 0.258968] [G loss: 1.402380]\n",
      "[Epoch 3/1000] [Batch 14/168] [D loss: 0.137061] [G loss: 2.771572]\n",
      "[Epoch 3/1000] [Batch 15/168] [D loss: 0.150843] [G loss: 2.214194]\n",
      "[Epoch 3/1000] [Batch 16/168] [D loss: 0.164759] [G loss: 1.665906]\n",
      "[Epoch 3/1000] [Batch 17/168] [D loss: 0.134643] [G loss: 2.890658]\n",
      "[Epoch 3/1000] [Batch 18/168] [D loss: 0.166706] [G loss: 1.990049]\n",
      "[Epoch 3/1000] [Batch 19/168] [D loss: 0.212029] [G loss: 2.059321]\n",
      "[Epoch 3/1000] [Batch 20/168] [D loss: 0.174803] [G loss: 2.391067]\n",
      "[Epoch 3/1000] [Batch 21/168] [D loss: 0.179704] [G loss: 1.878934]\n",
      "[Epoch 3/1000] [Batch 22/168] [D loss: 0.157582] [G loss: 2.738985]\n",
      "[Epoch 3/1000] [Batch 23/168] [D loss: 0.174198] [G loss: 1.994197]\n",
      "[Epoch 3/1000] [Batch 24/168] [D loss: 0.113701] [G loss: 2.776844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/1000] [Batch 25/168] [D loss: 0.209510] [G loss: 1.623322]\n",
      "[Epoch 3/1000] [Batch 26/168] [D loss: 0.137174] [G loss: 3.166479]\n",
      "[Epoch 3/1000] [Batch 27/168] [D loss: 0.312634] [G loss: 1.133029]\n",
      "[Epoch 3/1000] [Batch 28/168] [D loss: 0.270310] [G loss: 5.493306]\n",
      "[Epoch 3/1000] [Batch 29/168] [D loss: 0.096132] [G loss: 3.246691]\n",
      "[Epoch 3/1000] [Batch 30/168] [D loss: 0.310882] [G loss: 1.066993]\n",
      "[Epoch 3/1000] [Batch 31/168] [D loss: 0.151319] [G loss: 5.604024]\n",
      "[Epoch 3/1000] [Batch 32/168] [D loss: 0.111495] [G loss: 4.728361]\n",
      "[Epoch 3/1000] [Batch 33/168] [D loss: 0.181692] [G loss: 1.774908]\n",
      "[Epoch 3/1000] [Batch 34/168] [D loss: 0.167128] [G loss: 1.978020]\n",
      "[Epoch 3/1000] [Batch 35/168] [D loss: 0.144827] [G loss: 3.232724]\n",
      "[Epoch 3/1000] [Batch 36/168] [D loss: 0.167461] [G loss: 2.041204]\n",
      "[Epoch 3/1000] [Batch 37/168] [D loss: 0.172990] [G loss: 2.451246]\n",
      "[Epoch 3/1000] [Batch 38/168] [D loss: 0.224487] [G loss: 2.025046]\n",
      "[Epoch 3/1000] [Batch 39/168] [D loss: 0.183046] [G loss: 2.572046]\n",
      "[Epoch 3/1000] [Batch 40/168] [D loss: 0.309553] [G loss: 1.399026]\n",
      "[Epoch 3/1000] [Batch 41/168] [D loss: 0.334694] [G loss: 5.316173]\n",
      "[Epoch 3/1000] [Batch 42/168] [D loss: 0.327068] [G loss: 1.027442]\n",
      "[Epoch 3/1000] [Batch 43/168] [D loss: 0.280854] [G loss: 6.461010]\n",
      "[Epoch 3/1000] [Batch 44/168] [D loss: 0.073021] [G loss: 3.240953]\n",
      "[Epoch 3/1000] [Batch 45/168] [D loss: 0.704061] [G loss: 0.377106]\n",
      "[Epoch 3/1000] [Batch 46/168] [D loss: 1.270191] [G loss: 11.111104]\n",
      "[Epoch 3/1000] [Batch 47/168] [D loss: 0.070091] [G loss: 7.840549]\n",
      "[Epoch 3/1000] [Batch 48/168] [D loss: 0.035930] [G loss: 3.544414]\n",
      "[Epoch 3/1000] [Batch 49/168] [D loss: 0.548254] [G loss: 0.700864]\n",
      "[Epoch 3/1000] [Batch 50/168] [D loss: 0.106154] [G loss: 5.814689]\n",
      "[Epoch 3/1000] [Batch 51/168] [D loss: 0.159109] [G loss: 5.442772]\n",
      "[Epoch 3/1000] [Batch 52/168] [D loss: 0.147401] [G loss: 2.559382]\n",
      "[Epoch 3/1000] [Batch 53/168] [D loss: 0.288061] [G loss: 1.440856]\n",
      "[Epoch 3/1000] [Batch 54/168] [D loss: 0.128135] [G loss: 3.861004]\n",
      "[Epoch 3/1000] [Batch 55/168] [D loss: 0.169265] [G loss: 3.036284]\n",
      "[Epoch 3/1000] [Batch 56/168] [D loss: 0.401237] [G loss: 0.906467]\n",
      "[Epoch 3/1000] [Batch 57/168] [D loss: 0.316711] [G loss: 6.663560]\n",
      "[Epoch 3/1000] [Batch 58/168] [D loss: 0.065950] [G loss: 4.575311]\n",
      "[Epoch 3/1000] [Batch 59/168] [D loss: 0.264187] [G loss: 1.230127]\n",
      "[Epoch 3/1000] [Batch 60/168] [D loss: 0.130305] [G loss: 4.008143]\n",
      "[Epoch 3/1000] [Batch 61/168] [D loss: 0.118673] [G loss: 2.822455]\n",
      "[Epoch 3/1000] [Batch 62/168] [D loss: 0.259403] [G loss: 1.313052]\n",
      "[Epoch 3/1000] [Batch 63/168] [D loss: 0.191156] [G loss: 4.217291]\n",
      "[Epoch 3/1000] [Batch 64/168] [D loss: 0.151433] [G loss: 2.151600]\n",
      "[Epoch 3/1000] [Batch 65/168] [D loss: 0.264661] [G loss: 1.076872]\n",
      "[Epoch 3/1000] [Batch 66/168] [D loss: 0.225541] [G loss: 5.415763]\n",
      "[Epoch 3/1000] [Batch 67/168] [D loss: 0.083519] [G loss: 3.441836]\n",
      "[Epoch 3/1000] [Batch 68/168] [D loss: 0.206439] [G loss: 1.301463]\n",
      "[Epoch 3/1000] [Batch 69/168] [D loss: 0.056231] [G loss: 4.237431]\n",
      "[Epoch 3/1000] [Batch 70/168] [D loss: 0.065684] [G loss: 3.961962]\n",
      "[Epoch 3/1000] [Batch 71/168] [D loss: 0.126206] [G loss: 2.136429]\n",
      "[Epoch 3/1000] [Batch 72/168] [D loss: 0.118509] [G loss: 2.268589]\n",
      "[Epoch 3/1000] [Batch 73/168] [D loss: 0.103626] [G loss: 2.690456]\n",
      "[Epoch 3/1000] [Batch 74/168] [D loss: 0.201929] [G loss: 2.118012]\n",
      "[Epoch 3/1000] [Batch 75/168] [D loss: 0.168817] [G loss: 1.741733]\n",
      "[Epoch 3/1000] [Batch 76/168] [D loss: 0.215229] [G loss: 4.662881]\n",
      "[Epoch 3/1000] [Batch 77/168] [D loss: 0.289743] [G loss: 1.035530]\n",
      "[Epoch 3/1000] [Batch 78/168] [D loss: 0.371415] [G loss: 8.798399]\n",
      "[Epoch 3/1000] [Batch 79/168] [D loss: 0.040390] [G loss: 4.035486]\n",
      "[Epoch 3/1000] [Batch 80/168] [D loss: 0.775227] [G loss: 0.367515]\n",
      "[Epoch 3/1000] [Batch 81/168] [D loss: 1.296023] [G loss: 12.569535]\n",
      "[Epoch 3/1000] [Batch 82/168] [D loss: 0.080813] [G loss: 7.880264]\n",
      "[Epoch 3/1000] [Batch 83/168] [D loss: 0.157356] [G loss: 2.125588]\n",
      "[Epoch 3/1000] [Batch 84/168] [D loss: 0.343216] [G loss: 0.931344]\n",
      "[Epoch 3/1000] [Batch 85/168] [D loss: 0.129433] [G loss: 4.467670]\n",
      "[Epoch 3/1000] [Batch 86/168] [D loss: 0.169027] [G loss: 3.629255]\n",
      "[Epoch 3/1000] [Batch 87/168] [D loss: 0.242340] [G loss: 1.550711]\n",
      "[Epoch 3/1000] [Batch 88/168] [D loss: 0.264357] [G loss: 1.700376]\n",
      "[Epoch 3/1000] [Batch 89/168] [D loss: 0.247230] [G loss: 2.953495]\n",
      "[Epoch 3/1000] [Batch 90/168] [D loss: 0.212597] [G loss: 1.562650]\n",
      "[Epoch 3/1000] [Batch 91/168] [D loss: 0.219609] [G loss: 2.662952]\n",
      "[Epoch 3/1000] [Batch 92/168] [D loss: 0.199260] [G loss: 1.875434]\n",
      "[Epoch 3/1000] [Batch 93/168] [D loss: 0.217535] [G loss: 1.927679]\n",
      "[Epoch 3/1000] [Batch 94/168] [D loss: 0.194492] [G loss: 2.828648]\n",
      "[Epoch 3/1000] [Batch 95/168] [D loss: 0.313284] [G loss: 1.360529]\n",
      "[Epoch 3/1000] [Batch 96/168] [D loss: 0.224388] [G loss: 3.883511]\n",
      "[Epoch 3/1000] [Batch 97/168] [D loss: 0.242087] [G loss: 1.414087]\n",
      "[Epoch 3/1000] [Batch 98/168] [D loss: 0.217637] [G loss: 2.876314]\n",
      "[Epoch 3/1000] [Batch 99/168] [D loss: 0.297565] [G loss: 1.204784]\n",
      "[Epoch 3/1000] [Batch 100/168] [D loss: 0.501774] [G loss: 5.590992]\n",
      "[Epoch 3/1000] [Batch 101/168] [D loss: 0.266383] [G loss: 1.180094]\n",
      "[Epoch 3/1000] [Batch 102/168] [D loss: 0.092755] [G loss: 5.048845]\n",
      "[Epoch 3/1000] [Batch 103/168] [D loss: 0.066316] [G loss: 3.867196]\n",
      "[Epoch 3/1000] [Batch 104/168] [D loss: 0.278424] [G loss: 1.190048]\n",
      "[Epoch 3/1000] [Batch 105/168] [D loss: 0.213670] [G loss: 5.608640]\n",
      "[Epoch 3/1000] [Batch 106/168] [D loss: 0.078350] [G loss: 3.416560]\n",
      "[Epoch 3/1000] [Batch 107/168] [D loss: 0.351300] [G loss: 0.874280]\n",
      "[Epoch 3/1000] [Batch 108/168] [D loss: 0.254313] [G loss: 6.838316]\n",
      "[Epoch 3/1000] [Batch 109/168] [D loss: 0.067482] [G loss: 5.452688]\n",
      "[Epoch 3/1000] [Batch 110/168] [D loss: 0.092030] [G loss: 2.214155]\n",
      "[Epoch 3/1000] [Batch 111/168] [D loss: 0.190413] [G loss: 1.290808]\n",
      "[Epoch 3/1000] [Batch 112/168] [D loss: 0.116593] [G loss: 4.951890]\n",
      "[Epoch 3/1000] [Batch 113/168] [D loss: 0.086315] [G loss: 3.729594]\n",
      "[Epoch 3/1000] [Batch 114/168] [D loss: 0.241192] [G loss: 1.252461]\n",
      "[Epoch 3/1000] [Batch 115/168] [D loss: 0.214588] [G loss: 3.965921]\n",
      "[Epoch 3/1000] [Batch 116/168] [D loss: 0.187442] [G loss: 1.530703]\n",
      "[Epoch 3/1000] [Batch 117/168] [D loss: 0.154695] [G loss: 2.657113]\n",
      "[Epoch 3/1000] [Batch 118/168] [D loss: 0.345998] [G loss: 1.334873]\n",
      "[Epoch 3/1000] [Batch 119/168] [D loss: 0.207024] [G loss: 2.647988]\n",
      "[Epoch 3/1000] [Batch 120/168] [D loss: 0.238814] [G loss: 1.416831]\n",
      "[Epoch 3/1000] [Batch 121/168] [D loss: 0.292449] [G loss: 3.080490]\n",
      "[Epoch 3/1000] [Batch 122/168] [D loss: 0.442900] [G loss: 0.819014]\n",
      "[Epoch 3/1000] [Batch 123/168] [D loss: 0.579956] [G loss: 6.759568]\n",
      "[Epoch 3/1000] [Batch 124/168] [D loss: 0.132972] [G loss: 1.876757]\n",
      "[Epoch 3/1000] [Batch 125/168] [D loss: 0.201345] [G loss: 1.437685]\n",
      "[Epoch 3/1000] [Batch 126/168] [D loss: 0.102181] [G loss: 4.172432]\n",
      "[Epoch 3/1000] [Batch 127/168] [D loss: 0.153087] [G loss: 2.825906]\n",
      "[Epoch 3/1000] [Batch 128/168] [D loss: 0.446690] [G loss: 0.861686]\n",
      "[Epoch 3/1000] [Batch 129/168] [D loss: 1.018597] [G loss: 6.227181]\n",
      "[Epoch 3/1000] [Batch 130/168] [D loss: 0.722671] [G loss: 0.359784]\n",
      "[Epoch 3/1000] [Batch 131/168] [D loss: 0.272646] [G loss: 6.374074]\n",
      "[Epoch 3/1000] [Batch 132/168] [D loss: 0.121135] [G loss: 5.678949]\n",
      "[Epoch 3/1000] [Batch 133/168] [D loss: 0.074043] [G loss: 2.995553]\n",
      "[Epoch 3/1000] [Batch 134/168] [D loss: 0.324860] [G loss: 1.188780]\n",
      "[Epoch 3/1000] [Batch 135/168] [D loss: 0.166730] [G loss: 3.656415]\n",
      "[Epoch 3/1000] [Batch 136/168] [D loss: 0.168784] [G loss: 2.501963]\n",
      "[Epoch 3/1000] [Batch 137/168] [D loss: 0.211141] [G loss: 1.715044]\n",
      "[Epoch 3/1000] [Batch 138/168] [D loss: 0.193147] [G loss: 2.595210]\n",
      "[Epoch 3/1000] [Batch 139/168] [D loss: 0.215617] [G loss: 2.541635]\n",
      "[Epoch 3/1000] [Batch 140/168] [D loss: 0.270067] [G loss: 1.628846]\n",
      "[Epoch 3/1000] [Batch 141/168] [D loss: 0.226716] [G loss: 2.310868]\n",
      "[Epoch 3/1000] [Batch 142/168] [D loss: 0.193332] [G loss: 2.120885]\n",
      "[Epoch 3/1000] [Batch 143/168] [D loss: 0.173157] [G loss: 2.282488]\n",
      "[Epoch 3/1000] [Batch 144/168] [D loss: 0.156572] [G loss: 2.044899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/1000] [Batch 145/168] [D loss: 0.174986] [G loss: 2.399006]\n",
      "[Epoch 3/1000] [Batch 146/168] [D loss: 0.254977] [G loss: 1.909424]\n",
      "[Epoch 3/1000] [Batch 147/168] [D loss: 0.202573] [G loss: 2.164639]\n",
      "[Epoch 3/1000] [Batch 148/168] [D loss: 0.223511] [G loss: 1.740510]\n",
      "[Epoch 3/1000] [Batch 149/168] [D loss: 0.210056] [G loss: 2.996397]\n",
      "[Epoch 3/1000] [Batch 150/168] [D loss: 0.385792] [G loss: 0.863487]\n",
      "[Epoch 3/1000] [Batch 151/168] [D loss: 0.934974] [G loss: 8.451374]\n",
      "[Epoch 3/1000] [Batch 152/168] [D loss: 0.402306] [G loss: 0.809486]\n",
      "[Epoch 3/1000] [Batch 153/168] [D loss: 0.105099] [G loss: 5.867491]\n",
      "[Epoch 3/1000] [Batch 154/168] [D loss: 0.082009] [G loss: 3.560015]\n",
      "[Epoch 3/1000] [Batch 155/168] [D loss: 0.431119] [G loss: 0.871501]\n",
      "[Epoch 3/1000] [Batch 156/168] [D loss: 0.554942] [G loss: 5.809309]\n",
      "[Epoch 3/1000] [Batch 157/168] [D loss: 0.222659] [G loss: 1.547805]\n",
      "[Epoch 3/1000] [Batch 158/168] [D loss: 0.169901] [G loss: 1.866020]\n",
      "[Epoch 3/1000] [Batch 159/168] [D loss: 0.218682] [G loss: 3.403411]\n",
      "[Epoch 3/1000] [Batch 160/168] [D loss: 0.318823] [G loss: 1.060514]\n",
      "[Epoch 3/1000] [Batch 161/168] [D loss: 0.381632] [G loss: 4.899433]\n",
      "[Epoch 3/1000] [Batch 162/168] [D loss: 0.205202] [G loss: 1.550948]\n",
      "[Epoch 3/1000] [Batch 163/168] [D loss: 0.118396] [G loss: 2.452906]\n",
      "[Epoch 3/1000] [Batch 164/168] [D loss: 0.140826] [G loss: 3.144676]\n",
      "[Epoch 3/1000] [Batch 165/168] [D loss: 0.186487] [G loss: 1.516636]\n",
      "[Epoch 3/1000] [Batch 166/168] [D loss: 0.147862] [G loss: 4.818752]\n",
      "[Epoch 3/1000] [Batch 167/168] [D loss: 0.093554] [G loss: 2.739089]\n",
      "[Epoch 3/1000] [Batch 168/168] [D loss: 0.291606] [G loss: 1.063145]\n",
      "[Epoch 4/1000] [Batch 1/168] [D loss: 0.533157] [G loss: 6.922985]\n",
      "[Epoch 4/1000] [Batch 2/168] [D loss: 0.075806] [G loss: 2.562645]\n",
      "[Epoch 4/1000] [Batch 3/168] [D loss: 0.261148] [G loss: 1.110724]\n",
      "[Epoch 4/1000] [Batch 4/168] [D loss: 0.074606] [G loss: 6.124001]\n",
      "[Epoch 4/1000] [Batch 5/168] [D loss: 0.130938] [G loss: 5.430258]\n",
      "[Epoch 4/1000] [Batch 6/168] [D loss: 0.113902] [G loss: 2.315309]\n",
      "[Epoch 4/1000] [Batch 7/168] [D loss: 0.247141] [G loss: 1.162525]\n",
      "[Epoch 4/1000] [Batch 8/168] [D loss: 0.200591] [G loss: 5.090997]\n",
      "[Epoch 4/1000] [Batch 9/168] [D loss: 0.080482] [G loss: 3.488584]\n",
      "[Epoch 4/1000] [Batch 10/168] [D loss: 0.352880] [G loss: 0.879611]\n",
      "[Epoch 4/1000] [Batch 11/168] [D loss: 0.360895] [G loss: 6.151348]\n",
      "[Epoch 4/1000] [Batch 12/168] [D loss: 0.071636] [G loss: 3.030018]\n",
      "[Epoch 4/1000] [Batch 13/168] [D loss: 0.379012] [G loss: 0.759472]\n",
      "[Epoch 4/1000] [Batch 14/168] [D loss: 0.264194] [G loss: 7.121729]\n",
      "[Epoch 4/1000] [Batch 15/168] [D loss: 0.097897] [G loss: 5.836032]\n",
      "[Epoch 4/1000] [Batch 16/168] [D loss: 0.152601] [G loss: 1.815302]\n",
      "[Epoch 4/1000] [Batch 17/168] [D loss: 0.108213] [G loss: 2.282934]\n",
      "[Epoch 4/1000] [Batch 18/168] [D loss: 0.110390] [G loss: 2.506496]\n",
      "[Epoch 4/1000] [Batch 19/168] [D loss: 0.190187] [G loss: 2.089208]\n",
      "[Epoch 4/1000] [Batch 20/168] [D loss: 0.253354] [G loss: 1.994554]\n",
      "[Epoch 4/1000] [Batch 21/168] [D loss: 0.274094] [G loss: 1.903905]\n",
      "[Epoch 4/1000] [Batch 22/168] [D loss: 0.208766] [G loss: 1.530219]\n",
      "[Epoch 4/1000] [Batch 23/168] [D loss: 0.238059] [G loss: 5.165760]\n",
      "[Epoch 4/1000] [Batch 24/168] [D loss: 0.391930] [G loss: 0.817048]\n",
      "[Epoch 4/1000] [Batch 25/168] [D loss: 0.634263] [G loss: 8.973581]\n",
      "[Epoch 4/1000] [Batch 26/168] [D loss: 0.035768] [G loss: 3.213833]\n",
      "[Epoch 4/1000] [Batch 27/168] [D loss: 0.839083] [G loss: 0.285614]\n",
      "[Epoch 4/1000] [Batch 28/168] [D loss: 1.089258] [G loss: 13.057823]\n",
      "[Epoch 4/1000] [Batch 29/168] [D loss: 0.062462] [G loss: 9.609781]\n",
      "[Epoch 4/1000] [Batch 30/168] [D loss: 0.027240] [G loss: 3.894314]\n",
      "[Epoch 4/1000] [Batch 31/168] [D loss: 1.114699] [G loss: 0.178503]\n",
      "[Epoch 4/1000] [Batch 32/168] [D loss: 0.546452] [G loss: 9.186878]\n",
      "[Epoch 4/1000] [Batch 33/168] [D loss: 0.193676] [G loss: 7.639201]\n",
      "[Epoch 4/1000] [Batch 34/168] [D loss: 0.036598] [G loss: 3.467447]\n",
      "[Epoch 4/1000] [Batch 35/168] [D loss: 0.445281] [G loss: 0.783959]\n",
      "[Epoch 4/1000] [Batch 36/168] [D loss: 0.074644] [G loss: 4.259522]\n",
      "[Epoch 4/1000] [Batch 37/168] [D loss: 0.235142] [G loss: 4.408853]\n",
      "[Epoch 4/1000] [Batch 38/168] [D loss: 0.243195] [G loss: 1.616833]\n",
      "[Epoch 4/1000] [Batch 39/168] [D loss: 0.181051] [G loss: 2.145368]\n",
      "[Epoch 4/1000] [Batch 40/168] [D loss: 0.227843] [G loss: 2.627066]\n",
      "[Epoch 4/1000] [Batch 41/168] [D loss: 0.252940] [G loss: 1.553608]\n",
      "[Epoch 4/1000] [Batch 42/168] [D loss: 0.165230] [G loss: 3.308951]\n",
      "[Epoch 4/1000] [Batch 43/168] [D loss: 0.238138] [G loss: 1.697402]\n",
      "[Epoch 4/1000] [Batch 44/168] [D loss: 0.209884] [G loss: 3.005501]\n",
      "[Epoch 4/1000] [Batch 45/168] [D loss: 0.301241] [G loss: 1.127727]\n",
      "[Epoch 4/1000] [Batch 46/168] [D loss: 0.278164] [G loss: 5.482872]\n",
      "[Epoch 4/1000] [Batch 47/168] [D loss: 0.144220] [G loss: 2.208629]\n",
      "[Epoch 4/1000] [Batch 48/168] [D loss: 0.321379] [G loss: 1.003080]\n",
      "[Epoch 4/1000] [Batch 49/168] [D loss: 0.502982] [G loss: 6.846853]\n",
      "[Epoch 4/1000] [Batch 50/168] [D loss: 0.106319] [G loss: 2.444750]\n",
      "[Epoch 4/1000] [Batch 51/168] [D loss: 0.449100] [G loss: 0.775875]\n",
      "[Epoch 4/1000] [Batch 52/168] [D loss: 0.462281] [G loss: 8.765987]\n",
      "[Epoch 4/1000] [Batch 53/168] [D loss: 0.077829] [G loss: 5.909703]\n",
      "[Epoch 4/1000] [Batch 54/168] [D loss: 0.214701] [G loss: 1.335529]\n",
      "[Epoch 4/1000] [Batch 55/168] [D loss: 0.104875] [G loss: 2.483323]\n",
      "[Epoch 4/1000] [Batch 56/168] [D loss: 0.217425] [G loss: 2.577543]\n",
      "[Epoch 4/1000] [Batch 57/168] [D loss: 0.314583] [G loss: 1.214337]\n",
      "[Epoch 4/1000] [Batch 58/168] [D loss: 0.425134] [G loss: 4.859992]\n",
      "[Epoch 4/1000] [Batch 59/168] [D loss: 0.281919] [G loss: 1.154675]\n",
      "[Epoch 4/1000] [Batch 60/168] [D loss: 0.219347] [G loss: 4.449663]\n",
      "[Epoch 4/1000] [Batch 61/168] [D loss: 0.106439] [G loss: 2.589000]\n",
      "[Epoch 4/1000] [Batch 62/168] [D loss: 0.221931] [G loss: 1.444093]\n",
      "[Epoch 4/1000] [Batch 63/168] [D loss: 0.304334] [G loss: 4.506150]\n",
      "[Epoch 4/1000] [Batch 64/168] [D loss: 0.278234] [G loss: 1.208995]\n",
      "[Epoch 4/1000] [Batch 65/168] [D loss: 0.145247] [G loss: 4.360903]\n",
      "[Epoch 4/1000] [Batch 66/168] [D loss: 0.112208] [G loss: 2.768712]\n",
      "[Epoch 4/1000] [Batch 67/168] [D loss: 0.254650] [G loss: 1.289200]\n",
      "[Epoch 4/1000] [Batch 68/168] [D loss: 0.384957] [G loss: 5.657380]\n",
      "[Epoch 4/1000] [Batch 69/168] [D loss: 0.084023] [G loss: 2.442878]\n",
      "[Epoch 4/1000] [Batch 70/168] [D loss: 0.264957] [G loss: 1.088693]\n",
      "[Epoch 4/1000] [Batch 71/168] [D loss: 0.224612] [G loss: 6.612599]\n",
      "[Epoch 4/1000] [Batch 72/168] [D loss: 0.089855] [G loss: 5.105122]\n",
      "[Epoch 4/1000] [Batch 73/168] [D loss: 0.216864] [G loss: 1.415511]\n",
      "[Epoch 4/1000] [Batch 74/168] [D loss: 0.092027] [G loss: 3.088030]\n",
      "[Epoch 4/1000] [Batch 75/168] [D loss: 0.167733] [G loss: 2.329502]\n",
      "[Epoch 4/1000] [Batch 76/168] [D loss: 0.298272] [G loss: 1.232700]\n",
      "[Epoch 4/1000] [Batch 77/168] [D loss: 0.324007] [G loss: 4.585620]\n",
      "[Epoch 4/1000] [Batch 78/168] [D loss: 0.176089] [G loss: 1.483041]\n",
      "[Epoch 4/1000] [Batch 79/168] [D loss: 0.081261] [G loss: 2.972973]\n",
      "[Epoch 4/1000] [Batch 80/168] [D loss: 0.087108] [G loss: 3.068707]\n",
      "[Epoch 4/1000] [Batch 81/168] [D loss: 0.158239] [G loss: 1.727061]\n",
      "[Epoch 4/1000] [Batch 82/168] [D loss: 0.137023] [G loss: 3.151563]\n",
      "[Epoch 4/1000] [Batch 83/168] [D loss: 0.189191] [G loss: 1.654196]\n",
      "[Epoch 4/1000] [Batch 84/168] [D loss: 0.149496] [G loss: 2.795659]\n",
      "[Epoch 4/1000] [Batch 85/168] [D loss: 0.167892] [G loss: 1.786804]\n",
      "[Epoch 4/1000] [Batch 86/168] [D loss: 0.130123] [G loss: 3.123615]\n",
      "[Epoch 4/1000] [Batch 87/168] [D loss: 0.157453] [G loss: 2.350031]\n",
      "[Epoch 4/1000] [Batch 88/168] [D loss: 0.103851] [G loss: 2.421030]\n",
      "[Epoch 4/1000] [Batch 89/168] [D loss: 0.150564] [G loss: 2.594458]\n",
      "[Epoch 4/1000] [Batch 90/168] [D loss: 0.290885] [G loss: 1.302731]\n",
      "[Epoch 4/1000] [Batch 91/168] [D loss: 0.873138] [G loss: 6.063878]\n",
      "[Epoch 4/1000] [Batch 92/168] [D loss: 2.330565] [G loss: 0.017033]\n",
      "[Epoch 4/1000] [Batch 93/168] [D loss: 0.942533] [G loss: 11.076206]\n",
      "[Epoch 4/1000] [Batch 94/168] [D loss: 0.088582] [G loss: 8.206333]\n",
      "[Epoch 4/1000] [Batch 95/168] [D loss: 0.019264] [G loss: 4.451397]\n",
      "[Epoch 4/1000] [Batch 96/168] [D loss: 0.292194] [G loss: 1.347993]\n",
      "[Epoch 4/1000] [Batch 97/168] [D loss: 0.079103] [G loss: 2.631019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/1000] [Batch 98/168] [D loss: 0.092955] [G loss: 2.950293]\n",
      "[Epoch 4/1000] [Batch 99/168] [D loss: 0.145852] [G loss: 2.358581]\n",
      "[Epoch 4/1000] [Batch 100/168] [D loss: 0.207493] [G loss: 2.037093]\n",
      "[Epoch 4/1000] [Batch 101/168] [D loss: 0.193614] [G loss: 1.996884]\n",
      "[Epoch 4/1000] [Batch 102/168] [D loss: 0.148333] [G loss: 2.566558]\n",
      "[Epoch 4/1000] [Batch 103/168] [D loss: 0.216532] [G loss: 2.201509]\n",
      "[Epoch 4/1000] [Batch 104/168] [D loss: 0.223507] [G loss: 1.538852]\n",
      "[Epoch 4/1000] [Batch 105/168] [D loss: 0.197150] [G loss: 4.029507]\n",
      "[Epoch 4/1000] [Batch 106/168] [D loss: 0.211626] [G loss: 1.656307]\n",
      "[Epoch 4/1000] [Batch 107/168] [D loss: 0.132244] [G loss: 3.431985]\n",
      "[Epoch 4/1000] [Batch 108/168] [D loss: 0.179067] [G loss: 1.977303]\n",
      "[Epoch 4/1000] [Batch 109/168] [D loss: 0.185184] [G loss: 2.432978]\n",
      "[Epoch 4/1000] [Batch 110/168] [D loss: 0.137989] [G loss: 2.647769]\n",
      "[Epoch 4/1000] [Batch 111/168] [D loss: 0.172937] [G loss: 1.601495]\n",
      "[Epoch 4/1000] [Batch 112/168] [D loss: 0.281878] [G loss: 2.968549]\n",
      "[Epoch 4/1000] [Batch 113/168] [D loss: 0.454497] [G loss: 0.674346]\n",
      "[Epoch 4/1000] [Batch 114/168] [D loss: 1.068232] [G loss: 9.010788]\n",
      "[Epoch 4/1000] [Batch 115/168] [D loss: 0.030088] [G loss: 3.728646]\n",
      "[Epoch 4/1000] [Batch 116/168] [D loss: 0.432234] [G loss: 0.688141]\n",
      "[Epoch 4/1000] [Batch 117/168] [D loss: 0.040121] [G loss: 6.177845]\n",
      "[Epoch 4/1000] [Batch 118/168] [D loss: 0.129749] [G loss: 6.975316]\n",
      "[Epoch 4/1000] [Batch 119/168] [D loss: 0.057823] [G loss: 4.377348]\n",
      "[Epoch 4/1000] [Batch 120/168] [D loss: 0.165659] [G loss: 1.484398]\n",
      "[Epoch 4/1000] [Batch 121/168] [D loss: 0.103076] [G loss: 2.430225]\n",
      "[Epoch 4/1000] [Batch 122/168] [D loss: 0.126790] [G loss: 2.927196]\n",
      "[Epoch 4/1000] [Batch 123/168] [D loss: 0.190736] [G loss: 1.562560]\n",
      "[Epoch 4/1000] [Batch 124/168] [D loss: 0.255521] [G loss: 3.338370]\n",
      "[Epoch 4/1000] [Batch 125/168] [D loss: 0.292815] [G loss: 1.063231]\n",
      "[Epoch 4/1000] [Batch 126/168] [D loss: 0.281862] [G loss: 6.027867]\n",
      "[Epoch 4/1000] [Batch 127/168] [D loss: 0.093535] [G loss: 3.072918]\n",
      "[Epoch 4/1000] [Batch 128/168] [D loss: 0.442392] [G loss: 0.664453]\n",
      "[Epoch 4/1000] [Batch 129/168] [D loss: 0.547949] [G loss: 8.479841]\n",
      "[Epoch 4/1000] [Batch 130/168] [D loss: 0.072749] [G loss: 5.555212]\n",
      "[Epoch 4/1000] [Batch 131/168] [D loss: 0.281357] [G loss: 1.233636]\n",
      "[Epoch 4/1000] [Batch 132/168] [D loss: 0.063189] [G loss: 3.802428]\n",
      "[Epoch 4/1000] [Batch 133/168] [D loss: 0.139908] [G loss: 3.315097]\n",
      "[Epoch 4/1000] [Batch 134/168] [D loss: 0.269254] [G loss: 1.493867]\n",
      "[Epoch 4/1000] [Batch 135/168] [D loss: 0.209207] [G loss: 3.671021]\n",
      "[Epoch 4/1000] [Batch 136/168] [D loss: 0.235098] [G loss: 1.671210]\n",
      "[Epoch 4/1000] [Batch 137/168] [D loss: 0.109593] [G loss: 3.346946]\n",
      "[Epoch 4/1000] [Batch 138/168] [D loss: 0.111050] [G loss: 2.506041]\n",
      "[Epoch 4/1000] [Batch 139/168] [D loss: 0.121126] [G loss: 2.166782]\n",
      "[Epoch 4/1000] [Batch 140/168] [D loss: 0.112151] [G loss: 2.715853]\n",
      "[Epoch 4/1000] [Batch 141/168] [D loss: 0.149694] [G loss: 2.093631]\n",
      "[Epoch 4/1000] [Batch 142/168] [D loss: 0.105318] [G loss: 2.604174]\n",
      "[Epoch 4/1000] [Batch 143/168] [D loss: 0.133089] [G loss: 2.440497]\n",
      "[Epoch 4/1000] [Batch 144/168] [D loss: 0.165649] [G loss: 2.233589]\n",
      "[Epoch 4/1000] [Batch 145/168] [D loss: 0.151950] [G loss: 2.243938]\n",
      "[Epoch 4/1000] [Batch 146/168] [D loss: 0.153616] [G loss: 2.196928]\n",
      "[Epoch 4/1000] [Batch 147/168] [D loss: 0.119524] [G loss: 2.341957]\n",
      "[Epoch 4/1000] [Batch 148/168] [D loss: 0.146803] [G loss: 2.234337]\n",
      "[Epoch 4/1000] [Batch 149/168] [D loss: 0.228407] [G loss: 2.250707]\n",
      "[Epoch 4/1000] [Batch 150/168] [D loss: 0.379686] [G loss: 0.823637]\n",
      "[Epoch 4/1000] [Batch 151/168] [D loss: 1.207218] [G loss: 10.235374]\n",
      "[Epoch 4/1000] [Batch 152/168] [D loss: 0.068370] [G loss: 2.523660]\n",
      "[Epoch 4/1000] [Batch 153/168] [D loss: 0.916544] [G loss: 0.257206]\n",
      "[Epoch 4/1000] [Batch 154/168] [D loss: 0.666516] [G loss: 12.173469]\n",
      "[Epoch 4/1000] [Batch 155/168] [D loss: 0.148143] [G loss: 11.057969]\n",
      "[Epoch 4/1000] [Batch 156/168] [D loss: 0.017323] [G loss: 6.686790]\n",
      "[Epoch 4/1000] [Batch 157/168] [D loss: 0.243436] [G loss: 1.527284]\n",
      "[Epoch 4/1000] [Batch 158/168] [D loss: 0.162030] [G loss: 2.027873]\n",
      "[Epoch 4/1000] [Batch 159/168] [D loss: 0.215740] [G loss: 3.367792]\n",
      "[Epoch 4/1000] [Batch 160/168] [D loss: 0.313984] [G loss: 1.381386]\n",
      "[Epoch 4/1000] [Batch 161/168] [D loss: 0.207065] [G loss: 3.598726]\n",
      "[Epoch 4/1000] [Batch 162/168] [D loss: 0.276556] [G loss: 1.607756]\n",
      "[Epoch 4/1000] [Batch 163/168] [D loss: 0.110997] [G loss: 3.732198]\n",
      "[Epoch 4/1000] [Batch 164/168] [D loss: 0.095835] [G loss: 2.654174]\n",
      "[Epoch 4/1000] [Batch 165/168] [D loss: 0.177548] [G loss: 1.681220]\n",
      "[Epoch 4/1000] [Batch 166/168] [D loss: 0.099179] [G loss: 3.676245]\n",
      "[Epoch 4/1000] [Batch 167/168] [D loss: 0.148335] [G loss: 1.797411]\n",
      "[Epoch 4/1000] [Batch 168/168] [D loss: 0.120652] [G loss: 2.448297]\n",
      "[Epoch 5/1000] [Batch 1/168] [D loss: 0.194739] [G loss: 2.297244]\n",
      "[Epoch 5/1000] [Batch 2/168] [D loss: 0.201710] [G loss: 1.754035]\n",
      "[Epoch 5/1000] [Batch 3/168] [D loss: 0.153968] [G loss: 3.550705]\n",
      "[Epoch 5/1000] [Batch 4/168] [D loss: 0.168910] [G loss: 1.776587]\n",
      "[Epoch 5/1000] [Batch 5/168] [D loss: 0.102135] [G loss: 2.951265]\n",
      "[Epoch 5/1000] [Batch 6/168] [D loss: 0.172556] [G loss: 2.078065]\n",
      "[Epoch 5/1000] [Batch 7/168] [D loss: 0.219982] [G loss: 1.962788]\n",
      "[Epoch 5/1000] [Batch 8/168] [D loss: 0.153221] [G loss: 2.189774]\n",
      "[Epoch 5/1000] [Batch 9/168] [D loss: 0.176240] [G loss: 2.892673]\n",
      "[Epoch 5/1000] [Batch 10/168] [D loss: 0.299681] [G loss: 1.055231]\n",
      "[Epoch 5/1000] [Batch 11/168] [D loss: 0.318625] [G loss: 7.992637]\n",
      "[Epoch 5/1000] [Batch 12/168] [D loss: 0.049443] [G loss: 5.547927]\n",
      "[Epoch 5/1000] [Batch 13/168] [D loss: 0.121882] [G loss: 1.955496]\n",
      "[Epoch 5/1000] [Batch 14/168] [D loss: 0.071961] [G loss: 2.551648]\n",
      "[Epoch 5/1000] [Batch 15/168] [D loss: 0.071488] [G loss: 3.205726]\n",
      "[Epoch 5/1000] [Batch 16/168] [D loss: 0.179404] [G loss: 1.844374]\n",
      "[Epoch 5/1000] [Batch 17/168] [D loss: 0.380502] [G loss: 3.675017]\n",
      "[Epoch 5/1000] [Batch 18/168] [D loss: 1.083281] [G loss: 0.243799]\n",
      "[Epoch 5/1000] [Batch 19/168] [D loss: 1.911652] [G loss: 13.344553]\n",
      "[Epoch 5/1000] [Batch 20/168] [D loss: 0.101159] [G loss: 9.978397]\n",
      "[Epoch 5/1000] [Batch 21/168] [D loss: 0.007869] [G loss: 5.540232]\n",
      "[Epoch 5/1000] [Batch 22/168] [D loss: 0.183775] [G loss: 1.756585]\n",
      "[Epoch 5/1000] [Batch 23/168] [D loss: 0.140358] [G loss: 1.939250]\n",
      "[Epoch 5/1000] [Batch 24/168] [D loss: 0.042839] [G loss: 3.535318]\n",
      "[Epoch 5/1000] [Batch 25/168] [D loss: 0.068797] [G loss: 3.447284]\n",
      "[Epoch 5/1000] [Batch 26/168] [D loss: 0.177973] [G loss: 2.009780]\n",
      "[Epoch 5/1000] [Batch 27/168] [D loss: 0.191685] [G loss: 2.441716]\n",
      "[Epoch 5/1000] [Batch 28/168] [D loss: 0.182963] [G loss: 2.325873]\n",
      "[Epoch 5/1000] [Batch 29/168] [D loss: 0.165835] [G loss: 1.873487]\n",
      "[Epoch 5/1000] [Batch 30/168] [D loss: 0.108148] [G loss: 2.891222]\n",
      "[Epoch 5/1000] [Batch 31/168] [D loss: 0.102313] [G loss: 2.348648]\n",
      "[Epoch 5/1000] [Batch 32/168] [D loss: 0.090648] [G loss: 2.562041]\n",
      "[Epoch 5/1000] [Batch 33/168] [D loss: 0.113226] [G loss: 2.608305]\n",
      "[Epoch 5/1000] [Batch 34/168] [D loss: 0.119286] [G loss: 2.346755]\n",
      "[Epoch 5/1000] [Batch 35/168] [D loss: 0.138413] [G loss: 2.395238]\n",
      "[Epoch 5/1000] [Batch 36/168] [D loss: 0.113907] [G loss: 2.342442]\n",
      "[Epoch 5/1000] [Batch 37/168] [D loss: 0.158226] [G loss: 2.571568]\n",
      "[Epoch 5/1000] [Batch 38/168] [D loss: 0.124564] [G loss: 2.216569]\n",
      "[Epoch 5/1000] [Batch 39/168] [D loss: 0.115398] [G loss: 2.356055]\n",
      "[Epoch 5/1000] [Batch 40/168] [D loss: 0.120758] [G loss: 2.623634]\n",
      "[Epoch 5/1000] [Batch 41/168] [D loss: 0.205793] [G loss: 1.717610]\n",
      "[Epoch 5/1000] [Batch 42/168] [D loss: 0.191855] [G loss: 3.559487]\n",
      "[Epoch 5/1000] [Batch 43/168] [D loss: 0.257043] [G loss: 1.256770]\n",
      "[Epoch 5/1000] [Batch 44/168] [D loss: 0.180626] [G loss: 6.152795]\n",
      "[Epoch 5/1000] [Batch 45/168] [D loss: 0.078575] [G loss: 3.533369]\n",
      "[Epoch 5/1000] [Batch 46/168] [D loss: 0.711253] [G loss: 0.414907]\n",
      "[Epoch 5/1000] [Batch 47/168] [D loss: 1.895912] [G loss: 12.751161]\n",
      "[Epoch 5/1000] [Batch 48/168] [D loss: 0.062180] [G loss: 7.692778]\n",
      "[Epoch 5/1000] [Batch 49/168] [D loss: 0.189626] [G loss: 1.444530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/1000] [Batch 50/168] [D loss: 0.163641] [G loss: 1.557391]\n",
      "[Epoch 5/1000] [Batch 51/168] [D loss: 0.068743] [G loss: 4.313961]\n",
      "[Epoch 5/1000] [Batch 52/168] [D loss: 0.104183] [G loss: 2.883781]\n",
      "[Epoch 5/1000] [Batch 53/168] [D loss: 0.344848] [G loss: 1.154631]\n",
      "[Epoch 5/1000] [Batch 54/168] [D loss: 0.431050] [G loss: 5.026703]\n",
      "[Epoch 5/1000] [Batch 55/168] [D loss: 0.344766] [G loss: 0.885157]\n",
      "[Epoch 5/1000] [Batch 56/168] [D loss: 0.315052] [G loss: 6.656789]\n",
      "[Epoch 5/1000] [Batch 57/168] [D loss: 0.084407] [G loss: 3.343317]\n",
      "[Epoch 5/1000] [Batch 58/168] [D loss: 0.582495] [G loss: 0.513902]\n",
      "[Epoch 5/1000] [Batch 59/168] [D loss: 0.857982] [G loss: 9.640777]\n",
      "[Epoch 5/1000] [Batch 60/168] [D loss: 0.112874] [G loss: 6.407118]\n",
      "[Epoch 5/1000] [Batch 61/168] [D loss: 0.271085] [G loss: 1.432903]\n",
      "[Epoch 5/1000] [Batch 62/168] [D loss: 0.062114] [G loss: 2.905620]\n",
      "[Epoch 5/1000] [Batch 63/168] [D loss: 0.110289] [G loss: 3.167704]\n",
      "[Epoch 5/1000] [Batch 64/168] [D loss: 0.198572] [G loss: 2.130437]\n",
      "[Epoch 5/1000] [Batch 65/168] [D loss: 0.167659] [G loss: 2.170797]\n",
      "[Epoch 5/1000] [Batch 66/168] [D loss: 0.140186] [G loss: 2.755886]\n",
      "[Epoch 5/1000] [Batch 67/168] [D loss: 0.181603] [G loss: 2.200690]\n",
      "[Epoch 5/1000] [Batch 68/168] [D loss: 0.143819] [G loss: 2.256941]\n",
      "[Epoch 5/1000] [Batch 69/168] [D loss: 0.120425] [G loss: 2.539018]\n",
      "[Epoch 5/1000] [Batch 70/168] [D loss: 0.095206] [G loss: 2.499523]\n",
      "[Epoch 5/1000] [Batch 71/168] [D loss: 0.153005] [G loss: 2.349902]\n",
      "[Epoch 5/1000] [Batch 72/168] [D loss: 0.136217] [G loss: 1.989098]\n",
      "[Epoch 5/1000] [Batch 73/168] [D loss: 0.180494] [G loss: 2.732929]\n",
      "[Epoch 5/1000] [Batch 74/168] [D loss: 0.183845] [G loss: 1.506842]\n",
      "[Epoch 5/1000] [Batch 75/168] [D loss: 0.137879] [G loss: 4.076936]\n",
      "[Epoch 5/1000] [Batch 76/168] [D loss: 0.109972] [G loss: 2.311697]\n",
      "[Epoch 5/1000] [Batch 77/168] [D loss: 0.191221] [G loss: 1.458540]\n",
      "[Epoch 5/1000] [Batch 78/168] [D loss: 0.275121] [G loss: 4.885949]\n",
      "[Epoch 5/1000] [Batch 79/168] [D loss: 0.305655] [G loss: 1.035836]\n",
      "[Epoch 5/1000] [Batch 80/168] [D loss: 0.280687] [G loss: 6.427826]\n",
      "[Epoch 5/1000] [Batch 81/168] [D loss: 0.059145] [G loss: 3.682549]\n",
      "[Epoch 5/1000] [Batch 82/168] [D loss: 0.338968] [G loss: 0.857629]\n",
      "[Epoch 5/1000] [Batch 83/168] [D loss: 0.258936] [G loss: 7.435412]\n",
      "[Epoch 5/1000] [Batch 84/168] [D loss: 0.161210] [G loss: 5.426798]\n",
      "[Epoch 5/1000] [Batch 85/168] [D loss: 0.451519] [G loss: 0.691444]\n",
      "[Epoch 5/1000] [Batch 86/168] [D loss: 0.222089] [G loss: 7.457402]\n",
      "[Epoch 5/1000] [Batch 87/168] [D loss: 0.091093] [G loss: 6.351909]\n",
      "[Epoch 5/1000] [Batch 88/168] [D loss: 0.099147] [G loss: 2.144039]\n",
      "[Epoch 5/1000] [Batch 89/168] [D loss: 0.134647] [G loss: 1.808319]\n",
      "[Epoch 5/1000] [Batch 90/168] [D loss: 0.104192] [G loss: 3.919081]\n",
      "[Epoch 5/1000] [Batch 91/168] [D loss: 0.121992] [G loss: 2.692787]\n",
      "[Epoch 5/1000] [Batch 92/168] [D loss: 0.195971] [G loss: 1.557476]\n",
      "[Epoch 5/1000] [Batch 93/168] [D loss: 0.312338] [G loss: 3.804781]\n",
      "[Epoch 5/1000] [Batch 94/168] [D loss: 0.523334] [G loss: 0.601194]\n",
      "[Epoch 5/1000] [Batch 95/168] [D loss: 1.043091] [G loss: 10.233631]\n",
      "[Epoch 5/1000] [Batch 96/168] [D loss: 0.014107] [G loss: 5.277615]\n",
      "[Epoch 5/1000] [Batch 97/168] [D loss: 0.275661] [G loss: 1.181435]\n",
      "[Epoch 5/1000] [Batch 98/168] [D loss: 0.030458] [G loss: 3.630615]\n",
      "[Epoch 5/1000] [Batch 99/168] [D loss: 0.064667] [G loss: 3.935173]\n",
      "[Epoch 5/1000] [Batch 100/168] [D loss: 0.126134] [G loss: 2.122923]\n",
      "[Epoch 5/1000] [Batch 101/168] [D loss: 0.199488] [G loss: 1.943010]\n",
      "[Epoch 5/1000] [Batch 102/168] [D loss: 0.246252] [G loss: 2.773175]\n",
      "[Epoch 5/1000] [Batch 103/168] [D loss: 0.265874] [G loss: 1.274744]\n",
      "[Epoch 5/1000] [Batch 104/168] [D loss: 0.244963] [G loss: 4.855897]\n",
      "[Epoch 5/1000] [Batch 105/168] [D loss: 0.109656] [G loss: 2.351001]\n",
      "[Epoch 5/1000] [Batch 106/168] [D loss: 0.212392] [G loss: 1.328891]\n",
      "[Epoch 5/1000] [Batch 107/168] [D loss: 0.246277] [G loss: 5.579806]\n",
      "[Epoch 5/1000] [Batch 108/168] [D loss: 0.117425] [G loss: 2.220662]\n",
      "[Epoch 5/1000] [Batch 109/168] [D loss: 0.304181] [G loss: 1.129380]\n",
      "[Epoch 5/1000] [Batch 110/168] [D loss: 0.443538] [G loss: 6.446869]\n",
      "[Epoch 5/1000] [Batch 111/168] [D loss: 0.165646] [G loss: 1.738198]\n",
      "[Epoch 5/1000] [Batch 112/168] [D loss: 0.183972] [G loss: 1.999937]\n",
      "[Epoch 5/1000] [Batch 113/168] [D loss: 0.152684] [G loss: 2.219158]\n",
      "[Epoch 5/1000] [Batch 114/168] [D loss: 0.186454] [G loss: 2.213031]\n",
      "[Epoch 5/1000] [Batch 115/168] [D loss: 0.289750] [G loss: 1.827856]\n",
      "[Epoch 5/1000] [Batch 116/168] [D loss: 0.171592] [G loss: 2.443616]\n",
      "[Epoch 5/1000] [Batch 117/168] [D loss: 0.309758] [G loss: 1.262070]\n",
      "[Epoch 5/1000] [Batch 118/168] [D loss: 0.453995] [G loss: 6.447557]\n",
      "[Epoch 5/1000] [Batch 119/168] [D loss: 0.212467] [G loss: 1.381482]\n",
      "[Epoch 5/1000] [Batch 120/168] [D loss: 0.047240] [G loss: 3.756925]\n",
      "[Epoch 5/1000] [Batch 121/168] [D loss: 0.089029] [G loss: 3.491211]\n",
      "[Epoch 5/1000] [Batch 122/168] [D loss: 0.173782] [G loss: 1.713633]\n",
      "[Epoch 5/1000] [Batch 123/168] [D loss: 0.157663] [G loss: 3.872899]\n",
      "[Epoch 5/1000] [Batch 124/168] [D loss: 0.190888] [G loss: 2.115811]\n",
      "[Epoch 5/1000] [Batch 125/168] [D loss: 0.173241] [G loss: 2.022248]\n",
      "[Epoch 5/1000] [Batch 126/168] [D loss: 0.093767] [G loss: 3.220410]\n",
      "[Epoch 5/1000] [Batch 127/168] [D loss: 0.139257] [G loss: 2.295118]\n",
      "[Epoch 5/1000] [Batch 128/168] [D loss: 0.100589] [G loss: 2.479007]\n",
      "[Epoch 5/1000] [Batch 129/168] [D loss: 0.131242] [G loss: 2.819622]\n",
      "[Epoch 5/1000] [Batch 130/168] [D loss: 0.233967] [G loss: 1.513900]\n",
      "[Epoch 5/1000] [Batch 131/168] [D loss: 0.286970] [G loss: 5.063103]\n",
      "[Epoch 5/1000] [Batch 132/168] [D loss: 0.418261] [G loss: 0.717324]\n",
      "[Epoch 5/1000] [Batch 133/168] [D loss: 0.777667] [G loss: 10.150511]\n",
      "[Epoch 5/1000] [Batch 134/168] [D loss: 0.033314] [G loss: 4.672744]\n",
      "[Epoch 5/1000] [Batch 135/168] [D loss: 0.710743] [G loss: 0.435410]\n",
      "[Epoch 5/1000] [Batch 136/168] [D loss: 0.382952] [G loss: 9.502665]\n",
      "[Epoch 5/1000] [Batch 137/168] [D loss: 0.248517] [G loss: 8.546603]\n",
      "[Epoch 5/1000] [Batch 138/168] [D loss: 0.048799] [G loss: 3.681365]\n",
      "[Epoch 5/1000] [Batch 139/168] [D loss: 0.639886] [G loss: 0.479651]\n",
      "[Epoch 5/1000] [Batch 140/168] [D loss: 0.348372] [G loss: 7.599344]\n",
      "[Epoch 5/1000] [Batch 141/168] [D loss: 0.177486] [G loss: 7.082800]\n",
      "[Epoch 5/1000] [Batch 142/168] [D loss: 0.031643] [G loss: 3.844640]\n",
      "[Epoch 5/1000] [Batch 143/168] [D loss: 0.300144] [G loss: 1.091426]\n",
      "[Epoch 5/1000] [Batch 144/168] [D loss: 0.064563] [G loss: 4.687040]\n",
      "[Epoch 5/1000] [Batch 145/168] [D loss: 0.099932] [G loss: 4.631769]\n",
      "[Epoch 5/1000] [Batch 146/168] [D loss: 0.107198] [G loss: 2.300580]\n",
      "[Epoch 5/1000] [Batch 147/168] [D loss: 0.182615] [G loss: 1.513053]\n",
      "[Epoch 5/1000] [Batch 148/168] [D loss: 0.162395] [G loss: 4.008681]\n",
      "[Epoch 5/1000] [Batch 149/168] [D loss: 0.126469] [G loss: 2.243356]\n",
      "[Epoch 5/1000] [Batch 150/168] [D loss: 0.185621] [G loss: 1.842270]\n",
      "[Epoch 5/1000] [Batch 151/168] [D loss: 0.117146] [G loss: 3.069404]\n",
      "[Epoch 5/1000] [Batch 152/168] [D loss: 0.176793] [G loss: 1.933610]\n",
      "[Epoch 5/1000] [Batch 153/168] [D loss: 0.140936] [G loss: 2.543630]\n",
      "[Epoch 5/1000] [Batch 154/168] [D loss: 0.148566] [G loss: 2.324336]\n",
      "[Epoch 5/1000] [Batch 155/168] [D loss: 0.114231] [G loss: 2.303603]\n",
      "[Epoch 5/1000] [Batch 156/168] [D loss: 0.149467] [G loss: 2.742601]\n",
      "[Epoch 5/1000] [Batch 157/168] [D loss: 0.181224] [G loss: 1.622077]\n",
      "[Epoch 5/1000] [Batch 158/168] [D loss: 0.270534] [G loss: 3.600370]\n",
      "[Epoch 5/1000] [Batch 159/168] [D loss: 0.561992] [G loss: 0.494011]\n",
      "[Epoch 5/1000] [Batch 160/168] [D loss: 1.273479] [G loss: 11.796802]\n",
      "[Epoch 5/1000] [Batch 161/168] [D loss: 0.030223] [G loss: 7.905428]\n",
      "[Epoch 5/1000] [Batch 162/168] [D loss: 0.022396] [G loss: 3.477592]\n",
      "[Epoch 5/1000] [Batch 163/168] [D loss: 0.409814] [G loss: 0.692835]\n",
      "[Epoch 5/1000] [Batch 164/168] [D loss: 0.035541] [G loss: 6.801208]\n",
      "[Epoch 5/1000] [Batch 165/168] [D loss: 0.194356] [G loss: 7.952632]\n",
      "[Epoch 5/1000] [Batch 166/168] [D loss: 0.072327] [G loss: 5.498298]\n",
      "[Epoch 5/1000] [Batch 167/168] [D loss: 0.106151] [G loss: 2.219219]\n",
      "[Epoch 5/1000] [Batch 168/168] [D loss: 0.172212] [G loss: 1.544071]\n",
      "[Epoch 6/1000] [Batch 1/168] [D loss: 0.103985] [G loss: 4.147916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/1000] [Batch 2/168] [D loss: 0.097381] [G loss: 3.057808]\n",
      "[Epoch 6/1000] [Batch 3/168] [D loss: 0.297406] [G loss: 1.192599]\n",
      "[Epoch 6/1000] [Batch 4/168] [D loss: 0.215122] [G loss: 4.605447]\n",
      "[Epoch 6/1000] [Batch 5/168] [D loss: 0.149586] [G loss: 1.950171]\n",
      "[Epoch 6/1000] [Batch 6/168] [D loss: 0.128105] [G loss: 2.362990]\n",
      "[Epoch 6/1000] [Batch 7/168] [D loss: 0.126540] [G loss: 2.800794]\n",
      "[Epoch 6/1000] [Batch 8/168] [D loss: 0.204577] [G loss: 1.708415]\n",
      "[Epoch 6/1000] [Batch 9/168] [D loss: 0.125361] [G loss: 3.967901]\n",
      "[Epoch 6/1000] [Batch 10/168] [D loss: 0.190189] [G loss: 1.609174]\n",
      "[Epoch 6/1000] [Batch 11/168] [D loss: 0.186035] [G loss: 5.664993]\n",
      "[Epoch 6/1000] [Batch 12/168] [D loss: 0.065329] [G loss: 2.708710]\n",
      "[Epoch 6/1000] [Batch 13/168] [D loss: 0.141693] [G loss: 1.720628]\n",
      "[Epoch 6/1000] [Batch 14/168] [D loss: 0.090448] [G loss: 5.974174]\n",
      "[Epoch 6/1000] [Batch 15/168] [D loss: 0.057828] [G loss: 4.536985]\n",
      "[Epoch 6/1000] [Batch 16/168] [D loss: 0.171967] [G loss: 1.691411]\n",
      "[Epoch 6/1000] [Batch 17/168] [D loss: 0.125638] [G loss: 3.537090]\n",
      "[Epoch 6/1000] [Batch 18/168] [D loss: 0.224314] [G loss: 1.772017]\n",
      "[Epoch 6/1000] [Batch 19/168] [D loss: 0.166254] [G loss: 3.732010]\n",
      "[Epoch 6/1000] [Batch 20/168] [D loss: 0.313284] [G loss: 1.015658]\n",
      "[Epoch 6/1000] [Batch 21/168] [D loss: 0.554788] [G loss: 8.810192]\n",
      "[Epoch 6/1000] [Batch 22/168] [D loss: 0.019077] [G loss: 4.329258]\n",
      "[Epoch 6/1000] [Batch 23/168] [D loss: 0.589638] [G loss: 0.560931]\n",
      "[Epoch 6/1000] [Batch 24/168] [D loss: 0.503095] [G loss: 10.895162]\n",
      "[Epoch 6/1000] [Batch 25/168] [D loss: 0.114879] [G loss: 8.680342]\n",
      "[Epoch 6/1000] [Batch 26/168] [D loss: 0.031200] [G loss: 3.590159]\n",
      "[Epoch 6/1000] [Batch 27/168] [D loss: 0.734274] [G loss: 0.395433]\n",
      "[Epoch 6/1000] [Batch 28/168] [D loss: 0.689636] [G loss: 9.977596]\n",
      "[Epoch 6/1000] [Batch 29/168] [D loss: 0.129845] [G loss: 8.397430]\n",
      "[Epoch 6/1000] [Batch 30/168] [D loss: 0.024424] [G loss: 3.947769]\n",
      "[Epoch 6/1000] [Batch 31/168] [D loss: 0.593170] [G loss: 0.506555]\n",
      "[Epoch 6/1000] [Batch 32/168] [D loss: 0.379466] [G loss: 8.538359]\n",
      "[Epoch 6/1000] [Batch 33/168] [D loss: 0.152249] [G loss: 7.348498]\n",
      "[Epoch 6/1000] [Batch 34/168] [D loss: 0.033370] [G loss: 3.521779]\n",
      "[Epoch 6/1000] [Batch 35/168] [D loss: 0.469445] [G loss: 0.750066]\n",
      "[Epoch 6/1000] [Batch 36/168] [D loss: 0.255524] [G loss: 7.351558]\n",
      "[Epoch 6/1000] [Batch 37/168] [D loss: 0.140991] [G loss: 6.514054]\n",
      "[Epoch 6/1000] [Batch 38/168] [D loss: 0.071699] [G loss: 2.846704]\n",
      "[Epoch 6/1000] [Batch 39/168] [D loss: 0.360812] [G loss: 0.991873]\n",
      "[Epoch 6/1000] [Batch 40/168] [D loss: 0.304657] [G loss: 6.608382]\n",
      "[Epoch 6/1000] [Batch 41/168] [D loss: 0.053269] [G loss: 4.477278]\n",
      "[Epoch 6/1000] [Batch 42/168] [D loss: 0.232340] [G loss: 1.329607]\n",
      "[Epoch 6/1000] [Batch 43/168] [D loss: 0.115248] [G loss: 4.514948]\n",
      "[Epoch 6/1000] [Batch 44/168] [D loss: 0.077343] [G loss: 3.418341]\n",
      "[Epoch 6/1000] [Batch 45/168] [D loss: 0.215520] [G loss: 1.401195]\n",
      "[Epoch 6/1000] [Batch 46/168] [D loss: 0.172029] [G loss: 4.697289]\n",
      "[Epoch 6/1000] [Batch 47/168] [D loss: 0.115883] [G loss: 2.476205]\n",
      "[Epoch 6/1000] [Batch 48/168] [D loss: 0.203652] [G loss: 1.561538]\n",
      "[Epoch 6/1000] [Batch 49/168] [D loss: 0.166775] [G loss: 5.019020]\n",
      "[Epoch 6/1000] [Batch 50/168] [D loss: 0.098575] [G loss: 2.724354]\n",
      "[Epoch 6/1000] [Batch 51/168] [D loss: 0.335741] [G loss: 1.046297]\n",
      "[Epoch 6/1000] [Batch 52/168] [D loss: 0.465875] [G loss: 7.477506]\n",
      "[Epoch 6/1000] [Batch 53/168] [D loss: 0.064222] [G loss: 3.533765]\n",
      "[Epoch 6/1000] [Batch 54/168] [D loss: 0.642249] [G loss: 0.434844]\n",
      "[Epoch 6/1000] [Batch 55/168] [D loss: 0.676709] [G loss: 10.711779]\n",
      "[Epoch 6/1000] [Batch 56/168] [D loss: 0.069900] [G loss: 9.016472]\n",
      "[Epoch 6/1000] [Batch 57/168] [D loss: 0.009158] [G loss: 5.592089]\n",
      "[Epoch 6/1000] [Batch 58/168] [D loss: 0.133819] [G loss: 1.687572]\n",
      "[Epoch 6/1000] [Batch 59/168] [D loss: 0.118202] [G loss: 1.961464]\n",
      "[Epoch 6/1000] [Batch 60/168] [D loss: 0.062864] [G loss: 3.873733]\n",
      "[Epoch 6/1000] [Batch 61/168] [D loss: 0.091597] [G loss: 3.089628]\n",
      "[Epoch 6/1000] [Batch 62/168] [D loss: 0.191271] [G loss: 1.804817]\n",
      "[Epoch 6/1000] [Batch 63/168] [D loss: 0.145587] [G loss: 2.965525]\n",
      "[Epoch 6/1000] [Batch 64/168] [D loss: 0.172515] [G loss: 2.047074]\n",
      "[Epoch 6/1000] [Batch 65/168] [D loss: 0.128360] [G loss: 2.938930]\n",
      "[Epoch 6/1000] [Batch 66/168] [D loss: 0.161138] [G loss: 1.896796]\n",
      "[Epoch 6/1000] [Batch 67/168] [D loss: 0.147727] [G loss: 3.596474]\n",
      "[Epoch 6/1000] [Batch 68/168] [D loss: 0.258219] [G loss: 1.517173]\n",
      "[Epoch 6/1000] [Batch 69/168] [D loss: 0.190439] [G loss: 4.544929]\n",
      "[Epoch 6/1000] [Batch 70/168] [D loss: 0.203171] [G loss: 1.486031]\n",
      "[Epoch 6/1000] [Batch 71/168] [D loss: 0.128570] [G loss: 5.034371]\n",
      "[Epoch 6/1000] [Batch 72/168] [D loss: 0.077925] [G loss: 2.980481]\n",
      "[Epoch 6/1000] [Batch 73/168] [D loss: 0.228125] [G loss: 1.267844]\n",
      "[Epoch 6/1000] [Batch 74/168] [D loss: 0.244585] [G loss: 6.348781]\n",
      "[Epoch 6/1000] [Batch 75/168] [D loss: 0.090153] [G loss: 3.772998]\n",
      "[Epoch 6/1000] [Batch 76/168] [D loss: 0.458558] [G loss: 0.649375]\n",
      "[Epoch 6/1000] [Batch 77/168] [D loss: 0.667433] [G loss: 9.550744]\n",
      "[Epoch 6/1000] [Batch 78/168] [D loss: 0.050466] [G loss: 6.861294]\n",
      "[Epoch 6/1000] [Batch 79/168] [D loss: 0.042062] [G loss: 3.170872]\n",
      "[Epoch 6/1000] [Batch 80/168] [D loss: 0.254285] [G loss: 1.263982]\n",
      "[Epoch 6/1000] [Batch 81/168] [D loss: 0.034973] [G loss: 5.225803]\n",
      "[Epoch 6/1000] [Batch 82/168] [D loss: 0.070557] [G loss: 5.297386]\n",
      "[Epoch 6/1000] [Batch 83/168] [D loss: 0.099201] [G loss: 2.868823]\n",
      "[Epoch 6/1000] [Batch 84/168] [D loss: 0.318836] [G loss: 1.122919]\n",
      "[Epoch 6/1000] [Batch 85/168] [D loss: 0.409348] [G loss: 5.447383]\n",
      "[Epoch 6/1000] [Batch 86/168] [D loss: 0.144318] [G loss: 2.451211]\n",
      "[Epoch 6/1000] [Batch 87/168] [D loss: 0.272196] [G loss: 1.340746]\n",
      "[Epoch 6/1000] [Batch 88/168] [D loss: 0.134299] [G loss: 5.126633]\n",
      "[Epoch 6/1000] [Batch 89/168] [D loss: 0.103196] [G loss: 3.785654]\n",
      "[Epoch 6/1000] [Batch 90/168] [D loss: 0.234052] [G loss: 1.598845]\n",
      "[Epoch 6/1000] [Batch 91/168] [D loss: 0.117172] [G loss: 3.130167]\n",
      "[Epoch 6/1000] [Batch 92/168] [D loss: 0.135830] [G loss: 2.814936]\n",
      "[Epoch 6/1000] [Batch 93/168] [D loss: 0.150927] [G loss: 2.013712]\n",
      "[Epoch 6/1000] [Batch 94/168] [D loss: 0.114516] [G loss: 2.787450]\n",
      "[Epoch 6/1000] [Batch 95/168] [D loss: 0.110890] [G loss: 2.352711]\n",
      "[Epoch 6/1000] [Batch 96/168] [D loss: 0.134306] [G loss: 2.513792]\n",
      "[Epoch 6/1000] [Batch 97/168] [D loss: 0.180019] [G loss: 2.399895]\n",
      "[Epoch 6/1000] [Batch 98/168] [D loss: 0.177310] [G loss: 2.165486]\n",
      "[Epoch 6/1000] [Batch 99/168] [D loss: 0.088683] [G loss: 2.729942]\n",
      "[Epoch 6/1000] [Batch 100/168] [D loss: 0.192500] [G loss: 2.330870]\n",
      "[Epoch 6/1000] [Batch 101/168] [D loss: 0.154766] [G loss: 2.149862]\n",
      "[Epoch 6/1000] [Batch 102/168] [D loss: 0.134864] [G loss: 3.078609]\n",
      "[Epoch 6/1000] [Batch 103/168] [D loss: 0.172644] [G loss: 1.874857]\n",
      "[Epoch 6/1000] [Batch 104/168] [D loss: 0.160891] [G loss: 3.445928]\n",
      "[Epoch 6/1000] [Batch 105/168] [D loss: 0.164134] [G loss: 1.886973]\n",
      "[Epoch 6/1000] [Batch 106/168] [D loss: 0.124510] [G loss: 2.919923]\n",
      "[Epoch 6/1000] [Batch 107/168] [D loss: 0.122988] [G loss: 2.299703]\n",
      "[Epoch 6/1000] [Batch 108/168] [D loss: 0.171609] [G loss: 2.767953]\n",
      "[Epoch 6/1000] [Batch 109/168] [D loss: 0.142662] [G loss: 2.205424]\n",
      "[Epoch 6/1000] [Batch 110/168] [D loss: 0.105855] [G loss: 3.365973]\n",
      "[Epoch 6/1000] [Batch 111/168] [D loss: 0.135346] [G loss: 2.111917]\n",
      "[Epoch 6/1000] [Batch 112/168] [D loss: 0.087978] [G loss: 2.675703]\n",
      "[Epoch 6/1000] [Batch 113/168] [D loss: 0.133649] [G loss: 2.504798]\n",
      "[Epoch 6/1000] [Batch 114/168] [D loss: 0.146220] [G loss: 2.230749]\n",
      "[Epoch 6/1000] [Batch 115/168] [D loss: 0.191376] [G loss: 2.510439]\n",
      "[Epoch 6/1000] [Batch 116/168] [D loss: 0.161461] [G loss: 1.939484]\n",
      "[Epoch 6/1000] [Batch 117/168] [D loss: 0.147590] [G loss: 3.521258]\n",
      "[Epoch 6/1000] [Batch 118/168] [D loss: 0.265323] [G loss: 1.117131]\n",
      "[Epoch 6/1000] [Batch 119/168] [D loss: 0.414750] [G loss: 8.980338]\n",
      "[Epoch 6/1000] [Batch 120/168] [D loss: 0.037118] [G loss: 5.625037]\n",
      "[Epoch 6/1000] [Batch 121/168] [D loss: 0.244196] [G loss: 1.151643]\n",
      "[Epoch 6/1000] [Batch 122/168] [D loss: 0.100468] [G loss: 6.943185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/1000] [Batch 123/168] [D loss: 0.065908] [G loss: 5.977565]\n",
      "[Epoch 6/1000] [Batch 124/168] [D loss: 0.120427] [G loss: 2.216386]\n",
      "[Epoch 6/1000] [Batch 125/168] [D loss: 0.165725] [G loss: 1.857746]\n",
      "[Epoch 6/1000] [Batch 126/168] [D loss: 0.298537] [G loss: 4.597250]\n",
      "[Epoch 6/1000] [Batch 127/168] [D loss: 0.232497] [G loss: 1.282205]\n",
      "[Epoch 6/1000] [Batch 128/168] [D loss: 0.155188] [G loss: 7.241410]\n",
      "[Epoch 6/1000] [Batch 129/168] [D loss: 0.058159] [G loss: 5.482028]\n",
      "[Epoch 6/1000] [Batch 130/168] [D loss: 0.102064] [G loss: 2.124258]\n",
      "[Epoch 6/1000] [Batch 131/168] [D loss: 0.045093] [G loss: 3.151279]\n",
      "[Epoch 6/1000] [Batch 132/168] [D loss: 0.078050] [G loss: 3.011839]\n",
      "[Epoch 6/1000] [Batch 133/168] [D loss: 0.134563] [G loss: 2.004161]\n",
      "[Epoch 6/1000] [Batch 134/168] [D loss: 0.196771] [G loss: 3.227151]\n",
      "[Epoch 6/1000] [Batch 135/168] [D loss: 0.339193] [G loss: 0.852756]\n",
      "[Epoch 6/1000] [Batch 136/168] [D loss: 0.653623] [G loss: 9.790582]\n",
      "[Epoch 6/1000] [Batch 137/168] [D loss: 0.015705] [G loss: 4.904312]\n",
      "[Epoch 6/1000] [Batch 138/168] [D loss: 0.655031] [G loss: 0.510567]\n",
      "[Epoch 6/1000] [Batch 139/168] [D loss: 0.509717] [G loss: 11.518069]\n",
      "[Epoch 6/1000] [Batch 140/168] [D loss: 0.052740] [G loss: 9.475134]\n",
      "[Epoch 6/1000] [Batch 141/168] [D loss: 0.010812] [G loss: 5.719588]\n",
      "[Epoch 6/1000] [Batch 142/168] [D loss: 0.122727] [G loss: 2.171865]\n",
      "[Epoch 6/1000] [Batch 143/168] [D loss: 0.062803] [G loss: 2.619570]\n",
      "[Epoch 6/1000] [Batch 144/168] [D loss: 0.061762] [G loss: 3.525501]\n",
      "[Epoch 6/1000] [Batch 145/168] [D loss: 0.142669] [G loss: 2.640066]\n",
      "[Epoch 6/1000] [Batch 146/168] [D loss: 0.166798] [G loss: 1.783644]\n",
      "[Epoch 6/1000] [Batch 147/168] [D loss: 0.177272] [G loss: 4.497591]\n",
      "[Epoch 6/1000] [Batch 148/168] [D loss: 0.149630] [G loss: 1.900714]\n",
      "[Epoch 6/1000] [Batch 149/168] [D loss: 0.079275] [G loss: 3.567847]\n",
      "[Epoch 6/1000] [Batch 150/168] [D loss: 0.103508] [G loss: 2.630349]\n",
      "[Epoch 6/1000] [Batch 151/168] [D loss: 0.175302] [G loss: 1.881076]\n",
      "[Epoch 6/1000] [Batch 152/168] [D loss: 0.129505] [G loss: 4.375250]\n",
      "[Epoch 6/1000] [Batch 153/168] [D loss: 0.173610] [G loss: 1.810472]\n",
      "[Epoch 6/1000] [Batch 154/168] [D loss: 0.155776] [G loss: 4.162719]\n",
      "[Epoch 6/1000] [Batch 155/168] [D loss: 0.215450] [G loss: 1.548381]\n",
      "[Epoch 6/1000] [Batch 156/168] [D loss: 0.140583] [G loss: 5.113162]\n",
      "[Epoch 6/1000] [Batch 157/168] [D loss: 0.142458] [G loss: 2.035208]\n",
      "[Epoch 6/1000] [Batch 158/168] [D loss: 0.151318] [G loss: 3.199798]\n",
      "[Epoch 6/1000] [Batch 159/168] [D loss: 0.310010] [G loss: 1.190594]\n",
      "[Epoch 6/1000] [Batch 160/168] [D loss: 0.483384] [G loss: 7.970726]\n",
      "[Epoch 6/1000] [Batch 161/168] [D loss: 0.057747] [G loss: 3.367738]\n",
      "[Epoch 6/1000] [Batch 162/168] [D loss: 0.511748] [G loss: 0.935031]\n",
      "[Epoch 6/1000] [Batch 163/168] [D loss: 0.379384] [G loss: 9.265060]\n",
      "[Epoch 6/1000] [Batch 164/168] [D loss: 0.109051] [G loss: 7.215273]\n",
      "[Epoch 6/1000] [Batch 165/168] [D loss: 0.076169] [G loss: 2.769743]\n",
      "[Epoch 6/1000] [Batch 166/168] [D loss: 0.220113] [G loss: 1.457347]\n",
      "[Epoch 6/1000] [Batch 167/168] [D loss: 0.100106] [G loss: 4.765252]\n",
      "[Epoch 6/1000] [Batch 168/168] [D loss: 0.109510] [G loss: 4.074900]\n",
      "[Epoch 7/1000] [Batch 1/168] [D loss: 0.240264] [G loss: 1.543401]\n",
      "[Epoch 7/1000] [Batch 2/168] [D loss: 0.198172] [G loss: 4.940592]\n",
      "[Epoch 7/1000] [Batch 3/168] [D loss: 0.092353] [G loss: 2.938776]\n",
      "[Epoch 7/1000] [Batch 4/168] [D loss: 0.235996] [G loss: 1.484560]\n",
      "[Epoch 7/1000] [Batch 5/168] [D loss: 0.158550] [G loss: 5.999227]\n",
      "[Epoch 7/1000] [Batch 6/168] [D loss: 0.085271] [G loss: 4.103831]\n",
      "[Epoch 7/1000] [Batch 7/168] [D loss: 0.515197] [G loss: 0.833809]\n",
      "[Epoch 7/1000] [Batch 8/168] [D loss: 0.901826] [G loss: 10.175920]\n",
      "[Epoch 7/1000] [Batch 9/168] [D loss: 0.040670] [G loss: 5.095785]\n",
      "[Epoch 7/1000] [Batch 10/168] [D loss: 0.536980] [G loss: 0.839251]\n",
      "[Epoch 7/1000] [Batch 11/168] [D loss: 0.096108] [G loss: 7.634648]\n",
      "[Epoch 7/1000] [Batch 12/168] [D loss: 0.131535] [G loss: 7.647205]\n",
      "[Epoch 7/1000] [Batch 13/168] [D loss: 0.071509] [G loss: 4.537556]\n",
      "[Epoch 7/1000] [Batch 14/168] [D loss: 0.350644] [G loss: 1.057969]\n",
      "[Epoch 7/1000] [Batch 15/168] [D loss: 0.231916] [G loss: 5.728451]\n",
      "[Epoch 7/1000] [Batch 16/168] [D loss: 0.077346] [G loss: 4.609257]\n",
      "[Epoch 7/1000] [Batch 17/168] [D loss: 0.134573] [G loss: 1.787357]\n",
      "[Epoch 7/1000] [Batch 18/168] [D loss: 0.070967] [G loss: 2.931988]\n",
      "[Epoch 7/1000] [Batch 19/168] [D loss: 0.104211] [G loss: 2.980363]\n",
      "[Epoch 7/1000] [Batch 20/168] [D loss: 0.153547] [G loss: 1.976729]\n",
      "[Epoch 7/1000] [Batch 21/168] [D loss: 0.123493] [G loss: 2.978852]\n",
      "[Epoch 7/1000] [Batch 22/168] [D loss: 0.227505] [G loss: 2.132115]\n",
      "[Epoch 7/1000] [Batch 23/168] [D loss: 0.173216] [G loss: 1.885313]\n",
      "[Epoch 7/1000] [Batch 24/168] [D loss: 0.147611] [G loss: 3.519641]\n",
      "[Epoch 7/1000] [Batch 25/168] [D loss: 0.181727] [G loss: 1.651335]\n",
      "[Epoch 7/1000] [Batch 26/168] [D loss: 0.160504] [G loss: 4.963759]\n",
      "[Epoch 7/1000] [Batch 27/168] [D loss: 0.129304] [G loss: 2.423542]\n",
      "[Epoch 7/1000] [Batch 28/168] [D loss: 0.179361] [G loss: 1.602254]\n",
      "[Epoch 7/1000] [Batch 29/168] [D loss: 0.238646] [G loss: 4.773673]\n",
      "[Epoch 7/1000] [Batch 30/168] [D loss: 0.141733] [G loss: 1.857993]\n",
      "[Epoch 7/1000] [Batch 31/168] [D loss: 0.095559] [G loss: 2.990214]\n",
      "[Epoch 7/1000] [Batch 32/168] [D loss: 0.090506] [G loss: 2.491478]\n",
      "[Epoch 7/1000] [Batch 33/168] [D loss: 0.116202] [G loss: 2.902938]\n",
      "[Epoch 7/1000] [Batch 34/168] [D loss: 0.128831] [G loss: 2.071924]\n",
      "[Epoch 7/1000] [Batch 35/168] [D loss: 0.163549] [G loss: 3.263146]\n",
      "[Epoch 7/1000] [Batch 36/168] [D loss: 0.303578] [G loss: 1.072105]\n",
      "[Epoch 7/1000] [Batch 37/168] [D loss: 0.436964] [G loss: 7.814919]\n",
      "[Epoch 7/1000] [Batch 38/168] [D loss: 0.091345] [G loss: 2.424613]\n",
      "[Epoch 7/1000] [Batch 39/168] [D loss: 0.401978] [G loss: 0.742304]\n",
      "[Epoch 7/1000] [Batch 40/168] [D loss: 0.589001] [G loss: 11.215754]\n",
      "[Epoch 7/1000] [Batch 41/168] [D loss: 0.055742] [G loss: 7.143287]\n",
      "[Epoch 7/1000] [Batch 42/168] [D loss: 0.232847] [G loss: 1.278399]\n",
      "[Epoch 7/1000] [Batch 43/168] [D loss: 0.041505] [G loss: 3.871650]\n",
      "[Epoch 7/1000] [Batch 44/168] [D loss: 0.123353] [G loss: 3.668987]\n",
      "[Epoch 7/1000] [Batch 45/168] [D loss: 0.329128] [G loss: 1.045502]\n",
      "[Epoch 7/1000] [Batch 46/168] [D loss: 0.577442] [G loss: 7.009386]\n",
      "[Epoch 7/1000] [Batch 47/168] [D loss: 0.118492] [G loss: 2.167155]\n",
      "[Epoch 7/1000] [Batch 48/168] [D loss: 0.129624] [G loss: 1.799729]\n",
      "[Epoch 7/1000] [Batch 49/168] [D loss: 0.097613] [G loss: 4.681744]\n",
      "[Epoch 7/1000] [Batch 50/168] [D loss: 0.103987] [G loss: 2.327519]\n",
      "[Epoch 7/1000] [Batch 51/168] [D loss: 0.265945] [G loss: 1.413624]\n",
      "[Epoch 7/1000] [Batch 52/168] [D loss: 0.345881] [G loss: 4.697429]\n",
      "[Epoch 7/1000] [Batch 53/168] [D loss: 0.553724] [G loss: 0.654363]\n",
      "[Epoch 7/1000] [Batch 54/168] [D loss: 0.745661] [G loss: 10.745531]\n",
      "[Epoch 7/1000] [Batch 55/168] [D loss: 0.019356] [G loss: 7.633837]\n",
      "[Epoch 7/1000] [Batch 56/168] [D loss: 0.031060] [G loss: 3.255106]\n",
      "[Epoch 7/1000] [Batch 57/168] [D loss: 0.374252] [G loss: 0.856945]\n",
      "[Epoch 7/1000] [Batch 58/168] [D loss: 0.070883] [G loss: 7.152492]\n",
      "[Epoch 7/1000] [Batch 59/168] [D loss: 0.146627] [G loss: 7.616446]\n",
      "[Epoch 7/1000] [Batch 60/168] [D loss: 0.057454] [G loss: 4.294508]\n",
      "[Epoch 7/1000] [Batch 61/168] [D loss: 0.386348] [G loss: 0.967876]\n",
      "[Epoch 7/1000] [Batch 62/168] [D loss: 0.305204] [G loss: 6.928110]\n",
      "[Epoch 7/1000] [Batch 63/168] [D loss: 0.060803] [G loss: 5.176806]\n",
      "[Epoch 7/1000] [Batch 64/168] [D loss: 0.159465] [G loss: 2.053163]\n",
      "[Epoch 7/1000] [Batch 65/168] [D loss: 0.061061] [G loss: 3.297987]\n",
      "[Epoch 7/1000] [Batch 66/168] [D loss: 0.112398] [G loss: 2.634410]\n",
      "[Epoch 7/1000] [Batch 67/168] [D loss: 0.136993] [G loss: 2.331116]\n",
      "[Epoch 7/1000] [Batch 68/168] [D loss: 0.185648] [G loss: 1.904345]\n",
      "[Epoch 7/1000] [Batch 69/168] [D loss: 0.285338] [G loss: 3.348364]\n",
      "[Epoch 7/1000] [Batch 70/168] [D loss: 0.522128] [G loss: 0.586349]\n",
      "[Epoch 7/1000] [Batch 71/168] [D loss: 0.825610] [G loss: 9.443540]\n",
      "[Epoch 7/1000] [Batch 72/168] [D loss: 0.042457] [G loss: 5.658438]\n",
      "[Epoch 7/1000] [Batch 73/168] [D loss: 0.160126] [G loss: 1.739896]\n",
      "[Epoch 7/1000] [Batch 74/168] [D loss: 0.050398] [G loss: 2.691678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/1000] [Batch 75/168] [D loss: 0.033233] [G loss: 3.369504]\n",
      "[Epoch 7/1000] [Batch 76/168] [D loss: 0.065535] [G loss: 2.647240]\n",
      "[Epoch 7/1000] [Batch 77/168] [D loss: 0.093659] [G loss: 2.900652]\n",
      "[Epoch 7/1000] [Batch 78/168] [D loss: 0.130836] [G loss: 2.295325]\n",
      "[Epoch 7/1000] [Batch 79/168] [D loss: 0.129289] [G loss: 2.692018]\n",
      "[Epoch 7/1000] [Batch 80/168] [D loss: 0.110767] [G loss: 2.284271]\n",
      "[Epoch 7/1000] [Batch 81/168] [D loss: 0.081690] [G loss: 2.907225]\n",
      "[Epoch 7/1000] [Batch 82/168] [D loss: 0.092307] [G loss: 2.691015]\n",
      "[Epoch 7/1000] [Batch 83/168] [D loss: 0.157471] [G loss: 2.226952]\n",
      "[Epoch 7/1000] [Batch 84/168] [D loss: 0.099036] [G loss: 3.020134]\n",
      "[Epoch 7/1000] [Batch 85/168] [D loss: 0.162256] [G loss: 2.104279]\n",
      "[Epoch 7/1000] [Batch 86/168] [D loss: 0.106536] [G loss: 3.735726]\n",
      "[Epoch 7/1000] [Batch 87/168] [D loss: 0.165160] [G loss: 2.011729]\n",
      "[Epoch 7/1000] [Batch 88/168] [D loss: 0.138167] [G loss: 3.888187]\n",
      "[Epoch 7/1000] [Batch 89/168] [D loss: 0.186942] [G loss: 1.720121]\n",
      "[Epoch 7/1000] [Batch 90/168] [D loss: 0.159015] [G loss: 6.122370]\n",
      "[Epoch 7/1000] [Batch 91/168] [D loss: 0.077552] [G loss: 3.799090]\n",
      "[Epoch 7/1000] [Batch 92/168] [D loss: 0.349922] [G loss: 0.959442]\n",
      "[Epoch 7/1000] [Batch 93/168] [D loss: 0.621850] [G loss: 9.466503]\n",
      "[Epoch 7/1000] [Batch 94/168] [D loss: 0.035090] [G loss: 6.361423]\n",
      "[Epoch 7/1000] [Batch 95/168] [D loss: 0.074490] [G loss: 2.403543]\n",
      "[Epoch 7/1000] [Batch 96/168] [D loss: 0.256859] [G loss: 1.098351]\n",
      "[Epoch 7/1000] [Batch 97/168] [D loss: 0.172436] [G loss: 6.360743]\n",
      "[Epoch 7/1000] [Batch 98/168] [D loss: 0.051420] [G loss: 5.485227]\n",
      "[Epoch 7/1000] [Batch 99/168] [D loss: 0.092032] [G loss: 2.634317]\n",
      "[Epoch 7/1000] [Batch 100/168] [D loss: 0.244056] [G loss: 1.404231]\n",
      "[Epoch 7/1000] [Batch 101/168] [D loss: 0.278670] [G loss: 5.390656]\n",
      "[Epoch 7/1000] [Batch 102/168] [D loss: 0.101992] [G loss: 2.487330]\n",
      "[Epoch 7/1000] [Batch 103/168] [D loss: 0.274208] [G loss: 1.123393]\n",
      "[Epoch 7/1000] [Batch 104/168] [D loss: 0.358906] [G loss: 7.294100]\n",
      "[Epoch 7/1000] [Batch 105/168] [D loss: 0.065060] [G loss: 4.178251]\n",
      "[Epoch 7/1000] [Batch 106/168] [D loss: 0.579974] [G loss: 0.567835]\n",
      "[Epoch 7/1000] [Batch 107/168] [D loss: 1.000743] [G loss: 10.502217]\n",
      "[Epoch 7/1000] [Batch 108/168] [D loss: 0.058051] [G loss: 6.294826]\n",
      "[Epoch 7/1000] [Batch 109/168] [D loss: 0.534809] [G loss: 0.717016]\n",
      "[Epoch 7/1000] [Batch 110/168] [D loss: 0.212340] [G loss: 7.205429]\n",
      "[Epoch 7/1000] [Batch 111/168] [D loss: 0.177879] [G loss: 5.602882]\n",
      "[Epoch 7/1000] [Batch 112/168] [D loss: 0.236411] [G loss: 1.293365]\n",
      "[Epoch 7/1000] [Batch 113/168] [D loss: 0.069661] [G loss: 3.506607]\n",
      "[Epoch 7/1000] [Batch 114/168] [D loss: 0.087339] [G loss: 3.490160]\n",
      "[Epoch 7/1000] [Batch 115/168] [D loss: 0.158211] [G loss: 2.101036]\n",
      "[Epoch 7/1000] [Batch 116/168] [D loss: 0.134000] [G loss: 2.412957]\n",
      "[Epoch 7/1000] [Batch 117/168] [D loss: 0.132386] [G loss: 2.475185]\n",
      "[Epoch 7/1000] [Batch 118/168] [D loss: 0.196888] [G loss: 1.800863]\n",
      "[Epoch 7/1000] [Batch 119/168] [D loss: 0.181731] [G loss: 2.677308]\n",
      "[Epoch 7/1000] [Batch 120/168] [D loss: 0.232884] [G loss: 1.569330]\n",
      "[Epoch 7/1000] [Batch 121/168] [D loss: 0.193695] [G loss: 3.358206]\n",
      "[Epoch 7/1000] [Batch 122/168] [D loss: 0.215736] [G loss: 1.356082]\n",
      "[Epoch 7/1000] [Batch 123/168] [D loss: 0.212896] [G loss: 4.468828]\n",
      "[Epoch 7/1000] [Batch 124/168] [D loss: 0.161534] [G loss: 1.855688]\n",
      "[Epoch 7/1000] [Batch 125/168] [D loss: 0.138033] [G loss: 2.181258]\n",
      "[Epoch 7/1000] [Batch 126/168] [D loss: 0.144013] [G loss: 2.592103]\n",
      "[Epoch 7/1000] [Batch 127/168] [D loss: 0.283551] [G loss: 1.564436]\n",
      "[Epoch 7/1000] [Batch 128/168] [D loss: 0.176167] [G loss: 3.382932]\n",
      "[Epoch 7/1000] [Batch 129/168] [D loss: 0.248730] [G loss: 1.427771]\n",
      "[Epoch 7/1000] [Batch 130/168] [D loss: 0.269540] [G loss: 4.908395]\n",
      "[Epoch 7/1000] [Batch 131/168] [D loss: 0.184067] [G loss: 1.699752]\n",
      "[Epoch 7/1000] [Batch 132/168] [D loss: 0.126853] [G loss: 4.190435]\n",
      "[Epoch 7/1000] [Batch 133/168] [D loss: 0.141347] [G loss: 2.134231]\n",
      "[Epoch 7/1000] [Batch 134/168] [D loss: 0.141728] [G loss: 2.642914]\n",
      "[Epoch 7/1000] [Batch 135/168] [D loss: 0.213762] [G loss: 2.241540]\n",
      "[Epoch 7/1000] [Batch 136/168] [D loss: 0.234203] [G loss: 1.487065]\n",
      "[Epoch 7/1000] [Batch 137/168] [D loss: 0.285742] [G loss: 5.535548]\n",
      "[Epoch 7/1000] [Batch 138/168] [D loss: 0.174509] [G loss: 1.613849]\n",
      "[Epoch 7/1000] [Batch 139/168] [D loss: 0.078886] [G loss: 3.519577]\n",
      "[Epoch 7/1000] [Batch 140/168] [D loss: 0.110119] [G loss: 2.893820]\n",
      "[Epoch 7/1000] [Batch 141/168] [D loss: 0.201435] [G loss: 1.476834]\n",
      "[Epoch 7/1000] [Batch 142/168] [D loss: 0.255915] [G loss: 5.867324]\n",
      "[Epoch 7/1000] [Batch 143/168] [D loss: 0.095565] [G loss: 2.816609]\n",
      "[Epoch 7/1000] [Batch 144/168] [D loss: 0.219179] [G loss: 1.421838]\n",
      "[Epoch 7/1000] [Batch 145/168] [D loss: 0.220714] [G loss: 6.449672]\n",
      "[Epoch 7/1000] [Batch 146/168] [D loss: 0.059533] [G loss: 4.007165]\n",
      "[Epoch 7/1000] [Batch 147/168] [D loss: 0.415439] [G loss: 0.781819]\n",
      "[Epoch 7/1000] [Batch 148/168] [D loss: 0.622834] [G loss: 9.885658]\n",
      "[Epoch 7/1000] [Batch 149/168] [D loss: 0.064916] [G loss: 7.048012]\n",
      "[Epoch 7/1000] [Batch 150/168] [D loss: 0.112387] [G loss: 2.579224]\n",
      "[Epoch 7/1000] [Batch 151/168] [D loss: 0.076275] [G loss: 2.576324]\n",
      "[Epoch 7/1000] [Batch 152/168] [D loss: 0.042061] [G loss: 3.387782]\n",
      "[Epoch 7/1000] [Batch 153/168] [D loss: 0.132080] [G loss: 2.556015]\n",
      "[Epoch 7/1000] [Batch 154/168] [D loss: 0.159763] [G loss: 2.012332]\n",
      "[Epoch 7/1000] [Batch 155/168] [D loss: 0.159805] [G loss: 3.758657]\n",
      "[Epoch 7/1000] [Batch 156/168] [D loss: 0.282334] [G loss: 1.190800]\n",
      "[Epoch 7/1000] [Batch 157/168] [D loss: 0.384637] [G loss: 7.980400]\n",
      "[Epoch 7/1000] [Batch 158/168] [D loss: 0.048333] [G loss: 3.477081]\n",
      "[Epoch 7/1000] [Batch 159/168] [D loss: 0.986947] [G loss: 0.230302]\n",
      "[Epoch 7/1000] [Batch 160/168] [D loss: 2.106847] [G loss: 14.668768]\n",
      "[Epoch 7/1000] [Batch 161/168] [D loss: 0.256938] [G loss: 11.111763]\n",
      "[Epoch 7/1000] [Batch 162/168] [D loss: 0.011535] [G loss: 4.918365]\n",
      "[Epoch 7/1000] [Batch 163/168] [D loss: 0.506440] [G loss: 0.735195]\n",
      "[Epoch 7/1000] [Batch 164/168] [D loss: 0.012371] [G loss: 4.611432]\n",
      "[Epoch 7/1000] [Batch 165/168] [D loss: 0.031389] [G loss: 4.925323]\n",
      "[Epoch 7/1000] [Batch 166/168] [D loss: 0.095547] [G loss: 2.760247]\n",
      "[Epoch 7/1000] [Batch 167/168] [D loss: 0.289881] [G loss: 1.262451]\n",
      "[Epoch 7/1000] [Batch 168/168] [D loss: 0.280161] [G loss: 4.163235]\n",
      "[Epoch 8/1000] [Batch 1/168] [D loss: 0.143239] [G loss: 2.053130]\n",
      "[Epoch 8/1000] [Batch 2/168] [D loss: 0.122967] [G loss: 2.171810]\n",
      "[Epoch 8/1000] [Batch 3/168] [D loss: 0.106358] [G loss: 3.268699]\n",
      "[Epoch 8/1000] [Batch 4/168] [D loss: 0.152995] [G loss: 2.185981]\n",
      "[Epoch 8/1000] [Batch 5/168] [D loss: 0.135090] [G loss: 2.515762]\n",
      "[Epoch 8/1000] [Batch 6/168] [D loss: 0.144952] [G loss: 2.394030]\n",
      "[Epoch 8/1000] [Batch 7/168] [D loss: 0.133204] [G loss: 2.610610]\n",
      "[Epoch 8/1000] [Batch 8/168] [D loss: 0.135727] [G loss: 2.154972]\n",
      "[Epoch 8/1000] [Batch 9/168] [D loss: 0.130937] [G loss: 2.958202]\n",
      "[Epoch 8/1000] [Batch 10/168] [D loss: 0.175280] [G loss: 2.051878]\n",
      "[Epoch 8/1000] [Batch 11/168] [D loss: 0.115161] [G loss: 2.674063]\n",
      "[Epoch 8/1000] [Batch 12/168] [D loss: 0.133039] [G loss: 2.477455]\n",
      "[Epoch 8/1000] [Batch 13/168] [D loss: 0.153585] [G loss: 2.275813]\n",
      "[Epoch 8/1000] [Batch 14/168] [D loss: 0.107256] [G loss: 2.662809]\n",
      "[Epoch 8/1000] [Batch 15/168] [D loss: 0.132468] [G loss: 2.826168]\n",
      "[Epoch 8/1000] [Batch 16/168] [D loss: 0.202262] [G loss: 1.531792]\n",
      "[Epoch 8/1000] [Batch 17/168] [D loss: 0.225007] [G loss: 5.059619]\n",
      "[Epoch 8/1000] [Batch 18/168] [D loss: 0.104227] [G loss: 2.302338]\n",
      "[Epoch 8/1000] [Batch 19/168] [D loss: 0.085554] [G loss: 2.291956]\n",
      "[Epoch 8/1000] [Batch 20/168] [D loss: 0.089194] [G loss: 3.595393]\n",
      "[Epoch 8/1000] [Batch 21/168] [D loss: 0.110928] [G loss: 2.575707]\n",
      "[Epoch 8/1000] [Batch 22/168] [D loss: 0.160617] [G loss: 2.108779]\n",
      "[Epoch 8/1000] [Batch 23/168] [D loss: 0.178789] [G loss: 2.572755]\n",
      "[Epoch 8/1000] [Batch 24/168] [D loss: 0.170730] [G loss: 1.879094]\n",
      "[Epoch 8/1000] [Batch 25/168] [D loss: 0.146328] [G loss: 3.754111]\n",
      "[Epoch 8/1000] [Batch 26/168] [D loss: 0.192773] [G loss: 1.920676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/1000] [Batch 27/168] [D loss: 0.144340] [G loss: 2.625648]\n",
      "[Epoch 8/1000] [Batch 28/168] [D loss: 0.136665] [G loss: 2.482166]\n",
      "[Epoch 8/1000] [Batch 29/168] [D loss: 0.186796] [G loss: 1.988430]\n",
      "[Epoch 8/1000] [Batch 30/168] [D loss: 0.128935] [G loss: 2.970791]\n",
      "[Epoch 8/1000] [Batch 31/168] [D loss: 0.223766] [G loss: 1.578330]\n",
      "[Epoch 8/1000] [Batch 32/168] [D loss: 0.262312] [G loss: 4.582356]\n",
      "[Epoch 8/1000] [Batch 33/168] [D loss: 0.301536] [G loss: 1.200380]\n",
      "[Epoch 8/1000] [Batch 34/168] [D loss: 0.154675] [G loss: 6.381968]\n",
      "[Epoch 8/1000] [Batch 35/168] [D loss: 0.109814] [G loss: 4.471882]\n",
      "[Epoch 8/1000] [Batch 36/168] [D loss: 0.356152] [G loss: 1.066325]\n",
      "[Epoch 8/1000] [Batch 37/168] [D loss: 0.522612] [G loss: 7.523847]\n",
      "[Epoch 8/1000] [Batch 38/168] [D loss: 0.079049] [G loss: 2.847191]\n",
      "[Epoch 8/1000] [Batch 39/168] [D loss: 0.369686] [G loss: 1.101906]\n",
      "[Epoch 8/1000] [Batch 40/168] [D loss: 0.392336] [G loss: 8.224477]\n",
      "[Epoch 8/1000] [Batch 41/168] [D loss: 0.064995] [G loss: 5.391546]\n",
      "[Epoch 8/1000] [Batch 42/168] [D loss: 0.251707] [G loss: 1.480201]\n",
      "[Epoch 8/1000] [Batch 43/168] [D loss: 0.080522] [G loss: 4.734200]\n",
      "[Epoch 8/1000] [Batch 44/168] [D loss: 0.070670] [G loss: 3.635955]\n",
      "[Epoch 8/1000] [Batch 45/168] [D loss: 0.258507] [G loss: 1.395273]\n",
      "[Epoch 8/1000] [Batch 46/168] [D loss: 0.245722] [G loss: 4.656352]\n",
      "[Epoch 8/1000] [Batch 47/168] [D loss: 0.181190] [G loss: 1.580781]\n",
      "[Epoch 8/1000] [Batch 48/168] [D loss: 0.117470] [G loss: 3.853141]\n",
      "[Epoch 8/1000] [Batch 49/168] [D loss: 0.127043] [G loss: 2.254433]\n",
      "[Epoch 8/1000] [Batch 50/168] [D loss: 0.129604] [G loss: 2.187022]\n",
      "[Epoch 8/1000] [Batch 51/168] [D loss: 0.197132] [G loss: 3.231426]\n",
      "[Epoch 8/1000] [Batch 52/168] [D loss: 0.589131] [G loss: 0.556034]\n",
      "[Epoch 8/1000] [Batch 53/168] [D loss: 1.484809] [G loss: 13.083600]\n",
      "[Epoch 8/1000] [Batch 54/168] [D loss: 0.030217] [G loss: 8.917610]\n",
      "[Epoch 8/1000] [Batch 55/168] [D loss: 0.091321] [G loss: 2.957200]\n",
      "[Epoch 8/1000] [Batch 56/168] [D loss: 0.592536] [G loss: 0.576056]\n",
      "[Epoch 8/1000] [Batch 57/168] [D loss: 0.207279] [G loss: 8.654337]\n",
      "[Epoch 8/1000] [Batch 58/168] [D loss: 0.205554] [G loss: 7.816015]\n",
      "[Epoch 8/1000] [Batch 59/168] [D loss: 0.070642] [G loss: 3.664318]\n",
      "[Epoch 8/1000] [Batch 60/168] [D loss: 0.342234] [G loss: 0.923662]\n",
      "[Epoch 8/1000] [Batch 61/168] [D loss: 0.107284] [G loss: 4.819085]\n",
      "[Epoch 8/1000] [Batch 62/168] [D loss: 0.113308] [G loss: 4.442157]\n",
      "[Epoch 8/1000] [Batch 63/168] [D loss: 0.169370] [G loss: 1.636068]\n",
      "[Epoch 8/1000] [Batch 64/168] [D loss: 0.129000] [G loss: 2.450231]\n",
      "[Epoch 8/1000] [Batch 65/168] [D loss: 0.166500] [G loss: 2.452870]\n",
      "[Epoch 8/1000] [Batch 66/168] [D loss: 0.264075] [G loss: 1.481659]\n",
      "[Epoch 8/1000] [Batch 67/168] [D loss: 0.238243] [G loss: 3.323541]\n",
      "[Epoch 8/1000] [Batch 68/168] [D loss: 0.338994] [G loss: 1.067168]\n",
      "[Epoch 8/1000] [Batch 69/168] [D loss: 0.232305] [G loss: 5.321103]\n",
      "[Epoch 8/1000] [Batch 70/168] [D loss: 0.110167] [G loss: 2.885148]\n",
      "[Epoch 8/1000] [Batch 71/168] [D loss: 0.460960] [G loss: 0.774263]\n",
      "[Epoch 8/1000] [Batch 72/168] [D loss: 0.749983] [G loss: 8.413965]\n",
      "[Epoch 8/1000] [Batch 73/168] [D loss: 0.042076] [G loss: 4.690540]\n",
      "[Epoch 8/1000] [Batch 74/168] [D loss: 0.484226] [G loss: 0.751436]\n",
      "[Epoch 8/1000] [Batch 75/168] [D loss: 0.183419] [G loss: 7.614092]\n",
      "[Epoch 8/1000] [Batch 76/168] [D loss: 0.170582] [G loss: 7.012313]\n",
      "[Epoch 8/1000] [Batch 77/168] [D loss: 0.085315] [G loss: 2.647687]\n",
      "[Epoch 8/1000] [Batch 78/168] [D loss: 0.403569] [G loss: 0.797245]\n",
      "[Epoch 8/1000] [Batch 79/168] [D loss: 0.457800] [G loss: 7.011890]\n",
      "[Epoch 8/1000] [Batch 80/168] [D loss: 0.061982] [G loss: 4.264900]\n",
      "[Epoch 8/1000] [Batch 81/168] [D loss: 0.310518] [G loss: 1.023852]\n",
      "[Epoch 8/1000] [Batch 82/168] [D loss: 0.133123] [G loss: 5.280394]\n",
      "[Epoch 8/1000] [Batch 83/168] [D loss: 0.086159] [G loss: 4.432533]\n",
      "[Epoch 8/1000] [Batch 84/168] [D loss: 0.175628] [G loss: 1.697011]\n",
      "[Epoch 8/1000] [Batch 85/168] [D loss: 0.124404] [G loss: 3.343915]\n",
      "[Epoch 8/1000] [Batch 86/168] [D loss: 0.155739] [G loss: 2.291416]\n",
      "[Epoch 8/1000] [Batch 87/168] [D loss: 0.171993] [G loss: 1.907123]\n",
      "[Epoch 8/1000] [Batch 88/168] [D loss: 0.149751] [G loss: 3.549434]\n",
      "[Epoch 8/1000] [Batch 89/168] [D loss: 0.205485] [G loss: 1.874002]\n",
      "[Epoch 8/1000] [Batch 90/168] [D loss: 0.101055] [G loss: 2.676831]\n",
      "[Epoch 8/1000] [Batch 91/168] [D loss: 0.122523] [G loss: 2.576581]\n",
      "[Epoch 8/1000] [Batch 92/168] [D loss: 0.139955] [G loss: 2.062560]\n",
      "[Epoch 8/1000] [Batch 93/168] [D loss: 0.163701] [G loss: 2.672030]\n",
      "[Epoch 8/1000] [Batch 94/168] [D loss: 0.229385] [G loss: 1.627038]\n",
      "[Epoch 8/1000] [Batch 95/168] [D loss: 0.187151] [G loss: 3.939292]\n",
      "[Epoch 8/1000] [Batch 96/168] [D loss: 0.423540] [G loss: 0.829782]\n",
      "[Epoch 8/1000] [Batch 97/168] [D loss: 0.656934] [G loss: 8.377291]\n",
      "[Epoch 8/1000] [Batch 98/168] [D loss: 0.063977] [G loss: 3.648214]\n",
      "[Epoch 8/1000] [Batch 99/168] [D loss: 0.805287] [G loss: 0.339755]\n",
      "[Epoch 8/1000] [Batch 100/168] [D loss: 0.619242] [G loss: 11.091695]\n",
      "[Epoch 8/1000] [Batch 101/168] [D loss: 0.161422] [G loss: 9.667884]\n",
      "[Epoch 8/1000] [Batch 102/168] [D loss: 0.019016] [G loss: 5.038627]\n",
      "[Epoch 8/1000] [Batch 103/168] [D loss: 0.236576] [G loss: 1.277060]\n",
      "[Epoch 8/1000] [Batch 104/168] [D loss: 0.064865] [G loss: 2.895429]\n",
      "[Epoch 8/1000] [Batch 105/168] [D loss: 0.106636] [G loss: 3.370134]\n",
      "[Epoch 8/1000] [Batch 106/168] [D loss: 0.183140] [G loss: 2.165934]\n",
      "[Epoch 8/1000] [Batch 107/168] [D loss: 0.176889] [G loss: 1.925618]\n",
      "[Epoch 8/1000] [Batch 108/168] [D loss: 0.177414] [G loss: 2.867274]\n",
      "[Epoch 8/1000] [Batch 109/168] [D loss: 0.163640] [G loss: 2.164031]\n",
      "[Epoch 8/1000] [Batch 110/168] [D loss: 0.126436] [G loss: 2.525210]\n",
      "[Epoch 8/1000] [Batch 111/168] [D loss: 0.133856] [G loss: 2.934847]\n",
      "[Epoch 8/1000] [Batch 112/168] [D loss: 0.116101] [G loss: 2.210373]\n",
      "[Epoch 8/1000] [Batch 113/168] [D loss: 0.108264] [G loss: 2.936695]\n",
      "[Epoch 8/1000] [Batch 114/168] [D loss: 0.103646] [G loss: 2.350470]\n",
      "[Epoch 8/1000] [Batch 115/168] [D loss: 0.099320] [G loss: 2.853700]\n",
      "[Epoch 8/1000] [Batch 116/168] [D loss: 0.144805] [G loss: 2.191560]\n",
      "[Epoch 8/1000] [Batch 117/168] [D loss: 0.173224] [G loss: 2.460938]\n",
      "[Epoch 8/1000] [Batch 118/168] [D loss: 0.188206] [G loss: 2.067980]\n",
      "[Epoch 8/1000] [Batch 119/168] [D loss: 0.145373] [G loss: 2.580046]\n",
      "[Epoch 8/1000] [Batch 120/168] [D loss: 0.153636] [G loss: 2.070159]\n",
      "[Epoch 8/1000] [Batch 121/168] [D loss: 0.209205] [G loss: 3.297440]\n",
      "[Epoch 8/1000] [Batch 122/168] [D loss: 0.286177] [G loss: 1.091963]\n",
      "[Epoch 8/1000] [Batch 123/168] [D loss: 0.400821] [G loss: 7.481133]\n",
      "[Epoch 8/1000] [Batch 124/168] [D loss: 0.039127] [G loss: 3.793160]\n",
      "[Epoch 8/1000] [Batch 125/168] [D loss: 0.548059] [G loss: 0.593683]\n",
      "[Epoch 8/1000] [Batch 126/168] [D loss: 0.693348] [G loss: 10.143469]\n",
      "[Epoch 8/1000] [Batch 127/168] [D loss: 0.062848] [G loss: 7.385350]\n",
      "[Epoch 8/1000] [Batch 128/168] [D loss: 0.040180] [G loss: 3.054599]\n",
      "[Epoch 8/1000] [Batch 129/168] [D loss: 0.344583] [G loss: 0.928418]\n",
      "[Epoch 8/1000] [Batch 130/168] [D loss: 0.080458] [G loss: 6.405165]\n",
      "[Epoch 8/1000] [Batch 131/168] [D loss: 0.238893] [G loss: 6.353141]\n",
      "[Epoch 8/1000] [Batch 132/168] [D loss: 0.142308] [G loss: 1.935806]\n",
      "[Epoch 8/1000] [Batch 133/168] [D loss: 0.134374] [G loss: 1.881702]\n",
      "[Epoch 8/1000] [Batch 134/168] [D loss: 0.118745] [G loss: 3.888708]\n",
      "[Epoch 8/1000] [Batch 135/168] [D loss: 0.146396] [G loss: 2.336130]\n",
      "[Epoch 8/1000] [Batch 136/168] [D loss: 0.194957] [G loss: 2.008470]\n",
      "[Epoch 8/1000] [Batch 137/168] [D loss: 0.142005] [G loss: 2.367938]\n",
      "[Epoch 8/1000] [Batch 138/168] [D loss: 0.156026] [G loss: 2.394521]\n",
      "[Epoch 8/1000] [Batch 139/168] [D loss: 0.143292] [G loss: 2.202528]\n",
      "[Epoch 8/1000] [Batch 140/168] [D loss: 0.170753] [G loss: 2.919177]\n",
      "[Epoch 8/1000] [Batch 141/168] [D loss: 0.308696] [G loss: 1.091959]\n",
      "[Epoch 8/1000] [Batch 142/168] [D loss: 0.641499] [G loss: 8.335178]\n",
      "[Epoch 8/1000] [Batch 143/168] [D loss: 0.088555] [G loss: 2.401107]\n",
      "[Epoch 8/1000] [Batch 144/168] [D loss: 0.299692] [G loss: 1.086668]\n",
      "[Epoch 8/1000] [Batch 145/168] [D loss: 0.245352] [G loss: 8.052459]\n",
      "[Epoch 8/1000] [Batch 146/168] [D loss: 0.088366] [G loss: 6.364931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/1000] [Batch 147/168] [D loss: 0.113380] [G loss: 2.334144]\n",
      "[Epoch 8/1000] [Batch 148/168] [D loss: 0.241819] [G loss: 1.387946]\n",
      "[Epoch 8/1000] [Batch 149/168] [D loss: 0.379212] [G loss: 5.984613]\n",
      "[Epoch 8/1000] [Batch 150/168] [D loss: 0.101080] [G loss: 2.502965]\n",
      "[Epoch 8/1000] [Batch 151/168] [D loss: 0.217472] [G loss: 1.545346]\n",
      "[Epoch 8/1000] [Batch 152/168] [D loss: 0.104082] [G loss: 5.775308]\n",
      "[Epoch 8/1000] [Batch 153/168] [D loss: 0.100852] [G loss: 4.638613]\n",
      "[Epoch 8/1000] [Batch 154/168] [D loss: 0.189676] [G loss: 1.582704]\n",
      "[Epoch 8/1000] [Batch 155/168] [D loss: 0.064639] [G loss: 4.079299]\n",
      "[Epoch 8/1000] [Batch 156/168] [D loss: 0.083166] [G loss: 3.351300]\n",
      "[Epoch 8/1000] [Batch 157/168] [D loss: 0.224674] [G loss: 1.355258]\n",
      "[Epoch 8/1000] [Batch 158/168] [D loss: 0.208706] [G loss: 5.656889]\n",
      "[Epoch 8/1000] [Batch 159/168] [D loss: 0.059901] [G loss: 3.258321]\n",
      "[Epoch 8/1000] [Batch 160/168] [D loss: 0.288913] [G loss: 1.218775]\n",
      "[Epoch 8/1000] [Batch 161/168] [D loss: 0.236883] [G loss: 7.000407]\n",
      "[Epoch 8/1000] [Batch 162/168] [D loss: 0.070557] [G loss: 5.727365]\n",
      "[Epoch 8/1000] [Batch 163/168] [D loss: 0.141296] [G loss: 1.742068]\n",
      "[Epoch 8/1000] [Batch 164/168] [D loss: 0.070715] [G loss: 3.062502]\n",
      "[Epoch 8/1000] [Batch 165/168] [D loss: 0.070363] [G loss: 3.180610]\n",
      "[Epoch 8/1000] [Batch 166/168] [D loss: 0.121531] [G loss: 1.994518]\n",
      "[Epoch 8/1000] [Batch 167/168] [D loss: 0.119079] [G loss: 3.290599]\n",
      "[Epoch 8/1000] [Batch 168/168] [D loss: 0.140209] [G loss: 1.887231]\n",
      "[Epoch 9/1000] [Batch 1/168] [D loss: 0.164399] [G loss: 4.043049]\n",
      "[Epoch 9/1000] [Batch 2/168] [D loss: 0.175919] [G loss: 1.804344]\n",
      "[Epoch 9/1000] [Batch 3/168] [D loss: 0.105073] [G loss: 3.313844]\n",
      "[Epoch 9/1000] [Batch 4/168] [D loss: 0.131199] [G loss: 2.117846]\n",
      "[Epoch 9/1000] [Batch 5/168] [D loss: 0.141962] [G loss: 3.538774]\n",
      "[Epoch 9/1000] [Batch 6/168] [D loss: 0.202129] [G loss: 1.480570]\n",
      "[Epoch 9/1000] [Batch 7/168] [D loss: 0.242298] [G loss: 6.402874]\n",
      "[Epoch 9/1000] [Batch 8/168] [D loss: 0.061596] [G loss: 2.805726]\n",
      "[Epoch 9/1000] [Batch 9/168] [D loss: 0.204606] [G loss: 1.242905]\n",
      "[Epoch 9/1000] [Batch 10/168] [D loss: 0.183555] [G loss: 7.967538]\n",
      "[Epoch 9/1000] [Batch 11/168] [D loss: 0.075707] [G loss: 6.010408]\n",
      "[Epoch 9/1000] [Batch 12/168] [D loss: 0.182253] [G loss: 1.469276]\n",
      "[Epoch 9/1000] [Batch 13/168] [D loss: 0.086229] [G loss: 4.991821]\n",
      "[Epoch 9/1000] [Batch 14/168] [D loss: 0.079127] [G loss: 3.285302]\n",
      "[Epoch 9/1000] [Batch 15/168] [D loss: 0.303179] [G loss: 1.072301]\n",
      "[Epoch 9/1000] [Batch 16/168] [D loss: 0.562162] [G loss: 9.242807]\n",
      "[Epoch 9/1000] [Batch 17/168] [D loss: 0.016197] [G loss: 4.530258]\n",
      "[Epoch 9/1000] [Batch 18/168] [D loss: 0.439940] [G loss: 0.765464]\n",
      "[Epoch 9/1000] [Batch 19/168] [D loss: 0.244628] [G loss: 9.456196]\n",
      "[Epoch 9/1000] [Batch 20/168] [D loss: 0.123882] [G loss: 8.432211]\n",
      "[Epoch 9/1000] [Batch 21/168] [D loss: 0.028981] [G loss: 4.011445]\n",
      "[Epoch 9/1000] [Batch 22/168] [D loss: 0.580415] [G loss: 0.551688]\n",
      "[Epoch 9/1000] [Batch 23/168] [D loss: 0.483329] [G loss: 10.135886]\n",
      "[Epoch 9/1000] [Batch 24/168] [D loss: 0.083355] [G loss: 7.684342]\n",
      "[Epoch 9/1000] [Batch 25/168] [D loss: 0.093453] [G loss: 2.351418]\n",
      "[Epoch 9/1000] [Batch 26/168] [D loss: 0.249028] [G loss: 1.408226]\n",
      "[Epoch 9/1000] [Batch 27/168] [D loss: 0.231936] [G loss: 6.960367]\n",
      "[Epoch 9/1000] [Batch 28/168] [D loss: 0.042269] [G loss: 4.585165]\n",
      "[Epoch 9/1000] [Batch 29/168] [D loss: 0.216879] [G loss: 1.643794]\n",
      "[Epoch 9/1000] [Batch 30/168] [D loss: 0.108207] [G loss: 4.482627]\n",
      "[Epoch 9/1000] [Batch 31/168] [D loss: 0.124533] [G loss: 2.994253]\n",
      "[Epoch 9/1000] [Batch 32/168] [D loss: 0.179462] [G loss: 1.831098]\n",
      "[Epoch 9/1000] [Batch 33/168] [D loss: 0.155012] [G loss: 4.364809]\n",
      "[Epoch 9/1000] [Batch 34/168] [D loss: 0.191093] [G loss: 1.651970]\n",
      "[Epoch 9/1000] [Batch 35/168] [D loss: 0.219747] [G loss: 5.079473]\n",
      "[Epoch 9/1000] [Batch 36/168] [D loss: 0.204122] [G loss: 1.604733]\n",
      "[Epoch 9/1000] [Batch 37/168] [D loss: 0.160382] [G loss: 3.733872]\n",
      "[Epoch 9/1000] [Batch 38/168] [D loss: 0.256956] [G loss: 1.226302]\n",
      "[Epoch 9/1000] [Batch 39/168] [D loss: 0.458741] [G loss: 7.324269]\n",
      "[Epoch 9/1000] [Batch 40/168] [D loss: 0.072688] [G loss: 2.675396]\n",
      "[Epoch 9/1000] [Batch 41/168] [D loss: 0.369173] [G loss: 0.905278]\n",
      "[Epoch 9/1000] [Batch 42/168] [D loss: 0.528768] [G loss: 9.692585]\n",
      "[Epoch 9/1000] [Batch 43/168] [D loss: 0.031516] [G loss: 5.938103]\n",
      "[Epoch 9/1000] [Batch 44/168] [D loss: 0.232746] [G loss: 1.251841]\n",
      "[Epoch 9/1000] [Batch 45/168] [D loss: 0.044611] [G loss: 4.893175]\n",
      "[Epoch 9/1000] [Batch 46/168] [D loss: 0.089523] [G loss: 4.415543]\n",
      "[Epoch 9/1000] [Batch 47/168] [D loss: 0.176863] [G loss: 1.725688]\n",
      "[Epoch 9/1000] [Batch 48/168] [D loss: 0.152454] [G loss: 3.638989]\n",
      "[Epoch 9/1000] [Batch 49/168] [D loss: 0.149799] [G loss: 1.963812]\n",
      "[Epoch 9/1000] [Batch 50/168] [D loss: 0.133769] [G loss: 3.696741]\n",
      "[Epoch 9/1000] [Batch 51/168] [D loss: 0.148086] [G loss: 2.096163]\n",
      "[Epoch 9/1000] [Batch 52/168] [D loss: 0.098917] [G loss: 3.917434]\n",
      "[Epoch 9/1000] [Batch 53/168] [D loss: 0.147307] [G loss: 2.204929]\n",
      "[Epoch 9/1000] [Batch 54/168] [D loss: 0.129314] [G loss: 2.323875]\n",
      "[Epoch 9/1000] [Batch 55/168] [D loss: 0.122918] [G loss: 2.952886]\n",
      "[Epoch 9/1000] [Batch 56/168] [D loss: 0.175652] [G loss: 2.198592]\n",
      "[Epoch 9/1000] [Batch 57/168] [D loss: 0.092876] [G loss: 2.779488]\n",
      "[Epoch 9/1000] [Batch 58/168] [D loss: 0.124452] [G loss: 2.401342]\n",
      "[Epoch 9/1000] [Batch 59/168] [D loss: 0.119962] [G loss: 2.844572]\n",
      "[Epoch 9/1000] [Batch 60/168] [D loss: 0.144186] [G loss: 2.056459]\n",
      "[Epoch 9/1000] [Batch 61/168] [D loss: 0.144414] [G loss: 3.890327]\n",
      "[Epoch 9/1000] [Batch 62/168] [D loss: 0.172271] [G loss: 1.603126]\n",
      "[Epoch 9/1000] [Batch 63/168] [D loss: 0.159914] [G loss: 5.449071]\n",
      "[Epoch 9/1000] [Batch 64/168] [D loss: 0.073966] [G loss: 2.806797]\n",
      "[Epoch 9/1000] [Batch 65/168] [D loss: 0.211841] [G loss: 1.414996]\n",
      "[Epoch 9/1000] [Batch 66/168] [D loss: 0.294873] [G loss: 6.434253]\n",
      "[Epoch 9/1000] [Batch 67/168] [D loss: 0.081381] [G loss: 2.720688]\n",
      "[Epoch 9/1000] [Batch 68/168] [D loss: 0.273754] [G loss: 1.108857]\n",
      "[Epoch 9/1000] [Batch 69/168] [D loss: 0.274540] [G loss: 7.652649]\n",
      "[Epoch 9/1000] [Batch 70/168] [D loss: 0.095626] [G loss: 5.585820]\n",
      "[Epoch 9/1000] [Batch 71/168] [D loss: 0.174023] [G loss: 1.641280]\n",
      "[Epoch 9/1000] [Batch 72/168] [D loss: 0.041316] [G loss: 3.979248]\n",
      "[Epoch 9/1000] [Batch 73/168] [D loss: 0.046945] [G loss: 3.819850]\n",
      "[Epoch 9/1000] [Batch 74/168] [D loss: 0.084208] [G loss: 2.668125]\n",
      "[Epoch 9/1000] [Batch 75/168] [D loss: 0.119359] [G loss: 2.262918]\n",
      "[Epoch 9/1000] [Batch 76/168] [D loss: 0.124391] [G loss: 2.716952]\n",
      "[Epoch 9/1000] [Batch 77/168] [D loss: 0.093792] [G loss: 2.638476]\n",
      "[Epoch 9/1000] [Batch 78/168] [D loss: 0.114166] [G loss: 2.588288]\n",
      "[Epoch 9/1000] [Batch 79/168] [D loss: 0.091979] [G loss: 2.641402]\n",
      "[Epoch 9/1000] [Batch 80/168] [D loss: 0.078504] [G loss: 2.887881]\n",
      "[Epoch 9/1000] [Batch 81/168] [D loss: 0.132336] [G loss: 2.422141]\n",
      "[Epoch 9/1000] [Batch 82/168] [D loss: 0.164457] [G loss: 2.831246]\n",
      "[Epoch 9/1000] [Batch 83/168] [D loss: 0.286674] [G loss: 1.186539]\n",
      "[Epoch 9/1000] [Batch 84/168] [D loss: 0.514587] [G loss: 8.247901]\n",
      "[Epoch 9/1000] [Batch 85/168] [D loss: 0.078017] [G loss: 2.474484]\n",
      "[Epoch 9/1000] [Batch 86/168] [D loss: 0.465831] [G loss: 0.729153]\n",
      "[Epoch 9/1000] [Batch 87/168] [D loss: 0.581654] [G loss: 11.256170]\n",
      "[Epoch 9/1000] [Batch 88/168] [D loss: 0.047800] [G loss: 8.637091]\n",
      "[Epoch 9/1000] [Batch 89/168] [D loss: 0.040303] [G loss: 3.615977]\n",
      "[Epoch 9/1000] [Batch 90/168] [D loss: 0.576356] [G loss: 0.580740]\n",
      "[Epoch 9/1000] [Batch 91/168] [D loss: 0.670221] [G loss: 11.717697]\n",
      "[Epoch 9/1000] [Batch 92/168] [D loss: 0.072367] [G loss: 9.482086]\n",
      "[Epoch 9/1000] [Batch 93/168] [D loss: 0.018741] [G loss: 4.028028]\n",
      "[Epoch 9/1000] [Batch 94/168] [D loss: 1.103038] [G loss: 0.202859]\n",
      "[Epoch 9/1000] [Batch 95/168] [D loss: 1.543639] [G loss: 11.843858]\n",
      "[Epoch 9/1000] [Batch 96/168] [D loss: 0.088072] [G loss: 7.130304]\n",
      "[Epoch 9/1000] [Batch 97/168] [D loss: 0.072776] [G loss: 2.610997]\n",
      "[Epoch 9/1000] [Batch 98/168] [D loss: 0.261241] [G loss: 1.187816]\n",
      "[Epoch 9/1000] [Batch 99/168] [D loss: 0.046094] [G loss: 4.450237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/1000] [Batch 100/168] [D loss: 0.103341] [G loss: 4.929277]\n",
      "[Epoch 9/1000] [Batch 101/168] [D loss: 0.084605] [G loss: 2.755198]\n",
      "[Epoch 9/1000] [Batch 102/168] [D loss: 0.248538] [G loss: 1.417019]\n",
      "[Epoch 9/1000] [Batch 103/168] [D loss: 0.190625] [G loss: 3.113622]\n",
      "[Epoch 9/1000] [Batch 104/168] [D loss: 0.233272] [G loss: 1.815079]\n",
      "[Epoch 9/1000] [Batch 105/168] [D loss: 0.211883] [G loss: 2.635782]\n",
      "[Epoch 9/1000] [Batch 106/168] [D loss: 0.253834] [G loss: 1.577607]\n",
      "[Epoch 9/1000] [Batch 107/168] [D loss: 0.174096] [G loss: 4.416560]\n",
      "[Epoch 9/1000] [Batch 108/168] [D loss: 0.146320] [G loss: 1.818440]\n",
      "[Epoch 9/1000] [Batch 109/168] [D loss: 0.094930] [G loss: 3.357701]\n",
      "[Epoch 9/1000] [Batch 110/168] [D loss: 0.198251] [G loss: 2.263072]\n",
      "[Epoch 9/1000] [Batch 111/168] [D loss: 0.180980] [G loss: 2.523580]\n",
      "[Epoch 9/1000] [Batch 112/168] [D loss: 0.198452] [G loss: 1.717655]\n",
      "[Epoch 9/1000] [Batch 113/168] [D loss: 0.260471] [G loss: 5.032846]\n",
      "[Epoch 9/1000] [Batch 114/168] [D loss: 0.173144] [G loss: 1.574324]\n",
      "[Epoch 9/1000] [Batch 115/168] [D loss: 0.134138] [G loss: 3.493579]\n",
      "[Epoch 9/1000] [Batch 116/168] [D loss: 0.137016] [G loss: 1.861734]\n",
      "[Epoch 9/1000] [Batch 117/168] [D loss: 0.097864] [G loss: 3.229608]\n",
      "[Epoch 9/1000] [Batch 118/168] [D loss: 0.159516] [G loss: 2.159454]\n",
      "[Epoch 9/1000] [Batch 119/168] [D loss: 0.138769] [G loss: 2.417928]\n",
      "[Epoch 9/1000] [Batch 120/168] [D loss: 0.124310] [G loss: 2.446082]\n",
      "[Epoch 9/1000] [Batch 121/168] [D loss: 0.106331] [G loss: 2.784456]\n",
      "[Epoch 9/1000] [Batch 122/168] [D loss: 0.154827] [G loss: 1.961380]\n",
      "[Epoch 9/1000] [Batch 123/168] [D loss: 0.145258] [G loss: 4.082583]\n",
      "[Epoch 9/1000] [Batch 124/168] [D loss: 0.222955] [G loss: 1.402944]\n",
      "[Epoch 9/1000] [Batch 125/168] [D loss: 0.435355] [G loss: 6.695076]\n",
      "[Epoch 9/1000] [Batch 126/168] [D loss: 0.188610] [G loss: 1.444626]\n",
      "[Epoch 9/1000] [Batch 127/168] [D loss: 0.027034] [G loss: 4.993207]\n",
      "[Epoch 9/1000] [Batch 128/168] [D loss: 0.057613] [G loss: 4.328191]\n",
      "[Epoch 9/1000] [Batch 129/168] [D loss: 0.134095] [G loss: 2.032203]\n",
      "[Epoch 9/1000] [Batch 130/168] [D loss: 0.094156] [G loss: 3.714923]\n",
      "[Epoch 9/1000] [Batch 131/168] [D loss: 0.141939] [G loss: 2.366145]\n",
      "[Epoch 9/1000] [Batch 132/168] [D loss: 0.132955] [G loss: 2.710428]\n",
      "[Epoch 9/1000] [Batch 133/168] [D loss: 0.187530] [G loss: 1.866845]\n",
      "[Epoch 9/1000] [Batch 134/168] [D loss: 0.145218] [G loss: 4.908848]\n",
      "[Epoch 9/1000] [Batch 135/168] [D loss: 0.101560] [G loss: 2.427347]\n",
      "[Epoch 9/1000] [Batch 136/168] [D loss: 0.124947] [G loss: 2.285771]\n",
      "[Epoch 9/1000] [Batch 137/168] [D loss: 0.115659] [G loss: 3.179806]\n",
      "[Epoch 9/1000] [Batch 138/168] [D loss: 0.187149] [G loss: 1.715849]\n",
      "[Epoch 9/1000] [Batch 139/168] [D loss: 0.158221] [G loss: 5.061749]\n",
      "[Epoch 9/1000] [Batch 140/168] [D loss: 0.144451] [G loss: 2.097674]\n",
      "[Epoch 9/1000] [Batch 141/168] [D loss: 0.067344] [G loss: 2.595510]\n",
      "[Epoch 9/1000] [Batch 142/168] [D loss: 0.098248] [G loss: 3.461471]\n",
      "[Epoch 9/1000] [Batch 143/168] [D loss: 0.210002] [G loss: 1.596068]\n",
      "[Epoch 9/1000] [Batch 144/168] [D loss: 0.261504] [G loss: 5.795353]\n",
      "[Epoch 9/1000] [Batch 145/168] [D loss: 0.265963] [G loss: 1.135505]\n",
      "[Epoch 9/1000] [Batch 146/168] [D loss: 0.210983] [G loss: 7.668558]\n",
      "[Epoch 9/1000] [Batch 147/168] [D loss: 0.029066] [G loss: 4.774282]\n",
      "[Epoch 9/1000] [Batch 148/168] [D loss: 0.289453] [G loss: 1.250246]\n",
      "[Epoch 9/1000] [Batch 149/168] [D loss: 0.288633] [G loss: 7.716488]\n",
      "[Epoch 9/1000] [Batch 150/168] [D loss: 0.031018] [G loss: 4.912761]\n",
      "[Epoch 9/1000] [Batch 151/168] [D loss: 0.258961] [G loss: 1.336570]\n",
      "[Epoch 9/1000] [Batch 152/168] [D loss: 0.139851] [G loss: 7.166781]\n",
      "[Epoch 9/1000] [Batch 153/168] [D loss: 0.109477] [G loss: 5.118071]\n",
      "[Epoch 9/1000] [Batch 154/168] [D loss: 0.363045] [G loss: 1.059926]\n",
      "[Epoch 9/1000] [Batch 155/168] [D loss: 0.744172] [G loss: 8.822533]\n",
      "[Epoch 9/1000] [Batch 156/168] [D loss: 0.116351] [G loss: 2.594477]\n",
      "[Epoch 9/1000] [Batch 157/168] [D loss: 0.173017] [G loss: 1.584463]\n",
      "[Epoch 9/1000] [Batch 158/168] [D loss: 0.062353] [G loss: 5.670605]\n",
      "[Epoch 9/1000] [Batch 159/168] [D loss: 0.060687] [G loss: 4.477451]\n",
      "[Epoch 9/1000] [Batch 160/168] [D loss: 0.218098] [G loss: 1.660793]\n",
      "[Epoch 9/1000] [Batch 161/168] [D loss: 0.231680] [G loss: 4.524172]\n",
      "[Epoch 9/1000] [Batch 162/168] [D loss: 0.269671] [G loss: 1.268819]\n",
      "[Epoch 9/1000] [Batch 163/168] [D loss: 0.177850] [G loss: 6.166018]\n",
      "[Epoch 9/1000] [Batch 164/168] [D loss: 0.045293] [G loss: 4.201084]\n",
      "[Epoch 9/1000] [Batch 165/168] [D loss: 0.237997] [G loss: 1.456733]\n",
      "[Epoch 9/1000] [Batch 166/168] [D loss: 0.186547] [G loss: 6.203189]\n",
      "[Epoch 9/1000] [Batch 167/168] [D loss: 0.073342] [G loss: 3.688879]\n",
      "[Epoch 9/1000] [Batch 168/168] [D loss: 0.378651] [G loss: 0.902419]\n",
      "[Epoch 10/1000] [Batch 1/168] [D loss: 0.544400] [G loss: 9.029882]\n",
      "[Epoch 10/1000] [Batch 2/168] [D loss: 0.055815] [G loss: 5.894800]\n",
      "[Epoch 10/1000] [Batch 3/168] [D loss: 0.262850] [G loss: 1.805087]\n",
      "[Epoch 10/1000] [Batch 4/168] [D loss: 0.029132] [G loss: 5.467408]\n",
      "[Epoch 10/1000] [Batch 5/168] [D loss: 0.041590] [G loss: 5.331416]\n",
      "[Epoch 10/1000] [Batch 6/168] [D loss: 0.090989] [G loss: 3.027848]\n",
      "[Epoch 10/1000] [Batch 7/168] [D loss: 0.204572] [G loss: 1.532284]\n",
      "[Epoch 10/1000] [Batch 8/168] [D loss: 0.222436] [G loss: 5.053345]\n",
      "[Epoch 10/1000] [Batch 9/168] [D loss: 0.091639] [G loss: 2.801458]\n",
      "[Epoch 10/1000] [Batch 10/168] [D loss: 0.164954] [G loss: 1.837202]\n",
      "[Epoch 10/1000] [Batch 11/168] [D loss: 0.092170] [G loss: 5.315885]\n",
      "[Epoch 10/1000] [Batch 12/168] [D loss: 0.065748] [G loss: 4.312085]\n",
      "[Epoch 10/1000] [Batch 13/168] [D loss: 0.147039] [G loss: 1.894358]\n",
      "[Epoch 10/1000] [Batch 14/168] [D loss: 0.055332] [G loss: 3.700852]\n",
      "[Epoch 10/1000] [Batch 15/168] [D loss: 0.083060] [G loss: 3.463825]\n",
      "[Epoch 10/1000] [Batch 16/168] [D loss: 0.135263] [G loss: 2.096633]\n",
      "[Epoch 10/1000] [Batch 17/168] [D loss: 0.080152] [G loss: 3.230363]\n",
      "[Epoch 10/1000] [Batch 18/168] [D loss: 0.073590] [G loss: 3.065041]\n",
      "[Epoch 10/1000] [Batch 19/168] [D loss: 0.134139] [G loss: 1.919419]\n",
      "[Epoch 10/1000] [Batch 20/168] [D loss: 0.134657] [G loss: 4.668798]\n",
      "[Epoch 10/1000] [Batch 21/168] [D loss: 0.090938] [G loss: 2.338463]\n",
      "[Epoch 10/1000] [Batch 22/168] [D loss: 0.073925] [G loss: 3.331290]\n",
      "[Epoch 10/1000] [Batch 23/168] [D loss: 0.089712] [G loss: 2.652330]\n",
      "[Epoch 10/1000] [Batch 24/168] [D loss: 0.087302] [G loss: 2.910963]\n",
      "[Epoch 10/1000] [Batch 25/168] [D loss: 0.125851] [G loss: 2.670126]\n",
      "[Epoch 10/1000] [Batch 26/168] [D loss: 0.136947] [G loss: 2.685682]\n",
      "[Epoch 10/1000] [Batch 27/168] [D loss: 0.120109] [G loss: 2.103875]\n",
      "[Epoch 10/1000] [Batch 28/168] [D loss: 0.088484] [G loss: 4.227976]\n",
      "[Epoch 10/1000] [Batch 29/168] [D loss: 0.113370] [G loss: 2.365069]\n",
      "[Epoch 10/1000] [Batch 30/168] [D loss: 0.119485] [G loss: 2.788797]\n",
      "[Epoch 10/1000] [Batch 31/168] [D loss: 0.150213] [G loss: 2.168466]\n",
      "[Epoch 10/1000] [Batch 32/168] [D loss: 0.108185] [G loss: 3.575569]\n",
      "[Epoch 10/1000] [Batch 33/168] [D loss: 0.130837] [G loss: 2.193365]\n",
      "[Epoch 10/1000] [Batch 34/168] [D loss: 0.130372] [G loss: 4.221061]\n",
      "[Epoch 10/1000] [Batch 35/168] [D loss: 0.214898] [G loss: 1.358685]\n",
      "[Epoch 10/1000] [Batch 36/168] [D loss: 0.388911] [G loss: 7.097332]\n",
      "[Epoch 10/1000] [Batch 37/168] [D loss: 0.140788] [G loss: 1.782809]\n",
      "[Epoch 10/1000] [Batch 38/168] [D loss: 0.049808] [G loss: 3.388006]\n",
      "[Epoch 10/1000] [Batch 39/168] [D loss: 0.055266] [G loss: 3.448106]\n",
      "[Epoch 10/1000] [Batch 40/168] [D loss: 0.118519] [G loss: 2.394518]\n",
      "[Epoch 10/1000] [Batch 41/168] [D loss: 0.167353] [G loss: 3.101500]\n",
      "[Epoch 10/1000] [Batch 42/168] [D loss: 0.162243] [G loss: 1.904033]\n",
      "[Epoch 10/1000] [Batch 43/168] [D loss: 0.108442] [G loss: 4.266657]\n",
      "[Epoch 10/1000] [Batch 44/168] [D loss: 0.130806] [G loss: 2.061720]\n",
      "[Epoch 10/1000] [Batch 45/168] [D loss: 0.101450] [G loss: 3.522781]\n",
      "[Epoch 10/1000] [Batch 46/168] [D loss: 0.134953] [G loss: 1.980358]\n",
      "[Epoch 10/1000] [Batch 47/168] [D loss: 0.173484] [G loss: 4.182724]\n",
      "[Epoch 10/1000] [Batch 48/168] [D loss: 0.236668] [G loss: 1.266775]\n",
      "[Epoch 10/1000] [Batch 49/168] [D loss: 0.284276] [G loss: 8.131153]\n",
      "[Epoch 10/1000] [Batch 50/168] [D loss: 0.011000] [G loss: 5.174761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/1000] [Batch 51/168] [D loss: 0.131046] [G loss: 1.876511]\n",
      "[Epoch 10/1000] [Batch 52/168] [D loss: 0.023462] [G loss: 4.462788]\n",
      "[Epoch 10/1000] [Batch 53/168] [D loss: 0.042213] [G loss: 4.471622]\n",
      "[Epoch 10/1000] [Batch 54/168] [D loss: 0.173928] [G loss: 1.739255]\n",
      "[Epoch 10/1000] [Batch 55/168] [D loss: 0.303026] [G loss: 5.291340]\n",
      "[Epoch 10/1000] [Batch 56/168] [D loss: 0.417237] [G loss: 0.726702]\n",
      "[Epoch 10/1000] [Batch 57/168] [D loss: 0.930936] [G loss: 9.830022]\n",
      "[Epoch 10/1000] [Batch 58/168] [D loss: 0.057415] [G loss: 2.888470]\n",
      "[Epoch 10/1000] [Batch 59/168] [D loss: 0.647229] [G loss: 0.478419]\n",
      "[Epoch 10/1000] [Batch 60/168] [D loss: 0.350727] [G loss: 10.505911]\n",
      "[Epoch 10/1000] [Batch 61/168] [D loss: 0.093827] [G loss: 7.488538]\n",
      "[Epoch 10/1000] [Batch 62/168] [D loss: 0.112510] [G loss: 2.540648]\n",
      "[Epoch 10/1000] [Batch 63/168] [D loss: 0.202256] [G loss: 1.532506]\n",
      "[Epoch 10/1000] [Batch 64/168] [D loss: 0.205030] [G loss: 5.720923]\n",
      "[Epoch 10/1000] [Batch 65/168] [D loss: 0.159464] [G loss: 2.213346]\n",
      "[Epoch 10/1000] [Batch 66/168] [D loss: 0.244939] [G loss: 1.521470]\n",
      "[Epoch 10/1000] [Batch 67/168] [D loss: 0.212004] [G loss: 5.326842]\n",
      "[Epoch 10/1000] [Batch 68/168] [D loss: 0.115965] [G loss: 2.380557]\n",
      "[Epoch 10/1000] [Batch 69/168] [D loss: 0.123969] [G loss: 2.096478]\n",
      "[Epoch 10/1000] [Batch 70/168] [D loss: 0.129241] [G loss: 4.750837]\n",
      "[Epoch 10/1000] [Batch 71/168] [D loss: 0.128315] [G loss: 1.973568]\n",
      "[Epoch 10/1000] [Batch 72/168] [D loss: 0.145817] [G loss: 3.448068]\n",
      "[Epoch 10/1000] [Batch 73/168] [D loss: 0.277517] [G loss: 1.265658]\n",
      "[Epoch 10/1000] [Batch 74/168] [D loss: 0.426721] [G loss: 7.884720]\n",
      "[Epoch 10/1000] [Batch 75/168] [D loss: 0.044636] [G loss: 3.156159]\n",
      "[Epoch 10/1000] [Batch 76/168] [D loss: 0.589057] [G loss: 0.535244]\n",
      "[Epoch 10/1000] [Batch 77/168] [D loss: 0.731731] [G loss: 13.175735]\n",
      "[Epoch 10/1000] [Batch 78/168] [D loss: 0.042733] [G loss: 9.473635]\n",
      "[Epoch 10/1000] [Batch 79/168] [D loss: 0.034739] [G loss: 4.083128]\n",
      "[Epoch 10/1000] [Batch 80/168] [D loss: 0.551551] [G loss: 0.600478]\n",
      "[Epoch 10/1000] [Batch 81/168] [D loss: 0.407512] [G loss: 9.697480]\n",
      "[Epoch 10/1000] [Batch 82/168] [D loss: 0.093830] [G loss: 8.167006]\n",
      "[Epoch 10/1000] [Batch 83/168] [D loss: 0.026112] [G loss: 4.510893]\n",
      "[Epoch 10/1000] [Batch 84/168] [D loss: 0.328497] [G loss: 1.215789]\n",
      "[Epoch 10/1000] [Batch 85/168] [D loss: 0.152696] [G loss: 6.730969]\n",
      "[Epoch 10/1000] [Batch 86/168] [D loss: 0.090575] [G loss: 6.209961]\n",
      "[Epoch 10/1000] [Batch 87/168] [D loss: 0.068245] [G loss: 2.987842]\n",
      "[Epoch 10/1000] [Batch 88/168] [D loss: 0.294400] [G loss: 1.130603]\n",
      "[Epoch 10/1000] [Batch 89/168] [D loss: 0.211246] [G loss: 6.650049]\n",
      "[Epoch 10/1000] [Batch 90/168] [D loss: 0.069710] [G loss: 5.282331]\n",
      "[Epoch 10/1000] [Batch 91/168] [D loss: 0.167094] [G loss: 1.718653]\n",
      "[Epoch 10/1000] [Batch 92/168] [D loss: 0.067320] [G loss: 3.799901]\n",
      "[Epoch 10/1000] [Batch 93/168] [D loss: 0.134011] [G loss: 2.843365]\n",
      "[Epoch 10/1000] [Batch 94/168] [D loss: 0.254752] [G loss: 1.495590]\n",
      "[Epoch 10/1000] [Batch 95/168] [D loss: 0.166129] [G loss: 5.536989]\n",
      "[Epoch 10/1000] [Batch 96/168] [D loss: 0.096026] [G loss: 3.508883]\n",
      "[Epoch 10/1000] [Batch 97/168] [D loss: 0.454439] [G loss: 0.668213]\n",
      "[Epoch 10/1000] [Batch 98/168] [D loss: 0.811104] [G loss: 10.824950]\n",
      "[Epoch 10/1000] [Batch 99/168] [D loss: 0.026285] [G loss: 6.870192]\n",
      "[Epoch 10/1000] [Batch 100/168] [D loss: 0.174431] [G loss: 1.890188]\n",
      "[Epoch 10/1000] [Batch 101/168] [D loss: 0.076678] [G loss: 2.450693]\n",
      "[Epoch 10/1000] [Batch 102/168] [D loss: 0.080486] [G loss: 3.104709]\n",
      "[Epoch 10/1000] [Batch 103/168] [D loss: 0.156237] [G loss: 2.602100]\n",
      "[Epoch 10/1000] [Batch 104/168] [D loss: 0.211354] [G loss: 2.251158]\n",
      "[Epoch 10/1000] [Batch 105/168] [D loss: 0.179477] [G loss: 2.092895]\n",
      "[Epoch 10/1000] [Batch 106/168] [D loss: 0.141217] [G loss: 2.604789]\n",
      "[Epoch 10/1000] [Batch 107/168] [D loss: 0.141212] [G loss: 2.185066]\n",
      "[Epoch 10/1000] [Batch 108/168] [D loss: 0.098278] [G loss: 3.136466]\n",
      "[Epoch 10/1000] [Batch 109/168] [D loss: 0.123217] [G loss: 2.476380]\n",
      "[Epoch 10/1000] [Batch 110/168] [D loss: 0.155469] [G loss: 2.204416]\n",
      "[Epoch 10/1000] [Batch 111/168] [D loss: 0.220684] [G loss: 3.614477]\n",
      "[Epoch 10/1000] [Batch 112/168] [D loss: 0.342302] [G loss: 0.942849]\n",
      "[Epoch 10/1000] [Batch 113/168] [D loss: 0.704509] [G loss: 9.540485]\n",
      "[Epoch 10/1000] [Batch 114/168] [D loss: 0.029844] [G loss: 5.650521]\n",
      "[Epoch 10/1000] [Batch 115/168] [D loss: 0.187567] [G loss: 1.721565]\n",
      "[Epoch 10/1000] [Batch 116/168] [D loss: 0.020607] [G loss: 4.026647]\n",
      "[Epoch 10/1000] [Batch 117/168] [D loss: 0.022587] [G loss: 4.349470]\n",
      "[Epoch 10/1000] [Batch 118/168] [D loss: 0.069268] [G loss: 3.007920]\n",
      "[Epoch 10/1000] [Batch 119/168] [D loss: 0.162408] [G loss: 2.174838]\n",
      "[Epoch 10/1000] [Batch 120/168] [D loss: 0.111997] [G loss: 3.003465]\n",
      "[Epoch 10/1000] [Batch 121/168] [D loss: 0.172206] [G loss: 2.093712]\n",
      "[Epoch 10/1000] [Batch 122/168] [D loss: 0.119114] [G loss: 2.680644]\n",
      "[Epoch 10/1000] [Batch 123/168] [D loss: 0.149784] [G loss: 2.639402]\n",
      "[Epoch 10/1000] [Batch 124/168] [D loss: 0.166747] [G loss: 1.879895]\n",
      "[Epoch 10/1000] [Batch 125/168] [D loss: 0.144995] [G loss: 4.226425]\n",
      "[Epoch 10/1000] [Batch 126/168] [D loss: 0.140936] [G loss: 1.877504]\n",
      "[Epoch 10/1000] [Batch 127/168] [D loss: 0.092630] [G loss: 3.945654]\n",
      "[Epoch 10/1000] [Batch 128/168] [D loss: 0.111598] [G loss: 2.463003]\n",
      "[Epoch 10/1000] [Batch 129/168] [D loss: 0.109674] [G loss: 2.255022]\n",
      "[Epoch 10/1000] [Batch 130/168] [D loss: 0.138096] [G loss: 3.665793]\n",
      "[Epoch 10/1000] [Batch 131/168] [D loss: 0.134218] [G loss: 1.996594]\n",
      "[Epoch 10/1000] [Batch 132/168] [D loss: 0.063909] [G loss: 4.117178]\n",
      "[Epoch 10/1000] [Batch 133/168] [D loss: 0.116771] [G loss: 3.123137]\n",
      "[Epoch 10/1000] [Batch 134/168] [D loss: 0.159671] [G loss: 1.830567]\n",
      "[Epoch 10/1000] [Batch 135/168] [D loss: 0.093593] [G loss: 4.676170]\n",
      "[Epoch 10/1000] [Batch 136/168] [D loss: 0.077787] [G loss: 3.632485]\n",
      "[Epoch 10/1000] [Batch 137/168] [D loss: 0.176800] [G loss: 1.622928]\n",
      "[Epoch 10/1000] [Batch 138/168] [D loss: 0.183643] [G loss: 6.154603]\n",
      "[Epoch 10/1000] [Batch 139/168] [D loss: 0.034742] [G loss: 3.916178]\n",
      "[Epoch 10/1000] [Batch 140/168] [D loss: 0.207411] [G loss: 1.614541]\n",
      "[Epoch 10/1000] [Batch 141/168] [D loss: 0.150762] [G loss: 5.938187]\n",
      "[Epoch 10/1000] [Batch 142/168] [D loss: 0.071595] [G loss: 3.541269]\n",
      "[Epoch 10/1000] [Batch 143/168] [D loss: 0.249398] [G loss: 1.440195]\n",
      "[Epoch 10/1000] [Batch 144/168] [D loss: 0.357754] [G loss: 6.596972]\n",
      "[Epoch 10/1000] [Batch 145/168] [D loss: 0.062992] [G loss: 2.599258]\n",
      "[Epoch 10/1000] [Batch 146/168] [D loss: 0.168547] [G loss: 1.518321]\n",
      "[Epoch 10/1000] [Batch 147/168] [D loss: 0.059171] [G loss: 6.509254]\n",
      "[Epoch 10/1000] [Batch 148/168] [D loss: 0.070906] [G loss: 5.711123]\n",
      "[Epoch 10/1000] [Batch 149/168] [D loss: 0.238397] [G loss: 1.306764]\n",
      "[Epoch 10/1000] [Batch 150/168] [D loss: 0.390091] [G loss: 7.396493]\n",
      "[Epoch 10/1000] [Batch 151/168] [D loss: 0.088746] [G loss: 2.693501]\n",
      "[Epoch 10/1000] [Batch 152/168] [D loss: 0.105189] [G loss: 2.268939]\n",
      "[Epoch 10/1000] [Batch 153/168] [D loss: 0.040700] [G loss: 5.443615]\n",
      "[Epoch 10/1000] [Batch 154/168] [D loss: 0.044064] [G loss: 4.331069]\n",
      "[Epoch 10/1000] [Batch 155/168] [D loss: 0.178289] [G loss: 1.847619]\n",
      "[Epoch 10/1000] [Batch 156/168] [D loss: 0.219047] [G loss: 5.500382]\n",
      "[Epoch 10/1000] [Batch 157/168] [D loss: 0.176370] [G loss: 1.580020]\n",
      "[Epoch 10/1000] [Batch 158/168] [D loss: 0.129063] [G loss: 4.829881]\n",
      "[Epoch 10/1000] [Batch 159/168] [D loss: 0.098084] [G loss: 2.395895]\n",
      "[Epoch 10/1000] [Batch 160/168] [D loss: 0.093812] [G loss: 2.459422]\n",
      "[Epoch 10/1000] [Batch 161/168] [D loss: 0.115269] [G loss: 4.203996]\n",
      "[Epoch 10/1000] [Batch 162/168] [D loss: 0.123959] [G loss: 1.996267]\n",
      "[Epoch 10/1000] [Batch 163/168] [D loss: 0.118002] [G loss: 5.185431]\n",
      "[Epoch 10/1000] [Batch 164/168] [D loss: 0.076043] [G loss: 3.073313]\n",
      "[Epoch 10/1000] [Batch 165/168] [D loss: 0.115583] [G loss: 2.127881]\n",
      "[Epoch 10/1000] [Batch 166/168] [D loss: 0.082319] [G loss: 3.939130]\n",
      "[Epoch 10/1000] [Batch 167/168] [D loss: 0.115600] [G loss: 2.723741]\n",
      "[Epoch 10/1000] [Batch 168/168] [D loss: 0.141525] [G loss: 1.848950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/1000] [Batch 1/168] [D loss: 0.191745] [G loss: 5.653094]\n",
      "[Epoch 11/1000] [Batch 2/168] [D loss: 0.018657] [G loss: 4.282752]\n",
      "[Epoch 11/1000] [Batch 3/168] [D loss: 0.020472] [G loss: 3.616374]\n",
      "[Epoch 11/1000] [Batch 4/168] [D loss: 0.011203] [G loss: 4.535714]\n",
      "[Epoch 11/1000] [Batch 5/168] [D loss: 0.008120] [G loss: 5.008878]\n",
      "[Epoch 11/1000] [Batch 6/168] [D loss: 0.005443] [G loss: 5.620480]\n",
      "[Epoch 11/1000] [Batch 7/168] [D loss: 0.006472] [G loss: 5.122665]\n",
      "[Epoch 11/1000] [Batch 8/168] [D loss: 0.011719] [G loss: 5.072380]\n",
      "[Epoch 11/1000] [Batch 9/168] [D loss: 0.016932] [G loss: 4.647544]\n",
      "[Epoch 11/1000] [Batch 10/168] [D loss: 0.011386] [G loss: 4.570532]\n",
      "[Epoch 11/1000] [Batch 11/168] [D loss: 0.012117] [G loss: 4.638941]\n",
      "[Epoch 11/1000] [Batch 12/168] [D loss: 0.014657] [G loss: 4.384510]\n",
      "[Epoch 11/1000] [Batch 13/168] [D loss: 0.013534] [G loss: 5.057539]\n",
      "[Epoch 11/1000] [Batch 14/168] [D loss: 0.016290] [G loss: 4.580124]\n",
      "[Epoch 11/1000] [Batch 15/168] [D loss: 0.019293] [G loss: 4.708190]\n",
      "[Epoch 11/1000] [Batch 16/168] [D loss: 0.020945] [G loss: 4.095766]\n",
      "[Epoch 11/1000] [Batch 17/168] [D loss: 0.019430] [G loss: 4.468480]\n",
      "[Epoch 11/1000] [Batch 18/168] [D loss: 0.019452] [G loss: 4.462529]\n",
      "[Epoch 11/1000] [Batch 19/168] [D loss: 0.016345] [G loss: 4.380027]\n",
      "[Epoch 11/1000] [Batch 20/168] [D loss: 0.020050] [G loss: 4.686748]\n",
      "[Epoch 11/1000] [Batch 21/168] [D loss: 0.027194] [G loss: 4.440452]\n",
      "[Epoch 11/1000] [Batch 22/168] [D loss: 0.027058] [G loss: 4.112494]\n",
      "[Epoch 11/1000] [Batch 23/168] [D loss: 0.019614] [G loss: 4.122510]\n",
      "[Epoch 11/1000] [Batch 24/168] [D loss: 0.022328] [G loss: 4.374304]\n",
      "[Epoch 11/1000] [Batch 25/168] [D loss: 0.014748] [G loss: 4.727795]\n",
      "[Epoch 11/1000] [Batch 26/168] [D loss: 0.017563] [G loss: 4.858389]\n",
      "[Epoch 11/1000] [Batch 27/168] [D loss: 0.024093] [G loss: 4.302839]\n",
      "[Epoch 11/1000] [Batch 28/168] [D loss: 0.021874] [G loss: 4.195863]\n",
      "[Epoch 11/1000] [Batch 29/168] [D loss: 0.019716] [G loss: 4.889975]\n",
      "[Epoch 11/1000] [Batch 30/168] [D loss: 0.028604] [G loss: 4.768301]\n",
      "[Epoch 11/1000] [Batch 31/168] [D loss: 0.016704] [G loss: 4.092477]\n",
      "[Epoch 11/1000] [Batch 32/168] [D loss: 0.021415] [G loss: 4.166743]\n",
      "[Epoch 11/1000] [Batch 33/168] [D loss: 0.023563] [G loss: 4.862827]\n",
      "[Epoch 11/1000] [Batch 34/168] [D loss: 0.017739] [G loss: 4.795856]\n",
      "[Epoch 11/1000] [Batch 35/168] [D loss: 0.023071] [G loss: 4.389767]\n",
      "[Epoch 11/1000] [Batch 36/168] [D loss: 0.025781] [G loss: 3.937613]\n",
      "[Epoch 11/1000] [Batch 37/168] [D loss: 0.016730] [G loss: 4.653405]\n",
      "[Epoch 11/1000] [Batch 38/168] [D loss: 0.018075] [G loss: 4.731120]\n",
      "[Epoch 11/1000] [Batch 39/168] [D loss: 0.022528] [G loss: 4.881095]\n",
      "[Epoch 11/1000] [Batch 40/168] [D loss: 0.019515] [G loss: 4.131935]\n",
      "[Epoch 11/1000] [Batch 41/168] [D loss: 0.012659] [G loss: 4.611067]\n",
      "[Epoch 11/1000] [Batch 42/168] [D loss: 0.022852] [G loss: 4.909521]\n",
      "[Epoch 11/1000] [Batch 43/168] [D loss: 0.018542] [G loss: 4.504020]\n",
      "[Epoch 11/1000] [Batch 44/168] [D loss: 0.020518] [G loss: 4.373362]\n",
      "[Epoch 11/1000] [Batch 45/168] [D loss: 0.018589] [G loss: 4.491071]\n",
      "[Epoch 11/1000] [Batch 46/168] [D loss: 0.019894] [G loss: 4.615021]\n",
      "[Epoch 11/1000] [Batch 47/168] [D loss: 0.018292] [G loss: 4.295331]\n",
      "[Epoch 11/1000] [Batch 48/168] [D loss: 0.018113] [G loss: 4.628730]\n",
      "[Epoch 11/1000] [Batch 49/168] [D loss: 0.017407] [G loss: 4.403508]\n",
      "[Epoch 11/1000] [Batch 50/168] [D loss: 0.017415] [G loss: 4.543036]\n",
      "[Epoch 11/1000] [Batch 51/168] [D loss: 0.017226] [G loss: 4.396072]\n",
      "[Epoch 11/1000] [Batch 52/168] [D loss: 0.017435] [G loss: 4.817068]\n",
      "[Epoch 11/1000] [Batch 53/168] [D loss: 0.027054] [G loss: 4.664363]\n",
      "[Epoch 11/1000] [Batch 54/168] [D loss: 0.021272] [G loss: 4.130086]\n",
      "[Epoch 11/1000] [Batch 55/168] [D loss: 0.027004] [G loss: 3.842885]\n",
      "[Epoch 11/1000] [Batch 56/168] [D loss: 0.016258] [G loss: 4.551224]\n",
      "[Epoch 11/1000] [Batch 57/168] [D loss: 0.020647] [G loss: 4.958587]\n",
      "[Epoch 11/1000] [Batch 58/168] [D loss: 0.018064] [G loss: 4.313318]\n",
      "[Epoch 11/1000] [Batch 59/168] [D loss: 0.013462] [G loss: 4.416864]\n",
      "[Epoch 11/1000] [Batch 60/168] [D loss: 0.014333] [G loss: 4.858123]\n",
      "[Epoch 11/1000] [Batch 61/168] [D loss: 0.025280] [G loss: 4.619819]\n",
      "[Epoch 11/1000] [Batch 62/168] [D loss: 0.018071] [G loss: 4.186781]\n",
      "[Epoch 11/1000] [Batch 63/168] [D loss: 0.028348] [G loss: 4.580307]\n",
      "[Epoch 11/1000] [Batch 64/168] [D loss: 0.018115] [G loss: 4.329964]\n",
      "[Epoch 11/1000] [Batch 65/168] [D loss: 0.018975] [G loss: 4.210696]\n",
      "[Epoch 11/1000] [Batch 66/168] [D loss: 0.013589] [G loss: 4.629646]\n",
      "[Epoch 11/1000] [Batch 67/168] [D loss: 0.019526] [G loss: 4.917550]\n",
      "[Epoch 11/1000] [Batch 68/168] [D loss: 0.021620] [G loss: 4.605798]\n",
      "[Epoch 11/1000] [Batch 69/168] [D loss: 0.018303] [G loss: 4.097974]\n",
      "[Epoch 11/1000] [Batch 70/168] [D loss: 0.015610] [G loss: 4.993030]\n",
      "[Epoch 11/1000] [Batch 71/168] [D loss: 0.019307] [G loss: 4.571668]\n",
      "[Epoch 11/1000] [Batch 72/168] [D loss: 0.017131] [G loss: 4.563516]\n",
      "[Epoch 11/1000] [Batch 73/168] [D loss: 0.017259] [G loss: 4.619628]\n",
      "[Epoch 11/1000] [Batch 74/168] [D loss: 0.023718] [G loss: 4.489390]\n",
      "[Epoch 11/1000] [Batch 75/168] [D loss: 0.025137] [G loss: 4.212437]\n",
      "[Epoch 11/1000] [Batch 76/168] [D loss: 0.019997] [G loss: 3.850224]\n",
      "[Epoch 11/1000] [Batch 77/168] [D loss: 0.016626] [G loss: 4.900872]\n",
      "[Epoch 11/1000] [Batch 78/168] [D loss: 0.012059] [G loss: 4.856869]\n",
      "[Epoch 11/1000] [Batch 79/168] [D loss: 0.014067] [G loss: 4.742302]\n",
      "[Epoch 11/1000] [Batch 80/168] [D loss: 0.021154] [G loss: 4.594800]\n",
      "[Epoch 11/1000] [Batch 81/168] [D loss: 0.021930] [G loss: 4.214839]\n",
      "[Epoch 11/1000] [Batch 82/168] [D loss: 0.019942] [G loss: 4.283077]\n",
      "[Epoch 11/1000] [Batch 83/168] [D loss: 0.022517] [G loss: 4.498608]\n",
      "[Epoch 11/1000] [Batch 84/168] [D loss: 0.016530] [G loss: 4.505194]\n",
      "[Epoch 11/1000] [Batch 85/168] [D loss: 0.019515] [G loss: 4.501081]\n",
      "[Epoch 11/1000] [Batch 86/168] [D loss: 0.013049] [G loss: 4.738620]\n",
      "[Epoch 11/1000] [Batch 87/168] [D loss: 0.017339] [G loss: 4.604231]\n",
      "[Epoch 11/1000] [Batch 88/168] [D loss: 0.015250] [G loss: 4.579258]\n",
      "[Epoch 11/1000] [Batch 89/168] [D loss: 0.018944] [G loss: 4.331407]\n",
      "[Epoch 11/1000] [Batch 90/168] [D loss: 0.019985] [G loss: 4.741628]\n",
      "[Epoch 11/1000] [Batch 91/168] [D loss: 0.018358] [G loss: 4.474964]\n",
      "[Epoch 11/1000] [Batch 92/168] [D loss: 0.024664] [G loss: 4.552454]\n",
      "[Epoch 11/1000] [Batch 93/168] [D loss: 0.022272] [G loss: 4.008756]\n",
      "[Epoch 11/1000] [Batch 94/168] [D loss: 0.020224] [G loss: 4.382668]\n",
      "[Epoch 11/1000] [Batch 95/168] [D loss: 0.016190] [G loss: 4.707090]\n",
      "[Epoch 11/1000] [Batch 96/168] [D loss: 0.014372] [G loss: 4.819083]\n",
      "[Epoch 11/1000] [Batch 97/168] [D loss: 0.020704] [G loss: 4.415380]\n",
      "[Epoch 11/1000] [Batch 98/168] [D loss: 0.018362] [G loss: 4.662151]\n",
      "[Epoch 11/1000] [Batch 99/168] [D loss: 0.022535] [G loss: 3.961028]\n",
      "[Epoch 11/1000] [Batch 100/168] [D loss: 0.024699] [G loss: 4.402400]\n",
      "[Epoch 11/1000] [Batch 101/168] [D loss: 0.017376] [G loss: 4.603800]\n",
      "[Epoch 11/1000] [Batch 102/168] [D loss: 0.015249] [G loss: 4.640488]\n",
      "[Epoch 11/1000] [Batch 103/168] [D loss: 0.017009] [G loss: 4.276856]\n",
      "[Epoch 11/1000] [Batch 104/168] [D loss: 0.017382] [G loss: 4.421456]\n",
      "[Epoch 11/1000] [Batch 105/168] [D loss: 0.018985] [G loss: 4.788568]\n",
      "[Epoch 11/1000] [Batch 106/168] [D loss: 0.022901] [G loss: 4.734148]\n",
      "[Epoch 11/1000] [Batch 107/168] [D loss: 0.022003] [G loss: 3.979141]\n",
      "[Epoch 11/1000] [Batch 108/168] [D loss: 0.027834] [G loss: 4.416194]\n",
      "[Epoch 11/1000] [Batch 109/168] [D loss: 0.018714] [G loss: 4.100455]\n",
      "[Epoch 11/1000] [Batch 110/168] [D loss: 0.018377] [G loss: 4.438574]\n",
      "[Epoch 11/1000] [Batch 111/168] [D loss: 0.015629] [G loss: 5.168925]\n",
      "[Epoch 11/1000] [Batch 112/168] [D loss: 0.029426] [G loss: 4.722423]\n",
      "[Epoch 11/1000] [Batch 113/168] [D loss: 0.021361] [G loss: 3.843326]\n",
      "[Epoch 11/1000] [Batch 114/168] [D loss: 0.018493] [G loss: 4.123402]\n",
      "[Epoch 11/1000] [Batch 115/168] [D loss: 0.016801] [G loss: 4.834008]\n",
      "[Epoch 11/1000] [Batch 116/168] [D loss: 0.013082] [G loss: 5.176151]\n",
      "[Epoch 11/1000] [Batch 117/168] [D loss: 0.019552] [G loss: 4.774817]\n",
      "[Epoch 11/1000] [Batch 118/168] [D loss: 0.015974] [G loss: 4.488294]\n",
      "[Epoch 11/1000] [Batch 119/168] [D loss: 0.022475] [G loss: 4.294811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/1000] [Batch 120/168] [D loss: 0.016430] [G loss: 4.445204]\n",
      "[Epoch 11/1000] [Batch 121/168] [D loss: 0.018890] [G loss: 5.073123]\n",
      "[Epoch 11/1000] [Batch 122/168] [D loss: 0.019347] [G loss: 4.519485]\n",
      "[Epoch 11/1000] [Batch 123/168] [D loss: 0.019626] [G loss: 4.081455]\n",
      "[Epoch 11/1000] [Batch 124/168] [D loss: 0.015163] [G loss: 4.917612]\n",
      "[Epoch 11/1000] [Batch 125/168] [D loss: 0.020124] [G loss: 4.973163]\n",
      "[Epoch 11/1000] [Batch 126/168] [D loss: 0.013573] [G loss: 4.646658]\n",
      "[Epoch 11/1000] [Batch 127/168] [D loss: 0.019658] [G loss: 4.202658]\n",
      "[Epoch 11/1000] [Batch 128/168] [D loss: 0.023097] [G loss: 4.678339]\n",
      "[Epoch 11/1000] [Batch 129/168] [D loss: 0.020114] [G loss: 4.349794]\n",
      "[Epoch 11/1000] [Batch 130/168] [D loss: 0.014965] [G loss: 4.819304]\n",
      "[Epoch 11/1000] [Batch 131/168] [D loss: 0.026947] [G loss: 4.331588]\n",
      "[Epoch 11/1000] [Batch 132/168] [D loss: 0.023612] [G loss: 4.466260]\n",
      "[Epoch 11/1000] [Batch 133/168] [D loss: 0.022506] [G loss: 3.968046]\n",
      "[Epoch 11/1000] [Batch 134/168] [D loss: 0.020081] [G loss: 4.967632]\n",
      "[Epoch 11/1000] [Batch 135/168] [D loss: 0.019213] [G loss: 4.645273]\n",
      "[Epoch 11/1000] [Batch 136/168] [D loss: 0.020584] [G loss: 4.453180]\n",
      "[Epoch 11/1000] [Batch 137/168] [D loss: 0.020029] [G loss: 4.388241]\n",
      "[Epoch 11/1000] [Batch 138/168] [D loss: 0.015171] [G loss: 4.670212]\n",
      "[Epoch 11/1000] [Batch 139/168] [D loss: 0.014789] [G loss: 5.102008]\n",
      "[Epoch 11/1000] [Batch 140/168] [D loss: 0.021431] [G loss: 4.818005]\n",
      "[Epoch 11/1000] [Batch 141/168] [D loss: 0.023211] [G loss: 4.201208]\n",
      "[Epoch 11/1000] [Batch 142/168] [D loss: 0.017219] [G loss: 4.671214]\n",
      "[Epoch 11/1000] [Batch 143/168] [D loss: 0.014973] [G loss: 4.740249]\n",
      "[Epoch 11/1000] [Batch 144/168] [D loss: 0.017662] [G loss: 5.017796]\n",
      "[Epoch 11/1000] [Batch 145/168] [D loss: 0.017964] [G loss: 4.664274]\n",
      "[Epoch 11/1000] [Batch 146/168] [D loss: 0.021615] [G loss: 4.527697]\n",
      "[Epoch 11/1000] [Batch 147/168] [D loss: 0.022327] [G loss: 4.391878]\n",
      "[Epoch 11/1000] [Batch 148/168] [D loss: 0.018768] [G loss: 4.578599]\n",
      "[Epoch 11/1000] [Batch 149/168] [D loss: 0.015070] [G loss: 4.658455]\n",
      "[Epoch 11/1000] [Batch 150/168] [D loss: 0.016514] [G loss: 4.721907]\n",
      "[Epoch 11/1000] [Batch 151/168] [D loss: 0.021260] [G loss: 4.807027]\n",
      "[Epoch 11/1000] [Batch 152/168] [D loss: 0.018620] [G loss: 4.667887]\n",
      "[Epoch 11/1000] [Batch 153/168] [D loss: 0.018335] [G loss: 4.665791]\n",
      "[Epoch 11/1000] [Batch 154/168] [D loss: 0.020008] [G loss: 4.580994]\n",
      "[Epoch 11/1000] [Batch 155/168] [D loss: 0.024454] [G loss: 4.305025]\n",
      "[Epoch 11/1000] [Batch 156/168] [D loss: 0.031198] [G loss: 4.609197]\n",
      "[Epoch 11/1000] [Batch 157/168] [D loss: 0.023428] [G loss: 3.909599]\n",
      "[Epoch 11/1000] [Batch 158/168] [D loss: 0.016099] [G loss: 5.042432]\n",
      "[Epoch 11/1000] [Batch 159/168] [D loss: 0.015988] [G loss: 5.016340]\n",
      "[Epoch 11/1000] [Batch 160/168] [D loss: 0.016187] [G loss: 5.032313]\n",
      "[Epoch 11/1000] [Batch 161/168] [D loss: 0.017879] [G loss: 4.333030]\n",
      "[Epoch 11/1000] [Batch 162/168] [D loss: 0.013159] [G loss: 5.189020]\n",
      "[Epoch 11/1000] [Batch 163/168] [D loss: 0.017520] [G loss: 4.909000]\n",
      "[Epoch 11/1000] [Batch 164/168] [D loss: 0.017803] [G loss: 4.831198]\n",
      "[Epoch 11/1000] [Batch 165/168] [D loss: 0.017719] [G loss: 4.146312]\n",
      "[Epoch 11/1000] [Batch 166/168] [D loss: 0.014749] [G loss: 4.909460]\n",
      "[Epoch 11/1000] [Batch 167/168] [D loss: 0.015663] [G loss: 5.227804]\n",
      "[Epoch 11/1000] [Batch 168/168] [D loss: 0.014867] [G loss: 5.179845]\n",
      "[Epoch 12/1000] [Batch 1/168] [D loss: 0.019140] [G loss: 4.102252]\n",
      "[Epoch 12/1000] [Batch 2/168] [D loss: 0.014600] [G loss: 4.845506]\n",
      "[Epoch 12/1000] [Batch 3/168] [D loss: 0.013056] [G loss: 5.079385]\n",
      "[Epoch 12/1000] [Batch 4/168] [D loss: 0.015589] [G loss: 5.445912]\n",
      "[Epoch 12/1000] [Batch 5/168] [D loss: 0.019765] [G loss: 4.501356]\n",
      "[Epoch 12/1000] [Batch 6/168] [D loss: 0.017406] [G loss: 4.262709]\n",
      "[Epoch 12/1000] [Batch 7/168] [D loss: 0.018732] [G loss: 4.673554]\n",
      "[Epoch 12/1000] [Batch 8/168] [D loss: 0.015278] [G loss: 5.272757]\n",
      "[Epoch 12/1000] [Batch 9/168] [D loss: 0.020466] [G loss: 4.809527]\n",
      "[Epoch 12/1000] [Batch 10/168] [D loss: 0.018713] [G loss: 4.273405]\n",
      "[Epoch 12/1000] [Batch 11/168] [D loss: 0.018300] [G loss: 4.480681]\n",
      "[Epoch 12/1000] [Batch 12/168] [D loss: 0.013347] [G loss: 4.933241]\n",
      "[Epoch 12/1000] [Batch 13/168] [D loss: 0.013072] [G loss: 5.164475]\n",
      "[Epoch 12/1000] [Batch 14/168] [D loss: 0.018035] [G loss: 4.618814]\n",
      "[Epoch 12/1000] [Batch 15/168] [D loss: 0.019505] [G loss: 4.512921]\n",
      "[Epoch 12/1000] [Batch 16/168] [D loss: 0.017177] [G loss: 4.613925]\n",
      "[Epoch 12/1000] [Batch 17/168] [D loss: 0.016292] [G loss: 4.746958]\n",
      "[Epoch 12/1000] [Batch 18/168] [D loss: 0.019729] [G loss: 4.516368]\n",
      "[Epoch 12/1000] [Batch 19/168] [D loss: 0.019965] [G loss: 5.074355]\n",
      "[Epoch 12/1000] [Batch 20/168] [D loss: 0.014393] [G loss: 4.543389]\n",
      "[Epoch 12/1000] [Batch 21/168] [D loss: 0.017972] [G loss: 4.450009]\n",
      "[Epoch 12/1000] [Batch 22/168] [D loss: 0.016597] [G loss: 4.924153]\n",
      "[Epoch 12/1000] [Batch 23/168] [D loss: 0.030109] [G loss: 5.056001]\n",
      "[Epoch 12/1000] [Batch 24/168] [D loss: 0.024246] [G loss: 3.829109]\n",
      "[Epoch 12/1000] [Batch 25/168] [D loss: 0.015464] [G loss: 4.542060]\n",
      "[Epoch 12/1000] [Batch 26/168] [D loss: 0.015301] [G loss: 5.770226]\n",
      "[Epoch 12/1000] [Batch 27/168] [D loss: 0.013408] [G loss: 5.011928]\n",
      "[Epoch 12/1000] [Batch 28/168] [D loss: 0.014049] [G loss: 4.861787]\n",
      "[Epoch 12/1000] [Batch 29/168] [D loss: 0.014000] [G loss: 5.082502]\n",
      "[Epoch 12/1000] [Batch 30/168] [D loss: 0.017767] [G loss: 4.561083]\n",
      "[Epoch 12/1000] [Batch 31/168] [D loss: 0.020882] [G loss: 4.878164]\n",
      "[Epoch 12/1000] [Batch 32/168] [D loss: 0.017356] [G loss: 5.164671]\n",
      "[Epoch 12/1000] [Batch 33/168] [D loss: 0.016984] [G loss: 4.697630]\n",
      "[Epoch 12/1000] [Batch 34/168] [D loss: 0.016685] [G loss: 4.467579]\n",
      "[Epoch 12/1000] [Batch 35/168] [D loss: 0.011685] [G loss: 4.927552]\n",
      "[Epoch 12/1000] [Batch 36/168] [D loss: 0.020204] [G loss: 4.894445]\n",
      "[Epoch 12/1000] [Batch 37/168] [D loss: 0.016341] [G loss: 4.439514]\n",
      "[Epoch 12/1000] [Batch 38/168] [D loss: 0.021501] [G loss: 4.362976]\n",
      "[Epoch 12/1000] [Batch 39/168] [D loss: 0.019611] [G loss: 4.634915]\n",
      "[Epoch 12/1000] [Batch 40/168] [D loss: 0.017715] [G loss: 4.685687]\n",
      "[Epoch 12/1000] [Batch 41/168] [D loss: 0.016901] [G loss: 4.908369]\n",
      "[Epoch 12/1000] [Batch 42/168] [D loss: 0.017547] [G loss: 4.652801]\n",
      "[Epoch 12/1000] [Batch 43/168] [D loss: 0.019297] [G loss: 4.041559]\n",
      "[Epoch 12/1000] [Batch 44/168] [D loss: 0.018950] [G loss: 5.455377]\n",
      "[Epoch 12/1000] [Batch 45/168] [D loss: 0.015343] [G loss: 5.033512]\n",
      "[Epoch 12/1000] [Batch 46/168] [D loss: 0.013401] [G loss: 4.702456]\n",
      "[Epoch 12/1000] [Batch 47/168] [D loss: 0.018349] [G loss: 4.380489]\n",
      "[Epoch 12/1000] [Batch 48/168] [D loss: 0.020576] [G loss: 5.051921]\n",
      "[Epoch 12/1000] [Batch 49/168] [D loss: 0.020120] [G loss: 4.511895]\n",
      "[Epoch 12/1000] [Batch 50/168] [D loss: 0.017358] [G loss: 4.546104]\n",
      "[Epoch 12/1000] [Batch 51/168] [D loss: 0.015667] [G loss: 4.362049]\n",
      "[Epoch 12/1000] [Batch 52/168] [D loss: 0.012038] [G loss: 5.055027]\n",
      "[Epoch 12/1000] [Batch 53/168] [D loss: 0.013703] [G loss: 5.253668]\n",
      "[Epoch 12/1000] [Batch 54/168] [D loss: 0.019085] [G loss: 4.834813]\n",
      "[Epoch 12/1000] [Batch 55/168] [D loss: 0.027542] [G loss: 3.766485]\n",
      "[Epoch 12/1000] [Batch 56/168] [D loss: 0.016388] [G loss: 4.748591]\n",
      "[Epoch 12/1000] [Batch 57/168] [D loss: 0.012243] [G loss: 5.348145]\n",
      "[Epoch 12/1000] [Batch 58/168] [D loss: 0.012464] [G loss: 4.968922]\n",
      "[Epoch 12/1000] [Batch 59/168] [D loss: 0.013880] [G loss: 4.551033]\n",
      "[Epoch 12/1000] [Batch 60/168] [D loss: 0.012645] [G loss: 4.855278]\n",
      "[Epoch 12/1000] [Batch 61/168] [D loss: 0.012535] [G loss: 4.886032]\n",
      "[Epoch 12/1000] [Batch 62/168] [D loss: 0.014587] [G loss: 4.605901]\n",
      "[Epoch 12/1000] [Batch 63/168] [D loss: 0.018610] [G loss: 4.868136]\n",
      "[Epoch 12/1000] [Batch 64/168] [D loss: 0.025052] [G loss: 4.372339]\n",
      "[Epoch 12/1000] [Batch 65/168] [D loss: 0.014660] [G loss: 4.375172]\n",
      "[Epoch 12/1000] [Batch 66/168] [D loss: 0.018741] [G loss: 4.852018]\n",
      "[Epoch 12/1000] [Batch 67/168] [D loss: 0.011659] [G loss: 4.842826]\n",
      "[Epoch 12/1000] [Batch 68/168] [D loss: 0.021033] [G loss: 4.916646]\n",
      "[Epoch 12/1000] [Batch 69/168] [D loss: 0.021911] [G loss: 3.783490]\n",
      "[Epoch 12/1000] [Batch 70/168] [D loss: 0.012060] [G loss: 5.012344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/1000] [Batch 71/168] [D loss: 0.018592] [G loss: 5.385630]\n",
      "[Epoch 12/1000] [Batch 72/168] [D loss: 0.016344] [G loss: 4.378379]\n",
      "[Epoch 12/1000] [Batch 73/168] [D loss: 0.017277] [G loss: 4.406723]\n",
      "[Epoch 12/1000] [Batch 74/168] [D loss: 0.021641] [G loss: 4.903428]\n",
      "[Epoch 12/1000] [Batch 75/168] [D loss: 0.015014] [G loss: 4.410249]\n",
      "[Epoch 12/1000] [Batch 76/168] [D loss: 0.013199] [G loss: 4.432617]\n",
      "[Epoch 12/1000] [Batch 77/168] [D loss: 0.012728] [G loss: 4.959718]\n",
      "[Epoch 12/1000] [Batch 78/168] [D loss: 0.030291] [G loss: 4.874877]\n",
      "[Epoch 12/1000] [Batch 79/168] [D loss: 0.025713] [G loss: 3.547501]\n",
      "[Epoch 12/1000] [Batch 80/168] [D loss: 0.011220] [G loss: 5.057404]\n",
      "[Epoch 12/1000] [Batch 81/168] [D loss: 0.013933] [G loss: 5.608351]\n",
      "[Epoch 12/1000] [Batch 82/168] [D loss: 0.017897] [G loss: 5.192989]\n",
      "[Epoch 12/1000] [Batch 83/168] [D loss: 0.016394] [G loss: 4.285407]\n",
      "[Epoch 12/1000] [Batch 84/168] [D loss: 0.014570] [G loss: 4.435253]\n",
      "[Epoch 12/1000] [Batch 85/168] [D loss: 0.017218] [G loss: 5.175259]\n",
      "[Epoch 12/1000] [Batch 86/168] [D loss: 0.010001] [G loss: 4.931263]\n",
      "[Epoch 12/1000] [Batch 87/168] [D loss: 0.016721] [G loss: 4.872595]\n",
      "[Epoch 12/1000] [Batch 88/168] [D loss: 0.020378] [G loss: 4.162431]\n",
      "[Epoch 12/1000] [Batch 89/168] [D loss: 0.021011] [G loss: 4.757440]\n",
      "[Epoch 12/1000] [Batch 90/168] [D loss: 0.012798] [G loss: 4.541199]\n",
      "[Epoch 12/1000] [Batch 91/168] [D loss: 0.013920] [G loss: 4.819572]\n",
      "[Epoch 12/1000] [Batch 92/168] [D loss: 0.009765] [G loss: 5.062651]\n",
      "[Epoch 12/1000] [Batch 93/168] [D loss: 0.015510] [G loss: 4.999846]\n",
      "[Epoch 12/1000] [Batch 94/168] [D loss: 0.024785] [G loss: 4.474609]\n",
      "[Epoch 12/1000] [Batch 95/168] [D loss: 0.014341] [G loss: 4.575158]\n",
      "[Epoch 12/1000] [Batch 96/168] [D loss: 0.015437] [G loss: 4.719073]\n",
      "[Epoch 12/1000] [Batch 97/168] [D loss: 0.021861] [G loss: 4.828656]\n",
      "[Epoch 12/1000] [Batch 98/168] [D loss: 0.015075] [G loss: 4.238569]\n",
      "[Epoch 12/1000] [Batch 99/168] [D loss: 0.013627] [G loss: 4.780920]\n",
      "[Epoch 12/1000] [Batch 100/168] [D loss: 0.014284] [G loss: 5.425866]\n",
      "[Epoch 12/1000] [Batch 101/168] [D loss: 0.019327] [G loss: 5.000588]\n",
      "[Epoch 12/1000] [Batch 102/168] [D loss: 0.018312] [G loss: 4.197468]\n",
      "[Epoch 12/1000] [Batch 103/168] [D loss: 0.018262] [G loss: 4.504784]\n",
      "[Epoch 12/1000] [Batch 104/168] [D loss: 0.018318] [G loss: 5.087805]\n",
      "[Epoch 12/1000] [Batch 105/168] [D loss: 0.014986] [G loss: 4.366179]\n",
      "[Epoch 12/1000] [Batch 106/168] [D loss: 0.014986] [G loss: 4.642076]\n",
      "[Epoch 12/1000] [Batch 107/168] [D loss: 0.019641] [G loss: 5.125759]\n",
      "[Epoch 12/1000] [Batch 108/168] [D loss: 0.016759] [G loss: 4.715290]\n",
      "[Epoch 12/1000] [Batch 109/168] [D loss: 0.022301] [G loss: 5.051907]\n",
      "[Epoch 12/1000] [Batch 110/168] [D loss: 0.021176] [G loss: 3.785509]\n",
      "[Epoch 12/1000] [Batch 111/168] [D loss: 0.011289] [G loss: 5.460805]\n",
      "[Epoch 12/1000] [Batch 112/168] [D loss: 0.015851] [G loss: 5.413880]\n",
      "[Epoch 12/1000] [Batch 113/168] [D loss: 0.016613] [G loss: 4.335633]\n",
      "[Epoch 12/1000] [Batch 114/168] [D loss: 0.014140] [G loss: 4.775534]\n",
      "[Epoch 12/1000] [Batch 115/168] [D loss: 0.013394] [G loss: 5.116039]\n",
      "[Epoch 12/1000] [Batch 116/168] [D loss: 0.016566] [G loss: 4.636003]\n",
      "[Epoch 12/1000] [Batch 117/168] [D loss: 0.016745] [G loss: 4.730136]\n",
      "[Epoch 12/1000] [Batch 118/168] [D loss: 0.015133] [G loss: 4.802143]\n",
      "[Epoch 12/1000] [Batch 119/168] [D loss: 0.019503] [G loss: 4.792401]\n",
      "[Epoch 12/1000] [Batch 120/168] [D loss: 0.016021] [G loss: 4.250025]\n",
      "[Epoch 12/1000] [Batch 121/168] [D loss: 0.022185] [G loss: 4.656334]\n",
      "[Epoch 12/1000] [Batch 122/168] [D loss: 0.019932] [G loss: 4.843556]\n",
      "[Epoch 12/1000] [Batch 123/168] [D loss: 0.017734] [G loss: 4.152101]\n",
      "[Epoch 12/1000] [Batch 124/168] [D loss: 0.019397] [G loss: 4.795617]\n",
      "[Epoch 12/1000] [Batch 125/168] [D loss: 0.017959] [G loss: 4.884138]\n",
      "[Epoch 12/1000] [Batch 126/168] [D loss: 0.015394] [G loss: 4.268416]\n",
      "[Epoch 12/1000] [Batch 127/168] [D loss: 0.017721] [G loss: 4.623546]\n",
      "[Epoch 12/1000] [Batch 128/168] [D loss: 0.011126] [G loss: 5.284328]\n",
      "[Epoch 12/1000] [Batch 129/168] [D loss: 0.012927] [G loss: 4.965419]\n",
      "[Epoch 12/1000] [Batch 130/168] [D loss: 0.013140] [G loss: 4.513606]\n",
      "[Epoch 12/1000] [Batch 131/168] [D loss: 0.009964] [G loss: 5.037681]\n",
      "[Epoch 12/1000] [Batch 132/168] [D loss: 0.015119] [G loss: 4.979615]\n",
      "[Epoch 12/1000] [Batch 133/168] [D loss: 0.017897] [G loss: 4.591786]\n",
      "[Epoch 12/1000] [Batch 134/168] [D loss: 0.012504] [G loss: 4.369754]\n",
      "[Epoch 12/1000] [Batch 135/168] [D loss: 0.016534] [G loss: 5.222060]\n",
      "[Epoch 12/1000] [Batch 136/168] [D loss: 0.011472] [G loss: 5.046475]\n",
      "[Epoch 12/1000] [Batch 137/168] [D loss: 0.015532] [G loss: 4.493953]\n",
      "[Epoch 12/1000] [Batch 138/168] [D loss: 0.012927] [G loss: 5.067039]\n",
      "[Epoch 12/1000] [Batch 139/168] [D loss: 0.012890] [G loss: 5.067288]\n",
      "[Epoch 12/1000] [Batch 140/168] [D loss: 0.014596] [G loss: 4.654802]\n",
      "[Epoch 12/1000] [Batch 141/168] [D loss: 0.020754] [G loss: 4.868044]\n",
      "[Epoch 12/1000] [Batch 142/168] [D loss: 0.011484] [G loss: 4.708574]\n",
      "[Epoch 12/1000] [Batch 143/168] [D loss: 0.017941] [G loss: 5.168040]\n",
      "[Epoch 12/1000] [Batch 144/168] [D loss: 0.015835] [G loss: 4.625012]\n",
      "[Epoch 12/1000] [Batch 145/168] [D loss: 0.014238] [G loss: 4.511306]\n",
      "[Epoch 12/1000] [Batch 146/168] [D loss: 0.010590] [G loss: 5.004350]\n",
      "[Epoch 12/1000] [Batch 147/168] [D loss: 0.009295] [G loss: 5.613793]\n",
      "[Epoch 12/1000] [Batch 148/168] [D loss: 0.011295] [G loss: 5.310298]\n",
      "[Epoch 12/1000] [Batch 149/168] [D loss: 0.011437] [G loss: 4.802373]\n",
      "[Epoch 12/1000] [Batch 150/168] [D loss: 0.012016] [G loss: 4.851370]\n",
      "[Epoch 12/1000] [Batch 151/168] [D loss: 0.009377] [G loss: 5.381738]\n",
      "[Epoch 12/1000] [Batch 152/168] [D loss: 0.010285] [G loss: 5.226307]\n",
      "[Epoch 12/1000] [Batch 153/168] [D loss: 0.009705] [G loss: 5.231437]\n",
      "[Epoch 12/1000] [Batch 154/168] [D loss: 0.015034] [G loss: 4.964697]\n",
      "[Epoch 12/1000] [Batch 155/168] [D loss: 0.014363] [G loss: 4.450529]\n",
      "[Epoch 12/1000] [Batch 156/168] [D loss: 0.011987] [G loss: 5.229181]\n",
      "[Epoch 12/1000] [Batch 157/168] [D loss: 0.015696] [G loss: 5.324452]\n",
      "[Epoch 12/1000] [Batch 158/168] [D loss: 0.013978] [G loss: 4.433340]\n",
      "[Epoch 12/1000] [Batch 159/168] [D loss: 0.010901] [G loss: 4.892610]\n",
      "[Epoch 12/1000] [Batch 160/168] [D loss: 0.012260] [G loss: 5.440490]\n",
      "[Epoch 12/1000] [Batch 161/168] [D loss: 0.012182] [G loss: 5.097937]\n",
      "[Epoch 12/1000] [Batch 162/168] [D loss: 0.012780] [G loss: 4.543495]\n",
      "[Epoch 12/1000] [Batch 163/168] [D loss: 0.014811] [G loss: 5.075539]\n",
      "[Epoch 12/1000] [Batch 164/168] [D loss: 0.015876] [G loss: 5.248896]\n",
      "[Epoch 12/1000] [Batch 165/168] [D loss: 0.015112] [G loss: 4.599256]\n",
      "[Epoch 12/1000] [Batch 166/168] [D loss: 0.005552] [G loss: 5.829597]\n",
      "[Epoch 12/1000] [Batch 167/168] [D loss: 0.010214] [G loss: 5.838109]\n",
      "[Epoch 12/1000] [Batch 168/168] [D loss: 0.010416] [G loss: 5.399759]\n",
      "[Epoch 13/1000] [Batch 1/168] [D loss: 0.010380] [G loss: 4.815704]\n",
      "[Epoch 13/1000] [Batch 2/168] [D loss: 0.019055] [G loss: 5.072564]\n",
      "[Epoch 13/1000] [Batch 3/168] [D loss: 0.011081] [G loss: 4.630261]\n",
      "[Epoch 13/1000] [Batch 4/168] [D loss: 0.010917] [G loss: 5.075748]\n",
      "[Epoch 13/1000] [Batch 5/168] [D loss: 0.014958] [G loss: 5.575514]\n",
      "[Epoch 13/1000] [Batch 6/168] [D loss: 0.011589] [G loss: 4.625337]\n",
      "[Epoch 13/1000] [Batch 7/168] [D loss: 0.010878] [G loss: 5.236224]\n",
      "[Epoch 13/1000] [Batch 8/168] [D loss: 0.012508] [G loss: 5.207014]\n",
      "[Epoch 13/1000] [Batch 9/168] [D loss: 0.009775] [G loss: 4.933410]\n",
      "[Epoch 13/1000] [Batch 10/168] [D loss: 0.009385] [G loss: 5.141103]\n",
      "[Epoch 13/1000] [Batch 11/168] [D loss: 0.009967] [G loss: 5.601723]\n",
      "[Epoch 13/1000] [Batch 12/168] [D loss: 0.010040] [G loss: 5.283542]\n",
      "[Epoch 13/1000] [Batch 13/168] [D loss: 0.016933] [G loss: 4.518381]\n",
      "[Epoch 13/1000] [Batch 14/168] [D loss: 0.007890] [G loss: 5.248340]\n",
      "[Epoch 13/1000] [Batch 15/168] [D loss: 0.008491] [G loss: 5.701638]\n",
      "[Epoch 13/1000] [Batch 16/168] [D loss: 0.015248] [G loss: 5.147901]\n",
      "[Epoch 13/1000] [Batch 17/168] [D loss: 0.007827] [G loss: 4.939449]\n",
      "[Epoch 13/1000] [Batch 18/168] [D loss: 0.015025] [G loss: 4.644677]\n",
      "[Epoch 13/1000] [Batch 19/168] [D loss: 0.009244] [G loss: 5.417750]\n",
      "[Epoch 13/1000] [Batch 20/168] [D loss: 0.012382] [G loss: 5.360363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/1000] [Batch 21/168] [D loss: 0.030495] [G loss: 5.189398]\n",
      "[Epoch 13/1000] [Batch 22/168] [D loss: 0.029288] [G loss: 3.631274]\n",
      "[Epoch 13/1000] [Batch 23/168] [D loss: 0.011800] [G loss: 6.572326]\n",
      "[Epoch 13/1000] [Batch 24/168] [D loss: 0.012667] [G loss: 7.140228]\n",
      "[Epoch 13/1000] [Batch 25/168] [D loss: 0.005383] [G loss: 5.935143]\n",
      "[Epoch 13/1000] [Batch 26/168] [D loss: 0.010435] [G loss: 5.113352]\n",
      "[Epoch 13/1000] [Batch 27/168] [D loss: 0.010857] [G loss: 5.165104]\n",
      "[Epoch 13/1000] [Batch 28/168] [D loss: 0.008746] [G loss: 4.803751]\n",
      "[Epoch 13/1000] [Batch 29/168] [D loss: 0.008656] [G loss: 5.269526]\n",
      "[Epoch 13/1000] [Batch 30/168] [D loss: 0.011571] [G loss: 5.292562]\n",
      "[Epoch 13/1000] [Batch 31/168] [D loss: 0.010261] [G loss: 5.086926]\n",
      "[Epoch 13/1000] [Batch 32/168] [D loss: 0.009400] [G loss: 5.345614]\n",
      "[Epoch 13/1000] [Batch 33/168] [D loss: 0.010001] [G loss: 5.049367]\n",
      "[Epoch 13/1000] [Batch 34/168] [D loss: 0.009247] [G loss: 5.015088]\n",
      "[Epoch 13/1000] [Batch 35/168] [D loss: 0.009645] [G loss: 5.422091]\n",
      "[Epoch 13/1000] [Batch 36/168] [D loss: 0.009501] [G loss: 5.377894]\n",
      "[Epoch 13/1000] [Batch 37/168] [D loss: 0.015731] [G loss: 4.774580]\n",
      "[Epoch 13/1000] [Batch 38/168] [D loss: 0.010447] [G loss: 5.213725]\n",
      "[Epoch 13/1000] [Batch 39/168] [D loss: 0.013610] [G loss: 5.382699]\n",
      "[Epoch 13/1000] [Batch 40/168] [D loss: 0.011823] [G loss: 5.034968]\n",
      "[Epoch 13/1000] [Batch 41/168] [D loss: 0.010128] [G loss: 4.907432]\n",
      "[Epoch 13/1000] [Batch 42/168] [D loss: 0.010937] [G loss: 5.478158]\n",
      "[Epoch 13/1000] [Batch 43/168] [D loss: 0.011139] [G loss: 5.135169]\n",
      "[Epoch 13/1000] [Batch 44/168] [D loss: 0.007563] [G loss: 5.091164]\n",
      "[Epoch 13/1000] [Batch 45/168] [D loss: 0.011920] [G loss: 5.237875]\n",
      "[Epoch 13/1000] [Batch 46/168] [D loss: 0.011598] [G loss: 5.540924]\n",
      "[Epoch 13/1000] [Batch 47/168] [D loss: 0.010834] [G loss: 4.950799]\n",
      "[Epoch 13/1000] [Batch 48/168] [D loss: 0.010016] [G loss: 5.601948]\n",
      "[Epoch 13/1000] [Batch 49/168] [D loss: 0.011782] [G loss: 5.308425]\n",
      "[Epoch 13/1000] [Batch 50/168] [D loss: 0.009173] [G loss: 5.283472]\n",
      "[Epoch 13/1000] [Batch 51/168] [D loss: 0.014205] [G loss: 4.642076]\n",
      "[Epoch 13/1000] [Batch 52/168] [D loss: 0.009614] [G loss: 5.064840]\n",
      "[Epoch 13/1000] [Batch 53/168] [D loss: 0.009877] [G loss: 5.795927]\n",
      "[Epoch 13/1000] [Batch 54/168] [D loss: 0.013738] [G loss: 5.549014]\n",
      "[Epoch 13/1000] [Batch 55/168] [D loss: 0.014513] [G loss: 4.708552]\n",
      "[Epoch 13/1000] [Batch 56/168] [D loss: 0.011363] [G loss: 4.968037]\n",
      "[Epoch 13/1000] [Batch 57/168] [D loss: 0.012004] [G loss: 5.114745]\n",
      "[Epoch 13/1000] [Batch 58/168] [D loss: 0.014703] [G loss: 5.513003]\n",
      "[Epoch 13/1000] [Batch 59/168] [D loss: 0.013166] [G loss: 4.701926]\n",
      "[Epoch 13/1000] [Batch 60/168] [D loss: 0.008297] [G loss: 5.354378]\n",
      "[Epoch 13/1000] [Batch 61/168] [D loss: 0.007121] [G loss: 5.356472]\n",
      "[Epoch 13/1000] [Batch 62/168] [D loss: 0.008788] [G loss: 5.344996]\n",
      "[Epoch 13/1000] [Batch 63/168] [D loss: 0.008355] [G loss: 5.695615]\n",
      "[Epoch 13/1000] [Batch 64/168] [D loss: 0.011296] [G loss: 5.011284]\n",
      "[Epoch 13/1000] [Batch 65/168] [D loss: 0.014696] [G loss: 5.234796]\n",
      "[Epoch 13/1000] [Batch 66/168] [D loss: 0.012392] [G loss: 4.759366]\n",
      "[Epoch 13/1000] [Batch 67/168] [D loss: 0.017585] [G loss: 4.998453]\n",
      "[Epoch 13/1000] [Batch 68/168] [D loss: 0.011540] [G loss: 4.895882]\n",
      "[Epoch 13/1000] [Batch 69/168] [D loss: 0.011768] [G loss: 4.997408]\n",
      "[Epoch 13/1000] [Batch 70/168] [D loss: 0.012418] [G loss: 4.866262]\n",
      "[Epoch 13/1000] [Batch 71/168] [D loss: 0.008421] [G loss: 5.145737]\n",
      "[Epoch 13/1000] [Batch 72/168] [D loss: 0.016424] [G loss: 5.185614]\n",
      "[Epoch 13/1000] [Batch 73/168] [D loss: 0.016051] [G loss: 4.760690]\n",
      "[Epoch 13/1000] [Batch 74/168] [D loss: 0.012763] [G loss: 4.732592]\n",
      "[Epoch 13/1000] [Batch 75/168] [D loss: 0.010818] [G loss: 5.092836]\n",
      "[Epoch 13/1000] [Batch 76/168] [D loss: 0.010185] [G loss: 5.392041]\n",
      "[Epoch 13/1000] [Batch 77/168] [D loss: 0.010707] [G loss: 4.946317]\n",
      "[Epoch 13/1000] [Batch 78/168] [D loss: 0.014061] [G loss: 4.941056]\n",
      "[Epoch 13/1000] [Batch 79/168] [D loss: 0.011099] [G loss: 4.643525]\n",
      "[Epoch 13/1000] [Batch 80/168] [D loss: 0.010942] [G loss: 5.548895]\n",
      "[Epoch 13/1000] [Batch 81/168] [D loss: 0.009688] [G loss: 5.400672]\n",
      "[Epoch 13/1000] [Batch 82/168] [D loss: 0.011458] [G loss: 4.800278]\n",
      "[Epoch 13/1000] [Batch 83/168] [D loss: 0.010527] [G loss: 5.145313]\n",
      "[Epoch 13/1000] [Batch 84/168] [D loss: 0.012900] [G loss: 4.822793]\n",
      "[Epoch 13/1000] [Batch 85/168] [D loss: 0.013953] [G loss: 4.658230]\n",
      "[Epoch 13/1000] [Batch 86/168] [D loss: 0.013292] [G loss: 5.435240]\n",
      "[Epoch 13/1000] [Batch 87/168] [D loss: 0.014911] [G loss: 4.749643]\n",
      "[Epoch 13/1000] [Batch 88/168] [D loss: 0.011038] [G loss: 4.748367]\n",
      "[Epoch 13/1000] [Batch 89/168] [D loss: 0.011189] [G loss: 5.267074]\n",
      "[Epoch 13/1000] [Batch 90/168] [D loss: 0.007675] [G loss: 4.966788]\n",
      "[Epoch 13/1000] [Batch 91/168] [D loss: 0.012377] [G loss: 5.173800]\n",
      "[Epoch 13/1000] [Batch 92/168] [D loss: 0.012464] [G loss: 4.894810]\n",
      "[Epoch 13/1000] [Batch 93/168] [D loss: 0.012356] [G loss: 4.547447]\n",
      "[Epoch 13/1000] [Batch 94/168] [D loss: 0.014559] [G loss: 5.467748]\n",
      "[Epoch 13/1000] [Batch 95/168] [D loss: 0.016962] [G loss: 4.335378]\n",
      "[Epoch 13/1000] [Batch 96/168] [D loss: 0.016765] [G loss: 6.262886]\n",
      "[Epoch 13/1000] [Batch 97/168] [D loss: 0.006199] [G loss: 5.466497]\n",
      "[Epoch 13/1000] [Batch 98/168] [D loss: 0.009988] [G loss: 4.994869]\n",
      "[Epoch 13/1000] [Batch 99/168] [D loss: 0.012246] [G loss: 4.840814]\n",
      "[Epoch 13/1000] [Batch 100/168] [D loss: 0.012778] [G loss: 5.012707]\n",
      "[Epoch 13/1000] [Batch 101/168] [D loss: 0.012758] [G loss: 5.259023]\n",
      "[Epoch 13/1000] [Batch 102/168] [D loss: 0.014810] [G loss: 4.440546]\n",
      "[Epoch 13/1000] [Batch 103/168] [D loss: 0.011224] [G loss: 5.460764]\n",
      "[Epoch 13/1000] [Batch 104/168] [D loss: 0.011958] [G loss: 5.465623]\n",
      "[Epoch 13/1000] [Batch 105/168] [D loss: 0.011507] [G loss: 4.883547]\n",
      "[Epoch 13/1000] [Batch 106/168] [D loss: 0.011189] [G loss: 5.190794]\n",
      "[Epoch 13/1000] [Batch 107/168] [D loss: 0.011193] [G loss: 5.051655]\n",
      "[Epoch 13/1000] [Batch 108/168] [D loss: 0.012116] [G loss: 5.000614]\n",
      "[Epoch 13/1000] [Batch 109/168] [D loss: 0.010735] [G loss: 4.707124]\n",
      "[Epoch 13/1000] [Batch 110/168] [D loss: 0.013535] [G loss: 4.972453]\n",
      "[Epoch 13/1000] [Batch 111/168] [D loss: 0.014807] [G loss: 4.980398]\n",
      "[Epoch 13/1000] [Batch 112/168] [D loss: 0.010521] [G loss: 4.655189]\n",
      "[Epoch 13/1000] [Batch 113/168] [D loss: 0.009382] [G loss: 5.482064]\n",
      "[Epoch 13/1000] [Batch 114/168] [D loss: 0.011331] [G loss: 5.469545]\n",
      "[Epoch 13/1000] [Batch 115/168] [D loss: 0.013516] [G loss: 5.086000]\n",
      "[Epoch 13/1000] [Batch 116/168] [D loss: 0.015329] [G loss: 4.281154]\n",
      "[Epoch 13/1000] [Batch 117/168] [D loss: 0.011826] [G loss: 5.306138]\n",
      "[Epoch 13/1000] [Batch 118/168] [D loss: 0.015366] [G loss: 5.442789]\n",
      "[Epoch 13/1000] [Batch 119/168] [D loss: 0.013836] [G loss: 4.287190]\n",
      "[Epoch 13/1000] [Batch 120/168] [D loss: 0.006640] [G loss: 5.321043]\n",
      "[Epoch 13/1000] [Batch 121/168] [D loss: 0.008653] [G loss: 5.651919]\n",
      "[Epoch 13/1000] [Batch 122/168] [D loss: 0.009669] [G loss: 5.436600]\n",
      "[Epoch 13/1000] [Batch 123/168] [D loss: 0.011684] [G loss: 4.931512]\n",
      "[Epoch 13/1000] [Batch 124/168] [D loss: 0.012559] [G loss: 5.227686]\n",
      "[Epoch 13/1000] [Batch 125/168] [D loss: 0.009278] [G loss: 5.080194]\n",
      "[Epoch 13/1000] [Batch 126/168] [D loss: 0.017496] [G loss: 5.508707]\n",
      "[Epoch 13/1000] [Batch 127/168] [D loss: 0.013437] [G loss: 4.237057]\n",
      "[Epoch 13/1000] [Batch 128/168] [D loss: 0.008025] [G loss: 5.440467]\n",
      "[Epoch 13/1000] [Batch 129/168] [D loss: 0.004477] [G loss: 6.003939]\n",
      "[Epoch 13/1000] [Batch 130/168] [D loss: 0.015662] [G loss: 5.995987]\n",
      "[Epoch 13/1000] [Batch 131/168] [D loss: 0.013793] [G loss: 4.520413]\n",
      "[Epoch 13/1000] [Batch 132/168] [D loss: 0.013544] [G loss: 4.936093]\n",
      "[Epoch 13/1000] [Batch 133/168] [D loss: 0.008053] [G loss: 5.736720]\n",
      "[Epoch 13/1000] [Batch 134/168] [D loss: 0.009803] [G loss: 5.738773]\n",
      "[Epoch 13/1000] [Batch 135/168] [D loss: 0.007511] [G loss: 5.185559]\n",
      "[Epoch 13/1000] [Batch 136/168] [D loss: 0.007127] [G loss: 5.173274]\n",
      "[Epoch 13/1000] [Batch 137/168] [D loss: 0.008072] [G loss: 5.831556]\n",
      "[Epoch 13/1000] [Batch 138/168] [D loss: 0.008794] [G loss: 5.521150]\n",
      "[Epoch 13/1000] [Batch 139/168] [D loss: 0.011635] [G loss: 5.029934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/1000] [Batch 140/168] [D loss: 0.010466] [G loss: 4.987927]\n",
      "[Epoch 13/1000] [Batch 141/168] [D loss: 0.012936] [G loss: 5.598459]\n",
      "[Epoch 13/1000] [Batch 142/168] [D loss: 0.011294] [G loss: 4.980402]\n",
      "[Epoch 13/1000] [Batch 143/168] [D loss: 0.015018] [G loss: 4.985981]\n",
      "[Epoch 13/1000] [Batch 144/168] [D loss: 0.010548] [G loss: 4.831690]\n",
      "[Epoch 13/1000] [Batch 145/168] [D loss: 0.015765] [G loss: 5.409180]\n",
      "[Epoch 13/1000] [Batch 146/168] [D loss: 0.012775] [G loss: 5.070303]\n",
      "[Epoch 13/1000] [Batch 147/168] [D loss: 0.011571] [G loss: 4.744916]\n",
      "[Epoch 13/1000] [Batch 148/168] [D loss: 0.010924] [G loss: 5.557304]\n",
      "[Epoch 13/1000] [Batch 149/168] [D loss: 0.005765] [G loss: 5.643140]\n",
      "[Epoch 13/1000] [Batch 150/168] [D loss: 0.009017] [G loss: 5.503461]\n",
      "[Epoch 13/1000] [Batch 151/168] [D loss: 0.008012] [G loss: 5.821636]\n",
      "[Epoch 13/1000] [Batch 152/168] [D loss: 0.013589] [G loss: 4.618324]\n",
      "[Epoch 13/1000] [Batch 153/168] [D loss: 0.013531] [G loss: 5.189691]\n",
      "[Epoch 13/1000] [Batch 154/168] [D loss: 0.010050] [G loss: 4.868414]\n",
      "[Epoch 13/1000] [Batch 155/168] [D loss: 0.008923] [G loss: 5.383423]\n",
      "[Epoch 13/1000] [Batch 156/168] [D loss: 0.007365] [G loss: 5.414178]\n",
      "[Epoch 13/1000] [Batch 157/168] [D loss: 0.008336] [G loss: 5.602063]\n",
      "[Epoch 13/1000] [Batch 158/168] [D loss: 0.011749] [G loss: 5.360287]\n",
      "[Epoch 13/1000] [Batch 159/168] [D loss: 0.014193] [G loss: 4.431666]\n",
      "[Epoch 13/1000] [Batch 160/168] [D loss: 0.010001] [G loss: 6.198249]\n",
      "[Epoch 13/1000] [Batch 161/168] [D loss: 0.005212] [G loss: 5.880320]\n",
      "[Epoch 13/1000] [Batch 162/168] [D loss: 0.006560] [G loss: 5.451894]\n",
      "[Epoch 13/1000] [Batch 163/168] [D loss: 0.009640] [G loss: 5.060481]\n",
      "[Epoch 13/1000] [Batch 164/168] [D loss: 0.009671] [G loss: 5.017331]\n",
      "[Epoch 13/1000] [Batch 165/168] [D loss: 0.007591] [G loss: 5.247906]\n",
      "[Epoch 13/1000] [Batch 166/168] [D loss: 0.013490] [G loss: 5.714762]\n",
      "[Epoch 13/1000] [Batch 167/168] [D loss: 0.011332] [G loss: 4.464979]\n",
      "[Epoch 13/1000] [Batch 168/168] [D loss: 0.010162] [G loss: 5.562248]\n",
      "[Epoch 14/1000] [Batch 1/168] [D loss: 0.009237] [G loss: 5.330484]\n",
      "[Epoch 14/1000] [Batch 2/168] [D loss: 0.008540] [G loss: 5.168671]\n",
      "[Epoch 14/1000] [Batch 3/168] [D loss: 0.008584] [G loss: 5.698515]\n",
      "[Epoch 14/1000] [Batch 4/168] [D loss: 0.008733] [G loss: 4.972690]\n",
      "[Epoch 14/1000] [Batch 5/168] [D loss: 0.008574] [G loss: 5.412804]\n",
      "[Epoch 14/1000] [Batch 6/168] [D loss: 0.012998] [G loss: 5.391233]\n",
      "[Epoch 14/1000] [Batch 7/168] [D loss: 0.009644] [G loss: 4.941121]\n",
      "[Epoch 14/1000] [Batch 8/168] [D loss: 0.008576] [G loss: 4.978096]\n",
      "[Epoch 14/1000] [Batch 9/168] [D loss: 0.009144] [G loss: 5.567394]\n",
      "[Epoch 14/1000] [Batch 10/168] [D loss: 0.010254] [G loss: 5.906801]\n",
      "[Epoch 14/1000] [Batch 11/168] [D loss: 0.010833] [G loss: 4.852580]\n",
      "[Epoch 14/1000] [Batch 12/168] [D loss: 0.008429] [G loss: 4.775472]\n",
      "[Epoch 14/1000] [Batch 13/168] [D loss: 0.006485] [G loss: 5.590622]\n",
      "[Epoch 14/1000] [Batch 14/168] [D loss: 0.008271] [G loss: 5.567074]\n",
      "[Epoch 14/1000] [Batch 15/168] [D loss: 0.008485] [G loss: 5.178952]\n",
      "[Epoch 14/1000] [Batch 16/168] [D loss: 0.009003] [G loss: 5.647130]\n",
      "[Epoch 14/1000] [Batch 17/168] [D loss: 0.010723] [G loss: 4.832765]\n",
      "[Epoch 14/1000] [Batch 18/168] [D loss: 0.012024] [G loss: 4.763870]\n",
      "[Epoch 14/1000] [Batch 19/168] [D loss: 0.013746] [G loss: 5.599669]\n",
      "[Epoch 14/1000] [Batch 20/168] [D loss: 0.013123] [G loss: 4.734876]\n",
      "[Epoch 14/1000] [Batch 21/168] [D loss: 0.009895] [G loss: 5.240280]\n",
      "[Epoch 14/1000] [Batch 22/168] [D loss: 0.012710] [G loss: 4.621047]\n",
      "[Epoch 14/1000] [Batch 23/168] [D loss: 0.011872] [G loss: 5.102924]\n",
      "[Epoch 14/1000] [Batch 24/168] [D loss: 0.013046] [G loss: 4.963118]\n",
      "[Epoch 14/1000] [Batch 25/168] [D loss: 0.008677] [G loss: 4.872167]\n",
      "[Epoch 14/1000] [Batch 26/168] [D loss: 0.011505] [G loss: 5.718565]\n",
      "[Epoch 14/1000] [Batch 27/168] [D loss: 0.008580] [G loss: 5.111858]\n",
      "[Epoch 14/1000] [Batch 28/168] [D loss: 0.013854] [G loss: 4.871922]\n",
      "[Epoch 14/1000] [Batch 29/168] [D loss: 0.008259] [G loss: 4.851110]\n",
      "[Epoch 14/1000] [Batch 30/168] [D loss: 0.009734] [G loss: 5.791576]\n",
      "[Epoch 14/1000] [Batch 31/168] [D loss: 0.009617] [G loss: 5.186541]\n",
      "[Epoch 14/1000] [Batch 32/168] [D loss: 0.013183] [G loss: 4.903968]\n",
      "[Epoch 14/1000] [Batch 33/168] [D loss: 0.010886] [G loss: 4.796772]\n",
      "[Epoch 14/1000] [Batch 34/168] [D loss: 0.011768] [G loss: 5.355919]\n",
      "[Epoch 14/1000] [Batch 35/168] [D loss: 0.012418] [G loss: 5.067975]\n",
      "[Epoch 14/1000] [Batch 36/168] [D loss: 0.011737] [G loss: 4.487026]\n",
      "[Epoch 14/1000] [Batch 37/168] [D loss: 0.009165] [G loss: 5.720322]\n",
      "[Epoch 14/1000] [Batch 38/168] [D loss: 0.015694] [G loss: 5.523965]\n",
      "[Epoch 14/1000] [Batch 39/168] [D loss: 0.011087] [G loss: 4.515576]\n",
      "[Epoch 14/1000] [Batch 40/168] [D loss: 0.013290] [G loss: 5.280213]\n",
      "[Epoch 14/1000] [Batch 41/168] [D loss: 0.012518] [G loss: 4.960164]\n",
      "[Epoch 14/1000] [Batch 42/168] [D loss: 0.009224] [G loss: 5.228393]\n",
      "[Epoch 14/1000] [Batch 43/168] [D loss: 0.008329] [G loss: 5.420710]\n",
      "[Epoch 14/1000] [Batch 44/168] [D loss: 0.010429] [G loss: 5.178747]\n",
      "[Epoch 14/1000] [Batch 45/168] [D loss: 0.007747] [G loss: 5.131010]\n",
      "[Epoch 14/1000] [Batch 46/168] [D loss: 0.012883] [G loss: 5.619566]\n",
      "[Epoch 14/1000] [Batch 47/168] [D loss: 0.013005] [G loss: 4.753877]\n",
      "[Epoch 14/1000] [Batch 48/168] [D loss: 0.008148] [G loss: 5.244797]\n",
      "[Epoch 14/1000] [Batch 49/168] [D loss: 0.007779] [G loss: 5.755423]\n",
      "[Epoch 14/1000] [Batch 50/168] [D loss: 0.008499] [G loss: 5.515816]\n",
      "[Epoch 14/1000] [Batch 51/168] [D loss: 0.009872] [G loss: 5.418755]\n",
      "[Epoch 14/1000] [Batch 52/168] [D loss: 0.011717] [G loss: 5.229551]\n",
      "[Epoch 14/1000] [Batch 53/168] [D loss: 0.013602] [G loss: 4.546328]\n",
      "[Epoch 14/1000] [Batch 54/168] [D loss: 0.010767] [G loss: 5.451164]\n",
      "[Epoch 14/1000] [Batch 55/168] [D loss: 0.011277] [G loss: 5.483711]\n",
      "[Epoch 14/1000] [Batch 56/168] [D loss: 0.010268] [G loss: 4.863708]\n",
      "[Epoch 14/1000] [Batch 57/168] [D loss: 0.007889] [G loss: 5.229082]\n",
      "[Epoch 14/1000] [Batch 58/168] [D loss: 0.008105] [G loss: 5.586511]\n",
      "[Epoch 14/1000] [Batch 59/168] [D loss: 0.010713] [G loss: 5.409760]\n",
      "[Epoch 14/1000] [Batch 60/168] [D loss: 0.014231] [G loss: 4.560604]\n",
      "[Epoch 14/1000] [Batch 61/168] [D loss: 0.015359] [G loss: 5.489451]\n",
      "[Epoch 14/1000] [Batch 62/168] [D loss: 0.013315] [G loss: 4.703053]\n",
      "[Epoch 14/1000] [Batch 63/168] [D loss: 0.008766] [G loss: 5.341914]\n",
      "[Epoch 14/1000] [Batch 64/168] [D loss: 0.009431] [G loss: 5.754786]\n",
      "[Epoch 14/1000] [Batch 65/168] [D loss: 0.007000] [G loss: 5.207667]\n",
      "[Epoch 14/1000] [Batch 66/168] [D loss: 0.009043] [G loss: 5.345029]\n",
      "[Epoch 14/1000] [Batch 67/168] [D loss: 0.017603] [G loss: 5.116504]\n",
      "[Epoch 14/1000] [Batch 68/168] [D loss: 0.021292] [G loss: 3.951634]\n",
      "[Epoch 14/1000] [Batch 69/168] [D loss: 0.013512] [G loss: 6.592253]\n",
      "[Epoch 14/1000] [Batch 70/168] [D loss: 0.008554] [G loss: 6.041858]\n",
      "[Epoch 14/1000] [Batch 71/168] [D loss: 0.009307] [G loss: 4.697400]\n",
      "[Epoch 14/1000] [Batch 72/168] [D loss: 0.013419] [G loss: 5.300273]\n",
      "[Epoch 14/1000] [Batch 73/168] [D loss: 0.008247] [G loss: 5.350766]\n",
      "[Epoch 14/1000] [Batch 74/168] [D loss: 0.006791] [G loss: 5.572686]\n",
      "[Epoch 14/1000] [Batch 75/168] [D loss: 0.010425] [G loss: 5.313997]\n",
      "[Epoch 14/1000] [Batch 76/168] [D loss: 0.010619] [G loss: 4.823388]\n",
      "[Epoch 14/1000] [Batch 77/168] [D loss: 0.009299] [G loss: 5.370333]\n",
      "[Epoch 14/1000] [Batch 78/168] [D loss: 0.014688] [G loss: 5.947621]\n",
      "[Epoch 14/1000] [Batch 79/168] [D loss: 0.016159] [G loss: 4.119746]\n",
      "[Epoch 14/1000] [Batch 80/168] [D loss: 0.027561] [G loss: 5.840075]\n",
      "[Epoch 14/1000] [Batch 81/168] [D loss: 0.023320] [G loss: 3.651213]\n",
      "[Epoch 14/1000] [Batch 82/168] [D loss: 0.013286] [G loss: 7.949780]\n",
      "[Epoch 14/1000] [Batch 83/168] [D loss: 0.009467] [G loss: 7.784826]\n",
      "[Epoch 14/1000] [Batch 84/168] [D loss: 0.008628] [G loss: 5.976364]\n",
      "[Epoch 14/1000] [Batch 85/168] [D loss: 0.009082] [G loss: 4.712987]\n",
      "[Epoch 14/1000] [Batch 86/168] [D loss: 0.003026] [G loss: 5.904677]\n",
      "[Epoch 14/1000] [Batch 87/168] [D loss: 0.006834] [G loss: 6.152780]\n",
      "[Epoch 14/1000] [Batch 88/168] [D loss: 0.006652] [G loss: 5.811848]\n",
      "[Epoch 14/1000] [Batch 89/168] [D loss: 0.007365] [G loss: 5.194950]\n",
      "[Epoch 14/1000] [Batch 90/168] [D loss: 0.007109] [G loss: 5.746654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/1000] [Batch 91/168] [D loss: 0.007746] [G loss: 5.553215]\n",
      "[Epoch 14/1000] [Batch 92/168] [D loss: 0.010348] [G loss: 5.680804]\n",
      "[Epoch 14/1000] [Batch 93/168] [D loss: 0.007736] [G loss: 5.431998]\n",
      "[Epoch 14/1000] [Batch 94/168] [D loss: 0.012654] [G loss: 4.911088]\n",
      "[Epoch 14/1000] [Batch 95/168] [D loss: 0.005297] [G loss: 5.609926]\n",
      "[Epoch 14/1000] [Batch 96/168] [D loss: 0.007108] [G loss: 5.584198]\n",
      "[Epoch 14/1000] [Batch 97/168] [D loss: 0.010874] [G loss: 5.847679]\n",
      "[Epoch 14/1000] [Batch 98/168] [D loss: 0.010729] [G loss: 4.810444]\n",
      "[Epoch 14/1000] [Batch 99/168] [D loss: 0.008617] [G loss: 5.295592]\n",
      "[Epoch 14/1000] [Batch 100/168] [D loss: 0.012263] [G loss: 5.691555]\n",
      "[Epoch 14/1000] [Batch 101/168] [D loss: 0.009299] [G loss: 4.779498]\n",
      "[Epoch 14/1000] [Batch 102/168] [D loss: 0.004680] [G loss: 5.682112]\n",
      "[Epoch 14/1000] [Batch 103/168] [D loss: 0.009870] [G loss: 5.856579]\n",
      "[Epoch 14/1000] [Batch 104/168] [D loss: 0.008681] [G loss: 5.178824]\n",
      "[Epoch 14/1000] [Batch 105/168] [D loss: 0.009677] [G loss: 4.852305]\n",
      "[Epoch 14/1000] [Batch 106/168] [D loss: 0.008373] [G loss: 5.810058]\n",
      "[Epoch 14/1000] [Batch 107/168] [D loss: 0.007080] [G loss: 5.830210]\n",
      "[Epoch 14/1000] [Batch 108/168] [D loss: 0.010711] [G loss: 5.272068]\n",
      "[Epoch 14/1000] [Batch 109/168] [D loss: 0.011866] [G loss: 4.469273]\n",
      "[Epoch 14/1000] [Batch 110/168] [D loss: 0.014542] [G loss: 6.344210]\n",
      "[Epoch 14/1000] [Batch 111/168] [D loss: 0.004527] [G loss: 5.468996]\n",
      "[Epoch 14/1000] [Batch 112/168] [D loss: 0.004983] [G loss: 5.627479]\n",
      "[Epoch 14/1000] [Batch 113/168] [D loss: 0.007242] [G loss: 5.457373]\n",
      "[Epoch 14/1000] [Batch 114/168] [D loss: 0.010586] [G loss: 4.940771]\n",
      "[Epoch 14/1000] [Batch 115/168] [D loss: 0.006358] [G loss: 5.549765]\n",
      "[Epoch 14/1000] [Batch 116/168] [D loss: 0.007181] [G loss: 5.466094]\n",
      "[Epoch 14/1000] [Batch 117/168] [D loss: 0.007129] [G loss: 5.720035]\n",
      "[Epoch 14/1000] [Batch 118/168] [D loss: 0.006479] [G loss: 5.085901]\n",
      "[Epoch 14/1000] [Batch 119/168] [D loss: 0.005504] [G loss: 5.542342]\n",
      "[Epoch 14/1000] [Batch 120/168] [D loss: 0.018870] [G loss: 5.648796]\n",
      "[Epoch 14/1000] [Batch 121/168] [D loss: 0.018235] [G loss: 3.831023]\n",
      "[Epoch 14/1000] [Batch 122/168] [D loss: 0.004273] [G loss: 6.867046]\n",
      "[Epoch 14/1000] [Batch 123/168] [D loss: 0.014826] [G loss: 7.552263]\n",
      "[Epoch 14/1000] [Batch 124/168] [D loss: 0.004626] [G loss: 5.880775]\n",
      "[Epoch 14/1000] [Batch 125/168] [D loss: 0.008030] [G loss: 4.785453]\n",
      "[Epoch 14/1000] [Batch 126/168] [D loss: 0.004155] [G loss: 5.905910]\n",
      "[Epoch 14/1000] [Batch 127/168] [D loss: 0.005688] [G loss: 6.156348]\n",
      "[Epoch 14/1000] [Batch 128/168] [D loss: 0.010086] [G loss: 6.049423]\n",
      "[Epoch 14/1000] [Batch 129/168] [D loss: 0.011619] [G loss: 4.466385]\n",
      "[Epoch 14/1000] [Batch 130/168] [D loss: 0.006222] [G loss: 5.384353]\n",
      "[Epoch 14/1000] [Batch 131/168] [D loss: 0.010445] [G loss: 6.266257]\n",
      "[Epoch 14/1000] [Batch 132/168] [D loss: 0.006202] [G loss: 5.204512]\n",
      "[Epoch 14/1000] [Batch 133/168] [D loss: 0.007627] [G loss: 5.251268]\n",
      "[Epoch 14/1000] [Batch 134/168] [D loss: 0.018531] [G loss: 5.655246]\n",
      "[Epoch 14/1000] [Batch 135/168] [D loss: 0.010590] [G loss: 4.546690]\n",
      "[Epoch 14/1000] [Batch 136/168] [D loss: 0.007591] [G loss: 5.643423]\n",
      "[Epoch 14/1000] [Batch 137/168] [D loss: 0.004759] [G loss: 5.712473]\n",
      "[Epoch 14/1000] [Batch 138/168] [D loss: 0.008147] [G loss: 6.041257]\n",
      "[Epoch 14/1000] [Batch 139/168] [D loss: 0.012452] [G loss: 5.148455]\n",
      "[Epoch 14/1000] [Batch 140/168] [D loss: 0.007793] [G loss: 5.109956]\n",
      "[Epoch 14/1000] [Batch 141/168] [D loss: 0.007990] [G loss: 5.129933]\n",
      "[Epoch 14/1000] [Batch 142/168] [D loss: 0.007609] [G loss: 6.130238]\n",
      "[Epoch 14/1000] [Batch 143/168] [D loss: 0.004893] [G loss: 5.682557]\n",
      "[Epoch 14/1000] [Batch 144/168] [D loss: 0.005404] [G loss: 5.524796]\n",
      "[Epoch 14/1000] [Batch 145/168] [D loss: 0.005381] [G loss: 5.590146]\n",
      "[Epoch 14/1000] [Batch 146/168] [D loss: 0.005516] [G loss: 5.315200]\n",
      "[Epoch 14/1000] [Batch 147/168] [D loss: 0.009352] [G loss: 5.955782]\n",
      "[Epoch 14/1000] [Batch 148/168] [D loss: 0.010357] [G loss: 4.918649]\n",
      "[Epoch 14/1000] [Batch 149/168] [D loss: 0.009832] [G loss: 5.283614]\n",
      "[Epoch 14/1000] [Batch 150/168] [D loss: 0.008252] [G loss: 5.098544]\n",
      "[Epoch 14/1000] [Batch 151/168] [D loss: 0.016060] [G loss: 5.633340]\n",
      "[Epoch 14/1000] [Batch 152/168] [D loss: 0.018310] [G loss: 3.896696]\n",
      "[Epoch 14/1000] [Batch 153/168] [D loss: 0.009898] [G loss: 7.581041]\n",
      "[Epoch 14/1000] [Batch 154/168] [D loss: 0.009347] [G loss: 7.189590]\n",
      "[Epoch 14/1000] [Batch 155/168] [D loss: 0.004647] [G loss: 5.514409]\n",
      "[Epoch 14/1000] [Batch 156/168] [D loss: 0.009126] [G loss: 5.027393]\n",
      "[Epoch 14/1000] [Batch 157/168] [D loss: 0.006673] [G loss: 5.414569]\n",
      "[Epoch 14/1000] [Batch 158/168] [D loss: 0.005299] [G loss: 6.205101]\n",
      "[Epoch 14/1000] [Batch 159/168] [D loss: 0.004084] [G loss: 6.094117]\n",
      "[Epoch 14/1000] [Batch 160/168] [D loss: 0.012739] [G loss: 5.529281]\n",
      "[Epoch 14/1000] [Batch 161/168] [D loss: 0.012760] [G loss: 4.292216]\n",
      "[Epoch 14/1000] [Batch 162/168] [D loss: 0.009344] [G loss: 6.425410]\n",
      "[Epoch 14/1000] [Batch 163/168] [D loss: 0.007091] [G loss: 5.785495]\n",
      "[Epoch 14/1000] [Batch 164/168] [D loss: 0.005481] [G loss: 5.395617]\n",
      "[Epoch 14/1000] [Batch 165/168] [D loss: 0.007219] [G loss: 5.125356]\n",
      "[Epoch 14/1000] [Batch 166/168] [D loss: 0.008997] [G loss: 6.316539]\n",
      "[Epoch 14/1000] [Batch 167/168] [D loss: 0.007633] [G loss: 5.432889]\n",
      "[Epoch 14/1000] [Batch 168/168] [D loss: 0.008794] [G loss: 5.082411]\n",
      "[Epoch 15/1000] [Batch 1/168] [D loss: 0.007814] [G loss: 5.378942]\n",
      "[Epoch 15/1000] [Batch 2/168] [D loss: 0.008366] [G loss: 5.449275]\n",
      "[Epoch 15/1000] [Batch 3/168] [D loss: 0.006610] [G loss: 5.895707]\n",
      "[Epoch 15/1000] [Batch 4/168] [D loss: 0.008574] [G loss: 4.923207]\n",
      "[Epoch 15/1000] [Batch 5/168] [D loss: 0.011433] [G loss: 5.360589]\n",
      "[Epoch 15/1000] [Batch 6/168] [D loss: 0.011004] [G loss: 5.304020]\n",
      "[Epoch 15/1000] [Batch 7/168] [D loss: 0.009947] [G loss: 4.659541]\n",
      "[Epoch 15/1000] [Batch 8/168] [D loss: 0.005474] [G loss: 5.999829]\n",
      "[Epoch 15/1000] [Batch 9/168] [D loss: 0.014930] [G loss: 6.340128]\n",
      "[Epoch 15/1000] [Batch 10/168] [D loss: 0.009586] [G loss: 4.537066]\n",
      "[Epoch 15/1000] [Batch 11/168] [D loss: 0.010059] [G loss: 4.842447]\n",
      "[Epoch 15/1000] [Batch 12/168] [D loss: 0.008612] [G loss: 7.183234]\n",
      "[Epoch 15/1000] [Batch 13/168] [D loss: 0.012051] [G loss: 6.462393]\n",
      "[Epoch 15/1000] [Batch 14/168] [D loss: 0.010414] [G loss: 4.565549]\n",
      "[Epoch 15/1000] [Batch 15/168] [D loss: 0.005826] [G loss: 5.664587]\n",
      "[Epoch 15/1000] [Batch 16/168] [D loss: 0.006132] [G loss: 5.829293]\n",
      "[Epoch 15/1000] [Batch 17/168] [D loss: 0.004803] [G loss: 5.798150]\n",
      "[Epoch 15/1000] [Batch 18/168] [D loss: 0.011586] [G loss: 5.601316]\n",
      "[Epoch 15/1000] [Batch 19/168] [D loss: 0.009239] [G loss: 4.801991]\n",
      "[Epoch 15/1000] [Batch 20/168] [D loss: 0.005495] [G loss: 5.438070]\n",
      "[Epoch 15/1000] [Batch 21/168] [D loss: 0.009703] [G loss: 6.321332]\n",
      "[Epoch 15/1000] [Batch 22/168] [D loss: 0.008765] [G loss: 4.928286]\n",
      "[Epoch 15/1000] [Batch 23/168] [D loss: 0.009097] [G loss: 5.877982]\n",
      "[Epoch 15/1000] [Batch 24/168] [D loss: 0.007358] [G loss: 5.498802]\n",
      "[Epoch 15/1000] [Batch 25/168] [D loss: 0.007487] [G loss: 5.426463]\n",
      "[Epoch 15/1000] [Batch 26/168] [D loss: 0.011098] [G loss: 5.773940]\n",
      "[Epoch 15/1000] [Batch 27/168] [D loss: 0.011188] [G loss: 4.557678]\n",
      "[Epoch 15/1000] [Batch 28/168] [D loss: 0.006645] [G loss: 6.121628]\n",
      "[Epoch 15/1000] [Batch 29/168] [D loss: 0.009734] [G loss: 5.755505]\n",
      "[Epoch 15/1000] [Batch 30/168] [D loss: 0.010460] [G loss: 4.655384]\n",
      "[Epoch 15/1000] [Batch 31/168] [D loss: 0.015819] [G loss: 6.207871]\n",
      "[Epoch 15/1000] [Batch 32/168] [D loss: 0.011710] [G loss: 4.458356]\n",
      "[Epoch 15/1000] [Batch 33/168] [D loss: 0.005459] [G loss: 6.379191]\n",
      "[Epoch 15/1000] [Batch 34/168] [D loss: 0.009824] [G loss: 6.453163]\n",
      "[Epoch 15/1000] [Batch 35/168] [D loss: 0.011240] [G loss: 5.149128]\n",
      "[Epoch 15/1000] [Batch 36/168] [D loss: 0.012489] [G loss: 4.476167]\n",
      "[Epoch 15/1000] [Batch 37/168] [D loss: 0.005781] [G loss: 6.541711]\n",
      "[Epoch 15/1000] [Batch 38/168] [D loss: 0.019743] [G loss: 6.571738]\n",
      "[Epoch 15/1000] [Batch 39/168] [D loss: 0.024432] [G loss: 3.555105]\n",
      "[Epoch 15/1000] [Batch 40/168] [D loss: 0.018717] [G loss: 9.131327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] [Batch 41/168] [D loss: 0.002682] [G loss: 7.976793]\n",
      "[Epoch 15/1000] [Batch 42/168] [D loss: 0.002097] [G loss: 6.885335]\n",
      "[Epoch 15/1000] [Batch 43/168] [D loss: 0.003366] [G loss: 6.155196]\n",
      "[Epoch 15/1000] [Batch 44/168] [D loss: 0.004365] [G loss: 5.694088]\n",
      "[Epoch 15/1000] [Batch 45/168] [D loss: 0.005323] [G loss: 5.765162]\n",
      "[Epoch 15/1000] [Batch 46/168] [D loss: 0.004240] [G loss: 5.864135]\n",
      "[Epoch 15/1000] [Batch 47/168] [D loss: 0.007404] [G loss: 5.738557]\n",
      "[Epoch 15/1000] [Batch 48/168] [D loss: 0.008282] [G loss: 5.154403]\n",
      "[Epoch 15/1000] [Batch 49/168] [D loss: 0.005036] [G loss: 5.367776]\n",
      "[Epoch 15/1000] [Batch 50/168] [D loss: 0.006696] [G loss: 5.493999]\n",
      "[Epoch 15/1000] [Batch 51/168] [D loss: 0.011562] [G loss: 5.619423]\n",
      "[Epoch 15/1000] [Batch 52/168] [D loss: 0.014012] [G loss: 4.507210]\n",
      "[Epoch 15/1000] [Batch 53/168] [D loss: 0.005365] [G loss: 5.748020]\n",
      "[Epoch 15/1000] [Batch 54/168] [D loss: 0.011769] [G loss: 6.197724]\n",
      "[Epoch 15/1000] [Batch 55/168] [D loss: 0.009905] [G loss: 4.630534]\n",
      "[Epoch 15/1000] [Batch 56/168] [D loss: 0.009164] [G loss: 5.329536]\n",
      "[Epoch 15/1000] [Batch 57/168] [D loss: 0.006082] [G loss: 5.905717]\n",
      "[Epoch 15/1000] [Batch 58/168] [D loss: 0.007013] [G loss: 5.437716]\n",
      "[Epoch 15/1000] [Batch 59/168] [D loss: 0.005896] [G loss: 5.711385]\n",
      "[Epoch 15/1000] [Batch 60/168] [D loss: 0.006037] [G loss: 5.772566]\n",
      "[Epoch 15/1000] [Batch 61/168] [D loss: 0.008920] [G loss: 5.318691]\n",
      "[Epoch 15/1000] [Batch 62/168] [D loss: 0.011924] [G loss: 4.935722]\n",
      "[Epoch 15/1000] [Batch 63/168] [D loss: 0.010243] [G loss: 5.549211]\n",
      "[Epoch 15/1000] [Batch 64/168] [D loss: 0.008309] [G loss: 5.214957]\n",
      "[Epoch 15/1000] [Batch 65/168] [D loss: 0.006637] [G loss: 5.600281]\n",
      "[Epoch 15/1000] [Batch 66/168] [D loss: 0.008930] [G loss: 5.320882]\n",
      "[Epoch 15/1000] [Batch 67/168] [D loss: 0.007771] [G loss: 5.663256]\n",
      "[Epoch 15/1000] [Batch 68/168] [D loss: 0.006961] [G loss: 5.257601]\n",
      "[Epoch 15/1000] [Batch 69/168] [D loss: 0.009606] [G loss: 5.501791]\n",
      "[Epoch 15/1000] [Batch 70/168] [D loss: 0.007512] [G loss: 5.656871]\n",
      "[Epoch 15/1000] [Batch 71/168] [D loss: 0.010411] [G loss: 4.906200]\n",
      "[Epoch 15/1000] [Batch 72/168] [D loss: 0.013435] [G loss: 6.488123]\n",
      "[Epoch 15/1000] [Batch 73/168] [D loss: 0.010450] [G loss: 4.631510]\n",
      "[Epoch 15/1000] [Batch 74/168] [D loss: 0.008205] [G loss: 5.958686]\n",
      "[Epoch 15/1000] [Batch 75/168] [D loss: 0.007603] [G loss: 5.657445]\n",
      "[Epoch 15/1000] [Batch 76/168] [D loss: 0.004852] [G loss: 5.711630]\n",
      "[Epoch 15/1000] [Batch 77/168] [D loss: 0.005166] [G loss: 5.541213]\n",
      "[Epoch 15/1000] [Batch 78/168] [D loss: 0.008561] [G loss: 6.119875]\n",
      "[Epoch 15/1000] [Batch 79/168] [D loss: 0.009067] [G loss: 4.885780]\n",
      "[Epoch 15/1000] [Batch 80/168] [D loss: 0.005485] [G loss: 5.784389]\n",
      "[Epoch 15/1000] [Batch 81/168] [D loss: 0.004625] [G loss: 5.936677]\n",
      "[Epoch 15/1000] [Batch 82/168] [D loss: 0.004919] [G loss: 6.019437]\n",
      "[Epoch 15/1000] [Batch 83/168] [D loss: 0.008645] [G loss: 5.670319]\n",
      "[Epoch 15/1000] [Batch 84/168] [D loss: 0.009219] [G loss: 5.039772]\n",
      "[Epoch 15/1000] [Batch 85/168] [D loss: 0.009516] [G loss: 5.622287]\n",
      "[Epoch 15/1000] [Batch 86/168] [D loss: 0.005769] [G loss: 6.085032]\n",
      "[Epoch 15/1000] [Batch 87/168] [D loss: 0.007689] [G loss: 5.227756]\n",
      "[Epoch 15/1000] [Batch 88/168] [D loss: 0.010327] [G loss: 5.574234]\n",
      "[Epoch 15/1000] [Batch 89/168] [D loss: 0.006725] [G loss: 5.410949]\n",
      "[Epoch 15/1000] [Batch 90/168] [D loss: 0.006526] [G loss: 5.341107]\n",
      "[Epoch 15/1000] [Batch 91/168] [D loss: 0.010561] [G loss: 6.492193]\n",
      "[Epoch 15/1000] [Batch 92/168] [D loss: 0.015633] [G loss: 4.643273]\n",
      "[Epoch 15/1000] [Batch 93/168] [D loss: 0.018040] [G loss: 7.547104]\n",
      "[Epoch 15/1000] [Batch 94/168] [D loss: 0.007658] [G loss: 5.237838]\n",
      "[Epoch 15/1000] [Batch 95/168] [D loss: 0.005184] [G loss: 5.624109]\n",
      "[Epoch 15/1000] [Batch 96/168] [D loss: 0.003384] [G loss: 6.169396]\n",
      "[Epoch 15/1000] [Batch 97/168] [D loss: 0.007838] [G loss: 6.265997]\n",
      "[Epoch 15/1000] [Batch 98/168] [D loss: 0.003976] [G loss: 5.880557]\n",
      "[Epoch 15/1000] [Batch 99/168] [D loss: 0.006168] [G loss: 5.828059]\n",
      "[Epoch 15/1000] [Batch 100/168] [D loss: 0.006325] [G loss: 5.770929]\n",
      "[Epoch 15/1000] [Batch 101/168] [D loss: 0.009610] [G loss: 5.344190]\n",
      "[Epoch 15/1000] [Batch 102/168] [D loss: 0.006821] [G loss: 5.045185]\n",
      "[Epoch 15/1000] [Batch 103/168] [D loss: 0.006697] [G loss: 6.257180]\n",
      "[Epoch 15/1000] [Batch 104/168] [D loss: 0.007304] [G loss: 6.630073]\n",
      "[Epoch 15/1000] [Batch 105/168] [D loss: 0.010248] [G loss: 4.740719]\n",
      "[Epoch 15/1000] [Batch 106/168] [D loss: 0.016085] [G loss: 6.594575]\n",
      "[Epoch 15/1000] [Batch 107/168] [D loss: 0.006445] [G loss: 5.352056]\n",
      "[Epoch 15/1000] [Batch 108/168] [D loss: 0.020334] [G loss: 5.315664]\n",
      "[Epoch 15/1000] [Batch 109/168] [D loss: 0.005991] [G loss: 5.468672]\n",
      "[Epoch 15/1000] [Batch 110/168] [D loss: 0.003452] [G loss: 6.296685]\n",
      "[Epoch 15/1000] [Batch 111/168] [D loss: 0.004783] [G loss: 6.620813]\n",
      "[Epoch 15/1000] [Batch 112/168] [D loss: 0.007980] [G loss: 5.700016]\n",
      "[Epoch 15/1000] [Batch 113/168] [D loss: 0.005244] [G loss: 5.557832]\n",
      "[Epoch 15/1000] [Batch 114/168] [D loss: 0.004686] [G loss: 6.204194]\n",
      "[Epoch 15/1000] [Batch 115/168] [D loss: 0.009742] [G loss: 6.053606]\n",
      "[Epoch 15/1000] [Batch 116/168] [D loss: 0.005471] [G loss: 5.511090]\n",
      "[Epoch 15/1000] [Batch 117/168] [D loss: 0.006114] [G loss: 5.494364]\n",
      "[Epoch 15/1000] [Batch 118/168] [D loss: 0.010325] [G loss: 6.091311]\n",
      "[Epoch 15/1000] [Batch 119/168] [D loss: 0.008563] [G loss: 5.532463]\n",
      "[Epoch 15/1000] [Batch 120/168] [D loss: 0.005878] [G loss: 5.532199]\n",
      "[Epoch 15/1000] [Batch 121/168] [D loss: 0.006423] [G loss: 5.931709]\n",
      "[Epoch 15/1000] [Batch 122/168] [D loss: 0.007357] [G loss: 6.115809]\n",
      "[Epoch 15/1000] [Batch 123/168] [D loss: 0.010365] [G loss: 5.598636]\n",
      "[Epoch 15/1000] [Batch 124/168] [D loss: 0.008715] [G loss: 5.645305]\n",
      "[Epoch 15/1000] [Batch 125/168] [D loss: 0.007700] [G loss: 5.173844]\n",
      "[Epoch 15/1000] [Batch 126/168] [D loss: 0.004163] [G loss: 6.580052]\n",
      "[Epoch 15/1000] [Batch 127/168] [D loss: 0.003937] [G loss: 6.927398]\n",
      "[Epoch 15/1000] [Batch 128/168] [D loss: 0.007696] [G loss: 6.210931]\n",
      "[Epoch 15/1000] [Batch 129/168] [D loss: 0.012478] [G loss: 4.960644]\n",
      "[Epoch 15/1000] [Batch 130/168] [D loss: 0.009476] [G loss: 5.518003]\n",
      "[Epoch 15/1000] [Batch 131/168] [D loss: 0.005595] [G loss: 6.459475]\n",
      "[Epoch 15/1000] [Batch 132/168] [D loss: 0.005841] [G loss: 6.190900]\n",
      "[Epoch 15/1000] [Batch 133/168] [D loss: 0.006810] [G loss: 5.641515]\n",
      "[Epoch 15/1000] [Batch 134/168] [D loss: 0.008760] [G loss: 5.939058]\n",
      "[Epoch 15/1000] [Batch 135/168] [D loss: 0.006201] [G loss: 5.537093]\n",
      "[Epoch 15/1000] [Batch 136/168] [D loss: 0.010711] [G loss: 6.311781]\n",
      "[Epoch 15/1000] [Batch 137/168] [D loss: 0.014214] [G loss: 5.546457]\n",
      "[Epoch 15/1000] [Batch 138/168] [D loss: 0.014537] [G loss: 4.184979]\n",
      "[Epoch 15/1000] [Batch 139/168] [D loss: 0.007367] [G loss: 7.917908]\n",
      "[Epoch 15/1000] [Batch 140/168] [D loss: 0.002443] [G loss: 8.160746]\n",
      "[Epoch 15/1000] [Batch 141/168] [D loss: 0.003469] [G loss: 7.286109]\n",
      "[Epoch 15/1000] [Batch 142/168] [D loss: 0.006044] [G loss: 6.221605]\n",
      "[Epoch 15/1000] [Batch 143/168] [D loss: 0.005833] [G loss: 5.538332]\n",
      "[Epoch 15/1000] [Batch 144/168] [D loss: 0.006374] [G loss: 5.405560]\n",
      "[Epoch 15/1000] [Batch 145/168] [D loss: 0.005103] [G loss: 6.561156]\n",
      "[Epoch 15/1000] [Batch 146/168] [D loss: 0.007959] [G loss: 6.315364]\n",
      "[Epoch 15/1000] [Batch 147/168] [D loss: 0.007684] [G loss: 5.546607]\n",
      "[Epoch 15/1000] [Batch 148/168] [D loss: 0.009847] [G loss: 4.664933]\n",
      "[Epoch 15/1000] [Batch 149/168] [D loss: 0.013099] [G loss: 7.181831]\n",
      "[Epoch 15/1000] [Batch 150/168] [D loss: 0.006951] [G loss: 5.709609]\n",
      "[Epoch 15/1000] [Batch 151/168] [D loss: 0.007710] [G loss: 4.966460]\n",
      "[Epoch 15/1000] [Batch 152/168] [D loss: 0.003288] [G loss: 6.390177]\n",
      "[Epoch 15/1000] [Batch 153/168] [D loss: 0.004780] [G loss: 6.718991]\n",
      "[Epoch 15/1000] [Batch 154/168] [D loss: 0.003531] [G loss: 6.085275]\n",
      "[Epoch 15/1000] [Batch 155/168] [D loss: 0.006410] [G loss: 5.926577]\n",
      "[Epoch 15/1000] [Batch 156/168] [D loss: 0.005088] [G loss: 5.713309]\n",
      "[Epoch 15/1000] [Batch 157/168] [D loss: 0.009676] [G loss: 5.418705]\n",
      "[Epoch 15/1000] [Batch 158/168] [D loss: 0.007552] [G loss: 5.356247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] [Batch 159/168] [D loss: 0.009802] [G loss: 6.150418]\n",
      "[Epoch 15/1000] [Batch 160/168] [D loss: 0.009507] [G loss: 5.022892]\n",
      "[Epoch 15/1000] [Batch 161/168] [D loss: 0.007680] [G loss: 6.568925]\n",
      "[Epoch 15/1000] [Batch 162/168] [D loss: 0.008256] [G loss: 5.998509]\n",
      "[Epoch 15/1000] [Batch 163/168] [D loss: 0.007334] [G loss: 5.027521]\n",
      "[Epoch 15/1000] [Batch 164/168] [D loss: 0.008267] [G loss: 5.432685]\n",
      "[Epoch 15/1000] [Batch 165/168] [D loss: 0.009615] [G loss: 6.133924]\n",
      "[Epoch 15/1000] [Batch 166/168] [D loss: 0.009521] [G loss: 5.210963]\n",
      "[Epoch 15/1000] [Batch 167/168] [D loss: 0.007090] [G loss: 6.024989]\n",
      "[Epoch 15/1000] [Batch 168/168] [D loss: 0.005336] [G loss: 6.447744]\n",
      "[Epoch 16/1000] [Batch 1/168] [D loss: 0.005939] [G loss: 5.766856]\n",
      "[Epoch 16/1000] [Batch 2/168] [D loss: 0.007150] [G loss: 5.606744]\n",
      "[Epoch 16/1000] [Batch 3/168] [D loss: 0.005916] [G loss: 5.604276]\n",
      "[Epoch 16/1000] [Batch 4/168] [D loss: 0.007813] [G loss: 5.712351]\n",
      "[Epoch 16/1000] [Batch 5/168] [D loss: 0.008231] [G loss: 6.252873]\n",
      "[Epoch 16/1000] [Batch 6/168] [D loss: 0.011885] [G loss: 4.757834]\n",
      "[Epoch 16/1000] [Batch 7/168] [D loss: 0.009367] [G loss: 6.932989]\n",
      "[Epoch 16/1000] [Batch 8/168] [D loss: 0.005548] [G loss: 6.388245]\n",
      "[Epoch 16/1000] [Batch 9/168] [D loss: 0.007167] [G loss: 5.203202]\n",
      "[Epoch 16/1000] [Batch 10/168] [D loss: 0.008802] [G loss: 6.152379]\n",
      "[Epoch 16/1000] [Batch 11/168] [D loss: 0.006914] [G loss: 5.327523]\n",
      "[Epoch 16/1000] [Batch 12/168] [D loss: 0.004620] [G loss: 6.471012]\n",
      "[Epoch 16/1000] [Batch 13/168] [D loss: 0.004073] [G loss: 6.212217]\n",
      "[Epoch 16/1000] [Batch 14/168] [D loss: 0.005886] [G loss: 6.147038]\n",
      "[Epoch 16/1000] [Batch 15/168] [D loss: 0.004896] [G loss: 5.848310]\n",
      "[Epoch 16/1000] [Batch 16/168] [D loss: 0.007796] [G loss: 5.874624]\n",
      "[Epoch 16/1000] [Batch 17/168] [D loss: 0.005249] [G loss: 5.608074]\n",
      "[Epoch 16/1000] [Batch 18/168] [D loss: 0.005857] [G loss: 5.767080]\n",
      "[Epoch 16/1000] [Batch 19/168] [D loss: 0.006479] [G loss: 6.197547]\n",
      "[Epoch 16/1000] [Batch 20/168] [D loss: 0.004544] [G loss: 5.846957]\n",
      "[Epoch 16/1000] [Batch 21/168] [D loss: 0.004642] [G loss: 5.707705]\n",
      "[Epoch 16/1000] [Batch 22/168] [D loss: 0.003474] [G loss: 6.007741]\n",
      "[Epoch 16/1000] [Batch 23/168] [D loss: 0.004904] [G loss: 6.512602]\n",
      "[Epoch 16/1000] [Batch 24/168] [D loss: 0.009731] [G loss: 5.560001]\n",
      "[Epoch 16/1000] [Batch 25/168] [D loss: 0.006657] [G loss: 5.406017]\n",
      "[Epoch 16/1000] [Batch 26/168] [D loss: 0.005412] [G loss: 5.964202]\n",
      "[Epoch 16/1000] [Batch 27/168] [D loss: 0.005148] [G loss: 6.217894]\n",
      "[Epoch 16/1000] [Batch 28/168] [D loss: 0.004339] [G loss: 5.711008]\n",
      "[Epoch 16/1000] [Batch 29/168] [D loss: 0.004208] [G loss: 6.040365]\n",
      "[Epoch 16/1000] [Batch 30/168] [D loss: 0.005143] [G loss: 6.131860]\n",
      "[Epoch 16/1000] [Batch 31/168] [D loss: 0.005303] [G loss: 5.836585]\n",
      "[Epoch 16/1000] [Batch 32/168] [D loss: 0.006035] [G loss: 5.427350]\n",
      "[Epoch 16/1000] [Batch 33/168] [D loss: 0.009085] [G loss: 5.902806]\n",
      "[Epoch 16/1000] [Batch 34/168] [D loss: 0.006320] [G loss: 5.489894]\n",
      "[Epoch 16/1000] [Batch 35/168] [D loss: 0.006834] [G loss: 5.396416]\n",
      "[Epoch 16/1000] [Batch 36/168] [D loss: 0.006145] [G loss: 5.836570]\n",
      "[Epoch 16/1000] [Batch 37/168] [D loss: 0.005089] [G loss: 6.164691]\n",
      "[Epoch 16/1000] [Batch 38/168] [D loss: 0.007218] [G loss: 5.478786]\n",
      "[Epoch 16/1000] [Batch 39/168] [D loss: 0.007858] [G loss: 5.783066]\n",
      "[Epoch 16/1000] [Batch 40/168] [D loss: 0.008584] [G loss: 6.102865]\n",
      "[Epoch 16/1000] [Batch 41/168] [D loss: 0.009175] [G loss: 5.139964]\n",
      "[Epoch 16/1000] [Batch 42/168] [D loss: 0.004657] [G loss: 6.309761]\n",
      "[Epoch 16/1000] [Batch 43/168] [D loss: 0.005603] [G loss: 6.299582]\n",
      "[Epoch 16/1000] [Batch 44/168] [D loss: 0.007231] [G loss: 5.468324]\n",
      "[Epoch 16/1000] [Batch 45/168] [D loss: 0.004472] [G loss: 6.846951]\n",
      "[Epoch 16/1000] [Batch 46/168] [D loss: 0.006592] [G loss: 6.114110]\n",
      "[Epoch 16/1000] [Batch 47/168] [D loss: 0.009515] [G loss: 5.162261]\n",
      "[Epoch 16/1000] [Batch 48/168] [D loss: 0.010375] [G loss: 6.254004]\n",
      "[Epoch 16/1000] [Batch 49/168] [D loss: 0.007781] [G loss: 5.121449]\n",
      "[Epoch 16/1000] [Batch 50/168] [D loss: 0.005326] [G loss: 5.785874]\n",
      "[Epoch 16/1000] [Batch 51/168] [D loss: 0.006053] [G loss: 6.822392]\n",
      "[Epoch 16/1000] [Batch 52/168] [D loss: 0.004731] [G loss: 5.835216]\n",
      "[Epoch 16/1000] [Batch 53/168] [D loss: 0.004385] [G loss: 5.983163]\n",
      "[Epoch 16/1000] [Batch 54/168] [D loss: 0.004206] [G loss: 6.454579]\n",
      "[Epoch 16/1000] [Batch 55/168] [D loss: 0.008028] [G loss: 6.219689]\n",
      "[Epoch 16/1000] [Batch 56/168] [D loss: 0.006807] [G loss: 5.245567]\n",
      "[Epoch 16/1000] [Batch 57/168] [D loss: 0.004968] [G loss: 6.301093]\n",
      "[Epoch 16/1000] [Batch 58/168] [D loss: 0.005848] [G loss: 5.788321]\n",
      "[Epoch 16/1000] [Batch 59/168] [D loss: 0.004960] [G loss: 6.277374]\n",
      "[Epoch 16/1000] [Batch 60/168] [D loss: 0.006437] [G loss: 5.835003]\n",
      "[Epoch 16/1000] [Batch 61/168] [D loss: 0.007278] [G loss: 5.905594]\n",
      "[Epoch 16/1000] [Batch 62/168] [D loss: 0.010505] [G loss: 5.068471]\n",
      "[Epoch 16/1000] [Batch 63/168] [D loss: 0.002283] [G loss: 6.466148]\n",
      "[Epoch 16/1000] [Batch 64/168] [D loss: 0.004611] [G loss: 7.240977]\n",
      "[Epoch 16/1000] [Batch 65/168] [D loss: 0.005026] [G loss: 6.212513]\n",
      "[Epoch 16/1000] [Batch 66/168] [D loss: 0.009385] [G loss: 5.329245]\n",
      "[Epoch 16/1000] [Batch 67/168] [D loss: 0.004380] [G loss: 5.491261]\n",
      "[Epoch 16/1000] [Batch 68/168] [D loss: 0.003040] [G loss: 6.398067]\n",
      "[Epoch 16/1000] [Batch 69/168] [D loss: 0.007875] [G loss: 6.357758]\n",
      "[Epoch 16/1000] [Batch 70/168] [D loss: 0.006596] [G loss: 5.016128]\n",
      "[Epoch 16/1000] [Batch 71/168] [D loss: 0.004309] [G loss: 6.258990]\n",
      "[Epoch 16/1000] [Batch 72/168] [D loss: 0.005545] [G loss: 6.636155]\n",
      "[Epoch 16/1000] [Batch 73/168] [D loss: 0.006041] [G loss: 6.034626]\n",
      "[Epoch 16/1000] [Batch 74/168] [D loss: 0.008748] [G loss: 4.791244]\n",
      "[Epoch 16/1000] [Batch 75/168] [D loss: 0.005413] [G loss: 6.166971]\n",
      "[Epoch 16/1000] [Batch 76/168] [D loss: 0.008939] [G loss: 6.749151]\n",
      "[Epoch 16/1000] [Batch 77/168] [D loss: 0.008382] [G loss: 4.842707]\n",
      "[Epoch 16/1000] [Batch 78/168] [D loss: 0.005660] [G loss: 6.016529]\n",
      "[Epoch 16/1000] [Batch 79/168] [D loss: 0.003988] [G loss: 6.249655]\n",
      "[Epoch 16/1000] [Batch 80/168] [D loss: 0.007695] [G loss: 5.528614]\n",
      "[Epoch 16/1000] [Batch 81/168] [D loss: 0.005999] [G loss: 5.508922]\n",
      "[Epoch 16/1000] [Batch 82/168] [D loss: 0.004173] [G loss: 5.850734]\n",
      "[Epoch 16/1000] [Batch 83/168] [D loss: 0.003298] [G loss: 6.143566]\n",
      "[Epoch 16/1000] [Batch 84/168] [D loss: 0.006119] [G loss: 6.036630]\n",
      "[Epoch 16/1000] [Batch 85/168] [D loss: 0.009384] [G loss: 5.268669]\n",
      "[Epoch 16/1000] [Batch 86/168] [D loss: 0.006847] [G loss: 5.281926]\n",
      "[Epoch 16/1000] [Batch 87/168] [D loss: 0.008351] [G loss: 5.422362]\n",
      "[Epoch 16/1000] [Batch 88/168] [D loss: 0.007149] [G loss: 5.197982]\n",
      "[Epoch 16/1000] [Batch 89/168] [D loss: 0.006716] [G loss: 6.134204]\n",
      "[Epoch 16/1000] [Batch 90/168] [D loss: 0.012273] [G loss: 5.604288]\n",
      "[Epoch 16/1000] [Batch 91/168] [D loss: 0.015018] [G loss: 4.207002]\n",
      "[Epoch 16/1000] [Batch 92/168] [D loss: 0.010973] [G loss: 8.229491]\n",
      "[Epoch 16/1000] [Batch 93/168] [D loss: 0.003531] [G loss: 7.347213]\n",
      "[Epoch 16/1000] [Batch 94/168] [D loss: 0.003876] [G loss: 5.831119]\n",
      "[Epoch 16/1000] [Batch 95/168] [D loss: 0.007232] [G loss: 5.338265]\n",
      "[Epoch 16/1000] [Batch 96/168] [D loss: 0.005431] [G loss: 5.580308]\n",
      "[Epoch 16/1000] [Batch 97/168] [D loss: 0.010998] [G loss: 5.925462]\n",
      "[Epoch 16/1000] [Batch 98/168] [D loss: 0.007390] [G loss: 5.087884]\n",
      "[Epoch 16/1000] [Batch 99/168] [D loss: 0.008810] [G loss: 6.163786]\n",
      "[Epoch 16/1000] [Batch 100/168] [D loss: 0.004109] [G loss: 5.814675]\n",
      "[Epoch 16/1000] [Batch 101/168] [D loss: 0.005424] [G loss: 5.548861]\n",
      "[Epoch 16/1000] [Batch 102/168] [D loss: 0.008671] [G loss: 6.141104]\n",
      "[Epoch 16/1000] [Batch 103/168] [D loss: 0.004643] [G loss: 5.456123]\n",
      "[Epoch 16/1000] [Batch 104/168] [D loss: 0.004605] [G loss: 6.012353]\n",
      "[Epoch 16/1000] [Batch 105/168] [D loss: 0.007305] [G loss: 5.551617]\n",
      "[Epoch 16/1000] [Batch 106/168] [D loss: 0.011985] [G loss: 4.877374]\n",
      "[Epoch 16/1000] [Batch 107/168] [D loss: 0.006646] [G loss: 5.735671]\n",
      "[Epoch 16/1000] [Batch 108/168] [D loss: 0.007609] [G loss: 5.927596]\n",
      "[Epoch 16/1000] [Batch 109/168] [D loss: 0.005798] [G loss: 5.299221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/1000] [Batch 110/168] [D loss: 0.005414] [G loss: 6.142596]\n",
      "[Epoch 16/1000] [Batch 111/168] [D loss: 0.005234] [G loss: 6.015871]\n",
      "[Epoch 16/1000] [Batch 112/168] [D loss: 0.003978] [G loss: 5.486315]\n",
      "[Epoch 16/1000] [Batch 113/168] [D loss: 0.006230] [G loss: 5.742438]\n",
      "[Epoch 16/1000] [Batch 114/168] [D loss: 0.005109] [G loss: 5.739049]\n",
      "[Epoch 16/1000] [Batch 115/168] [D loss: 0.007121] [G loss: 5.637408]\n",
      "[Epoch 16/1000] [Batch 116/168] [D loss: 0.010515] [G loss: 5.262195]\n",
      "[Epoch 16/1000] [Batch 117/168] [D loss: 0.007088] [G loss: 4.904211]\n",
      "[Epoch 16/1000] [Batch 118/168] [D loss: 0.011425] [G loss: 7.183469]\n",
      "[Epoch 16/1000] [Batch 119/168] [D loss: 0.003992] [G loss: 5.685997]\n",
      "[Epoch 16/1000] [Batch 120/168] [D loss: 0.006605] [G loss: 5.143320]\n",
      "[Epoch 16/1000] [Batch 121/168] [D loss: 0.005210] [G loss: 6.538957]\n",
      "[Epoch 16/1000] [Batch 122/168] [D loss: 0.009711] [G loss: 6.310628]\n",
      "[Epoch 16/1000] [Batch 123/168] [D loss: 0.007772] [G loss: 4.910273]\n",
      "[Epoch 16/1000] [Batch 124/168] [D loss: 0.004063] [G loss: 6.044777]\n",
      "[Epoch 16/1000] [Batch 125/168] [D loss: 0.003094] [G loss: 6.555270]\n",
      "[Epoch 16/1000] [Batch 126/168] [D loss: 0.008243] [G loss: 6.168854]\n",
      "[Epoch 16/1000] [Batch 127/168] [D loss: 0.012892] [G loss: 4.574941]\n",
      "[Epoch 16/1000] [Batch 128/168] [D loss: 0.004884] [G loss: 7.001503]\n",
      "[Epoch 16/1000] [Batch 129/168] [D loss: 0.005604] [G loss: 6.946351]\n",
      "[Epoch 16/1000] [Batch 130/168] [D loss: 0.008901] [G loss: 5.215995]\n",
      "[Epoch 16/1000] [Batch 131/168] [D loss: 0.005916] [G loss: 5.587256]\n",
      "[Epoch 16/1000] [Batch 132/168] [D loss: 0.011517] [G loss: 6.064757]\n",
      "[Epoch 16/1000] [Batch 133/168] [D loss: 0.009816] [G loss: 4.962629]\n",
      "[Epoch 16/1000] [Batch 134/168] [D loss: 0.006654] [G loss: 5.632518]\n",
      "[Epoch 16/1000] [Batch 135/168] [D loss: 0.004039] [G loss: 6.230748]\n",
      "[Epoch 16/1000] [Batch 136/168] [D loss: 0.003951] [G loss: 6.082408]\n",
      "[Epoch 16/1000] [Batch 137/168] [D loss: 0.003548] [G loss: 6.338850]\n",
      "[Epoch 16/1000] [Batch 138/168] [D loss: 0.006486] [G loss: 6.412114]\n",
      "[Epoch 16/1000] [Batch 139/168] [D loss: 0.008305] [G loss: 4.934419]\n",
      "[Epoch 16/1000] [Batch 140/168] [D loss: 0.012070] [G loss: 7.091863]\n",
      "[Epoch 16/1000] [Batch 141/168] [D loss: 0.007995] [G loss: 4.856588]\n",
      "[Epoch 16/1000] [Batch 142/168] [D loss: 0.001897] [G loss: 6.861197]\n",
      "[Epoch 16/1000] [Batch 143/168] [D loss: 0.009736] [G loss: 7.673365]\n",
      "[Epoch 16/1000] [Batch 144/168] [D loss: 0.005962] [G loss: 5.551464]\n",
      "[Epoch 16/1000] [Batch 145/168] [D loss: 0.005777] [G loss: 5.256931]\n",
      "[Epoch 16/1000] [Batch 146/168] [D loss: 0.006055] [G loss: 6.939004]\n",
      "[Epoch 16/1000] [Batch 147/168] [D loss: 0.006915] [G loss: 6.293148]\n",
      "[Epoch 16/1000] [Batch 148/168] [D loss: 0.007292] [G loss: 5.096689]\n",
      "[Epoch 16/1000] [Batch 149/168] [D loss: 0.004982] [G loss: 6.205942]\n",
      "[Epoch 16/1000] [Batch 150/168] [D loss: 0.009182] [G loss: 6.587130]\n",
      "[Epoch 16/1000] [Batch 151/168] [D loss: 0.008061] [G loss: 5.203923]\n",
      "[Epoch 16/1000] [Batch 152/168] [D loss: 0.004148] [G loss: 6.484881]\n",
      "[Epoch 16/1000] [Batch 153/168] [D loss: 0.006878] [G loss: 6.802562]\n",
      "[Epoch 16/1000] [Batch 154/168] [D loss: 0.005203] [G loss: 5.370159]\n",
      "[Epoch 16/1000] [Batch 155/168] [D loss: 0.005708] [G loss: 5.674971]\n",
      "[Epoch 16/1000] [Batch 156/168] [D loss: 0.009981] [G loss: 6.238231]\n",
      "[Epoch 16/1000] [Batch 157/168] [D loss: 0.007375] [G loss: 5.131906]\n",
      "[Epoch 16/1000] [Batch 158/168] [D loss: 0.007051] [G loss: 5.881953]\n",
      "[Epoch 16/1000] [Batch 159/168] [D loss: 0.005213] [G loss: 5.953892]\n",
      "[Epoch 16/1000] [Batch 160/168] [D loss: 0.006026] [G loss: 6.339984]\n",
      "[Epoch 16/1000] [Batch 161/168] [D loss: 0.004169] [G loss: 5.690703]\n",
      "[Epoch 16/1000] [Batch 162/168] [D loss: 0.004732] [G loss: 6.136839]\n",
      "[Epoch 16/1000] [Batch 163/168] [D loss: 0.006741] [G loss: 5.732492]\n",
      "[Epoch 16/1000] [Batch 164/168] [D loss: 0.004508] [G loss: 5.927086]\n",
      "[Epoch 16/1000] [Batch 165/168] [D loss: 0.006387] [G loss: 6.008119]\n",
      "[Epoch 16/1000] [Batch 166/168] [D loss: 0.007152] [G loss: 5.835513]\n",
      "[Epoch 16/1000] [Batch 167/168] [D loss: 0.006606] [G loss: 5.199334]\n",
      "[Epoch 16/1000] [Batch 168/168] [D loss: 0.004895] [G loss: 6.612123]\n",
      "[Epoch 17/1000] [Batch 1/168] [D loss: 0.007144] [G loss: 6.280951]\n",
      "[Epoch 17/1000] [Batch 2/168] [D loss: 0.004771] [G loss: 5.619550]\n",
      "[Epoch 17/1000] [Batch 3/168] [D loss: 0.004565] [G loss: 6.076842]\n",
      "[Epoch 17/1000] [Batch 4/168] [D loss: 0.004122] [G loss: 6.536418]\n",
      "[Epoch 17/1000] [Batch 5/168] [D loss: 0.009838] [G loss: 6.053846]\n",
      "[Epoch 17/1000] [Batch 6/168] [D loss: 0.007406] [G loss: 4.930920]\n",
      "[Epoch 17/1000] [Batch 7/168] [D loss: 0.006468] [G loss: 7.318322]\n",
      "[Epoch 17/1000] [Batch 8/168] [D loss: 0.002986] [G loss: 6.120743]\n",
      "[Epoch 17/1000] [Batch 9/168] [D loss: 0.003784] [G loss: 6.128822]\n",
      "[Epoch 17/1000] [Batch 10/168] [D loss: 0.007157] [G loss: 6.614141]\n",
      "[Epoch 17/1000] [Batch 11/168] [D loss: 0.011053] [G loss: 4.827626]\n",
      "[Epoch 17/1000] [Batch 12/168] [D loss: 0.013674] [G loss: 7.732577]\n",
      "[Epoch 17/1000] [Batch 13/168] [D loss: 0.004454] [G loss: 5.649070]\n",
      "[Epoch 17/1000] [Batch 14/168] [D loss: 0.003052] [G loss: 6.202906]\n",
      "[Epoch 17/1000] [Batch 15/168] [D loss: 0.004661] [G loss: 6.984566]\n",
      "[Epoch 17/1000] [Batch 16/168] [D loss: 0.003013] [G loss: 6.428965]\n",
      "[Epoch 17/1000] [Batch 17/168] [D loss: 0.004871] [G loss: 5.618792]\n",
      "[Epoch 17/1000] [Batch 18/168] [D loss: 0.003625] [G loss: 6.692625]\n",
      "[Epoch 17/1000] [Batch 19/168] [D loss: 0.003344] [G loss: 6.400550]\n",
      "[Epoch 17/1000] [Batch 20/168] [D loss: 0.003797] [G loss: 6.556494]\n",
      "[Epoch 17/1000] [Batch 21/168] [D loss: 0.003851] [G loss: 6.092580]\n",
      "[Epoch 17/1000] [Batch 22/168] [D loss: 0.004654] [G loss: 5.985632]\n",
      "[Epoch 17/1000] [Batch 23/168] [D loss: 0.006345] [G loss: 6.195042]\n",
      "[Epoch 17/1000] [Batch 24/168] [D loss: 0.004426] [G loss: 5.837255]\n",
      "[Epoch 17/1000] [Batch 25/168] [D loss: 0.004996] [G loss: 6.070794]\n",
      "[Epoch 17/1000] [Batch 26/168] [D loss: 0.006521] [G loss: 6.212678]\n",
      "[Epoch 17/1000] [Batch 27/168] [D loss: 0.005949] [G loss: 5.506808]\n",
      "[Epoch 17/1000] [Batch 28/168] [D loss: 0.009403] [G loss: 6.000594]\n",
      "[Epoch 17/1000] [Batch 29/168] [D loss: 0.010516] [G loss: 5.614136]\n",
      "[Epoch 17/1000] [Batch 30/168] [D loss: 0.003794] [G loss: 6.201873]\n",
      "[Epoch 17/1000] [Batch 31/168] [D loss: 0.004629] [G loss: 6.876353]\n",
      "[Epoch 17/1000] [Batch 32/168] [D loss: 0.006252] [G loss: 6.387229]\n",
      "[Epoch 17/1000] [Batch 33/168] [D loss: 0.008426] [G loss: 5.355980]\n",
      "[Epoch 17/1000] [Batch 34/168] [D loss: 0.006351] [G loss: 6.471539]\n",
      "[Epoch 17/1000] [Batch 35/168] [D loss: 0.009234] [G loss: 6.477869]\n",
      "[Epoch 17/1000] [Batch 36/168] [D loss: 0.006651] [G loss: 5.244927]\n",
      "[Epoch 17/1000] [Batch 37/168] [D loss: 0.006390] [G loss: 6.743993]\n",
      "[Epoch 17/1000] [Batch 38/168] [D loss: 0.003921] [G loss: 6.585095]\n",
      "[Epoch 17/1000] [Batch 39/168] [D loss: 0.007867] [G loss: 5.373118]\n",
      "[Epoch 17/1000] [Batch 40/168] [D loss: 0.005551] [G loss: 7.146636]\n",
      "[Epoch 17/1000] [Batch 41/168] [D loss: 0.004562] [G loss: 6.471785]\n",
      "[Epoch 17/1000] [Batch 42/168] [D loss: 0.007213] [G loss: 5.431381]\n",
      "[Epoch 17/1000] [Batch 43/168] [D loss: 0.003649] [G loss: 7.218154]\n",
      "[Epoch 17/1000] [Batch 44/168] [D loss: 0.004429] [G loss: 6.927505]\n",
      "[Epoch 17/1000] [Batch 45/168] [D loss: 0.004892] [G loss: 6.235687]\n",
      "[Epoch 17/1000] [Batch 46/168] [D loss: 0.006091] [G loss: 6.463476]\n",
      "[Epoch 17/1000] [Batch 47/168] [D loss: 0.006828] [G loss: 5.486876]\n",
      "[Epoch 17/1000] [Batch 48/168] [D loss: 0.005321] [G loss: 6.232387]\n",
      "[Epoch 17/1000] [Batch 49/168] [D loss: 0.013251] [G loss: 6.863743]\n",
      "[Epoch 17/1000] [Batch 50/168] [D loss: 0.026384] [G loss: 3.647672]\n",
      "[Epoch 17/1000] [Batch 51/168] [D loss: 0.213624] [G loss: 14.509323]\n",
      "[Epoch 17/1000] [Batch 52/168] [D loss: 9.914536] [G loss: 0.000151]\n",
      "[Epoch 17/1000] [Batch 53/168] [D loss: 7.346165] [G loss: 28.540113]\n",
      "[Epoch 17/1000] [Batch 54/168] [D loss: 0.232155] [G loss: 9.161023]\n",
      "[Epoch 17/1000] [Batch 55/168] [D loss: 0.968769] [G loss: 0.981670]\n",
      "[Epoch 17/1000] [Batch 56/168] [D loss: 0.012738] [G loss: 8.767234]\n",
      "[Epoch 17/1000] [Batch 57/168] [D loss: 0.171275] [G loss: 11.449488]\n",
      "[Epoch 17/1000] [Batch 58/168] [D loss: 0.046557] [G loss: 10.027159]\n",
      "[Epoch 17/1000] [Batch 59/168] [D loss: 0.020364] [G loss: 7.410042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/1000] [Batch 60/168] [D loss: 0.033839] [G loss: 4.836072]\n",
      "[Epoch 17/1000] [Batch 61/168] [D loss: 0.027847] [G loss: 3.945650]\n",
      "[Epoch 17/1000] [Batch 62/168] [D loss: 0.041038] [G loss: 3.419039]\n",
      "[Epoch 17/1000] [Batch 63/168] [D loss: 0.041091] [G loss: 3.740202]\n",
      "[Epoch 17/1000] [Batch 64/168] [D loss: 0.065774] [G loss: 4.271150]\n",
      "[Epoch 17/1000] [Batch 65/168] [D loss: 0.044002] [G loss: 3.721034]\n",
      "[Epoch 17/1000] [Batch 66/168] [D loss: 0.039185] [G loss: 3.743194]\n",
      "[Epoch 17/1000] [Batch 67/168] [D loss: 0.045043] [G loss: 4.046635]\n",
      "[Epoch 17/1000] [Batch 68/168] [D loss: 0.044643] [G loss: 3.998769]\n",
      "[Epoch 17/1000] [Batch 69/168] [D loss: 0.039562] [G loss: 3.882587]\n",
      "[Epoch 17/1000] [Batch 70/168] [D loss: 0.039667] [G loss: 3.511983]\n",
      "[Epoch 17/1000] [Batch 71/168] [D loss: 0.040695] [G loss: 3.682308]\n",
      "[Epoch 17/1000] [Batch 72/168] [D loss: 0.040280] [G loss: 3.860529]\n",
      "[Epoch 17/1000] [Batch 73/168] [D loss: 0.030941] [G loss: 4.023160]\n",
      "[Epoch 17/1000] [Batch 74/168] [D loss: 0.028735] [G loss: 3.702675]\n",
      "[Epoch 17/1000] [Batch 75/168] [D loss: 0.024556] [G loss: 4.046794]\n",
      "[Epoch 17/1000] [Batch 76/168] [D loss: 0.039201] [G loss: 4.279799]\n",
      "[Epoch 17/1000] [Batch 77/168] [D loss: 0.043723] [G loss: 3.570914]\n",
      "[Epoch 17/1000] [Batch 78/168] [D loss: 0.039394] [G loss: 3.678280]\n",
      "[Epoch 17/1000] [Batch 79/168] [D loss: 0.031342] [G loss: 3.925279]\n",
      "[Epoch 17/1000] [Batch 80/168] [D loss: 0.030145] [G loss: 4.148620]\n",
      "[Epoch 17/1000] [Batch 81/168] [D loss: 0.021339] [G loss: 3.934503]\n",
      "[Epoch 17/1000] [Batch 82/168] [D loss: 0.021055] [G loss: 4.208068]\n",
      "[Epoch 17/1000] [Batch 83/168] [D loss: 0.031704] [G loss: 4.105276]\n",
      "[Epoch 17/1000] [Batch 84/168] [D loss: 0.023157] [G loss: 3.943156]\n",
      "[Epoch 17/1000] [Batch 85/168] [D loss: 0.021510] [G loss: 3.938311]\n",
      "[Epoch 17/1000] [Batch 86/168] [D loss: 0.019046] [G loss: 4.363775]\n",
      "[Epoch 17/1000] [Batch 87/168] [D loss: 0.026967] [G loss: 4.244076]\n",
      "[Epoch 17/1000] [Batch 88/168] [D loss: 0.026183] [G loss: 3.827468]\n",
      "[Epoch 17/1000] [Batch 89/168] [D loss: 0.021663] [G loss: 4.114234]\n",
      "[Epoch 17/1000] [Batch 90/168] [D loss: 0.028264] [G loss: 4.246987]\n",
      "[Epoch 17/1000] [Batch 91/168] [D loss: 0.029398] [G loss: 3.975976]\n",
      "[Epoch 17/1000] [Batch 92/168] [D loss: 0.027413] [G loss: 3.687137]\n",
      "[Epoch 17/1000] [Batch 93/168] [D loss: 0.019764] [G loss: 4.151787]\n",
      "[Epoch 17/1000] [Batch 94/168] [D loss: 0.023168] [G loss: 4.089918]\n",
      "[Epoch 17/1000] [Batch 95/168] [D loss: 0.025695] [G loss: 4.121401]\n",
      "[Epoch 17/1000] [Batch 96/168] [D loss: 0.036148] [G loss: 3.853550]\n",
      "[Epoch 17/1000] [Batch 97/168] [D loss: 0.041430] [G loss: 3.739004]\n",
      "[Epoch 17/1000] [Batch 98/168] [D loss: 0.032493] [G loss: 3.628999]\n",
      "[Epoch 17/1000] [Batch 99/168] [D loss: 0.032879] [G loss: 3.740149]\n",
      "[Epoch 17/1000] [Batch 100/168] [D loss: 0.037339] [G loss: 4.114484]\n",
      "[Epoch 17/1000] [Batch 101/168] [D loss: 0.043161] [G loss: 3.653101]\n",
      "[Epoch 17/1000] [Batch 102/168] [D loss: 0.052367] [G loss: 3.324750]\n",
      "[Epoch 17/1000] [Batch 103/168] [D loss: 0.051623] [G loss: 4.363819]\n",
      "[Epoch 17/1000] [Batch 104/168] [D loss: 0.033887] [G loss: 3.532871]\n",
      "[Epoch 17/1000] [Batch 105/168] [D loss: 0.029695] [G loss: 4.219122]\n",
      "[Epoch 17/1000] [Batch 106/168] [D loss: 0.044194] [G loss: 4.382389]\n",
      "[Epoch 17/1000] [Batch 107/168] [D loss: 0.033992] [G loss: 3.829096]\n",
      "[Epoch 17/1000] [Batch 108/168] [D loss: 0.038717] [G loss: 3.499490]\n",
      "[Epoch 17/1000] [Batch 109/168] [D loss: 0.036901] [G loss: 3.939444]\n",
      "[Epoch 17/1000] [Batch 110/168] [D loss: 0.059415] [G loss: 3.482112]\n",
      "[Epoch 17/1000] [Batch 111/168] [D loss: 0.033277] [G loss: 3.374921]\n",
      "[Epoch 17/1000] [Batch 112/168] [D loss: 0.026455] [G loss: 4.699642]\n",
      "[Epoch 17/1000] [Batch 113/168] [D loss: 0.034011] [G loss: 3.942317]\n",
      "[Epoch 17/1000] [Batch 114/168] [D loss: 0.030570] [G loss: 3.836185]\n",
      "[Epoch 17/1000] [Batch 115/168] [D loss: 0.030934] [G loss: 3.767378]\n",
      "[Epoch 17/1000] [Batch 116/168] [D loss: 0.027063] [G loss: 3.773285]\n",
      "[Epoch 17/1000] [Batch 117/168] [D loss: 0.022663] [G loss: 4.352957]\n",
      "[Epoch 17/1000] [Batch 118/168] [D loss: 0.038076] [G loss: 4.213356]\n",
      "[Epoch 17/1000] [Batch 119/168] [D loss: 0.037210] [G loss: 3.290931]\n",
      "[Epoch 17/1000] [Batch 120/168] [D loss: 0.021452] [G loss: 4.460965]\n",
      "[Epoch 17/1000] [Batch 121/168] [D loss: 0.029226] [G loss: 4.181093]\n",
      "[Epoch 17/1000] [Batch 122/168] [D loss: 0.024951] [G loss: 3.809408]\n",
      "[Epoch 17/1000] [Batch 123/168] [D loss: 0.031807] [G loss: 3.500159]\n",
      "[Epoch 17/1000] [Batch 124/168] [D loss: 0.030664] [G loss: 4.572020]\n",
      "[Epoch 17/1000] [Batch 125/168] [D loss: 0.022889] [G loss: 4.418833]\n",
      "[Epoch 17/1000] [Batch 126/168] [D loss: 0.027559] [G loss: 3.810676]\n",
      "[Epoch 17/1000] [Batch 127/168] [D loss: 0.025905] [G loss: 3.704795]\n",
      "[Epoch 17/1000] [Batch 128/168] [D loss: 0.034031] [G loss: 4.414883]\n",
      "[Epoch 17/1000] [Batch 129/168] [D loss: 0.027945] [G loss: 3.644368]\n",
      "[Epoch 17/1000] [Batch 130/168] [D loss: 0.020953] [G loss: 4.122526]\n",
      "[Epoch 17/1000] [Batch 131/168] [D loss: 0.023375] [G loss: 4.460470]\n",
      "[Epoch 17/1000] [Batch 132/168] [D loss: 0.022711] [G loss: 4.205561]\n",
      "[Epoch 17/1000] [Batch 133/168] [D loss: 0.032004] [G loss: 3.775964]\n",
      "[Epoch 17/1000] [Batch 134/168] [D loss: 0.015823] [G loss: 4.189765]\n",
      "[Epoch 17/1000] [Batch 135/168] [D loss: 0.016814] [G loss: 4.744051]\n",
      "[Epoch 17/1000] [Batch 136/168] [D loss: 0.036944] [G loss: 4.363568]\n",
      "[Epoch 17/1000] [Batch 137/168] [D loss: 0.032596] [G loss: 3.399371]\n",
      "[Epoch 17/1000] [Batch 138/168] [D loss: 0.018918] [G loss: 4.648744]\n",
      "[Epoch 17/1000] [Batch 139/168] [D loss: 0.019549] [G loss: 4.687042]\n",
      "[Epoch 17/1000] [Batch 140/168] [D loss: 0.024688] [G loss: 3.967045]\n",
      "[Epoch 17/1000] [Batch 141/168] [D loss: 0.025215] [G loss: 4.528968]\n",
      "[Epoch 17/1000] [Batch 142/168] [D loss: 0.018570] [G loss: 4.177872]\n",
      "[Epoch 17/1000] [Batch 143/168] [D loss: 0.016913] [G loss: 4.825478]\n",
      "[Epoch 17/1000] [Batch 144/168] [D loss: 0.013431] [G loss: 4.613626]\n",
      "[Epoch 17/1000] [Batch 145/168] [D loss: 0.015305] [G loss: 4.512616]\n",
      "[Epoch 17/1000] [Batch 146/168] [D loss: 0.021490] [G loss: 4.275759]\n",
      "[Epoch 17/1000] [Batch 147/168] [D loss: 0.023734] [G loss: 4.416058]\n",
      "[Epoch 17/1000] [Batch 148/168] [D loss: 0.031462] [G loss: 4.122347]\n",
      "[Epoch 17/1000] [Batch 149/168] [D loss: 0.035431] [G loss: 3.680883]\n",
      "[Epoch 17/1000] [Batch 150/168] [D loss: 0.023943] [G loss: 4.798429]\n",
      "[Epoch 17/1000] [Batch 151/168] [D loss: 0.016335] [G loss: 4.230533]\n",
      "[Epoch 17/1000] [Batch 152/168] [D loss: 0.013359] [G loss: 4.592339]\n",
      "[Epoch 17/1000] [Batch 153/168] [D loss: 0.024613] [G loss: 4.160688]\n",
      "[Epoch 17/1000] [Batch 154/168] [D loss: 0.019088] [G loss: 4.818323]\n",
      "[Epoch 17/1000] [Batch 155/168] [D loss: 0.026039] [G loss: 4.071149]\n",
      "[Epoch 17/1000] [Batch 156/168] [D loss: 0.027071] [G loss: 3.819269]\n",
      "[Epoch 17/1000] [Batch 157/168] [D loss: 0.025527] [G loss: 4.721114]\n",
      "[Epoch 17/1000] [Batch 158/168] [D loss: 0.028887] [G loss: 4.230618]\n",
      "[Epoch 17/1000] [Batch 159/168] [D loss: 0.026957] [G loss: 3.769014]\n",
      "[Epoch 17/1000] [Batch 160/168] [D loss: 0.017412] [G loss: 4.462167]\n",
      "[Epoch 17/1000] [Batch 161/168] [D loss: 0.017470] [G loss: 4.955400]\n",
      "[Epoch 17/1000] [Batch 162/168] [D loss: 0.017981] [G loss: 4.432950]\n",
      "[Epoch 17/1000] [Batch 163/168] [D loss: 0.026299] [G loss: 3.797192]\n",
      "[Epoch 17/1000] [Batch 164/168] [D loss: 0.026005] [G loss: 5.294545]\n",
      "[Epoch 17/1000] [Batch 165/168] [D loss: 0.015248] [G loss: 4.369016]\n",
      "[Epoch 17/1000] [Batch 166/168] [D loss: 0.015250] [G loss: 4.449407]\n",
      "[Epoch 17/1000] [Batch 167/168] [D loss: 0.012776] [G loss: 4.702647]\n",
      "[Epoch 17/1000] [Batch 168/168] [D loss: 0.020025] [G loss: 4.828150]\n",
      "[Epoch 18/1000] [Batch 1/168] [D loss: 0.012901] [G loss: 4.659270]\n",
      "[Epoch 18/1000] [Batch 2/168] [D loss: 0.016182] [G loss: 4.449165]\n",
      "[Epoch 18/1000] [Batch 3/168] [D loss: 0.012654] [G loss: 4.631152]\n",
      "[Epoch 18/1000] [Batch 4/168] [D loss: 0.014262] [G loss: 5.039233]\n",
      "[Epoch 18/1000] [Batch 5/168] [D loss: 0.019252] [G loss: 4.429140]\n",
      "[Epoch 18/1000] [Batch 6/168] [D loss: 0.019809] [G loss: 4.306605]\n",
      "[Epoch 18/1000] [Batch 7/168] [D loss: 0.013467] [G loss: 4.499954]\n",
      "[Epoch 18/1000] [Batch 8/168] [D loss: 0.015017] [G loss: 4.945334]\n",
      "[Epoch 18/1000] [Batch 9/168] [D loss: 0.022106] [G loss: 4.627035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] [Batch 10/168] [D loss: 0.022189] [G loss: 3.792286]\n",
      "[Epoch 18/1000] [Batch 11/168] [D loss: 0.018595] [G loss: 4.864776]\n",
      "[Epoch 18/1000] [Batch 12/168] [D loss: 0.014257] [G loss: 4.884062]\n",
      "[Epoch 18/1000] [Batch 13/168] [D loss: 0.017625] [G loss: 4.421148]\n",
      "[Epoch 18/1000] [Batch 14/168] [D loss: 0.016374] [G loss: 4.285610]\n",
      "[Epoch 18/1000] [Batch 15/168] [D loss: 0.014801] [G loss: 4.644188]\n",
      "[Epoch 18/1000] [Batch 16/168] [D loss: 0.022441] [G loss: 4.413239]\n",
      "[Epoch 18/1000] [Batch 17/168] [D loss: 0.013911] [G loss: 4.567994]\n",
      "[Epoch 18/1000] [Batch 18/168] [D loss: 0.015716] [G loss: 4.323430]\n",
      "[Epoch 18/1000] [Batch 19/168] [D loss: 0.015570] [G loss: 4.787151]\n",
      "[Epoch 18/1000] [Batch 20/168] [D loss: 0.017107] [G loss: 4.482536]\n",
      "[Epoch 18/1000] [Batch 21/168] [D loss: 0.021245] [G loss: 4.526508]\n",
      "[Epoch 18/1000] [Batch 22/168] [D loss: 0.016964] [G loss: 4.118801]\n",
      "[Epoch 18/1000] [Batch 23/168] [D loss: 0.018025] [G loss: 4.732078]\n",
      "[Epoch 18/1000] [Batch 24/168] [D loss: 0.013828] [G loss: 4.528420]\n",
      "[Epoch 18/1000] [Batch 25/168] [D loss: 0.015070] [G loss: 4.378242]\n",
      "[Epoch 18/1000] [Batch 26/168] [D loss: 0.015547] [G loss: 4.925252]\n",
      "[Epoch 18/1000] [Batch 27/168] [D loss: 0.018871] [G loss: 4.207009]\n",
      "[Epoch 18/1000] [Batch 28/168] [D loss: 0.021839] [G loss: 5.327770]\n",
      "[Epoch 18/1000] [Batch 29/168] [D loss: 0.012475] [G loss: 4.505484]\n",
      "[Epoch 18/1000] [Batch 30/168] [D loss: 0.014904] [G loss: 4.301252]\n",
      "[Epoch 18/1000] [Batch 31/168] [D loss: 0.012926] [G loss: 5.501337]\n",
      "[Epoch 18/1000] [Batch 32/168] [D loss: 0.014040] [G loss: 5.259019]\n",
      "[Epoch 18/1000] [Batch 33/168] [D loss: 0.016293] [G loss: 3.995823]\n",
      "[Epoch 18/1000] [Batch 34/168] [D loss: 0.014250] [G loss: 4.789826]\n",
      "[Epoch 18/1000] [Batch 35/168] [D loss: 0.016369] [G loss: 5.182553]\n",
      "[Epoch 18/1000] [Batch 36/168] [D loss: 0.016416] [G loss: 4.570797]\n",
      "[Epoch 18/1000] [Batch 37/168] [D loss: 0.018551] [G loss: 4.181718]\n",
      "[Epoch 18/1000] [Batch 38/168] [D loss: 0.017997] [G loss: 4.853516]\n",
      "[Epoch 18/1000] [Batch 39/168] [D loss: 0.013533] [G loss: 4.840511]\n",
      "[Epoch 18/1000] [Batch 40/168] [D loss: 0.016653] [G loss: 4.592768]\n",
      "[Epoch 18/1000] [Batch 41/168] [D loss: 0.016344] [G loss: 4.385020]\n",
      "[Epoch 18/1000] [Batch 42/168] [D loss: 0.016449] [G loss: 4.473726]\n",
      "[Epoch 18/1000] [Batch 43/168] [D loss: 0.018702] [G loss: 4.580271]\n",
      "[Epoch 18/1000] [Batch 44/168] [D loss: 0.016642] [G loss: 4.421424]\n",
      "[Epoch 18/1000] [Batch 45/168] [D loss: 0.018344] [G loss: 4.377967]\n",
      "[Epoch 18/1000] [Batch 46/168] [D loss: 0.015491] [G loss: 4.710176]\n",
      "[Epoch 18/1000] [Batch 47/168] [D loss: 0.017592] [G loss: 4.659740]\n",
      "[Epoch 18/1000] [Batch 48/168] [D loss: 0.022846] [G loss: 4.001992]\n",
      "[Epoch 18/1000] [Batch 49/168] [D loss: 0.015902] [G loss: 4.718363]\n",
      "[Epoch 18/1000] [Batch 50/168] [D loss: 0.018522] [G loss: 4.625293]\n",
      "[Epoch 18/1000] [Batch 51/168] [D loss: 0.019981] [G loss: 4.577750]\n",
      "[Epoch 18/1000] [Batch 52/168] [D loss: 0.015220] [G loss: 4.271098]\n",
      "[Epoch 18/1000] [Batch 53/168] [D loss: 0.014143] [G loss: 4.802969]\n",
      "[Epoch 18/1000] [Batch 54/168] [D loss: 0.016910] [G loss: 4.872706]\n",
      "[Epoch 18/1000] [Batch 55/168] [D loss: 0.020751] [G loss: 3.910819]\n",
      "[Epoch 18/1000] [Batch 56/168] [D loss: 0.026393] [G loss: 5.192978]\n",
      "[Epoch 18/1000] [Batch 57/168] [D loss: 0.032994] [G loss: 3.577301]\n",
      "[Epoch 18/1000] [Batch 58/168] [D loss: 0.015822] [G loss: 5.413630]\n",
      "[Epoch 18/1000] [Batch 59/168] [D loss: 0.011821] [G loss: 5.053346]\n",
      "[Epoch 18/1000] [Batch 60/168] [D loss: 0.014502] [G loss: 4.791063]\n",
      "[Epoch 18/1000] [Batch 61/168] [D loss: 0.010547] [G loss: 4.910529]\n",
      "[Epoch 18/1000] [Batch 62/168] [D loss: 0.012270] [G loss: 4.423819]\n",
      "[Epoch 18/1000] [Batch 63/168] [D loss: 0.018905] [G loss: 5.304981]\n",
      "[Epoch 18/1000] [Batch 64/168] [D loss: 0.019427] [G loss: 4.300490]\n",
      "[Epoch 18/1000] [Batch 65/168] [D loss: 0.017586] [G loss: 4.303758]\n",
      "[Epoch 18/1000] [Batch 66/168] [D loss: 0.009311] [G loss: 5.532744]\n",
      "[Epoch 18/1000] [Batch 67/168] [D loss: 0.009709] [G loss: 5.386853]\n",
      "[Epoch 18/1000] [Batch 68/168] [D loss: 0.018901] [G loss: 4.548139]\n",
      "[Epoch 18/1000] [Batch 69/168] [D loss: 0.013649] [G loss: 4.633064]\n",
      "[Epoch 18/1000] [Batch 70/168] [D loss: 0.015450] [G loss: 5.203053]\n",
      "[Epoch 18/1000] [Batch 71/168] [D loss: 0.011692] [G loss: 4.660679]\n",
      "[Epoch 18/1000] [Batch 72/168] [D loss: 0.012338] [G loss: 4.727393]\n",
      "[Epoch 18/1000] [Batch 73/168] [D loss: 0.013140] [G loss: 5.045313]\n",
      "[Epoch 18/1000] [Batch 74/168] [D loss: 0.014311] [G loss: 4.451563]\n",
      "[Epoch 18/1000] [Batch 75/168] [D loss: 0.015408] [G loss: 4.928442]\n",
      "[Epoch 18/1000] [Batch 76/168] [D loss: 0.017298] [G loss: 4.675275]\n",
      "[Epoch 18/1000] [Batch 77/168] [D loss: 0.014565] [G loss: 4.296207]\n",
      "[Epoch 18/1000] [Batch 78/168] [D loss: 0.017189] [G loss: 5.151710]\n",
      "[Epoch 18/1000] [Batch 79/168] [D loss: 0.019856] [G loss: 4.366059]\n",
      "[Epoch 18/1000] [Batch 80/168] [D loss: 0.021371] [G loss: 3.928854]\n",
      "[Epoch 18/1000] [Batch 81/168] [D loss: 0.030737] [G loss: 6.363272]\n",
      "[Epoch 18/1000] [Batch 82/168] [D loss: 0.015534] [G loss: 4.197745]\n",
      "[Epoch 18/1000] [Batch 83/168] [D loss: 0.011339] [G loss: 4.883932]\n",
      "[Epoch 18/1000] [Batch 84/168] [D loss: 0.008725] [G loss: 5.166577]\n",
      "[Epoch 18/1000] [Batch 85/168] [D loss: 0.011012] [G loss: 5.038920]\n",
      "[Epoch 18/1000] [Batch 86/168] [D loss: 0.022141] [G loss: 4.787999]\n",
      "[Epoch 18/1000] [Batch 87/168] [D loss: 0.021699] [G loss: 3.807971]\n",
      "[Epoch 18/1000] [Batch 88/168] [D loss: 0.029488] [G loss: 6.291207]\n",
      "[Epoch 18/1000] [Batch 89/168] [D loss: 0.015620] [G loss: 4.552437]\n",
      "[Epoch 18/1000] [Batch 90/168] [D loss: 0.017117] [G loss: 4.032384]\n",
      "[Epoch 18/1000] [Batch 91/168] [D loss: 0.014544] [G loss: 6.613142]\n",
      "[Epoch 18/1000] [Batch 92/168] [D loss: 0.006419] [G loss: 5.940595]\n",
      "[Epoch 18/1000] [Batch 93/168] [D loss: 0.008695] [G loss: 4.960074]\n",
      "[Epoch 18/1000] [Batch 94/168] [D loss: 0.013259] [G loss: 4.755570]\n",
      "[Epoch 18/1000] [Batch 95/168] [D loss: 0.011580] [G loss: 4.808081]\n",
      "[Epoch 18/1000] [Batch 96/168] [D loss: 0.012153] [G loss: 5.023268]\n",
      "[Epoch 18/1000] [Batch 97/168] [D loss: 0.012905] [G loss: 5.875790]\n",
      "[Epoch 18/1000] [Batch 98/168] [D loss: 0.011897] [G loss: 4.603505]\n",
      "[Epoch 18/1000] [Batch 99/168] [D loss: 0.010152] [G loss: 4.633175]\n",
      "[Epoch 18/1000] [Batch 100/168] [D loss: 0.027472] [G loss: 5.253200]\n",
      "[Epoch 18/1000] [Batch 101/168] [D loss: 0.020716] [G loss: 3.868907]\n",
      "[Epoch 18/1000] [Batch 102/168] [D loss: 0.015458] [G loss: 6.364656]\n",
      "[Epoch 18/1000] [Batch 103/168] [D loss: 0.009086] [G loss: 5.599982]\n",
      "[Epoch 18/1000] [Batch 104/168] [D loss: 0.012801] [G loss: 4.451770]\n",
      "[Epoch 18/1000] [Batch 105/168] [D loss: 0.009354] [G loss: 5.665414]\n",
      "[Epoch 18/1000] [Batch 106/168] [D loss: 0.010853] [G loss: 5.681239]\n",
      "[Epoch 18/1000] [Batch 107/168] [D loss: 0.013670] [G loss: 4.849962]\n",
      "[Epoch 18/1000] [Batch 108/168] [D loss: 0.015384] [G loss: 4.529364]\n",
      "[Epoch 18/1000] [Batch 109/168] [D loss: 0.009579] [G loss: 5.171527]\n",
      "[Epoch 18/1000] [Batch 110/168] [D loss: 0.012330] [G loss: 5.358615]\n",
      "[Epoch 18/1000] [Batch 111/168] [D loss: 0.010960] [G loss: 4.757401]\n",
      "[Epoch 18/1000] [Batch 112/168] [D loss: 0.016356] [G loss: 4.778632]\n",
      "[Epoch 18/1000] [Batch 113/168] [D loss: 0.018695] [G loss: 4.943237]\n",
      "[Epoch 18/1000] [Batch 114/168] [D loss: 0.019261] [G loss: 4.635538]\n",
      "[Epoch 18/1000] [Batch 115/168] [D loss: 0.019523] [G loss: 3.971260]\n",
      "[Epoch 18/1000] [Batch 116/168] [D loss: 0.009697] [G loss: 6.485684]\n",
      "[Epoch 18/1000] [Batch 117/168] [D loss: 0.009660] [G loss: 6.074330]\n",
      "[Epoch 18/1000] [Batch 118/168] [D loss: 0.017159] [G loss: 4.224426]\n",
      "[Epoch 18/1000] [Batch 119/168] [D loss: 0.022580] [G loss: 5.940214]\n",
      "[Epoch 18/1000] [Batch 120/168] [D loss: 0.018826] [G loss: 4.224112]\n",
      "[Epoch 18/1000] [Batch 121/168] [D loss: 0.011003] [G loss: 6.079282]\n",
      "[Epoch 18/1000] [Batch 122/168] [D loss: 0.009152] [G loss: 5.779387]\n",
      "[Epoch 18/1000] [Batch 123/168] [D loss: 0.012992] [G loss: 4.524076]\n",
      "[Epoch 18/1000] [Batch 124/168] [D loss: 0.017190] [G loss: 4.926266]\n",
      "[Epoch 18/1000] [Batch 125/168] [D loss: 0.016705] [G loss: 4.306367]\n",
      "[Epoch 18/1000] [Batch 126/168] [D loss: 0.021493] [G loss: 5.480187]\n",
      "[Epoch 18/1000] [Batch 127/168] [D loss: 0.018207] [G loss: 3.882252]\n",
      "[Epoch 18/1000] [Batch 128/168] [D loss: 0.021984] [G loss: 5.793077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] [Batch 129/168] [D loss: 0.011089] [G loss: 4.546823]\n",
      "[Epoch 18/1000] [Batch 130/168] [D loss: 0.011365] [G loss: 4.642454]\n",
      "[Epoch 18/1000] [Batch 131/168] [D loss: 0.013480] [G loss: 5.753075]\n",
      "[Epoch 18/1000] [Batch 132/168] [D loss: 0.009746] [G loss: 4.934984]\n",
      "[Epoch 18/1000] [Batch 133/168] [D loss: 0.014375] [G loss: 5.505006]\n",
      "[Epoch 18/1000] [Batch 134/168] [D loss: 0.009186] [G loss: 5.021144]\n",
      "[Epoch 18/1000] [Batch 135/168] [D loss: 0.013018] [G loss: 4.608037]\n",
      "[Epoch 18/1000] [Batch 136/168] [D loss: 0.009580] [G loss: 4.960094]\n",
      "[Epoch 18/1000] [Batch 137/168] [D loss: 0.008255] [G loss: 5.657267]\n",
      "[Epoch 18/1000] [Batch 138/168] [D loss: 0.011294] [G loss: 4.735586]\n",
      "[Epoch 18/1000] [Batch 139/168] [D loss: 0.011181] [G loss: 5.263093]\n",
      "[Epoch 18/1000] [Batch 140/168] [D loss: 0.027245] [G loss: 4.722828]\n",
      "[Epoch 18/1000] [Batch 141/168] [D loss: 0.017810] [G loss: 4.072105]\n",
      "[Epoch 18/1000] [Batch 142/168] [D loss: 0.014301] [G loss: 6.344862]\n",
      "[Epoch 18/1000] [Batch 143/168] [D loss: 0.008794] [G loss: 5.418193]\n",
      "[Epoch 18/1000] [Batch 144/168] [D loss: 0.016957] [G loss: 4.070903]\n",
      "[Epoch 18/1000] [Batch 145/168] [D loss: 0.012123] [G loss: 6.160594]\n",
      "[Epoch 18/1000] [Batch 146/168] [D loss: 0.009524] [G loss: 5.375016]\n",
      "[Epoch 18/1000] [Batch 147/168] [D loss: 0.012372] [G loss: 4.614238]\n",
      "[Epoch 18/1000] [Batch 148/168] [D loss: 0.008049] [G loss: 5.702212]\n",
      "[Epoch 18/1000] [Batch 149/168] [D loss: 0.013300] [G loss: 5.255822]\n",
      "[Epoch 18/1000] [Batch 150/168] [D loss: 0.019400] [G loss: 4.890334]\n",
      "[Epoch 18/1000] [Batch 151/168] [D loss: 0.017552] [G loss: 3.878522]\n",
      "[Epoch 18/1000] [Batch 152/168] [D loss: 0.031888] [G loss: 6.930645]\n",
      "[Epoch 18/1000] [Batch 153/168] [D loss: 0.028041] [G loss: 3.731153]\n",
      "[Epoch 18/1000] [Batch 154/168] [D loss: 0.011524] [G loss: 8.317881]\n",
      "[Epoch 18/1000] [Batch 155/168] [D loss: 0.010732] [G loss: 7.953315]\n",
      "[Epoch 18/1000] [Batch 156/168] [D loss: 0.006922] [G loss: 6.046081]\n",
      "[Epoch 18/1000] [Batch 157/168] [D loss: 0.015766] [G loss: 4.376169]\n",
      "[Epoch 18/1000] [Batch 158/168] [D loss: 0.009652] [G loss: 7.007879]\n",
      "[Epoch 18/1000] [Batch 159/168] [D loss: 0.004042] [G loss: 6.917547]\n",
      "[Epoch 18/1000] [Batch 160/168] [D loss: 0.005483] [G loss: 5.828115]\n",
      "[Epoch 18/1000] [Batch 161/168] [D loss: 0.008996] [G loss: 4.833446]\n",
      "[Epoch 18/1000] [Batch 162/168] [D loss: 0.007614] [G loss: 5.234614]\n",
      "[Epoch 18/1000] [Batch 163/168] [D loss: 0.013864] [G loss: 5.345781]\n",
      "[Epoch 18/1000] [Batch 164/168] [D loss: 0.012567] [G loss: 4.552987]\n",
      "[Epoch 18/1000] [Batch 165/168] [D loss: 0.015356] [G loss: 5.212152]\n",
      "[Epoch 18/1000] [Batch 166/168] [D loss: 0.013320] [G loss: 4.547002]\n",
      "[Epoch 18/1000] [Batch 167/168] [D loss: 0.012845] [G loss: 5.385475]\n",
      "[Epoch 18/1000] [Batch 168/168] [D loss: 0.014354] [G loss: 4.959722]\n",
      "[Epoch 19/1000] [Batch 1/168] [D loss: 0.011345] [G loss: 4.559550]\n",
      "[Epoch 19/1000] [Batch 2/168] [D loss: 0.007815] [G loss: 5.911539]\n",
      "[Epoch 19/1000] [Batch 3/168] [D loss: 0.015948] [G loss: 5.955336]\n",
      "[Epoch 19/1000] [Batch 4/168] [D loss: 0.038309] [G loss: 3.334030]\n",
      "[Epoch 19/1000] [Batch 5/168] [D loss: 0.235612] [G loss: 11.273944]\n",
      "[Epoch 19/1000] [Batch 6/168] [D loss: 5.090820] [G loss: 0.000429]\n",
      "[Epoch 19/1000] [Batch 7/168] [D loss: 7.443322] [G loss: 26.449970]\n",
      "[Epoch 19/1000] [Batch 8/168] [D loss: 1.896871] [G loss: 16.216845]\n",
      "[Epoch 19/1000] [Batch 9/168] [D loss: 0.129281] [G loss: 4.034832]\n",
      "[Epoch 19/1000] [Batch 10/168] [D loss: 0.493548] [G loss: 0.878594]\n",
      "[Epoch 19/1000] [Batch 11/168] [D loss: 0.006540] [G loss: 5.586690]\n",
      "[Epoch 19/1000] [Batch 12/168] [D loss: 0.001782] [G loss: 8.094015]\n",
      "[Epoch 19/1000] [Batch 13/168] [D loss: 0.001253] [G loss: 9.006059]\n",
      "[Epoch 19/1000] [Batch 14/168] [D loss: 0.004237] [G loss: 8.844267]\n",
      "[Epoch 19/1000] [Batch 15/168] [D loss: 0.003201] [G loss: 8.167202]\n",
      "[Epoch 19/1000] [Batch 16/168] [D loss: 0.007231] [G loss: 7.038012]\n",
      "[Epoch 19/1000] [Batch 17/168] [D loss: 0.015328] [G loss: 5.475711]\n",
      "[Epoch 19/1000] [Batch 18/168] [D loss: 0.056554] [G loss: 3.811145]\n",
      "[Epoch 19/1000] [Batch 19/168] [D loss: 0.037482] [G loss: 3.776539]\n",
      "[Epoch 19/1000] [Batch 20/168] [D loss: 0.044668] [G loss: 3.597700]\n",
      "[Epoch 19/1000] [Batch 21/168] [D loss: 0.042508] [G loss: 3.872686]\n",
      "[Epoch 19/1000] [Batch 22/168] [D loss: 0.033747] [G loss: 3.795886]\n",
      "[Epoch 19/1000] [Batch 23/168] [D loss: 0.048991] [G loss: 3.613066]\n",
      "[Epoch 19/1000] [Batch 24/168] [D loss: 0.078141] [G loss: 3.069388]\n",
      "[Epoch 19/1000] [Batch 25/168] [D loss: 0.072812] [G loss: 3.224019]\n",
      "[Epoch 19/1000] [Batch 26/168] [D loss: 0.064229] [G loss: 3.382056]\n",
      "[Epoch 19/1000] [Batch 27/168] [D loss: 0.081954] [G loss: 3.691183]\n",
      "[Epoch 19/1000] [Batch 28/168] [D loss: 0.085279] [G loss: 2.853193]\n",
      "[Epoch 19/1000] [Batch 29/168] [D loss: 0.047755] [G loss: 3.566654]\n",
      "[Epoch 19/1000] [Batch 30/168] [D loss: 0.041199] [G loss: 3.946779]\n",
      "[Epoch 19/1000] [Batch 31/168] [D loss: 0.039226] [G loss: 3.737998]\n",
      "[Epoch 19/1000] [Batch 32/168] [D loss: 0.035195] [G loss: 3.704143]\n",
      "[Epoch 19/1000] [Batch 33/168] [D loss: 0.048999] [G loss: 3.769661]\n",
      "[Epoch 19/1000] [Batch 34/168] [D loss: 0.033463] [G loss: 3.521085]\n",
      "[Epoch 19/1000] [Batch 35/168] [D loss: 0.027734] [G loss: 4.013196]\n",
      "[Epoch 19/1000] [Batch 36/168] [D loss: 0.028522] [G loss: 4.045141]\n",
      "[Epoch 19/1000] [Batch 37/168] [D loss: 0.029686] [G loss: 4.108285]\n",
      "[Epoch 19/1000] [Batch 38/168] [D loss: 0.035308] [G loss: 3.552882]\n",
      "[Epoch 19/1000] [Batch 39/168] [D loss: 0.031094] [G loss: 3.822512]\n",
      "[Epoch 19/1000] [Batch 40/168] [D loss: 0.039148] [G loss: 3.961573]\n",
      "[Epoch 19/1000] [Batch 41/168] [D loss: 0.022260] [G loss: 3.980131]\n",
      "[Epoch 19/1000] [Batch 42/168] [D loss: 0.035142] [G loss: 3.830204]\n",
      "[Epoch 19/1000] [Batch 43/168] [D loss: 0.028293] [G loss: 4.019960]\n",
      "[Epoch 19/1000] [Batch 44/168] [D loss: 0.028230] [G loss: 3.703887]\n",
      "[Epoch 19/1000] [Batch 45/168] [D loss: 0.026898] [G loss: 4.091206]\n",
      "[Epoch 19/1000] [Batch 46/168] [D loss: 0.021615] [G loss: 4.265158]\n",
      "[Epoch 19/1000] [Batch 47/168] [D loss: 0.028054] [G loss: 4.088480]\n",
      "[Epoch 19/1000] [Batch 48/168] [D loss: 0.027774] [G loss: 3.738723]\n",
      "[Epoch 19/1000] [Batch 49/168] [D loss: 0.030301] [G loss: 3.905618]\n",
      "[Epoch 19/1000] [Batch 50/168] [D loss: 0.028218] [G loss: 3.996175]\n",
      "[Epoch 19/1000] [Batch 51/168] [D loss: 0.040717] [G loss: 3.849763]\n",
      "[Epoch 19/1000] [Batch 52/168] [D loss: 0.032210] [G loss: 3.478021]\n",
      "[Epoch 19/1000] [Batch 53/168] [D loss: 0.027179] [G loss: 4.139756]\n",
      "[Epoch 19/1000] [Batch 54/168] [D loss: 0.023668] [G loss: 4.316148]\n",
      "[Epoch 19/1000] [Batch 55/168] [D loss: 0.028261] [G loss: 4.146022]\n",
      "[Epoch 19/1000] [Batch 56/168] [D loss: 0.030468] [G loss: 3.768728]\n",
      "[Epoch 19/1000] [Batch 57/168] [D loss: 0.026263] [G loss: 3.706635]\n",
      "[Epoch 19/1000] [Batch 58/168] [D loss: 0.025156] [G loss: 4.202524]\n",
      "[Epoch 19/1000] [Batch 59/168] [D loss: 0.025168] [G loss: 4.238108]\n",
      "[Epoch 19/1000] [Batch 60/168] [D loss: 0.027475] [G loss: 3.986017]\n",
      "[Epoch 19/1000] [Batch 61/168] [D loss: 0.026900] [G loss: 3.863684]\n",
      "[Epoch 19/1000] [Batch 62/168] [D loss: 0.023045] [G loss: 3.914098]\n",
      "[Epoch 19/1000] [Batch 63/168] [D loss: 0.028451] [G loss: 4.237122]\n",
      "[Epoch 19/1000] [Batch 64/168] [D loss: 0.022292] [G loss: 4.179513]\n",
      "[Epoch 19/1000] [Batch 65/168] [D loss: 0.020726] [G loss: 4.120952]\n",
      "[Epoch 19/1000] [Batch 66/168] [D loss: 0.014651] [G loss: 4.482584]\n",
      "[Epoch 19/1000] [Batch 67/168] [D loss: 0.021212] [G loss: 4.553897]\n",
      "[Epoch 19/1000] [Batch 68/168] [D loss: 0.024533] [G loss: 4.106127]\n",
      "[Epoch 19/1000] [Batch 69/168] [D loss: 0.018474] [G loss: 4.110332]\n",
      "[Epoch 19/1000] [Batch 70/168] [D loss: 0.015859] [G loss: 4.359149]\n",
      "[Epoch 19/1000] [Batch 71/168] [D loss: 0.017013] [G loss: 4.421517]\n",
      "[Epoch 19/1000] [Batch 72/168] [D loss: 0.017662] [G loss: 4.430668]\n",
      "[Epoch 19/1000] [Batch 73/168] [D loss: 0.015698] [G loss: 4.398433]\n",
      "[Epoch 19/1000] [Batch 74/168] [D loss: 0.020070] [G loss: 4.215685]\n",
      "[Epoch 19/1000] [Batch 75/168] [D loss: 0.021138] [G loss: 4.414364]\n",
      "[Epoch 19/1000] [Batch 76/168] [D loss: 0.024217] [G loss: 4.273648]\n",
      "[Epoch 19/1000] [Batch 77/168] [D loss: 0.029817] [G loss: 4.191501]\n",
      "[Epoch 19/1000] [Batch 78/168] [D loss: 0.026657] [G loss: 3.650951]\n",
      "[Epoch 19/1000] [Batch 79/168] [D loss: 0.014307] [G loss: 4.424254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/1000] [Batch 80/168] [D loss: 0.017361] [G loss: 4.644758]\n",
      "[Epoch 19/1000] [Batch 81/168] [D loss: 0.022228] [G loss: 4.043296]\n",
      "[Epoch 19/1000] [Batch 82/168] [D loss: 0.023570] [G loss: 4.200473]\n",
      "[Epoch 19/1000] [Batch 83/168] [D loss: 0.024966] [G loss: 4.248889]\n",
      "[Epoch 19/1000] [Batch 84/168] [D loss: 0.024220] [G loss: 4.023329]\n",
      "[Epoch 19/1000] [Batch 85/168] [D loss: 0.030181] [G loss: 3.756636]\n",
      "[Epoch 19/1000] [Batch 86/168] [D loss: 0.025450] [G loss: 4.460912]\n",
      "[Epoch 19/1000] [Batch 87/168] [D loss: 0.026867] [G loss: 4.164865]\n",
      "[Epoch 19/1000] [Batch 88/168] [D loss: 0.023823] [G loss: 4.173934]\n",
      "[Epoch 19/1000] [Batch 89/168] [D loss: 0.021626] [G loss: 4.414538]\n",
      "[Epoch 19/1000] [Batch 90/168] [D loss: 0.018633] [G loss: 4.290260]\n",
      "[Epoch 19/1000] [Batch 91/168] [D loss: 0.021013] [G loss: 4.203126]\n",
      "[Epoch 19/1000] [Batch 92/168] [D loss: 0.021095] [G loss: 4.681543]\n",
      "[Epoch 19/1000] [Batch 93/168] [D loss: 0.019048] [G loss: 4.388945]\n",
      "[Epoch 19/1000] [Batch 94/168] [D loss: 0.017831] [G loss: 4.354022]\n",
      "[Epoch 19/1000] [Batch 95/168] [D loss: 0.019266] [G loss: 4.559561]\n",
      "[Epoch 19/1000] [Batch 96/168] [D loss: 0.019963] [G loss: 4.325642]\n",
      "[Epoch 19/1000] [Batch 97/168] [D loss: 0.024660] [G loss: 4.358627]\n",
      "[Epoch 19/1000] [Batch 98/168] [D loss: 0.019371] [G loss: 4.449856]\n",
      "[Epoch 19/1000] [Batch 99/168] [D loss: 0.018129] [G loss: 4.353023]\n",
      "[Epoch 19/1000] [Batch 100/168] [D loss: 0.019786] [G loss: 4.213710]\n",
      "[Epoch 19/1000] [Batch 101/168] [D loss: 0.020911] [G loss: 4.445056]\n",
      "[Epoch 19/1000] [Batch 102/168] [D loss: 0.014272] [G loss: 4.682643]\n",
      "[Epoch 19/1000] [Batch 103/168] [D loss: 0.016563] [G loss: 4.444553]\n",
      "[Epoch 19/1000] [Batch 104/168] [D loss: 0.014924] [G loss: 4.401678]\n",
      "[Epoch 19/1000] [Batch 105/168] [D loss: 0.025209] [G loss: 4.390661]\n",
      "[Epoch 19/1000] [Batch 106/168] [D loss: 0.020905] [G loss: 4.469672]\n",
      "[Epoch 19/1000] [Batch 107/168] [D loss: 0.021117] [G loss: 4.324046]\n",
      "[Epoch 19/1000] [Batch 108/168] [D loss: 0.022662] [G loss: 4.150486]\n",
      "[Epoch 19/1000] [Batch 109/168] [D loss: 0.030269] [G loss: 4.458442]\n",
      "[Epoch 19/1000] [Batch 110/168] [D loss: 0.018827] [G loss: 4.424359]\n",
      "[Epoch 19/1000] [Batch 111/168] [D loss: 0.016501] [G loss: 4.435316]\n",
      "[Epoch 19/1000] [Batch 112/168] [D loss: 0.014536] [G loss: 4.505152]\n",
      "[Epoch 19/1000] [Batch 113/168] [D loss: 0.016454] [G loss: 4.370888]\n",
      "[Epoch 19/1000] [Batch 114/168] [D loss: 0.017237] [G loss: 4.814250]\n",
      "[Epoch 19/1000] [Batch 115/168] [D loss: 0.021038] [G loss: 4.594697]\n",
      "[Epoch 19/1000] [Batch 116/168] [D loss: 0.020994] [G loss: 4.034279]\n",
      "[Epoch 19/1000] [Batch 117/168] [D loss: 0.032262] [G loss: 3.979809]\n",
      "[Epoch 19/1000] [Batch 118/168] [D loss: 0.016127] [G loss: 4.678438]\n",
      "[Epoch 19/1000] [Batch 119/168] [D loss: 0.018495] [G loss: 4.829849]\n",
      "[Epoch 19/1000] [Batch 120/168] [D loss: 0.026253] [G loss: 4.274059]\n",
      "[Epoch 19/1000] [Batch 121/168] [D loss: 0.022471] [G loss: 3.757714]\n",
      "[Epoch 19/1000] [Batch 122/168] [D loss: 0.018422] [G loss: 4.539054]\n",
      "[Epoch 19/1000] [Batch 123/168] [D loss: 0.018605] [G loss: 4.928061]\n",
      "[Epoch 19/1000] [Batch 124/168] [D loss: 0.011066] [G loss: 4.700133]\n",
      "[Epoch 19/1000] [Batch 125/168] [D loss: 0.014256] [G loss: 4.505325]\n",
      "[Epoch 19/1000] [Batch 126/168] [D loss: 0.022733] [G loss: 4.481213]\n",
      "[Epoch 19/1000] [Batch 127/168] [D loss: 0.016621] [G loss: 4.603017]\n",
      "[Epoch 19/1000] [Batch 128/168] [D loss: 0.014164] [G loss: 4.570114]\n",
      "[Epoch 19/1000] [Batch 129/168] [D loss: 0.018512] [G loss: 4.444395]\n",
      "[Epoch 19/1000] [Batch 130/168] [D loss: 0.016431] [G loss: 4.444353]\n",
      "[Epoch 19/1000] [Batch 131/168] [D loss: 0.016622] [G loss: 4.635108]\n",
      "[Epoch 19/1000] [Batch 132/168] [D loss: 0.025660] [G loss: 4.417879]\n",
      "[Epoch 19/1000] [Batch 133/168] [D loss: 0.024317] [G loss: 4.355683]\n",
      "[Epoch 19/1000] [Batch 134/168] [D loss: 0.019045] [G loss: 4.519615]\n",
      "[Epoch 19/1000] [Batch 135/168] [D loss: 0.009795] [G loss: 4.758806]\n",
      "[Epoch 19/1000] [Batch 136/168] [D loss: 0.012647] [G loss: 5.029418]\n",
      "[Epoch 19/1000] [Batch 137/168] [D loss: 0.012947] [G loss: 4.583494]\n",
      "[Epoch 19/1000] [Batch 138/168] [D loss: 0.012697] [G loss: 4.924919]\n",
      "[Epoch 19/1000] [Batch 139/168] [D loss: 0.017038] [G loss: 4.657179]\n",
      "[Epoch 19/1000] [Batch 140/168] [D loss: 0.014827] [G loss: 4.494088]\n",
      "[Epoch 19/1000] [Batch 141/168] [D loss: 0.021475] [G loss: 4.559440]\n",
      "[Epoch 19/1000] [Batch 142/168] [D loss: 0.013898] [G loss: 4.742090]\n",
      "[Epoch 19/1000] [Batch 143/168] [D loss: 0.013556] [G loss: 4.469260]\n",
      "[Epoch 19/1000] [Batch 144/168] [D loss: 0.014325] [G loss: 4.992899]\n",
      "[Epoch 19/1000] [Batch 145/168] [D loss: 0.013166] [G loss: 4.936129]\n",
      "[Epoch 19/1000] [Batch 146/168] [D loss: 0.014840] [G loss: 4.605547]\n",
      "[Epoch 19/1000] [Batch 147/168] [D loss: 0.013252] [G loss: 4.708358]\n",
      "[Epoch 19/1000] [Batch 148/168] [D loss: 0.017524] [G loss: 4.511498]\n",
      "[Epoch 19/1000] [Batch 149/168] [D loss: 0.010211] [G loss: 5.064775]\n",
      "[Epoch 19/1000] [Batch 150/168] [D loss: 0.016894] [G loss: 4.723572]\n",
      "[Epoch 19/1000] [Batch 151/168] [D loss: 0.020333] [G loss: 4.388402]\n",
      "[Epoch 19/1000] [Batch 152/168] [D loss: 0.020587] [G loss: 4.073235]\n",
      "[Epoch 19/1000] [Batch 153/168] [D loss: 0.013792] [G loss: 4.678030]\n",
      "[Epoch 19/1000] [Batch 154/168] [D loss: 0.015367] [G loss: 5.105005]\n",
      "[Epoch 19/1000] [Batch 155/168] [D loss: 0.014316] [G loss: 4.710592]\n",
      "[Epoch 19/1000] [Batch 156/168] [D loss: 0.016313] [G loss: 4.519380]\n",
      "[Epoch 19/1000] [Batch 157/168] [D loss: 0.017574] [G loss: 4.200943]\n",
      "[Epoch 19/1000] [Batch 158/168] [D loss: 0.015234] [G loss: 4.860402]\n",
      "[Epoch 19/1000] [Batch 159/168] [D loss: 0.017063] [G loss: 4.810554]\n",
      "[Epoch 19/1000] [Batch 160/168] [D loss: 0.017131] [G loss: 4.652489]\n",
      "[Epoch 19/1000] [Batch 161/168] [D loss: 0.021106] [G loss: 4.095901]\n",
      "[Epoch 19/1000] [Batch 162/168] [D loss: 0.016564] [G loss: 4.906278]\n",
      "[Epoch 19/1000] [Batch 163/168] [D loss: 0.011205] [G loss: 4.889785]\n",
      "[Epoch 19/1000] [Batch 164/168] [D loss: 0.017081] [G loss: 4.713224]\n",
      "[Epoch 19/1000] [Batch 165/168] [D loss: 0.017921] [G loss: 4.529914]\n",
      "[Epoch 19/1000] [Batch 166/168] [D loss: 0.012048] [G loss: 4.822642]\n",
      "[Epoch 19/1000] [Batch 167/168] [D loss: 0.013347] [G loss: 4.806444]\n",
      "[Epoch 19/1000] [Batch 168/168] [D loss: 0.010396] [G loss: 4.865507]\n",
      "[Epoch 20/1000] [Batch 1/168] [D loss: 0.008704] [G loss: 5.037358]\n",
      "[Epoch 20/1000] [Batch 2/168] [D loss: 0.010059] [G loss: 5.097434]\n",
      "[Epoch 20/1000] [Batch 3/168] [D loss: 0.011735] [G loss: 4.944225]\n",
      "[Epoch 20/1000] [Batch 4/168] [D loss: 0.011362] [G loss: 4.794808]\n",
      "[Epoch 20/1000] [Batch 5/168] [D loss: 0.011191] [G loss: 4.998224]\n",
      "[Epoch 20/1000] [Batch 6/168] [D loss: 0.014240] [G loss: 4.994349]\n",
      "[Epoch 20/1000] [Batch 7/168] [D loss: 0.012817] [G loss: 4.528296]\n",
      "[Epoch 20/1000] [Batch 8/168] [D loss: 0.012252] [G loss: 5.214177]\n",
      "[Epoch 20/1000] [Batch 9/168] [D loss: 0.016278] [G loss: 5.075102]\n",
      "[Epoch 20/1000] [Batch 10/168] [D loss: 0.014225] [G loss: 4.409493]\n",
      "[Epoch 20/1000] [Batch 11/168] [D loss: 0.009038] [G loss: 4.885669]\n",
      "[Epoch 20/1000] [Batch 12/168] [D loss: 0.008663] [G loss: 5.328660]\n",
      "[Epoch 20/1000] [Batch 13/168] [D loss: 0.008078] [G loss: 5.462838]\n",
      "[Epoch 20/1000] [Batch 14/168] [D loss: 0.011104] [G loss: 5.171243]\n",
      "[Epoch 20/1000] [Batch 15/168] [D loss: 0.009232] [G loss: 4.865726]\n",
      "[Epoch 20/1000] [Batch 16/168] [D loss: 0.009986] [G loss: 4.890754]\n",
      "[Epoch 20/1000] [Batch 17/168] [D loss: 0.009450] [G loss: 5.069646]\n",
      "[Epoch 20/1000] [Batch 18/168] [D loss: 0.011409] [G loss: 5.049009]\n",
      "[Epoch 20/1000] [Batch 19/168] [D loss: 0.013249] [G loss: 5.214938]\n",
      "[Epoch 20/1000] [Batch 20/168] [D loss: 0.012196] [G loss: 4.674592]\n",
      "[Epoch 20/1000] [Batch 21/168] [D loss: 0.011237] [G loss: 4.846325]\n",
      "[Epoch 20/1000] [Batch 22/168] [D loss: 0.010073] [G loss: 4.910178]\n",
      "[Epoch 20/1000] [Batch 23/168] [D loss: 0.010838] [G loss: 5.211397]\n",
      "[Epoch 20/1000] [Batch 24/168] [D loss: 0.010544] [G loss: 4.987505]\n",
      "[Epoch 20/1000] [Batch 25/168] [D loss: 0.010244] [G loss: 4.878547]\n",
      "[Epoch 20/1000] [Batch 26/168] [D loss: 0.011383] [G loss: 4.724787]\n",
      "[Epoch 20/1000] [Batch 27/168] [D loss: 0.012513] [G loss: 4.868538]\n",
      "[Epoch 20/1000] [Batch 28/168] [D loss: 0.013387] [G loss: 5.046707]\n",
      "[Epoch 20/1000] [Batch 29/168] [D loss: 0.017025] [G loss: 4.533155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/1000] [Batch 30/168] [D loss: 0.009843] [G loss: 4.899650]\n",
      "[Epoch 20/1000] [Batch 31/168] [D loss: 0.015729] [G loss: 4.910695]\n",
      "[Epoch 20/1000] [Batch 32/168] [D loss: 0.011617] [G loss: 4.866564]\n",
      "[Epoch 20/1000] [Batch 33/168] [D loss: 0.009515] [G loss: 5.060617]\n",
      "[Epoch 20/1000] [Batch 34/168] [D loss: 0.012161] [G loss: 4.923357]\n",
      "[Epoch 20/1000] [Batch 35/168] [D loss: 0.008283] [G loss: 5.372048]\n",
      "[Epoch 20/1000] [Batch 36/168] [D loss: 0.014302] [G loss: 5.208308]\n",
      "[Epoch 20/1000] [Batch 37/168] [D loss: 0.011449] [G loss: 4.613128]\n",
      "[Epoch 20/1000] [Batch 38/168] [D loss: 0.011428] [G loss: 4.690061]\n",
      "[Epoch 20/1000] [Batch 39/168] [D loss: 0.011411] [G loss: 5.363984]\n",
      "[Epoch 20/1000] [Batch 40/168] [D loss: 0.012813] [G loss: 4.877439]\n",
      "[Epoch 20/1000] [Batch 41/168] [D loss: 0.009745] [G loss: 4.638890]\n",
      "[Epoch 20/1000] [Batch 42/168] [D loss: 0.009264] [G loss: 5.414021]\n",
      "[Epoch 20/1000] [Batch 43/168] [D loss: 0.008281] [G loss: 5.238367]\n",
      "[Epoch 20/1000] [Batch 44/168] [D loss: 0.011702] [G loss: 4.819465]\n",
      "[Epoch 20/1000] [Batch 45/168] [D loss: 0.010955] [G loss: 5.231432]\n",
      "[Epoch 20/1000] [Batch 46/168] [D loss: 0.014478] [G loss: 5.203117]\n",
      "[Epoch 20/1000] [Batch 47/168] [D loss: 0.015304] [G loss: 4.514185]\n",
      "[Epoch 20/1000] [Batch 48/168] [D loss: 0.011386] [G loss: 4.742883]\n",
      "[Epoch 20/1000] [Batch 49/168] [D loss: 0.014191] [G loss: 5.283953]\n",
      "[Epoch 20/1000] [Batch 50/168] [D loss: 0.012472] [G loss: 4.827806]\n",
      "[Epoch 20/1000] [Batch 51/168] [D loss: 0.012350] [G loss: 4.719357]\n",
      "[Epoch 20/1000] [Batch 52/168] [D loss: 0.014556] [G loss: 4.917002]\n",
      "[Epoch 20/1000] [Batch 53/168] [D loss: 0.020936] [G loss: 5.003182]\n",
      "[Epoch 20/1000] [Batch 54/168] [D loss: 0.016252] [G loss: 4.231913]\n",
      "[Epoch 20/1000] [Batch 55/168] [D loss: 0.007490] [G loss: 5.699948]\n",
      "[Epoch 20/1000] [Batch 56/168] [D loss: 0.008677] [G loss: 5.954455]\n",
      "[Epoch 20/1000] [Batch 57/168] [D loss: 0.009095] [G loss: 5.485772]\n",
      "[Epoch 20/1000] [Batch 58/168] [D loss: 0.011711] [G loss: 4.586878]\n",
      "[Epoch 20/1000] [Batch 59/168] [D loss: 0.008414] [G loss: 5.390594]\n",
      "[Epoch 20/1000] [Batch 60/168] [D loss: 0.010958] [G loss: 5.385358]\n",
      "[Epoch 20/1000] [Batch 61/168] [D loss: 0.010258] [G loss: 4.921906]\n",
      "[Epoch 20/1000] [Batch 62/168] [D loss: 0.012859] [G loss: 4.743011]\n",
      "[Epoch 20/1000] [Batch 63/168] [D loss: 0.010083] [G loss: 5.101260]\n",
      "[Epoch 20/1000] [Batch 64/168] [D loss: 0.010137] [G loss: 5.407294]\n",
      "[Epoch 20/1000] [Batch 65/168] [D loss: 0.010227] [G loss: 4.942800]\n",
      "[Epoch 20/1000] [Batch 66/168] [D loss: 0.020489] [G loss: 4.824465]\n",
      "[Epoch 20/1000] [Batch 67/168] [D loss: 0.010784] [G loss: 4.726644]\n",
      "[Epoch 20/1000] [Batch 68/168] [D loss: 0.012124] [G loss: 5.579034]\n",
      "[Epoch 20/1000] [Batch 69/168] [D loss: 0.010422] [G loss: 5.144286]\n",
      "[Epoch 20/1000] [Batch 70/168] [D loss: 0.007345] [G loss: 5.076616]\n",
      "[Epoch 20/1000] [Batch 71/168] [D loss: 0.006963] [G loss: 5.418595]\n",
      "[Epoch 20/1000] [Batch 72/168] [D loss: 0.007454] [G loss: 5.522247]\n",
      "[Epoch 20/1000] [Batch 73/168] [D loss: 0.007461] [G loss: 5.349629]\n",
      "[Epoch 20/1000] [Batch 74/168] [D loss: 0.009744] [G loss: 5.245026]\n",
      "[Epoch 20/1000] [Batch 75/168] [D loss: 0.010729] [G loss: 4.807880]\n",
      "[Epoch 20/1000] [Batch 76/168] [D loss: 0.009610] [G loss: 5.991088]\n",
      "[Epoch 20/1000] [Batch 77/168] [D loss: 0.011021] [G loss: 5.393490]\n",
      "[Epoch 20/1000] [Batch 78/168] [D loss: 0.009940] [G loss: 4.911608]\n",
      "[Epoch 20/1000] [Batch 79/168] [D loss: 0.010464] [G loss: 4.767984]\n",
      "[Epoch 20/1000] [Batch 80/168] [D loss: 0.007253] [G loss: 5.548464]\n",
      "[Epoch 20/1000] [Batch 81/168] [D loss: 0.006480] [G loss: 5.534860]\n",
      "[Epoch 20/1000] [Batch 82/168] [D loss: 0.006950] [G loss: 5.441979]\n",
      "[Epoch 20/1000] [Batch 83/168] [D loss: 0.008731] [G loss: 5.485186]\n",
      "[Epoch 20/1000] [Batch 84/168] [D loss: 0.009271] [G loss: 5.312458]\n",
      "[Epoch 20/1000] [Batch 85/168] [D loss: 0.009485] [G loss: 5.286932]\n",
      "[Epoch 20/1000] [Batch 86/168] [D loss: 0.008483] [G loss: 5.211092]\n",
      "[Epoch 20/1000] [Batch 87/168] [D loss: 0.010496] [G loss: 4.991806]\n",
      "[Epoch 20/1000] [Batch 88/168] [D loss: 0.007626] [G loss: 5.450139]\n",
      "[Epoch 20/1000] [Batch 89/168] [D loss: 0.009062] [G loss: 5.526720]\n",
      "[Epoch 20/1000] [Batch 90/168] [D loss: 0.010569] [G loss: 5.331307]\n",
      "[Epoch 20/1000] [Batch 91/168] [D loss: 0.009689] [G loss: 4.664818]\n",
      "[Epoch 20/1000] [Batch 92/168] [D loss: 0.012572] [G loss: 5.076827]\n",
      "[Epoch 20/1000] [Batch 93/168] [D loss: 0.012042] [G loss: 5.092920]\n",
      "[Epoch 20/1000] [Batch 94/168] [D loss: 0.010401] [G loss: 4.791611]\n",
      "[Epoch 20/1000] [Batch 95/168] [D loss: 0.011784] [G loss: 5.056078]\n",
      "[Epoch 20/1000] [Batch 96/168] [D loss: 0.010547] [G loss: 5.204571]\n",
      "[Epoch 20/1000] [Batch 97/168] [D loss: 0.009717] [G loss: 5.303677]\n",
      "[Epoch 20/1000] [Batch 98/168] [D loss: 0.008960] [G loss: 4.939846]\n",
      "[Epoch 20/1000] [Batch 99/168] [D loss: 0.008650] [G loss: 5.269096]\n",
      "[Epoch 20/1000] [Batch 100/168] [D loss: 0.011780] [G loss: 5.425335]\n",
      "[Epoch 20/1000] [Batch 101/168] [D loss: 0.008732] [G loss: 4.820351]\n",
      "[Epoch 20/1000] [Batch 102/168] [D loss: 0.007971] [G loss: 5.255627]\n",
      "[Epoch 20/1000] [Batch 103/168] [D loss: 0.007933] [G loss: 5.507128]\n",
      "[Epoch 20/1000] [Batch 104/168] [D loss: 0.011914] [G loss: 5.483896]\n",
      "[Epoch 20/1000] [Batch 105/168] [D loss: 0.009720] [G loss: 5.044514]\n",
      "[Epoch 20/1000] [Batch 106/168] [D loss: 0.008733] [G loss: 5.002198]\n",
      "[Epoch 20/1000] [Batch 107/168] [D loss: 0.010469] [G loss: 5.523214]\n",
      "[Epoch 20/1000] [Batch 108/168] [D loss: 0.008548] [G loss: 5.722101]\n",
      "[Epoch 20/1000] [Batch 109/168] [D loss: 0.007259] [G loss: 5.233158]\n",
      "[Epoch 20/1000] [Batch 110/168] [D loss: 0.008698] [G loss: 5.208545]\n",
      "[Epoch 20/1000] [Batch 111/168] [D loss: 0.010553] [G loss: 5.332321]\n",
      "[Epoch 20/1000] [Batch 112/168] [D loss: 0.009326] [G loss: 5.262314]\n",
      "[Epoch 20/1000] [Batch 113/168] [D loss: 0.009316] [G loss: 5.188725]\n",
      "[Epoch 20/1000] [Batch 114/168] [D loss: 0.007461] [G loss: 5.289025]\n",
      "[Epoch 20/1000] [Batch 115/168] [D loss: 0.005722] [G loss: 5.995347]\n",
      "[Epoch 20/1000] [Batch 116/168] [D loss: 0.008244] [G loss: 5.596353]\n",
      "[Epoch 20/1000] [Batch 117/168] [D loss: 0.006796] [G loss: 5.472936]\n",
      "[Epoch 20/1000] [Batch 118/168] [D loss: 0.005970] [G loss: 5.596789]\n",
      "[Epoch 20/1000] [Batch 119/168] [D loss: 0.010776] [G loss: 5.610709]\n",
      "[Epoch 20/1000] [Batch 120/168] [D loss: 0.007280] [G loss: 5.675581]\n",
      "[Epoch 20/1000] [Batch 121/168] [D loss: 0.008288] [G loss: 5.421858]\n",
      "[Epoch 20/1000] [Batch 122/168] [D loss: 0.006146] [G loss: 5.464444]\n",
      "[Epoch 20/1000] [Batch 123/168] [D loss: 0.007909] [G loss: 5.617689]\n",
      "[Epoch 20/1000] [Batch 124/168] [D loss: 0.009739] [G loss: 5.551842]\n",
      "[Epoch 20/1000] [Batch 125/168] [D loss: 0.008441] [G loss: 5.629624]\n",
      "[Epoch 20/1000] [Batch 126/168] [D loss: 0.011063] [G loss: 5.673270]\n",
      "[Epoch 20/1000] [Batch 127/168] [D loss: 0.009721] [G loss: 5.192432]\n",
      "[Epoch 20/1000] [Batch 128/168] [D loss: 0.007748] [G loss: 5.632953]\n",
      "[Epoch 20/1000] [Batch 129/168] [D loss: 0.006561] [G loss: 5.679878]\n",
      "[Epoch 20/1000] [Batch 130/168] [D loss: 0.010924] [G loss: 5.417413]\n",
      "[Epoch 20/1000] [Batch 131/168] [D loss: 0.008445] [G loss: 5.346284]\n",
      "[Epoch 20/1000] [Batch 132/168] [D loss: 0.007260] [G loss: 5.239761]\n",
      "[Epoch 20/1000] [Batch 133/168] [D loss: 0.007031] [G loss: 5.684166]\n",
      "[Epoch 20/1000] [Batch 134/168] [D loss: 0.006879] [G loss: 5.745180]\n",
      "[Epoch 20/1000] [Batch 135/168] [D loss: 0.008248] [G loss: 5.676528]\n",
      "[Epoch 20/1000] [Batch 136/168] [D loss: 0.006642] [G loss: 5.747467]\n",
      "[Epoch 20/1000] [Batch 137/168] [D loss: 0.009801] [G loss: 5.247578]\n",
      "[Epoch 20/1000] [Batch 138/168] [D loss: 0.008190] [G loss: 5.501276]\n",
      "[Epoch 20/1000] [Batch 139/168] [D loss: 0.012008] [G loss: 5.405666]\n",
      "[Epoch 20/1000] [Batch 140/168] [D loss: 0.007833] [G loss: 4.954898]\n",
      "[Epoch 20/1000] [Batch 141/168] [D loss: 0.004747] [G loss: 5.630682]\n",
      "[Epoch 20/1000] [Batch 142/168] [D loss: 0.004589] [G loss: 5.982323]\n",
      "[Epoch 20/1000] [Batch 143/168] [D loss: 0.005375] [G loss: 6.057043]\n",
      "[Epoch 20/1000] [Batch 144/168] [D loss: 0.007716] [G loss: 5.754611]\n",
      "[Epoch 20/1000] [Batch 145/168] [D loss: 0.005691] [G loss: 5.393567]\n",
      "[Epoch 20/1000] [Batch 146/168] [D loss: 0.009210] [G loss: 5.299850]\n",
      "[Epoch 20/1000] [Batch 147/168] [D loss: 0.006867] [G loss: 5.411101]\n",
      "[Epoch 20/1000] [Batch 148/168] [D loss: 0.004628] [G loss: 5.838358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/1000] [Batch 149/168] [D loss: 0.005090] [G loss: 5.814315]\n",
      "[Epoch 20/1000] [Batch 150/168] [D loss: 0.006684] [G loss: 5.643950]\n",
      "[Epoch 20/1000] [Batch 151/168] [D loss: 0.007881] [G loss: 5.542894]\n",
      "[Epoch 20/1000] [Batch 152/168] [D loss: 0.008101] [G loss: 5.523179]\n",
      "[Epoch 20/1000] [Batch 153/168] [D loss: 0.008228] [G loss: 5.065520]\n",
      "[Epoch 20/1000] [Batch 154/168] [D loss: 0.007615] [G loss: 5.270754]\n",
      "[Epoch 20/1000] [Batch 155/168] [D loss: 0.006508] [G loss: 5.893540]\n",
      "[Epoch 20/1000] [Batch 156/168] [D loss: 0.005298] [G loss: 5.714956]\n",
      "[Epoch 20/1000] [Batch 157/168] [D loss: 0.010979] [G loss: 5.273002]\n",
      "[Epoch 20/1000] [Batch 158/168] [D loss: 0.006242] [G loss: 5.483595]\n",
      "[Epoch 20/1000] [Batch 159/168] [D loss: 0.006633] [G loss: 5.625802]\n",
      "[Epoch 20/1000] [Batch 160/168] [D loss: 0.008137] [G loss: 5.411593]\n",
      "[Epoch 20/1000] [Batch 161/168] [D loss: 0.008181] [G loss: 4.946680]\n",
      "[Epoch 20/1000] [Batch 162/168] [D loss: 0.007528] [G loss: 5.639632]\n",
      "[Epoch 20/1000] [Batch 163/168] [D loss: 0.012149] [G loss: 5.671125]\n",
      "[Epoch 20/1000] [Batch 164/168] [D loss: 0.007151] [G loss: 5.048453]\n",
      "[Epoch 20/1000] [Batch 165/168] [D loss: 0.007156] [G loss: 5.183732]\n",
      "[Epoch 20/1000] [Batch 166/168] [D loss: 0.007909] [G loss: 5.966855]\n",
      "[Epoch 20/1000] [Batch 167/168] [D loss: 0.005885] [G loss: 5.702025]\n",
      "[Epoch 20/1000] [Batch 168/168] [D loss: 0.007238] [G loss: 5.463287]\n",
      "[Epoch 21/1000] [Batch 1/168] [D loss: 0.007710] [G loss: 5.144643]\n",
      "[Epoch 21/1000] [Batch 2/168] [D loss: 0.004895] [G loss: 6.507530]\n",
      "[Epoch 21/1000] [Batch 3/168] [D loss: 0.006540] [G loss: 6.833266]\n",
      "[Epoch 21/1000] [Batch 4/168] [D loss: 0.002988] [G loss: 6.362519]\n",
      "[Epoch 21/1000] [Batch 5/168] [D loss: 0.002957] [G loss: 6.027494]\n",
      "[Epoch 21/1000] [Batch 6/168] [D loss: 0.002914] [G loss: 6.244881]\n",
      "[Epoch 21/1000] [Batch 7/168] [D loss: 0.002994] [G loss: 6.980938]\n",
      "[Epoch 21/1000] [Batch 8/168] [D loss: 0.002318] [G loss: 7.061927]\n",
      "[Epoch 21/1000] [Batch 9/168] [D loss: 0.002997] [G loss: 6.828702]\n",
      "[Epoch 21/1000] [Batch 10/168] [D loss: 0.001379] [G loss: 6.900554]\n",
      "[Epoch 21/1000] [Batch 11/168] [D loss: 0.002608] [G loss: 6.757288]\n",
      "[Epoch 21/1000] [Batch 12/168] [D loss: 0.002200] [G loss: 6.979692]\n",
      "[Epoch 21/1000] [Batch 13/168] [D loss: 0.001421] [G loss: 7.016262]\n",
      "[Epoch 21/1000] [Batch 14/168] [D loss: 0.001747] [G loss: 7.064473]\n",
      "[Epoch 21/1000] [Batch 15/168] [D loss: 0.001389] [G loss: 7.267089]\n",
      "[Epoch 21/1000] [Batch 16/168] [D loss: 0.004124] [G loss: 7.182446]\n",
      "[Epoch 21/1000] [Batch 17/168] [D loss: 0.000946] [G loss: 7.126033]\n",
      "[Epoch 21/1000] [Batch 18/168] [D loss: 0.001398] [G loss: 6.941019]\n",
      "[Epoch 21/1000] [Batch 19/168] [D loss: 0.001807] [G loss: 7.022946]\n",
      "[Epoch 21/1000] [Batch 20/168] [D loss: 0.000904] [G loss: 7.370666]\n",
      "[Epoch 21/1000] [Batch 21/168] [D loss: 0.001554] [G loss: 7.395677]\n",
      "[Epoch 21/1000] [Batch 22/168] [D loss: 0.001053] [G loss: 7.297446]\n",
      "[Epoch 21/1000] [Batch 23/168] [D loss: 0.002868] [G loss: 7.505256]\n",
      "[Epoch 21/1000] [Batch 24/168] [D loss: 0.001125] [G loss: 7.430243]\n",
      "[Epoch 21/1000] [Batch 25/168] [D loss: 0.000984] [G loss: 7.398024]\n",
      "[Epoch 21/1000] [Batch 26/168] [D loss: 0.001053] [G loss: 7.251739]\n",
      "[Epoch 21/1000] [Batch 27/168] [D loss: 0.001043] [G loss: 7.487941]\n",
      "[Epoch 21/1000] [Batch 28/168] [D loss: 0.000623] [G loss: 7.637792]\n",
      "[Epoch 21/1000] [Batch 29/168] [D loss: 0.001102] [G loss: 7.451888]\n",
      "[Epoch 21/1000] [Batch 30/168] [D loss: 0.001020] [G loss: 7.428670]\n",
      "[Epoch 21/1000] [Batch 31/168] [D loss: 0.001144] [G loss: 7.489855]\n",
      "[Epoch 21/1000] [Batch 32/168] [D loss: 0.001419] [G loss: 7.475327]\n",
      "[Epoch 21/1000] [Batch 33/168] [D loss: 0.001427] [G loss: 7.484476]\n",
      "[Epoch 21/1000] [Batch 34/168] [D loss: 0.001471] [G loss: 7.545996]\n",
      "[Epoch 21/1000] [Batch 35/168] [D loss: 0.001025] [G loss: 7.651948]\n",
      "[Epoch 21/1000] [Batch 36/168] [D loss: 0.001040] [G loss: 7.770703]\n",
      "[Epoch 21/1000] [Batch 37/168] [D loss: 0.001264] [G loss: 7.707900]\n",
      "[Epoch 21/1000] [Batch 38/168] [D loss: 0.002204] [G loss: 7.242895]\n",
      "[Epoch 21/1000] [Batch 39/168] [D loss: 0.000806] [G loss: 7.498375]\n",
      "[Epoch 21/1000] [Batch 40/168] [D loss: 0.001128] [G loss: 7.124424]\n",
      "[Epoch 21/1000] [Batch 41/168] [D loss: 0.000851] [G loss: 7.386419]\n",
      "[Epoch 21/1000] [Batch 42/168] [D loss: 0.000897] [G loss: 7.464187]\n",
      "[Epoch 21/1000] [Batch 43/168] [D loss: 0.002321] [G loss: 7.668379]\n",
      "[Epoch 21/1000] [Batch 44/168] [D loss: 0.000878] [G loss: 7.752509]\n",
      "[Epoch 21/1000] [Batch 45/168] [D loss: 0.000838] [G loss: 7.448802]\n",
      "[Epoch 21/1000] [Batch 46/168] [D loss: 0.000792] [G loss: 7.550416]\n",
      "[Epoch 21/1000] [Batch 47/168] [D loss: 0.001037] [G loss: 7.535315]\n",
      "[Epoch 21/1000] [Batch 48/168] [D loss: 0.001701] [G loss: 7.609314]\n",
      "[Epoch 21/1000] [Batch 49/168] [D loss: 0.001196] [G loss: 7.603903]\n",
      "[Epoch 21/1000] [Batch 50/168] [D loss: 0.000798] [G loss: 7.576132]\n",
      "[Epoch 21/1000] [Batch 51/168] [D loss: 0.001503] [G loss: 7.534497]\n",
      "[Epoch 21/1000] [Batch 52/168] [D loss: 0.001195] [G loss: 7.372067]\n",
      "[Epoch 21/1000] [Batch 53/168] [D loss: 0.000676] [G loss: 7.699008]\n",
      "[Epoch 21/1000] [Batch 54/168] [D loss: 0.000878] [G loss: 7.532093]\n",
      "[Epoch 21/1000] [Batch 55/168] [D loss: 0.001158] [G loss: 7.543181]\n",
      "[Epoch 21/1000] [Batch 56/168] [D loss: 0.000776] [G loss: 7.583718]\n",
      "[Epoch 21/1000] [Batch 57/168] [D loss: 0.001556] [G loss: 7.504218]\n",
      "[Epoch 21/1000] [Batch 58/168] [D loss: 0.000782] [G loss: 7.509376]\n",
      "[Epoch 21/1000] [Batch 59/168] [D loss: 0.001144] [G loss: 7.668031]\n",
      "[Epoch 21/1000] [Batch 60/168] [D loss: 0.000988] [G loss: 7.462386]\n",
      "[Epoch 21/1000] [Batch 61/168] [D loss: 0.000982] [G loss: 7.650634]\n",
      "[Epoch 21/1000] [Batch 62/168] [D loss: 0.000775] [G loss: 7.813229]\n",
      "[Epoch 21/1000] [Batch 63/168] [D loss: 0.001198] [G loss: 7.730919]\n",
      "[Epoch 21/1000] [Batch 64/168] [D loss: 0.000895] [G loss: 7.826618]\n",
      "[Epoch 21/1000] [Batch 65/168] [D loss: 0.000927] [G loss: 7.583851]\n",
      "[Epoch 21/1000] [Batch 66/168] [D loss: 0.000776] [G loss: 7.598749]\n",
      "[Epoch 21/1000] [Batch 67/168] [D loss: 0.000752] [G loss: 7.696925]\n",
      "[Epoch 21/1000] [Batch 68/168] [D loss: 0.001270] [G loss: 7.455819]\n",
      "[Epoch 21/1000] [Batch 69/168] [D loss: 0.000981] [G loss: 7.821034]\n",
      "[Epoch 21/1000] [Batch 70/168] [D loss: 0.000712] [G loss: 7.586897]\n",
      "[Epoch 21/1000] [Batch 71/168] [D loss: 0.000678] [G loss: 7.640742]\n",
      "[Epoch 21/1000] [Batch 72/168] [D loss: 0.000848] [G loss: 7.406959]\n",
      "[Epoch 21/1000] [Batch 73/168] [D loss: 0.000568] [G loss: 7.688111]\n",
      "[Epoch 21/1000] [Batch 74/168] [D loss: 0.000969] [G loss: 7.771193]\n",
      "[Epoch 21/1000] [Batch 75/168] [D loss: 0.000922] [G loss: 7.841209]\n",
      "[Epoch 21/1000] [Batch 76/168] [D loss: 0.000803] [G loss: 7.548123]\n",
      "[Epoch 21/1000] [Batch 77/168] [D loss: 0.000908] [G loss: 7.597941]\n",
      "[Epoch 21/1000] [Batch 78/168] [D loss: 0.000631] [G loss: 7.632474]\n",
      "[Epoch 21/1000] [Batch 79/168] [D loss: 0.000920] [G loss: 7.755970]\n",
      "[Epoch 21/1000] [Batch 80/168] [D loss: 0.000804] [G loss: 7.658598]\n",
      "[Epoch 21/1000] [Batch 81/168] [D loss: 0.000685] [G loss: 7.892032]\n",
      "[Epoch 21/1000] [Batch 82/168] [D loss: 0.000946] [G loss: 7.787809]\n",
      "[Epoch 21/1000] [Batch 83/168] [D loss: 0.000711] [G loss: 7.793862]\n",
      "[Epoch 21/1000] [Batch 84/168] [D loss: 0.000639] [G loss: 7.835506]\n",
      "[Epoch 21/1000] [Batch 85/168] [D loss: 0.000832] [G loss: 7.795431]\n",
      "[Epoch 21/1000] [Batch 86/168] [D loss: 0.001365] [G loss: 8.046352]\n",
      "[Epoch 21/1000] [Batch 87/168] [D loss: 0.000850] [G loss: 7.409083]\n",
      "[Epoch 21/1000] [Batch 88/168] [D loss: 0.000766] [G loss: 7.701180]\n",
      "[Epoch 21/1000] [Batch 89/168] [D loss: 0.001347] [G loss: 7.742263]\n",
      "[Epoch 21/1000] [Batch 90/168] [D loss: 0.000947] [G loss: 7.437579]\n",
      "[Epoch 21/1000] [Batch 91/168] [D loss: 0.000699] [G loss: 7.340987]\n",
      "[Epoch 21/1000] [Batch 92/168] [D loss: 0.000701] [G loss: 7.821290]\n",
      "[Epoch 21/1000] [Batch 93/168] [D loss: 0.000906] [G loss: 7.704448]\n",
      "[Epoch 21/1000] [Batch 94/168] [D loss: 0.000637] [G loss: 7.778109]\n",
      "[Epoch 21/1000] [Batch 95/168] [D loss: 0.001090] [G loss: 7.762272]\n",
      "[Epoch 21/1000] [Batch 96/168] [D loss: 0.000834] [G loss: 8.004453]\n",
      "[Epoch 21/1000] [Batch 97/168] [D loss: 0.000836] [G loss: 7.678540]\n",
      "[Epoch 21/1000] [Batch 98/168] [D loss: 0.000963] [G loss: 7.566397]\n",
      "[Epoch 21/1000] [Batch 99/168] [D loss: 0.001722] [G loss: 7.496491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/1000] [Batch 100/168] [D loss: 0.001066] [G loss: 7.322432]\n",
      "[Epoch 21/1000] [Batch 101/168] [D loss: 0.000871] [G loss: 7.422111]\n",
      "[Epoch 21/1000] [Batch 102/168] [D loss: 0.001136] [G loss: 7.418283]\n",
      "[Epoch 21/1000] [Batch 103/168] [D loss: 0.000860] [G loss: 7.509531]\n",
      "[Epoch 21/1000] [Batch 104/168] [D loss: 0.000914] [G loss: 7.533864]\n",
      "[Epoch 21/1000] [Batch 105/168] [D loss: 0.001060] [G loss: 7.462153]\n",
      "[Epoch 21/1000] [Batch 106/168] [D loss: 0.000768] [G loss: 7.723118]\n",
      "[Epoch 21/1000] [Batch 107/168] [D loss: 0.000891] [G loss: 7.484191]\n",
      "[Epoch 21/1000] [Batch 108/168] [D loss: 0.001175] [G loss: 7.645695]\n",
      "[Epoch 21/1000] [Batch 109/168] [D loss: 0.000642] [G loss: 7.719321]\n",
      "[Epoch 21/1000] [Batch 110/168] [D loss: 0.000702] [G loss: 7.898541]\n",
      "[Epoch 21/1000] [Batch 111/168] [D loss: 0.002007] [G loss: 7.960292]\n",
      "[Epoch 21/1000] [Batch 112/168] [D loss: 0.000915] [G loss: 7.685674]\n",
      "[Epoch 21/1000] [Batch 113/168] [D loss: 0.001265] [G loss: 7.455607]\n",
      "[Epoch 21/1000] [Batch 114/168] [D loss: 0.000989] [G loss: 7.582435]\n",
      "[Epoch 21/1000] [Batch 115/168] [D loss: 0.001387] [G loss: 7.461263]\n",
      "[Epoch 21/1000] [Batch 116/168] [D loss: 0.001077] [G loss: 7.458054]\n",
      "[Epoch 21/1000] [Batch 117/168] [D loss: 0.000779] [G loss: 7.612283]\n",
      "[Epoch 21/1000] [Batch 118/168] [D loss: 0.000721] [G loss: 7.488337]\n",
      "[Epoch 21/1000] [Batch 119/168] [D loss: 0.001250] [G loss: 7.659713]\n",
      "[Epoch 21/1000] [Batch 120/168] [D loss: 0.000882] [G loss: 7.353748]\n",
      "[Epoch 21/1000] [Batch 121/168] [D loss: 0.000861] [G loss: 7.603988]\n",
      "[Epoch 21/1000] [Batch 122/168] [D loss: 0.000967] [G loss: 7.463220]\n",
      "[Epoch 21/1000] [Batch 123/168] [D loss: 0.000757] [G loss: 7.758050]\n",
      "[Epoch 21/1000] [Batch 124/168] [D loss: 0.001225] [G loss: 7.648855]\n",
      "[Epoch 21/1000] [Batch 125/168] [D loss: 0.000997] [G loss: 7.559388]\n",
      "[Epoch 21/1000] [Batch 126/168] [D loss: 0.001127] [G loss: 7.457901]\n",
      "[Epoch 21/1000] [Batch 127/168] [D loss: 0.000967] [G loss: 7.770382]\n",
      "[Epoch 21/1000] [Batch 128/168] [D loss: 0.002114] [G loss: 7.459160]\n",
      "[Epoch 21/1000] [Batch 129/168] [D loss: 0.000964] [G loss: 7.439526]\n",
      "[Epoch 21/1000] [Batch 130/168] [D loss: 0.001301] [G loss: 7.180230]\n",
      "[Epoch 21/1000] [Batch 131/168] [D loss: 0.001324] [G loss: 7.002937]\n",
      "[Epoch 21/1000] [Batch 132/168] [D loss: 0.001018] [G loss: 7.516253]\n",
      "[Epoch 21/1000] [Batch 133/168] [D loss: 0.000706] [G loss: 7.618287]\n",
      "[Epoch 21/1000] [Batch 134/168] [D loss: 0.001036] [G loss: 7.743225]\n",
      "[Epoch 21/1000] [Batch 135/168] [D loss: 0.000892] [G loss: 7.778206]\n",
      "[Epoch 21/1000] [Batch 136/168] [D loss: 0.001209] [G loss: 7.612024]\n",
      "[Epoch 21/1000] [Batch 137/168] [D loss: 0.001007] [G loss: 7.520773]\n",
      "[Epoch 21/1000] [Batch 138/168] [D loss: 0.000816] [G loss: 7.345658]\n",
      "[Epoch 21/1000] [Batch 139/168] [D loss: 0.001197] [G loss: 7.249402]\n",
      "[Epoch 21/1000] [Batch 140/168] [D loss: 0.001032] [G loss: 7.508335]\n",
      "[Epoch 21/1000] [Batch 141/168] [D loss: 0.000681] [G loss: 7.812196]\n",
      "[Epoch 21/1000] [Batch 142/168] [D loss: 0.001104] [G loss: 7.504551]\n",
      "[Epoch 21/1000] [Batch 143/168] [D loss: 0.000938] [G loss: 7.716572]\n",
      "[Epoch 21/1000] [Batch 144/168] [D loss: 0.000612] [G loss: 7.762589]\n",
      "[Epoch 21/1000] [Batch 145/168] [D loss: 0.000850] [G loss: 7.820024]\n",
      "[Epoch 21/1000] [Batch 146/168] [D loss: 0.001037] [G loss: 7.468473]\n",
      "[Epoch 21/1000] [Batch 147/168] [D loss: 0.001105] [G loss: 7.520685]\n",
      "[Epoch 21/1000] [Batch 148/168] [D loss: 0.001189] [G loss: 7.638195]\n",
      "[Epoch 21/1000] [Batch 149/168] [D loss: 0.000877] [G loss: 7.762730]\n",
      "[Epoch 21/1000] [Batch 150/168] [D loss: 0.001298] [G loss: 7.392025]\n",
      "[Epoch 21/1000] [Batch 151/168] [D loss: 0.000968] [G loss: 7.497107]\n",
      "[Epoch 21/1000] [Batch 152/168] [D loss: 0.001266] [G loss: 7.203004]\n",
      "[Epoch 21/1000] [Batch 153/168] [D loss: 0.000930] [G loss: 7.478090]\n",
      "[Epoch 21/1000] [Batch 154/168] [D loss: 0.000994] [G loss: 7.563991]\n",
      "[Epoch 21/1000] [Batch 155/168] [D loss: 0.001055] [G loss: 7.397069]\n",
      "[Epoch 21/1000] [Batch 156/168] [D loss: 0.001072] [G loss: 7.459231]\n",
      "[Epoch 21/1000] [Batch 157/168] [D loss: 0.000940] [G loss: 7.609990]\n",
      "[Epoch 21/1000] [Batch 158/168] [D loss: 0.001133] [G loss: 7.388507]\n",
      "[Epoch 21/1000] [Batch 159/168] [D loss: 0.001455] [G loss: 7.742652]\n",
      "[Epoch 21/1000] [Batch 160/168] [D loss: 0.001432] [G loss: 7.147257]\n",
      "[Epoch 21/1000] [Batch 161/168] [D loss: 0.001304] [G loss: 7.457528]\n",
      "[Epoch 21/1000] [Batch 162/168] [D loss: 0.001221] [G loss: 7.421790]\n",
      "[Epoch 21/1000] [Batch 163/168] [D loss: 0.000800] [G loss: 7.368416]\n",
      "[Epoch 21/1000] [Batch 164/168] [D loss: 0.000917] [G loss: 7.548233]\n",
      "[Epoch 21/1000] [Batch 165/168] [D loss: 0.000988] [G loss: 7.381835]\n",
      "[Epoch 21/1000] [Batch 166/168] [D loss: 0.000863] [G loss: 7.509739]\n",
      "[Epoch 21/1000] [Batch 167/168] [D loss: 0.001357] [G loss: 7.240039]\n",
      "[Epoch 21/1000] [Batch 168/168] [D loss: 0.001757] [G loss: 7.541980]\n",
      "[Epoch 22/1000] [Batch 1/168] [D loss: 0.000818] [G loss: 7.370087]\n",
      "[Epoch 22/1000] [Batch 2/168] [D loss: 0.001094] [G loss: 7.260304]\n",
      "[Epoch 22/1000] [Batch 3/168] [D loss: 0.001384] [G loss: 7.382699]\n",
      "[Epoch 22/1000] [Batch 4/168] [D loss: 0.001373] [G loss: 7.514588]\n",
      "[Epoch 22/1000] [Batch 5/168] [D loss: 0.001641] [G loss: 7.495563]\n",
      "[Epoch 22/1000] [Batch 6/168] [D loss: 0.000792] [G loss: 7.504671]\n",
      "[Epoch 22/1000] [Batch 7/168] [D loss: 0.001038] [G loss: 7.313646]\n",
      "[Epoch 22/1000] [Batch 8/168] [D loss: 0.001099] [G loss: 7.290751]\n",
      "[Epoch 22/1000] [Batch 9/168] [D loss: 0.001045] [G loss: 7.511262]\n",
      "[Epoch 22/1000] [Batch 10/168] [D loss: 0.000905] [G loss: 7.492468]\n",
      "[Epoch 22/1000] [Batch 11/168] [D loss: 0.000996] [G loss: 7.693545]\n",
      "[Epoch 22/1000] [Batch 12/168] [D loss: 0.000970] [G loss: 7.415802]\n",
      "[Epoch 22/1000] [Batch 13/168] [D loss: 0.001083] [G loss: 7.460959]\n",
      "[Epoch 22/1000] [Batch 14/168] [D loss: 0.001042] [G loss: 7.749220]\n",
      "[Epoch 22/1000] [Batch 15/168] [D loss: 0.001577] [G loss: 7.680638]\n",
      "[Epoch 22/1000] [Batch 16/168] [D loss: 0.000685] [G loss: 7.751649]\n",
      "[Epoch 22/1000] [Batch 17/168] [D loss: 0.000864] [G loss: 7.285490]\n",
      "[Epoch 22/1000] [Batch 18/168] [D loss: 0.001014] [G loss: 7.346838]\n",
      "[Epoch 22/1000] [Batch 19/168] [D loss: 0.000995] [G loss: 7.388293]\n",
      "[Epoch 22/1000] [Batch 20/168] [D loss: 0.000869] [G loss: 7.266567]\n",
      "[Epoch 22/1000] [Batch 21/168] [D loss: 0.000829] [G loss: 7.464929]\n",
      "[Epoch 22/1000] [Batch 22/168] [D loss: 0.001098] [G loss: 7.785735]\n",
      "[Epoch 22/1000] [Batch 23/168] [D loss: 0.000896] [G loss: 7.522985]\n",
      "[Epoch 22/1000] [Batch 24/168] [D loss: 0.000919] [G loss: 7.739512]\n",
      "[Epoch 22/1000] [Batch 25/168] [D loss: 0.000664] [G loss: 7.530431]\n",
      "[Epoch 22/1000] [Batch 26/168] [D loss: 0.000850] [G loss: 7.576598]\n",
      "[Epoch 22/1000] [Batch 27/168] [D loss: 0.000878] [G loss: 7.789024]\n",
      "[Epoch 22/1000] [Batch 28/168] [D loss: 0.000761] [G loss: 7.560540]\n",
      "[Epoch 22/1000] [Batch 29/168] [D loss: 0.000863] [G loss: 7.866663]\n",
      "[Epoch 22/1000] [Batch 30/168] [D loss: 0.000981] [G loss: 7.569457]\n",
      "[Epoch 22/1000] [Batch 31/168] [D loss: 0.000723] [G loss: 7.536251]\n",
      "[Epoch 22/1000] [Batch 32/168] [D loss: 0.000833] [G loss: 7.803229]\n",
      "[Epoch 22/1000] [Batch 33/168] [D loss: 0.000774] [G loss: 7.902692]\n",
      "[Epoch 22/1000] [Batch 34/168] [D loss: 0.001169] [G loss: 7.658399]\n",
      "[Epoch 22/1000] [Batch 35/168] [D loss: 0.001078] [G loss: 7.538448]\n",
      "[Epoch 22/1000] [Batch 36/168] [D loss: 0.000758] [G loss: 7.632649]\n",
      "[Epoch 22/1000] [Batch 37/168] [D loss: 0.001130] [G loss: 7.569643]\n",
      "[Epoch 22/1000] [Batch 38/168] [D loss: 0.001143] [G loss: 7.340330]\n",
      "[Epoch 22/1000] [Batch 39/168] [D loss: 0.001098] [G loss: 7.290330]\n",
      "[Epoch 22/1000] [Batch 40/168] [D loss: 0.001206] [G loss: 7.161986]\n",
      "[Epoch 22/1000] [Batch 41/168] [D loss: 0.000833] [G loss: 7.565113]\n",
      "[Epoch 22/1000] [Batch 42/168] [D loss: 0.001777] [G loss: 7.547690]\n",
      "[Epoch 22/1000] [Batch 43/168] [D loss: 0.001366] [G loss: 7.514956]\n",
      "[Epoch 22/1000] [Batch 44/168] [D loss: 0.000853] [G loss: 7.241892]\n",
      "[Epoch 22/1000] [Batch 45/168] [D loss: 0.001034] [G loss: 7.292377]\n",
      "[Epoch 22/1000] [Batch 46/168] [D loss: 0.000853] [G loss: 7.495253]\n",
      "[Epoch 22/1000] [Batch 47/168] [D loss: 0.000684] [G loss: 7.798453]\n",
      "[Epoch 22/1000] [Batch 48/168] [D loss: 0.001228] [G loss: 7.583169]\n",
      "[Epoch 22/1000] [Batch 49/168] [D loss: 0.001123] [G loss: 7.570221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/1000] [Batch 50/168] [D loss: 0.000862] [G loss: 7.579418]\n",
      "[Epoch 22/1000] [Batch 51/168] [D loss: 0.000832] [G loss: 7.728752]\n",
      "[Epoch 22/1000] [Batch 52/168] [D loss: 0.001028] [G loss: 7.515265]\n",
      "[Epoch 22/1000] [Batch 53/168] [D loss: 0.001418] [G loss: 7.363529]\n",
      "[Epoch 22/1000] [Batch 54/168] [D loss: 0.002071] [G loss: 7.449423]\n",
      "[Epoch 22/1000] [Batch 55/168] [D loss: 0.000916] [G loss: 7.501912]\n",
      "[Epoch 22/1000] [Batch 56/168] [D loss: 0.001095] [G loss: 7.086762]\n",
      "[Epoch 22/1000] [Batch 57/168] [D loss: 0.000871] [G loss: 7.414865]\n",
      "[Epoch 22/1000] [Batch 58/168] [D loss: 0.001135] [G loss: 7.594478]\n",
      "[Epoch 22/1000] [Batch 59/168] [D loss: 0.000878] [G loss: 7.554360]\n",
      "[Epoch 22/1000] [Batch 60/168] [D loss: 0.000758] [G loss: 7.544367]\n",
      "[Epoch 22/1000] [Batch 61/168] [D loss: 0.000737] [G loss: 7.431659]\n",
      "[Epoch 22/1000] [Batch 62/168] [D loss: 0.000894] [G loss: 7.552835]\n",
      "[Epoch 22/1000] [Batch 63/168] [D loss: 0.001436] [G loss: 7.447093]\n",
      "[Epoch 22/1000] [Batch 64/168] [D loss: 0.000707] [G loss: 7.656660]\n",
      "[Epoch 22/1000] [Batch 65/168] [D loss: 0.000867] [G loss: 7.625062]\n",
      "[Epoch 22/1000] [Batch 66/168] [D loss: 0.000776] [G loss: 7.614107]\n",
      "[Epoch 22/1000] [Batch 67/168] [D loss: 0.000868] [G loss: 7.715059]\n",
      "[Epoch 22/1000] [Batch 68/168] [D loss: 0.000716] [G loss: 7.531539]\n",
      "[Epoch 22/1000] [Batch 69/168] [D loss: 0.000992] [G loss: 7.421661]\n",
      "[Epoch 22/1000] [Batch 70/168] [D loss: 0.000665] [G loss: 7.700566]\n",
      "[Epoch 22/1000] [Batch 71/168] [D loss: 0.001415] [G loss: 7.650414]\n",
      "[Epoch 22/1000] [Batch 72/168] [D loss: 0.000784] [G loss: 7.760034]\n",
      "[Epoch 22/1000] [Batch 73/168] [D loss: 0.001167] [G loss: 7.712066]\n",
      "[Epoch 22/1000] [Batch 74/168] [D loss: 0.000822] [G loss: 7.472243]\n",
      "[Epoch 22/1000] [Batch 75/168] [D loss: 0.001583] [G loss: 7.642036]\n",
      "[Epoch 22/1000] [Batch 76/168] [D loss: 0.001355] [G loss: 7.351904]\n",
      "[Epoch 22/1000] [Batch 77/168] [D loss: 0.000865] [G loss: 7.299791]\n",
      "[Epoch 22/1000] [Batch 78/168] [D loss: 0.000783] [G loss: 7.501139]\n",
      "[Epoch 22/1000] [Batch 79/168] [D loss: 0.000746] [G loss: 7.657191]\n",
      "[Epoch 22/1000] [Batch 80/168] [D loss: 0.000909] [G loss: 7.333801]\n",
      "[Epoch 22/1000] [Batch 81/168] [D loss: 0.001021] [G loss: 7.622210]\n",
      "[Epoch 22/1000] [Batch 82/168] [D loss: 0.001192] [G loss: 7.415469]\n",
      "[Epoch 22/1000] [Batch 83/168] [D loss: 0.000899] [G loss: 7.697451]\n",
      "[Epoch 22/1000] [Batch 84/168] [D loss: 0.000611] [G loss: 7.650650]\n",
      "[Epoch 22/1000] [Batch 85/168] [D loss: 0.000907] [G loss: 7.646795]\n",
      "[Epoch 22/1000] [Batch 86/168] [D loss: 0.000749] [G loss: 7.704382]\n",
      "[Epoch 22/1000] [Batch 87/168] [D loss: 0.000836] [G loss: 7.765358]\n",
      "[Epoch 22/1000] [Batch 88/168] [D loss: 0.000679] [G loss: 8.048166]\n",
      "[Epoch 22/1000] [Batch 89/168] [D loss: 0.000833] [G loss: 7.712961]\n",
      "[Epoch 22/1000] [Batch 90/168] [D loss: 0.001349] [G loss: 7.747964]\n",
      "[Epoch 22/1000] [Batch 91/168] [D loss: 0.000919] [G loss: 7.508564]\n",
      "[Epoch 22/1000] [Batch 92/168] [D loss: 0.001328] [G loss: 7.557440]\n",
      "[Epoch 22/1000] [Batch 93/168] [D loss: 0.000901] [G loss: 7.699508]\n",
      "[Epoch 22/1000] [Batch 94/168] [D loss: 0.000732] [G loss: 7.654472]\n",
      "[Epoch 22/1000] [Batch 95/168] [D loss: 0.000794] [G loss: 7.757439]\n",
      "[Epoch 22/1000] [Batch 96/168] [D loss: 0.000716] [G loss: 7.580783]\n",
      "[Epoch 22/1000] [Batch 97/168] [D loss: 0.000757] [G loss: 7.728638]\n",
      "[Epoch 22/1000] [Batch 98/168] [D loss: 0.000609] [G loss: 7.773779]\n",
      "[Epoch 22/1000] [Batch 99/168] [D loss: 0.000680] [G loss: 7.777063]\n",
      "[Epoch 22/1000] [Batch 100/168] [D loss: 0.000757] [G loss: 7.804727]\n",
      "[Epoch 22/1000] [Batch 101/168] [D loss: 0.001262] [G loss: 7.844959]\n",
      "[Epoch 22/1000] [Batch 102/168] [D loss: 0.000967] [G loss: 7.480669]\n",
      "[Epoch 22/1000] [Batch 103/168] [D loss: 0.001012] [G loss: 7.777923]\n",
      "[Epoch 22/1000] [Batch 104/168] [D loss: 0.001066] [G loss: 7.621249]\n",
      "[Epoch 22/1000] [Batch 105/168] [D loss: 0.002313] [G loss: 7.332850]\n",
      "[Epoch 22/1000] [Batch 106/168] [D loss: 0.000850] [G loss: 7.325866]\n",
      "[Epoch 22/1000] [Batch 107/168] [D loss: 0.001166] [G loss: 7.146063]\n",
      "[Epoch 22/1000] [Batch 108/168] [D loss: 0.000971] [G loss: 7.181274]\n",
      "[Epoch 22/1000] [Batch 109/168] [D loss: 0.001040] [G loss: 7.265552]\n",
      "[Epoch 22/1000] [Batch 110/168] [D loss: 0.000784] [G loss: 7.765363]\n",
      "[Epoch 22/1000] [Batch 111/168] [D loss: 0.000995] [G loss: 7.730819]\n",
      "[Epoch 22/1000] [Batch 112/168] [D loss: 0.001013] [G loss: 7.383377]\n",
      "[Epoch 22/1000] [Batch 113/168] [D loss: 0.000863] [G loss: 7.765566]\n",
      "[Epoch 22/1000] [Batch 114/168] [D loss: 0.000876] [G loss: 7.760988]\n",
      "[Epoch 22/1000] [Batch 115/168] [D loss: 0.001897] [G loss: 7.744141]\n",
      "[Epoch 22/1000] [Batch 116/168] [D loss: 0.000620] [G loss: 7.736548]\n",
      "[Epoch 22/1000] [Batch 117/168] [D loss: 0.001095] [G loss: 7.658200]\n",
      "[Epoch 22/1000] [Batch 118/168] [D loss: 0.000895] [G loss: 7.734696]\n",
      "[Epoch 22/1000] [Batch 119/168] [D loss: 0.000873] [G loss: 7.683705]\n",
      "[Epoch 22/1000] [Batch 120/168] [D loss: 0.000952] [G loss: 7.464850]\n",
      "[Epoch 22/1000] [Batch 121/168] [D loss: 0.000701] [G loss: 7.712129]\n",
      "[Epoch 22/1000] [Batch 122/168] [D loss: 0.000886] [G loss: 7.723366]\n",
      "[Epoch 22/1000] [Batch 123/168] [D loss: 0.001482] [G loss: 7.727280]\n",
      "[Epoch 22/1000] [Batch 124/168] [D loss: 0.000577] [G loss: 7.616541]\n",
      "[Epoch 22/1000] [Batch 125/168] [D loss: 0.000711] [G loss: 7.683958]\n",
      "[Epoch 22/1000] [Batch 126/168] [D loss: 0.000673] [G loss: 7.642715]\n",
      "[Epoch 22/1000] [Batch 127/168] [D loss: 0.000967] [G loss: 7.578018]\n",
      "[Epoch 22/1000] [Batch 128/168] [D loss: 0.000658] [G loss: 7.586863]\n",
      "[Epoch 22/1000] [Batch 129/168] [D loss: 0.000910] [G loss: 7.610693]\n",
      "[Epoch 22/1000] [Batch 130/168] [D loss: 0.000678] [G loss: 7.853726]\n",
      "[Epoch 22/1000] [Batch 131/168] [D loss: 0.001008] [G loss: 7.734200]\n",
      "[Epoch 22/1000] [Batch 132/168] [D loss: 0.000976] [G loss: 7.808820]\n",
      "[Epoch 22/1000] [Batch 133/168] [D loss: 0.000748] [G loss: 7.650589]\n",
      "[Epoch 22/1000] [Batch 134/168] [D loss: 0.000615] [G loss: 7.834720]\n",
      "[Epoch 22/1000] [Batch 135/168] [D loss: 0.000703] [G loss: 7.701475]\n",
      "[Epoch 22/1000] [Batch 136/168] [D loss: 0.000857] [G loss: 7.608254]\n",
      "[Epoch 22/1000] [Batch 137/168] [D loss: 0.000614] [G loss: 8.008285]\n",
      "[Epoch 22/1000] [Batch 138/168] [D loss: 0.000855] [G loss: 7.722741]\n",
      "[Epoch 22/1000] [Batch 139/168] [D loss: 0.000785] [G loss: 7.820984]\n",
      "[Epoch 22/1000] [Batch 140/168] [D loss: 0.000694] [G loss: 7.750576]\n",
      "[Epoch 22/1000] [Batch 141/168] [D loss: 0.001077] [G loss: 7.912471]\n",
      "[Epoch 22/1000] [Batch 142/168] [D loss: 0.000882] [G loss: 7.743440]\n",
      "[Epoch 22/1000] [Batch 143/168] [D loss: 0.000999] [G loss: 7.539246]\n",
      "[Epoch 22/1000] [Batch 144/168] [D loss: 0.001132] [G loss: 7.695914]\n",
      "[Epoch 22/1000] [Batch 145/168] [D loss: 0.000954] [G loss: 7.324816]\n",
      "[Epoch 22/1000] [Batch 146/168] [D loss: 0.000922] [G loss: 7.613538]\n",
      "[Epoch 22/1000] [Batch 147/168] [D loss: 0.000828] [G loss: 7.590602]\n",
      "[Epoch 22/1000] [Batch 148/168] [D loss: 0.000844] [G loss: 7.829401]\n",
      "[Epoch 22/1000] [Batch 149/168] [D loss: 0.000832] [G loss: 7.522631]\n",
      "[Epoch 22/1000] [Batch 150/168] [D loss: 0.000753] [G loss: 7.714475]\n",
      "[Epoch 22/1000] [Batch 151/168] [D loss: 0.000879] [G loss: 7.413092]\n",
      "[Epoch 22/1000] [Batch 152/168] [D loss: 0.000749] [G loss: 7.802641]\n",
      "[Epoch 22/1000] [Batch 153/168] [D loss: 0.000983] [G loss: 7.835897]\n",
      "[Epoch 22/1000] [Batch 154/168] [D loss: 0.001013] [G loss: 7.577044]\n",
      "[Epoch 22/1000] [Batch 155/168] [D loss: 0.000681] [G loss: 7.735137]\n",
      "[Epoch 22/1000] [Batch 156/168] [D loss: 0.000990] [G loss: 7.602504]\n",
      "[Epoch 22/1000] [Batch 157/168] [D loss: 0.000564] [G loss: 7.589745]\n",
      "[Epoch 22/1000] [Batch 158/168] [D loss: 0.000781] [G loss: 7.567750]\n",
      "[Epoch 22/1000] [Batch 159/168] [D loss: 0.000753] [G loss: 7.920312]\n",
      "[Epoch 22/1000] [Batch 160/168] [D loss: 0.000778] [G loss: 8.012624]\n",
      "[Epoch 22/1000] [Batch 161/168] [D loss: 0.000739] [G loss: 7.767107]\n",
      "[Epoch 22/1000] [Batch 162/168] [D loss: 0.000769] [G loss: 7.810271]\n",
      "[Epoch 22/1000] [Batch 163/168] [D loss: 0.001015] [G loss: 7.574254]\n",
      "[Epoch 22/1000] [Batch 164/168] [D loss: 0.000918] [G loss: 7.698151]\n",
      "[Epoch 22/1000] [Batch 165/168] [D loss: 0.000951] [G loss: 7.477794]\n",
      "[Epoch 22/1000] [Batch 166/168] [D loss: 0.000916] [G loss: 7.638966]\n",
      "[Epoch 22/1000] [Batch 167/168] [D loss: 0.001052] [G loss: 7.537146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/1000] [Batch 168/168] [D loss: 0.000774] [G loss: 7.895748]\n",
      "[Epoch 23/1000] [Batch 1/168] [D loss: 0.001232] [G loss: 7.942709]\n",
      "[Epoch 23/1000] [Batch 2/168] [D loss: 0.001079] [G loss: 7.608705]\n",
      "[Epoch 23/1000] [Batch 3/168] [D loss: 0.000706] [G loss: 7.893483]\n",
      "[Epoch 23/1000] [Batch 4/168] [D loss: 0.000676] [G loss: 7.973475]\n",
      "[Epoch 23/1000] [Batch 5/168] [D loss: 0.000633] [G loss: 7.735377]\n",
      "[Epoch 23/1000] [Batch 6/168] [D loss: 0.000547] [G loss: 7.913360]\n",
      "[Epoch 23/1000] [Batch 7/168] [D loss: 0.000681] [G loss: 7.800906]\n",
      "[Epoch 23/1000] [Batch 8/168] [D loss: 0.000633] [G loss: 7.831083]\n",
      "[Epoch 23/1000] [Batch 9/168] [D loss: 0.000518] [G loss: 8.083267]\n",
      "[Epoch 23/1000] [Batch 10/168] [D loss: 0.000844] [G loss: 8.242735]\n",
      "[Epoch 23/1000] [Batch 11/168] [D loss: 0.000618] [G loss: 7.949733]\n",
      "[Epoch 23/1000] [Batch 12/168] [D loss: 0.000863] [G loss: 7.920946]\n",
      "[Epoch 23/1000] [Batch 13/168] [D loss: 0.000774] [G loss: 7.779368]\n",
      "[Epoch 23/1000] [Batch 14/168] [D loss: 0.001131] [G loss: 7.660454]\n",
      "[Epoch 23/1000] [Batch 15/168] [D loss: 0.001050] [G loss: 7.722738]\n",
      "[Epoch 23/1000] [Batch 16/168] [D loss: 0.000795] [G loss: 7.730500]\n",
      "[Epoch 23/1000] [Batch 17/168] [D loss: 0.000740] [G loss: 7.721637]\n",
      "[Epoch 23/1000] [Batch 18/168] [D loss: 0.000594] [G loss: 8.166128]\n",
      "[Epoch 23/1000] [Batch 19/168] [D loss: 0.001087] [G loss: 7.605296]\n",
      "[Epoch 23/1000] [Batch 20/168] [D loss: 0.000752] [G loss: 7.792314]\n",
      "[Epoch 23/1000] [Batch 21/168] [D loss: 0.000771] [G loss: 8.001053]\n",
      "[Epoch 23/1000] [Batch 22/168] [D loss: 0.000573] [G loss: 8.040883]\n",
      "[Epoch 23/1000] [Batch 23/168] [D loss: 0.000754] [G loss: 7.764558]\n",
      "[Epoch 23/1000] [Batch 24/168] [D loss: 0.000802] [G loss: 7.758391]\n",
      "[Epoch 23/1000] [Batch 25/168] [D loss: 0.000567] [G loss: 7.847783]\n",
      "[Epoch 23/1000] [Batch 26/168] [D loss: 0.000806] [G loss: 7.798949]\n",
      "[Epoch 23/1000] [Batch 27/168] [D loss: 0.000627] [G loss: 7.840203]\n",
      "[Epoch 23/1000] [Batch 28/168] [D loss: 0.000825] [G loss: 7.691042]\n",
      "[Epoch 23/1000] [Batch 29/168] [D loss: 0.000724] [G loss: 7.824150]\n",
      "[Epoch 23/1000] [Batch 30/168] [D loss: 0.000770] [G loss: 7.931049]\n",
      "[Epoch 23/1000] [Batch 31/168] [D loss: 0.001117] [G loss: 8.059767]\n",
      "[Epoch 23/1000] [Batch 32/168] [D loss: 0.000717] [G loss: 7.731131]\n",
      "[Epoch 23/1000] [Batch 33/168] [D loss: 0.000760] [G loss: 7.679241]\n",
      "[Epoch 23/1000] [Batch 34/168] [D loss: 0.000701] [G loss: 7.650227]\n",
      "[Epoch 23/1000] [Batch 35/168] [D loss: 0.000770] [G loss: 7.807769]\n",
      "[Epoch 23/1000] [Batch 36/168] [D loss: 0.000637] [G loss: 7.982713]\n",
      "[Epoch 23/1000] [Batch 37/168] [D loss: 0.000678] [G loss: 7.950946]\n",
      "[Epoch 23/1000] [Batch 38/168] [D loss: 0.000750] [G loss: 7.817088]\n",
      "[Epoch 23/1000] [Batch 39/168] [D loss: 0.000817] [G loss: 7.748015]\n",
      "[Epoch 23/1000] [Batch 40/168] [D loss: 0.000854] [G loss: 7.819174]\n",
      "[Epoch 23/1000] [Batch 41/168] [D loss: 0.000825] [G loss: 7.574790]\n",
      "[Epoch 23/1000] [Batch 42/168] [D loss: 0.001050] [G loss: 7.996330]\n",
      "[Epoch 23/1000] [Batch 43/168] [D loss: 0.000967] [G loss: 7.973152]\n",
      "[Epoch 23/1000] [Batch 44/168] [D loss: 0.000982] [G loss: 7.585670]\n",
      "[Epoch 23/1000] [Batch 45/168] [D loss: 0.000867] [G loss: 7.662946]\n",
      "[Epoch 23/1000] [Batch 46/168] [D loss: 0.000879] [G loss: 7.487871]\n",
      "[Epoch 23/1000] [Batch 47/168] [D loss: 0.000909] [G loss: 7.561598]\n",
      "[Epoch 23/1000] [Batch 48/168] [D loss: 0.000850] [G loss: 7.898993]\n",
      "[Epoch 23/1000] [Batch 49/168] [D loss: 0.000760] [G loss: 7.594178]\n",
      "[Epoch 23/1000] [Batch 50/168] [D loss: 0.000953] [G loss: 7.674578]\n",
      "[Epoch 23/1000] [Batch 51/168] [D loss: 0.000972] [G loss: 7.892803]\n",
      "[Epoch 23/1000] [Batch 52/168] [D loss: 0.000843] [G loss: 7.602692]\n",
      "[Epoch 23/1000] [Batch 53/168] [D loss: 0.000989] [G loss: 7.756163]\n",
      "[Epoch 23/1000] [Batch 54/168] [D loss: 0.000710] [G loss: 7.922366]\n",
      "[Epoch 23/1000] [Batch 55/168] [D loss: 0.000790] [G loss: 7.975256]\n",
      "[Epoch 23/1000] [Batch 56/168] [D loss: 0.000682] [G loss: 7.564297]\n",
      "[Epoch 23/1000] [Batch 57/168] [D loss: 0.000835] [G loss: 7.857568]\n",
      "[Epoch 23/1000] [Batch 58/168] [D loss: 0.000632] [G loss: 7.672088]\n",
      "[Epoch 23/1000] [Batch 59/168] [D loss: 0.000816] [G loss: 7.905879]\n",
      "[Epoch 23/1000] [Batch 60/168] [D loss: 0.000942] [G loss: 7.906718]\n",
      "[Epoch 23/1000] [Batch 61/168] [D loss: 0.000769] [G loss: 7.888145]\n",
      "[Epoch 23/1000] [Batch 62/168] [D loss: 0.000848] [G loss: 7.679588]\n",
      "[Epoch 23/1000] [Batch 63/168] [D loss: 0.000731] [G loss: 7.705693]\n",
      "[Epoch 23/1000] [Batch 64/168] [D loss: 0.000663] [G loss: 7.640998]\n",
      "[Epoch 23/1000] [Batch 65/168] [D loss: 0.000685] [G loss: 7.758565]\n",
      "[Epoch 23/1000] [Batch 66/168] [D loss: 0.000882] [G loss: 7.705564]\n",
      "[Epoch 23/1000] [Batch 67/168] [D loss: 0.000648] [G loss: 7.926991]\n",
      "[Epoch 23/1000] [Batch 68/168] [D loss: 0.001410] [G loss: 7.912663]\n",
      "[Epoch 23/1000] [Batch 69/168] [D loss: 0.001131] [G loss: 7.706228]\n",
      "[Epoch 23/1000] [Batch 70/168] [D loss: 0.000771] [G loss: 7.640999]\n",
      "[Epoch 23/1000] [Batch 71/168] [D loss: 0.000980] [G loss: 7.396451]\n",
      "[Epoch 23/1000] [Batch 72/168] [D loss: 0.001124] [G loss: 7.702615]\n",
      "[Epoch 23/1000] [Batch 73/168] [D loss: 0.000862] [G loss: 7.713812]\n",
      "[Epoch 23/1000] [Batch 74/168] [D loss: 0.000924] [G loss: 7.766811]\n",
      "[Epoch 23/1000] [Batch 75/168] [D loss: 0.000991] [G loss: 7.832610]\n",
      "[Epoch 23/1000] [Batch 76/168] [D loss: 0.000720] [G loss: 7.930470]\n",
      "[Epoch 23/1000] [Batch 77/168] [D loss: 0.000726] [G loss: 7.567187]\n",
      "[Epoch 23/1000] [Batch 78/168] [D loss: 0.000618] [G loss: 7.903020]\n",
      "[Epoch 23/1000] [Batch 79/168] [D loss: 0.000610] [G loss: 8.106177]\n",
      "[Epoch 23/1000] [Batch 80/168] [D loss: 0.000782] [G loss: 8.008916]\n",
      "[Epoch 23/1000] [Batch 81/168] [D loss: 0.001111] [G loss: 7.979950]\n",
      "[Epoch 23/1000] [Batch 82/168] [D loss: 0.000789] [G loss: 7.754726]\n",
      "[Epoch 23/1000] [Batch 83/168] [D loss: 0.000849] [G loss: 7.436618]\n",
      "[Epoch 23/1000] [Batch 84/168] [D loss: 0.001129] [G loss: 7.614440]\n",
      "[Epoch 23/1000] [Batch 85/168] [D loss: 0.000708] [G loss: 7.794959]\n",
      "[Epoch 23/1000] [Batch 86/168] [D loss: 0.000765] [G loss: 7.687442]\n",
      "[Epoch 23/1000] [Batch 87/168] [D loss: 0.001294] [G loss: 8.017715]\n",
      "[Epoch 23/1000] [Batch 88/168] [D loss: 0.000790] [G loss: 7.805450]\n",
      "[Epoch 23/1000] [Batch 89/168] [D loss: 0.001096] [G loss: 7.765643]\n",
      "[Epoch 23/1000] [Batch 90/168] [D loss: 0.000873] [G loss: 7.581158]\n",
      "[Epoch 23/1000] [Batch 91/168] [D loss: 0.001088] [G loss: 7.776927]\n",
      "[Epoch 23/1000] [Batch 92/168] [D loss: 0.000805] [G loss: 7.887932]\n",
      "[Epoch 23/1000] [Batch 93/168] [D loss: 0.000672] [G loss: 7.711231]\n",
      "[Epoch 23/1000] [Batch 94/168] [D loss: 0.000984] [G loss: 7.705591]\n",
      "[Epoch 23/1000] [Batch 95/168] [D loss: 0.001123] [G loss: 7.605005]\n",
      "[Epoch 23/1000] [Batch 96/168] [D loss: 0.000465] [G loss: 7.998001]\n",
      "[Epoch 23/1000] [Batch 97/168] [D loss: 0.000788] [G loss: 7.973107]\n",
      "[Epoch 23/1000] [Batch 98/168] [D loss: 0.000698] [G loss: 8.192299]\n",
      "[Epoch 23/1000] [Batch 99/168] [D loss: 0.000693] [G loss: 8.022157]\n",
      "[Epoch 23/1000] [Batch 100/168] [D loss: 0.000759] [G loss: 7.930089]\n",
      "[Epoch 23/1000] [Batch 101/168] [D loss: 0.000535] [G loss: 8.136614]\n",
      "[Epoch 23/1000] [Batch 102/168] [D loss: 0.000778] [G loss: 7.667242]\n",
      "[Epoch 23/1000] [Batch 103/168] [D loss: 0.000634] [G loss: 7.718220]\n",
      "[Epoch 23/1000] [Batch 104/168] [D loss: 0.000931] [G loss: 7.887249]\n",
      "[Epoch 23/1000] [Batch 105/168] [D loss: 0.000907] [G loss: 7.841336]\n",
      "[Epoch 23/1000] [Batch 106/168] [D loss: 0.000598] [G loss: 7.849975]\n",
      "[Epoch 23/1000] [Batch 107/168] [D loss: 0.000968] [G loss: 7.823423]\n",
      "[Epoch 23/1000] [Batch 108/168] [D loss: 0.000823] [G loss: 8.084120]\n",
      "[Epoch 23/1000] [Batch 109/168] [D loss: 0.000604] [G loss: 7.976476]\n",
      "[Epoch 23/1000] [Batch 110/168] [D loss: 0.000545] [G loss: 7.878835]\n",
      "[Epoch 23/1000] [Batch 111/168] [D loss: 0.000914] [G loss: 7.967258]\n",
      "[Epoch 23/1000] [Batch 112/168] [D loss: 0.000897] [G loss: 7.741417]\n",
      "[Epoch 23/1000] [Batch 113/168] [D loss: 0.000608] [G loss: 7.791998]\n",
      "[Epoch 23/1000] [Batch 114/168] [D loss: 0.000847] [G loss: 7.832756]\n",
      "[Epoch 23/1000] [Batch 115/168] [D loss: 0.000718] [G loss: 7.864962]\n",
      "[Epoch 23/1000] [Batch 116/168] [D loss: 0.000931] [G loss: 7.813314]\n",
      "[Epoch 23/1000] [Batch 117/168] [D loss: 0.000531] [G loss: 7.838255]\n",
      "[Epoch 23/1000] [Batch 118/168] [D loss: 0.000765] [G loss: 7.941532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/1000] [Batch 119/168] [D loss: 0.000676] [G loss: 7.818449]\n",
      "[Epoch 23/1000] [Batch 120/168] [D loss: 0.000685] [G loss: 7.670890]\n",
      "[Epoch 23/1000] [Batch 121/168] [D loss: 0.000632] [G loss: 7.896142]\n",
      "[Epoch 23/1000] [Batch 122/168] [D loss: 0.000689] [G loss: 7.764680]\n",
      "[Epoch 23/1000] [Batch 123/168] [D loss: 0.001001] [G loss: 8.025836]\n",
      "[Epoch 23/1000] [Batch 124/168] [D loss: 0.000739] [G loss: 7.732931]\n",
      "[Epoch 23/1000] [Batch 125/168] [D loss: 0.000593] [G loss: 8.134280]\n",
      "[Epoch 23/1000] [Batch 126/168] [D loss: 0.000866] [G loss: 7.943657]\n",
      "[Epoch 23/1000] [Batch 127/168] [D loss: 0.000741] [G loss: 7.851644]\n",
      "[Epoch 23/1000] [Batch 128/168] [D loss: 0.000919] [G loss: 7.980134]\n",
      "[Epoch 23/1000] [Batch 129/168] [D loss: 0.000776] [G loss: 7.573616]\n",
      "[Epoch 23/1000] [Batch 130/168] [D loss: 0.000755] [G loss: 8.006344]\n",
      "[Epoch 23/1000] [Batch 131/168] [D loss: 0.000655] [G loss: 8.149401]\n",
      "[Epoch 23/1000] [Batch 132/168] [D loss: 0.000870] [G loss: 7.938341]\n",
      "[Epoch 23/1000] [Batch 133/168] [D loss: 0.001044] [G loss: 8.139503]\n",
      "[Epoch 23/1000] [Batch 134/168] [D loss: 0.000597] [G loss: 7.738173]\n",
      "[Epoch 23/1000] [Batch 135/168] [D loss: 0.000953] [G loss: 7.380725]\n",
      "[Epoch 23/1000] [Batch 136/168] [D loss: 0.000855] [G loss: 7.718307]\n",
      "[Epoch 23/1000] [Batch 137/168] [D loss: 0.000950] [G loss: 7.833878]\n",
      "[Epoch 23/1000] [Batch 138/168] [D loss: 0.000589] [G loss: 7.868485]\n",
      "[Epoch 23/1000] [Batch 139/168] [D loss: 0.001114] [G loss: 8.087617]\n",
      "[Epoch 23/1000] [Batch 140/168] [D loss: 0.000565] [G loss: 7.810979]\n",
      "[Epoch 23/1000] [Batch 141/168] [D loss: 0.001005] [G loss: 7.832819]\n",
      "[Epoch 23/1000] [Batch 142/168] [D loss: 0.000977] [G loss: 7.861978]\n",
      "[Epoch 23/1000] [Batch 143/168] [D loss: 0.000825] [G loss: 7.760797]\n",
      "[Epoch 23/1000] [Batch 144/168] [D loss: 0.000777] [G loss: 7.717687]\n",
      "[Epoch 23/1000] [Batch 145/168] [D loss: 0.000661] [G loss: 7.711545]\n",
      "[Epoch 23/1000] [Batch 146/168] [D loss: 0.000759] [G loss: 7.913934]\n",
      "[Epoch 23/1000] [Batch 147/168] [D loss: 0.000540] [G loss: 7.975515]\n",
      "[Epoch 23/1000] [Batch 148/168] [D loss: 0.000636] [G loss: 7.827073]\n",
      "[Epoch 23/1000] [Batch 149/168] [D loss: 0.001378] [G loss: 7.843073]\n",
      "[Epoch 23/1000] [Batch 150/168] [D loss: 0.000745] [G loss: 7.762835]\n",
      "[Epoch 23/1000] [Batch 151/168] [D loss: 0.000616] [G loss: 7.909084]\n",
      "[Epoch 23/1000] [Batch 152/168] [D loss: 0.000867] [G loss: 7.940170]\n",
      "[Epoch 23/1000] [Batch 153/168] [D loss: 0.001009] [G loss: 7.637795]\n",
      "[Epoch 23/1000] [Batch 154/168] [D loss: 0.000770] [G loss: 7.990751]\n",
      "[Epoch 23/1000] [Batch 155/168] [D loss: 0.000700] [G loss: 7.970280]\n",
      "[Epoch 23/1000] [Batch 156/168] [D loss: 0.000596] [G loss: 7.879763]\n",
      "[Epoch 23/1000] [Batch 157/168] [D loss: 0.000975] [G loss: 7.716805]\n",
      "[Epoch 23/1000] [Batch 158/168] [D loss: 0.000653] [G loss: 7.842860]\n",
      "[Epoch 23/1000] [Batch 159/168] [D loss: 0.000716] [G loss: 7.894130]\n",
      "[Epoch 23/1000] [Batch 160/168] [D loss: 0.000601] [G loss: 7.955400]\n",
      "[Epoch 23/1000] [Batch 161/168] [D loss: 0.000849] [G loss: 8.196755]\n",
      "[Epoch 23/1000] [Batch 162/168] [D loss: 0.000706] [G loss: 7.581951]\n",
      "[Epoch 23/1000] [Batch 163/168] [D loss: 0.001053] [G loss: 7.702570]\n",
      "[Epoch 23/1000] [Batch 164/168] [D loss: 0.000514] [G loss: 8.007551]\n",
      "[Epoch 23/1000] [Batch 165/168] [D loss: 0.000948] [G loss: 7.759400]\n",
      "[Epoch 23/1000] [Batch 166/168] [D loss: 0.000620] [G loss: 7.943376]\n",
      "[Epoch 23/1000] [Batch 167/168] [D loss: 0.001061] [G loss: 7.649580]\n",
      "[Epoch 23/1000] [Batch 168/168] [D loss: 0.001087] [G loss: 7.510914]\n",
      "[Epoch 24/1000] [Batch 1/168] [D loss: 0.000560] [G loss: 8.033853]\n",
      "[Epoch 24/1000] [Batch 2/168] [D loss: 0.000639] [G loss: 7.958432]\n",
      "[Epoch 24/1000] [Batch 3/168] [D loss: 0.000685] [G loss: 7.946225]\n",
      "[Epoch 24/1000] [Batch 4/168] [D loss: 0.000519] [G loss: 8.084509]\n",
      "[Epoch 24/1000] [Batch 5/168] [D loss: 0.000770] [G loss: 7.718000]\n",
      "[Epoch 24/1000] [Batch 6/168] [D loss: 0.000882] [G loss: 7.577853]\n",
      "[Epoch 24/1000] [Batch 7/168] [D loss: 0.001004] [G loss: 7.873275]\n",
      "[Epoch 24/1000] [Batch 8/168] [D loss: 0.001316] [G loss: 7.850137]\n",
      "[Epoch 24/1000] [Batch 9/168] [D loss: 0.000731] [G loss: 7.788606]\n",
      "[Epoch 24/1000] [Batch 10/168] [D loss: 0.000680] [G loss: 7.998112]\n",
      "[Epoch 24/1000] [Batch 11/168] [D loss: 0.000701] [G loss: 7.638961]\n",
      "[Epoch 24/1000] [Batch 12/168] [D loss: 0.000649] [G loss: 7.838240]\n",
      "[Epoch 24/1000] [Batch 13/168] [D loss: 0.001203] [G loss: 7.996362]\n",
      "[Epoch 24/1000] [Batch 14/168] [D loss: 0.000909] [G loss: 7.582666]\n",
      "[Epoch 24/1000] [Batch 15/168] [D loss: 0.000805] [G loss: 7.739577]\n",
      "[Epoch 24/1000] [Batch 16/168] [D loss: 0.000700] [G loss: 7.728709]\n",
      "[Epoch 24/1000] [Batch 17/168] [D loss: 0.000518] [G loss: 7.968346]\n",
      "[Epoch 24/1000] [Batch 18/168] [D loss: 0.000697] [G loss: 8.116713]\n",
      "[Epoch 24/1000] [Batch 19/168] [D loss: 0.000818] [G loss: 8.059041]\n",
      "[Epoch 24/1000] [Batch 20/168] [D loss: 0.000717] [G loss: 7.913019]\n",
      "[Epoch 24/1000] [Batch 21/168] [D loss: 0.001128] [G loss: 7.636586]\n",
      "[Epoch 24/1000] [Batch 22/168] [D loss: 0.000803] [G loss: 7.913610]\n",
      "[Epoch 24/1000] [Batch 23/168] [D loss: 0.000893] [G loss: 7.731225]\n",
      "[Epoch 24/1000] [Batch 24/168] [D loss: 0.000737] [G loss: 7.594629]\n",
      "[Epoch 24/1000] [Batch 25/168] [D loss: 0.000557] [G loss: 7.834304]\n",
      "[Epoch 24/1000] [Batch 26/168] [D loss: 0.000688] [G loss: 7.711852]\n",
      "[Epoch 24/1000] [Batch 27/168] [D loss: 0.000607] [G loss: 7.774230]\n",
      "[Epoch 24/1000] [Batch 28/168] [D loss: 0.000705] [G loss: 7.839059]\n",
      "[Epoch 24/1000] [Batch 29/168] [D loss: 0.000699] [G loss: 8.059168]\n",
      "[Epoch 24/1000] [Batch 30/168] [D loss: 0.000594] [G loss: 7.974709]\n",
      "[Epoch 24/1000] [Batch 31/168] [D loss: 0.000575] [G loss: 8.046257]\n",
      "[Epoch 24/1000] [Batch 32/168] [D loss: 0.001446] [G loss: 8.055923]\n",
      "[Epoch 24/1000] [Batch 33/168] [D loss: 0.000671] [G loss: 7.754478]\n",
      "[Epoch 24/1000] [Batch 34/168] [D loss: 0.000685] [G loss: 7.745182]\n",
      "[Epoch 24/1000] [Batch 35/168] [D loss: 0.000775] [G loss: 7.751172]\n",
      "[Epoch 24/1000] [Batch 36/168] [D loss: 0.000793] [G loss: 7.747425]\n",
      "[Epoch 24/1000] [Batch 37/168] [D loss: 0.000595] [G loss: 7.810322]\n",
      "[Epoch 24/1000] [Batch 38/168] [D loss: 0.000593] [G loss: 7.857014]\n",
      "[Epoch 24/1000] [Batch 39/168] [D loss: 0.000757] [G loss: 7.650523]\n",
      "[Epoch 24/1000] [Batch 40/168] [D loss: 0.000846] [G loss: 7.756960]\n",
      "[Epoch 24/1000] [Batch 41/168] [D loss: 0.000773] [G loss: 7.825706]\n",
      "[Epoch 24/1000] [Batch 42/168] [D loss: 0.000737] [G loss: 8.094004]\n",
      "[Epoch 24/1000] [Batch 43/168] [D loss: 0.000764] [G loss: 8.168896]\n",
      "[Epoch 24/1000] [Batch 44/168] [D loss: 0.001076] [G loss: 7.803660]\n",
      "[Epoch 24/1000] [Batch 45/168] [D loss: 0.000890] [G loss: 7.583632]\n",
      "[Epoch 24/1000] [Batch 46/168] [D loss: 0.000703] [G loss: 7.556114]\n",
      "[Epoch 24/1000] [Batch 47/168] [D loss: 0.000787] [G loss: 7.910104]\n",
      "[Epoch 24/1000] [Batch 48/168] [D loss: 0.000803] [G loss: 7.799927]\n",
      "[Epoch 24/1000] [Batch 49/168] [D loss: 0.000533] [G loss: 8.210641]\n",
      "[Epoch 24/1000] [Batch 50/168] [D loss: 0.001056] [G loss: 7.952623]\n",
      "[Epoch 24/1000] [Batch 51/168] [D loss: 0.000837] [G loss: 7.774168]\n",
      "[Epoch 24/1000] [Batch 52/168] [D loss: 0.000586] [G loss: 7.948237]\n",
      "[Epoch 24/1000] [Batch 53/168] [D loss: 0.000633] [G loss: 7.702368]\n",
      "[Epoch 24/1000] [Batch 54/168] [D loss: 0.000710] [G loss: 7.853962]\n",
      "[Epoch 24/1000] [Batch 55/168] [D loss: 0.000796] [G loss: 7.845223]\n",
      "[Epoch 24/1000] [Batch 56/168] [D loss: 0.000667] [G loss: 7.673179]\n",
      "[Epoch 24/1000] [Batch 57/168] [D loss: 0.000674] [G loss: 8.124642]\n",
      "[Epoch 24/1000] [Batch 58/168] [D loss: 0.000595] [G loss: 8.290743]\n",
      "[Epoch 24/1000] [Batch 59/168] [D loss: 0.000621] [G loss: 7.914713]\n",
      "[Epoch 24/1000] [Batch 60/168] [D loss: 0.000741] [G loss: 8.080525]\n",
      "[Epoch 24/1000] [Batch 61/168] [D loss: 0.000999] [G loss: 7.941841]\n",
      "[Epoch 24/1000] [Batch 62/168] [D loss: 0.000957] [G loss: 7.822935]\n",
      "[Epoch 24/1000] [Batch 63/168] [D loss: 0.000818] [G loss: 7.551693]\n",
      "[Epoch 24/1000] [Batch 64/168] [D loss: 0.000906] [G loss: 7.683373]\n",
      "[Epoch 24/1000] [Batch 65/168] [D loss: 0.001030] [G loss: 7.931870]\n",
      "[Epoch 24/1000] [Batch 66/168] [D loss: 0.000642] [G loss: 7.718410]\n",
      "[Epoch 24/1000] [Batch 67/168] [D loss: 0.000713] [G loss: 7.922764]\n",
      "[Epoch 24/1000] [Batch 68/168] [D loss: 0.000843] [G loss: 7.650193]\n",
      "[Epoch 24/1000] [Batch 69/168] [D loss: 0.000647] [G loss: 8.105549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/1000] [Batch 70/168] [D loss: 0.000844] [G loss: 7.601474]\n",
      "[Epoch 24/1000] [Batch 71/168] [D loss: 0.000699] [G loss: 8.037662]\n",
      "[Epoch 24/1000] [Batch 72/168] [D loss: 0.000451] [G loss: 8.002869]\n",
      "[Epoch 24/1000] [Batch 73/168] [D loss: 0.000552] [G loss: 8.178547]\n",
      "[Epoch 24/1000] [Batch 74/168] [D loss: 0.000837] [G loss: 7.994007]\n",
      "[Epoch 24/1000] [Batch 75/168] [D loss: 0.000461] [G loss: 8.309246]\n",
      "[Epoch 24/1000] [Batch 76/168] [D loss: 0.001030] [G loss: 7.885760]\n",
      "[Epoch 24/1000] [Batch 77/168] [D loss: 0.001183] [G loss: 7.646937]\n",
      "[Epoch 24/1000] [Batch 78/168] [D loss: 0.000903] [G loss: 7.868670]\n",
      "[Epoch 24/1000] [Batch 79/168] [D loss: 0.000700] [G loss: 7.680212]\n",
      "[Epoch 24/1000] [Batch 80/168] [D loss: 0.000762] [G loss: 8.064354]\n",
      "[Epoch 24/1000] [Batch 81/168] [D loss: 0.000716] [G loss: 7.777644]\n",
      "[Epoch 24/1000] [Batch 82/168] [D loss: 0.000799] [G loss: 7.726658]\n",
      "[Epoch 24/1000] [Batch 83/168] [D loss: 0.000928] [G loss: 7.884209]\n",
      "[Epoch 24/1000] [Batch 84/168] [D loss: 0.000684] [G loss: 8.019867]\n",
      "[Epoch 24/1000] [Batch 85/168] [D loss: 0.001040] [G loss: 7.755622]\n",
      "[Epoch 24/1000] [Batch 86/168] [D loss: 0.000659] [G loss: 7.630184]\n",
      "[Epoch 24/1000] [Batch 87/168] [D loss: 0.000517] [G loss: 8.048585]\n",
      "[Epoch 24/1000] [Batch 88/168] [D loss: 0.001039] [G loss: 8.046278]\n",
      "[Epoch 24/1000] [Batch 89/168] [D loss: 0.001083] [G loss: 7.785809]\n",
      "[Epoch 24/1000] [Batch 90/168] [D loss: 0.000741] [G loss: 7.471224]\n",
      "[Epoch 24/1000] [Batch 91/168] [D loss: 0.000746] [G loss: 7.685397]\n",
      "[Epoch 24/1000] [Batch 92/168] [D loss: 0.000577] [G loss: 7.887143]\n",
      "[Epoch 24/1000] [Batch 93/168] [D loss: 0.000790] [G loss: 7.719619]\n",
      "[Epoch 24/1000] [Batch 94/168] [D loss: 0.001161] [G loss: 7.598685]\n",
      "[Epoch 24/1000] [Batch 95/168] [D loss: 0.000731] [G loss: 7.677156]\n",
      "[Epoch 24/1000] [Batch 96/168] [D loss: 0.000581] [G loss: 7.993141]\n",
      "[Epoch 24/1000] [Batch 97/168] [D loss: 0.000760] [G loss: 7.690106]\n",
      "[Epoch 24/1000] [Batch 98/168] [D loss: 0.000741] [G loss: 7.737754]\n",
      "[Epoch 24/1000] [Batch 99/168] [D loss: 0.000589] [G loss: 7.989910]\n",
      "[Epoch 24/1000] [Batch 100/168] [D loss: 0.001004] [G loss: 8.110754]\n",
      "[Epoch 24/1000] [Batch 101/168] [D loss: 0.000664] [G loss: 8.251018]\n",
      "[Epoch 24/1000] [Batch 102/168] [D loss: 0.000528] [G loss: 8.175259]\n",
      "[Epoch 24/1000] [Batch 103/168] [D loss: 0.000585] [G loss: 7.984700]\n",
      "[Epoch 24/1000] [Batch 104/168] [D loss: 0.000737] [G loss: 7.689640]\n",
      "[Epoch 24/1000] [Batch 105/168] [D loss: 0.000603] [G loss: 7.849226]\n",
      "[Epoch 24/1000] [Batch 106/168] [D loss: 0.000874] [G loss: 8.073369]\n",
      "[Epoch 24/1000] [Batch 107/168] [D loss: 0.000670] [G loss: 8.025628]\n",
      "[Epoch 24/1000] [Batch 108/168] [D loss: 0.000612] [G loss: 8.212433]\n",
      "[Epoch 24/1000] [Batch 109/168] [D loss: 0.000542] [G loss: 7.946997]\n",
      "[Epoch 24/1000] [Batch 110/168] [D loss: 0.001008] [G loss: 7.966372]\n",
      "[Epoch 24/1000] [Batch 111/168] [D loss: 0.000617] [G loss: 8.024340]\n",
      "[Epoch 24/1000] [Batch 112/168] [D loss: 0.000805] [G loss: 7.873904]\n",
      "[Epoch 24/1000] [Batch 113/168] [D loss: 0.000750] [G loss: 8.012584]\n",
      "[Epoch 24/1000] [Batch 114/168] [D loss: 0.000547] [G loss: 8.082329]\n",
      "[Epoch 24/1000] [Batch 115/168] [D loss: 0.000570] [G loss: 8.255876]\n",
      "[Epoch 24/1000] [Batch 116/168] [D loss: 0.000648] [G loss: 8.386511]\n",
      "[Epoch 24/1000] [Batch 117/168] [D loss: 0.000812] [G loss: 8.048671]\n",
      "[Epoch 24/1000] [Batch 118/168] [D loss: 0.000569] [G loss: 7.901197]\n",
      "[Epoch 24/1000] [Batch 119/168] [D loss: 0.000615] [G loss: 7.766328]\n",
      "[Epoch 24/1000] [Batch 120/168] [D loss: 0.000596] [G loss: 8.029723]\n",
      "[Epoch 24/1000] [Batch 121/168] [D loss: 0.001049] [G loss: 7.952748]\n",
      "[Epoch 24/1000] [Batch 122/168] [D loss: 0.000681] [G loss: 7.931175]\n",
      "[Epoch 24/1000] [Batch 123/168] [D loss: 0.000864] [G loss: 7.978800]\n",
      "[Epoch 24/1000] [Batch 124/168] [D loss: 0.000546] [G loss: 7.756807]\n",
      "[Epoch 24/1000] [Batch 125/168] [D loss: 0.001384] [G loss: 7.853816]\n",
      "[Epoch 24/1000] [Batch 126/168] [D loss: 0.000664] [G loss: 7.651113]\n",
      "[Epoch 24/1000] [Batch 127/168] [D loss: 0.001061] [G loss: 7.506105]\n",
      "[Epoch 24/1000] [Batch 128/168] [D loss: 0.000663] [G loss: 7.753901]\n",
      "[Epoch 24/1000] [Batch 129/168] [D loss: 0.000679] [G loss: 7.579734]\n",
      "[Epoch 24/1000] [Batch 130/168] [D loss: 0.000987] [G loss: 7.895373]\n",
      "[Epoch 24/1000] [Batch 131/168] [D loss: 0.000658] [G loss: 7.912772]\n",
      "[Epoch 24/1000] [Batch 132/168] [D loss: 0.000718] [G loss: 8.097452]\n",
      "[Epoch 24/1000] [Batch 133/168] [D loss: 0.000781] [G loss: 8.110830]\n",
      "[Epoch 24/1000] [Batch 134/168] [D loss: 0.000658] [G loss: 8.095966]\n",
      "[Epoch 24/1000] [Batch 135/168] [D loss: 0.000619] [G loss: 7.845242]\n",
      "[Epoch 24/1000] [Batch 136/168] [D loss: 0.000690] [G loss: 7.916515]\n",
      "[Epoch 24/1000] [Batch 137/168] [D loss: 0.000723] [G loss: 7.934495]\n",
      "[Epoch 24/1000] [Batch 138/168] [D loss: 0.000610] [G loss: 7.929265]\n",
      "[Epoch 24/1000] [Batch 139/168] [D loss: 0.000766] [G loss: 7.881377]\n",
      "[Epoch 24/1000] [Batch 140/168] [D loss: 0.000713] [G loss: 7.969442]\n",
      "[Epoch 24/1000] [Batch 141/168] [D loss: 0.000629] [G loss: 8.231656]\n",
      "[Epoch 24/1000] [Batch 142/168] [D loss: 0.000734] [G loss: 7.872960]\n",
      "[Epoch 24/1000] [Batch 143/168] [D loss: 0.000475] [G loss: 7.903915]\n",
      "[Epoch 24/1000] [Batch 144/168] [D loss: 0.000613] [G loss: 8.002687]\n",
      "[Epoch 24/1000] [Batch 145/168] [D loss: 0.000629] [G loss: 7.942039]\n",
      "[Epoch 24/1000] [Batch 146/168] [D loss: 0.000530] [G loss: 8.179412]\n",
      "[Epoch 24/1000] [Batch 147/168] [D loss: 0.001346] [G loss: 7.963427]\n",
      "[Epoch 24/1000] [Batch 148/168] [D loss: 0.000659] [G loss: 7.622578]\n",
      "[Epoch 24/1000] [Batch 149/168] [D loss: 0.000745] [G loss: 7.935954]\n",
      "[Epoch 24/1000] [Batch 150/168] [D loss: 0.001219] [G loss: 7.661067]\n",
      "[Epoch 24/1000] [Batch 151/168] [D loss: 0.000983] [G loss: 7.689571]\n",
      "[Epoch 24/1000] [Batch 152/168] [D loss: 0.000607] [G loss: 7.932297]\n",
      "[Epoch 24/1000] [Batch 153/168] [D loss: 0.000501] [G loss: 7.988433]\n",
      "[Epoch 24/1000] [Batch 154/168] [D loss: 0.000632] [G loss: 8.149796]\n",
      "[Epoch 24/1000] [Batch 155/168] [D loss: 0.000597] [G loss: 8.218819]\n",
      "[Epoch 24/1000] [Batch 156/168] [D loss: 0.000601] [G loss: 8.171837]\n",
      "[Epoch 24/1000] [Batch 157/168] [D loss: 0.001058] [G loss: 8.002610]\n",
      "[Epoch 24/1000] [Batch 158/168] [D loss: 0.000713] [G loss: 7.934299]\n",
      "[Epoch 24/1000] [Batch 159/168] [D loss: 0.000620] [G loss: 7.921890]\n",
      "[Epoch 24/1000] [Batch 160/168] [D loss: 0.000586] [G loss: 7.924325]\n",
      "[Epoch 24/1000] [Batch 161/168] [D loss: 0.000999] [G loss: 7.817519]\n",
      "[Epoch 24/1000] [Batch 162/168] [D loss: 0.000680] [G loss: 7.864389]\n",
      "[Epoch 24/1000] [Batch 163/168] [D loss: 0.000521] [G loss: 7.971560]\n",
      "[Epoch 24/1000] [Batch 164/168] [D loss: 0.000596] [G loss: 7.885556]\n",
      "[Epoch 24/1000] [Batch 165/168] [D loss: 0.000674] [G loss: 8.265402]\n",
      "[Epoch 24/1000] [Batch 166/168] [D loss: 0.000483] [G loss: 8.295195]\n",
      "[Epoch 24/1000] [Batch 167/168] [D loss: 0.000503] [G loss: 8.162277]\n",
      "[Epoch 24/1000] [Batch 168/168] [D loss: 0.000620] [G loss: 8.308447]\n",
      "[Epoch 25/1000] [Batch 1/168] [D loss: 0.000772] [G loss: 8.161241]\n",
      "[Epoch 25/1000] [Batch 2/168] [D loss: 0.000595] [G loss: 8.071002]\n",
      "[Epoch 25/1000] [Batch 3/168] [D loss: 0.000635] [G loss: 8.185158]\n",
      "[Epoch 25/1000] [Batch 4/168] [D loss: 0.000589] [G loss: 8.125386]\n",
      "[Epoch 25/1000] [Batch 5/168] [D loss: 0.000696] [G loss: 8.210045]\n",
      "[Epoch 25/1000] [Batch 6/168] [D loss: 0.000466] [G loss: 8.215364]\n",
      "[Epoch 25/1000] [Batch 7/168] [D loss: 0.000440] [G loss: 8.302967]\n",
      "[Epoch 25/1000] [Batch 8/168] [D loss: 0.000631] [G loss: 7.940010]\n",
      "[Epoch 25/1000] [Batch 9/168] [D loss: 0.000391] [G loss: 8.309835]\n",
      "[Epoch 25/1000] [Batch 10/168] [D loss: 0.000653] [G loss: 7.956131]\n",
      "[Epoch 25/1000] [Batch 11/168] [D loss: 0.000832] [G loss: 8.013551]\n",
      "[Epoch 25/1000] [Batch 12/168] [D loss: 0.000826] [G loss: 8.003134]\n",
      "[Epoch 25/1000] [Batch 13/168] [D loss: 0.000616] [G loss: 8.239157]\n",
      "[Epoch 25/1000] [Batch 14/168] [D loss: 0.000732] [G loss: 7.994270]\n",
      "[Epoch 25/1000] [Batch 15/168] [D loss: 0.000415] [G loss: 8.291949]\n",
      "[Epoch 25/1000] [Batch 16/168] [D loss: 0.000606] [G loss: 8.069987]\n",
      "[Epoch 25/1000] [Batch 17/168] [D loss: 0.000852] [G loss: 7.705887]\n",
      "[Epoch 25/1000] [Batch 18/168] [D loss: 0.000649] [G loss: 7.990071]\n",
      "[Epoch 25/1000] [Batch 19/168] [D loss: 0.000644] [G loss: 7.810057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/1000] [Batch 20/168] [D loss: 0.000739] [G loss: 7.911028]\n",
      "[Epoch 25/1000] [Batch 21/168] [D loss: 0.000854] [G loss: 7.799707]\n",
      "[Epoch 25/1000] [Batch 22/168] [D loss: 0.000789] [G loss: 8.150415]\n",
      "[Epoch 25/1000] [Batch 23/168] [D loss: 0.000645] [G loss: 7.954722]\n",
      "[Epoch 25/1000] [Batch 24/168] [D loss: 0.000871] [G loss: 7.990587]\n",
      "[Epoch 25/1000] [Batch 25/168] [D loss: 0.000863] [G loss: 7.639401]\n",
      "[Epoch 25/1000] [Batch 26/168] [D loss: 0.000599] [G loss: 7.962136]\n",
      "[Epoch 25/1000] [Batch 27/168] [D loss: 0.000635] [G loss: 7.938310]\n",
      "[Epoch 25/1000] [Batch 28/168] [D loss: 0.000437] [G loss: 8.217771]\n",
      "[Epoch 25/1000] [Batch 29/168] [D loss: 0.000722] [G loss: 8.049372]\n",
      "[Epoch 25/1000] [Batch 30/168] [D loss: 0.000612] [G loss: 7.959015]\n",
      "[Epoch 25/1000] [Batch 31/168] [D loss: 0.000579] [G loss: 7.837731]\n",
      "[Epoch 25/1000] [Batch 32/168] [D loss: 0.000597] [G loss: 8.162528]\n",
      "[Epoch 25/1000] [Batch 33/168] [D loss: 0.000755] [G loss: 8.396502]\n",
      "[Epoch 25/1000] [Batch 34/168] [D loss: 0.000376] [G loss: 8.141046]\n",
      "[Epoch 25/1000] [Batch 35/168] [D loss: 0.000427] [G loss: 8.071541]\n",
      "[Epoch 25/1000] [Batch 36/168] [D loss: 0.000757] [G loss: 8.036528]\n",
      "[Epoch 25/1000] [Batch 37/168] [D loss: 0.000690] [G loss: 7.779469]\n",
      "[Epoch 25/1000] [Batch 38/168] [D loss: 0.000533] [G loss: 8.155558]\n",
      "[Epoch 25/1000] [Batch 39/168] [D loss: 0.000404] [G loss: 8.246479]\n",
      "[Epoch 25/1000] [Batch 40/168] [D loss: 0.000349] [G loss: 8.459678]\n",
      "[Epoch 25/1000] [Batch 41/168] [D loss: 0.000591] [G loss: 8.210939]\n",
      "[Epoch 25/1000] [Batch 42/168] [D loss: 0.000696] [G loss: 8.052948]\n",
      "[Epoch 25/1000] [Batch 43/168] [D loss: 0.000677] [G loss: 8.353772]\n",
      "[Epoch 25/1000] [Batch 44/168] [D loss: 0.000561] [G loss: 8.011745]\n",
      "[Epoch 25/1000] [Batch 45/168] [D loss: 0.000702] [G loss: 7.745721]\n",
      "[Epoch 25/1000] [Batch 46/168] [D loss: 0.000652] [G loss: 8.209976]\n",
      "[Epoch 25/1000] [Batch 47/168] [D loss: 0.000674] [G loss: 8.414229]\n",
      "[Epoch 25/1000] [Batch 48/168] [D loss: 0.000436] [G loss: 8.351972]\n",
      "[Epoch 25/1000] [Batch 49/168] [D loss: 0.000523] [G loss: 8.117556]\n",
      "[Epoch 25/1000] [Batch 50/168] [D loss: 0.000575] [G loss: 8.396932]\n",
      "[Epoch 25/1000] [Batch 51/168] [D loss: 0.000744] [G loss: 8.003844]\n",
      "[Epoch 25/1000] [Batch 52/168] [D loss: 0.000879] [G loss: 7.880159]\n",
      "[Epoch 25/1000] [Batch 53/168] [D loss: 0.000619] [G loss: 8.067580]\n",
      "[Epoch 25/1000] [Batch 54/168] [D loss: 0.000528] [G loss: 7.893536]\n",
      "[Epoch 25/1000] [Batch 55/168] [D loss: 0.000718] [G loss: 7.885865]\n",
      "[Epoch 25/1000] [Batch 56/168] [D loss: 0.000559] [G loss: 8.072464]\n",
      "[Epoch 25/1000] [Batch 57/168] [D loss: 0.000599] [G loss: 7.975272]\n",
      "[Epoch 25/1000] [Batch 58/168] [D loss: 0.000556] [G loss: 7.887715]\n",
      "[Epoch 25/1000] [Batch 59/168] [D loss: 0.000473] [G loss: 7.935049]\n",
      "[Epoch 25/1000] [Batch 60/168] [D loss: 0.000615] [G loss: 8.009580]\n",
      "[Epoch 25/1000] [Batch 61/168] [D loss: 0.000598] [G loss: 7.973667]\n",
      "[Epoch 25/1000] [Batch 62/168] [D loss: 0.000549] [G loss: 8.175759]\n",
      "[Epoch 25/1000] [Batch 63/168] [D loss: 0.000582] [G loss: 8.148197]\n",
      "[Epoch 25/1000] [Batch 64/168] [D loss: 0.000662] [G loss: 8.087457]\n",
      "[Epoch 25/1000] [Batch 65/168] [D loss: 0.000492] [G loss: 8.277022]\n",
      "[Epoch 25/1000] [Batch 66/168] [D loss: 0.000677] [G loss: 8.121095]\n",
      "[Epoch 25/1000] [Batch 67/168] [D loss: 0.000622] [G loss: 7.921793]\n",
      "[Epoch 25/1000] [Batch 68/168] [D loss: 0.000427] [G loss: 8.072136]\n",
      "[Epoch 25/1000] [Batch 69/168] [D loss: 0.000899] [G loss: 7.986514]\n",
      "[Epoch 25/1000] [Batch 70/168] [D loss: 0.000516] [G loss: 7.974945]\n",
      "[Epoch 25/1000] [Batch 71/168] [D loss: 0.000574] [G loss: 8.134683]\n",
      "[Epoch 25/1000] [Batch 72/168] [D loss: 0.000545] [G loss: 8.284199]\n",
      "[Epoch 25/1000] [Batch 73/168] [D loss: 0.000658] [G loss: 7.783026]\n",
      "[Epoch 25/1000] [Batch 74/168] [D loss: 0.000515] [G loss: 7.953922]\n",
      "[Epoch 25/1000] [Batch 75/168] [D loss: 0.000527] [G loss: 8.084393]\n",
      "[Epoch 25/1000] [Batch 76/168] [D loss: 0.000763] [G loss: 8.053026]\n",
      "[Epoch 25/1000] [Batch 77/168] [D loss: 0.000657] [G loss: 8.105539]\n",
      "[Epoch 25/1000] [Batch 78/168] [D loss: 0.001049] [G loss: 8.166290]\n",
      "[Epoch 25/1000] [Batch 79/168] [D loss: 0.000592] [G loss: 7.864201]\n",
      "[Epoch 25/1000] [Batch 80/168] [D loss: 0.000542] [G loss: 7.953517]\n",
      "[Epoch 25/1000] [Batch 81/168] [D loss: 0.000779] [G loss: 7.954852]\n",
      "[Epoch 25/1000] [Batch 82/168] [D loss: 0.000610] [G loss: 8.095501]\n",
      "[Epoch 25/1000] [Batch 83/168] [D loss: 0.000629] [G loss: 8.127439]\n",
      "[Epoch 25/1000] [Batch 84/168] [D loss: 0.000609] [G loss: 8.053642]\n",
      "[Epoch 25/1000] [Batch 85/168] [D loss: 0.000667] [G loss: 7.828792]\n",
      "[Epoch 25/1000] [Batch 86/168] [D loss: 0.000791] [G loss: 8.110343]\n",
      "[Epoch 25/1000] [Batch 87/168] [D loss: 0.000547] [G loss: 8.064908]\n",
      "[Epoch 25/1000] [Batch 88/168] [D loss: 0.001074] [G loss: 8.225717]\n",
      "[Epoch 25/1000] [Batch 89/168] [D loss: 0.000620] [G loss: 7.861332]\n",
      "[Epoch 25/1000] [Batch 90/168] [D loss: 0.000576] [G loss: 8.088095]\n",
      "[Epoch 25/1000] [Batch 91/168] [D loss: 0.000715] [G loss: 8.117174]\n",
      "[Epoch 25/1000] [Batch 92/168] [D loss: 0.000450] [G loss: 8.138616]\n",
      "[Epoch 25/1000] [Batch 93/168] [D loss: 0.000581] [G loss: 8.209866]\n",
      "[Epoch 25/1000] [Batch 94/168] [D loss: 0.000617] [G loss: 7.990736]\n",
      "[Epoch 25/1000] [Batch 95/168] [D loss: 0.000524] [G loss: 7.935613]\n",
      "[Epoch 25/1000] [Batch 96/168] [D loss: 0.000704] [G loss: 7.627930]\n",
      "[Epoch 25/1000] [Batch 97/168] [D loss: 0.000642] [G loss: 8.199839]\n",
      "[Epoch 25/1000] [Batch 98/168] [D loss: 0.000482] [G loss: 8.062621]\n",
      "[Epoch 25/1000] [Batch 99/168] [D loss: 0.000409] [G loss: 8.234966]\n",
      "[Epoch 25/1000] [Batch 100/168] [D loss: 0.000414] [G loss: 8.279599]\n",
      "[Epoch 25/1000] [Batch 101/168] [D loss: 0.000511] [G loss: 8.282444]\n",
      "[Epoch 25/1000] [Batch 102/168] [D loss: 0.000537] [G loss: 8.239959]\n",
      "[Epoch 25/1000] [Batch 103/168] [D loss: 0.000948] [G loss: 8.302870]\n",
      "[Epoch 25/1000] [Batch 104/168] [D loss: 0.000642] [G loss: 8.001701]\n",
      "[Epoch 25/1000] [Batch 105/168] [D loss: 0.000342] [G loss: 8.304681]\n",
      "[Epoch 25/1000] [Batch 106/168] [D loss: 0.000655] [G loss: 7.761191]\n",
      "[Epoch 25/1000] [Batch 107/168] [D loss: 0.000708] [G loss: 7.917099]\n",
      "[Epoch 25/1000] [Batch 108/168] [D loss: 0.000478] [G loss: 8.206861]\n",
      "[Epoch 25/1000] [Batch 109/168] [D loss: 0.000536] [G loss: 8.378819]\n",
      "[Epoch 25/1000] [Batch 110/168] [D loss: 0.000631] [G loss: 8.127229]\n",
      "[Epoch 25/1000] [Batch 111/168] [D loss: 0.000987] [G loss: 8.257360]\n",
      "[Epoch 25/1000] [Batch 112/168] [D loss: 0.000572] [G loss: 7.832460]\n",
      "[Epoch 25/1000] [Batch 113/168] [D loss: 0.000525] [G loss: 7.878552]\n",
      "[Epoch 25/1000] [Batch 114/168] [D loss: 0.000515] [G loss: 7.937294]\n",
      "[Epoch 25/1000] [Batch 115/168] [D loss: 0.000402] [G loss: 7.872737]\n",
      "[Epoch 25/1000] [Batch 116/168] [D loss: 0.001099] [G loss: 8.237275]\n",
      "[Epoch 25/1000] [Batch 117/168] [D loss: 0.000567] [G loss: 7.931544]\n",
      "[Epoch 25/1000] [Batch 118/168] [D loss: 0.000416] [G loss: 8.073622]\n",
      "[Epoch 25/1000] [Batch 119/168] [D loss: 0.000721] [G loss: 7.900041]\n",
      "[Epoch 25/1000] [Batch 120/168] [D loss: 0.000620] [G loss: 8.167505]\n",
      "[Epoch 25/1000] [Batch 121/168] [D loss: 0.000436] [G loss: 8.337886]\n",
      "[Epoch 25/1000] [Batch 122/168] [D loss: 0.000523] [G loss: 8.293694]\n",
      "[Epoch 25/1000] [Batch 123/168] [D loss: 0.000863] [G loss: 8.066717]\n",
      "[Epoch 25/1000] [Batch 124/168] [D loss: 0.000504] [G loss: 8.002981]\n",
      "[Epoch 25/1000] [Batch 125/168] [D loss: 0.000532] [G loss: 7.918140]\n",
      "[Epoch 25/1000] [Batch 126/168] [D loss: 0.000612] [G loss: 8.081229]\n",
      "[Epoch 25/1000] [Batch 127/168] [D loss: 0.000396] [G loss: 8.368373]\n",
      "[Epoch 25/1000] [Batch 128/168] [D loss: 0.000380] [G loss: 8.311001]\n",
      "[Epoch 25/1000] [Batch 129/168] [D loss: 0.000596] [G loss: 8.365732]\n",
      "[Epoch 25/1000] [Batch 130/168] [D loss: 0.000516] [G loss: 8.175833]\n",
      "[Epoch 25/1000] [Batch 131/168] [D loss: 0.000483] [G loss: 8.302176]\n",
      "[Epoch 25/1000] [Batch 132/168] [D loss: 0.000562] [G loss: 8.093501]\n",
      "[Epoch 25/1000] [Batch 133/168] [D loss: 0.000492] [G loss: 8.250761]\n",
      "[Epoch 25/1000] [Batch 134/168] [D loss: 0.000640] [G loss: 8.387058]\n",
      "[Epoch 25/1000] [Batch 135/168] [D loss: 0.000527] [G loss: 8.375925]\n",
      "[Epoch 25/1000] [Batch 136/168] [D loss: 0.000503] [G loss: 8.216895]\n",
      "[Epoch 25/1000] [Batch 137/168] [D loss: 0.000584] [G loss: 8.127713]\n",
      "[Epoch 25/1000] [Batch 138/168] [D loss: 0.000471] [G loss: 8.012220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/1000] [Batch 139/168] [D loss: 0.000642] [G loss: 8.229829]\n",
      "[Epoch 25/1000] [Batch 140/168] [D loss: 0.000855] [G loss: 8.113731]\n",
      "[Epoch 25/1000] [Batch 141/168] [D loss: 0.000669] [G loss: 7.759659]\n",
      "[Epoch 25/1000] [Batch 142/168] [D loss: 0.000819] [G loss: 7.966861]\n",
      "[Epoch 25/1000] [Batch 143/168] [D loss: 0.000666] [G loss: 7.690998]\n",
      "[Epoch 25/1000] [Batch 144/168] [D loss: 0.000372] [G loss: 8.135295]\n",
      "[Epoch 25/1000] [Batch 145/168] [D loss: 0.000494] [G loss: 8.407654]\n",
      "[Epoch 25/1000] [Batch 146/168] [D loss: 0.000419] [G loss: 8.322295]\n",
      "[Epoch 25/1000] [Batch 147/168] [D loss: 0.000443] [G loss: 8.357204]\n",
      "[Epoch 25/1000] [Batch 148/168] [D loss: 0.000477] [G loss: 8.331333]\n",
      "[Epoch 25/1000] [Batch 149/168] [D loss: 0.000774] [G loss: 8.202442]\n",
      "[Epoch 25/1000] [Batch 150/168] [D loss: 0.000474] [G loss: 8.092192]\n",
      "[Epoch 25/1000] [Batch 151/168] [D loss: 0.001279] [G loss: 8.077287]\n",
      "[Epoch 25/1000] [Batch 152/168] [D loss: 0.000725] [G loss: 7.880457]\n",
      "[Epoch 25/1000] [Batch 153/168] [D loss: 0.000746] [G loss: 7.741545]\n",
      "[Epoch 25/1000] [Batch 154/168] [D loss: 0.000756] [G loss: 7.860940]\n",
      "[Epoch 25/1000] [Batch 155/168] [D loss: 0.000609] [G loss: 7.709021]\n",
      "[Epoch 25/1000] [Batch 156/168] [D loss: 0.000532] [G loss: 8.188494]\n",
      "[Epoch 25/1000] [Batch 157/168] [D loss: 0.000434] [G loss: 8.614075]\n",
      "[Epoch 25/1000] [Batch 158/168] [D loss: 0.000984] [G loss: 8.304779]\n",
      "[Epoch 25/1000] [Batch 159/168] [D loss: 0.000648] [G loss: 8.020514]\n",
      "[Epoch 25/1000] [Batch 160/168] [D loss: 0.000684] [G loss: 8.174669]\n",
      "[Epoch 25/1000] [Batch 161/168] [D loss: 0.000587] [G loss: 8.109027]\n",
      "[Epoch 25/1000] [Batch 162/168] [D loss: 0.000517] [G loss: 8.005054]\n",
      "[Epoch 25/1000] [Batch 163/168] [D loss: 0.000606] [G loss: 7.949976]\n",
      "[Epoch 25/1000] [Batch 164/168] [D loss: 0.000481] [G loss: 7.890349]\n",
      "[Epoch 25/1000] [Batch 165/168] [D loss: 0.000479] [G loss: 8.047081]\n",
      "[Epoch 25/1000] [Batch 166/168] [D loss: 0.000484] [G loss: 8.158682]\n",
      "[Epoch 25/1000] [Batch 167/168] [D loss: 0.000409] [G loss: 8.513647]\n",
      "[Epoch 25/1000] [Batch 168/168] [D loss: 0.000572] [G loss: 8.389707]\n",
      "[Epoch 26/1000] [Batch 1/168] [D loss: 0.000478] [G loss: 8.334312]\n",
      "[Epoch 26/1000] [Batch 2/168] [D loss: 0.000532] [G loss: 8.247104]\n",
      "[Epoch 26/1000] [Batch 3/168] [D loss: 0.000501] [G loss: 8.224845]\n",
      "[Epoch 26/1000] [Batch 4/168] [D loss: 0.000317] [G loss: 8.266129]\n",
      "[Epoch 26/1000] [Batch 5/168] [D loss: 0.000417] [G loss: 8.346662]\n",
      "[Epoch 26/1000] [Batch 6/168] [D loss: 0.000547] [G loss: 8.253183]\n",
      "[Epoch 26/1000] [Batch 7/168] [D loss: 0.000499] [G loss: 8.400672]\n",
      "[Epoch 26/1000] [Batch 8/168] [D loss: 0.000537] [G loss: 8.165627]\n",
      "[Epoch 26/1000] [Batch 9/168] [D loss: 0.000417] [G loss: 8.342460]\n",
      "[Epoch 26/1000] [Batch 10/168] [D loss: 0.000433] [G loss: 8.438644]\n",
      "[Epoch 26/1000] [Batch 11/168] [D loss: 0.000524] [G loss: 8.358211]\n",
      "[Epoch 26/1000] [Batch 12/168] [D loss: 0.000534] [G loss: 8.333831]\n",
      "[Epoch 26/1000] [Batch 13/168] [D loss: 0.000833] [G loss: 8.437535]\n",
      "[Epoch 26/1000] [Batch 14/168] [D loss: 0.000377] [G loss: 8.358255]\n",
      "[Epoch 26/1000] [Batch 15/168] [D loss: 0.000656] [G loss: 8.118543]\n",
      "[Epoch 26/1000] [Batch 16/168] [D loss: 0.000827] [G loss: 8.323793]\n",
      "[Epoch 26/1000] [Batch 17/168] [D loss: 0.000515] [G loss: 8.039210]\n",
      "[Epoch 26/1000] [Batch 18/168] [D loss: 0.000609] [G loss: 8.002297]\n",
      "[Epoch 26/1000] [Batch 19/168] [D loss: 0.000554] [G loss: 8.090832]\n",
      "[Epoch 26/1000] [Batch 20/168] [D loss: 0.000659] [G loss: 8.051745]\n",
      "[Epoch 26/1000] [Batch 21/168] [D loss: 0.000514] [G loss: 7.944314]\n",
      "[Epoch 26/1000] [Batch 22/168] [D loss: 0.000472] [G loss: 7.999304]\n",
      "[Epoch 26/1000] [Batch 23/168] [D loss: 0.000514] [G loss: 8.057571]\n",
      "[Epoch 26/1000] [Batch 24/168] [D loss: 0.000522] [G loss: 8.306072]\n",
      "[Epoch 26/1000] [Batch 25/168] [D loss: 0.000373] [G loss: 8.653463]\n",
      "[Epoch 26/1000] [Batch 26/168] [D loss: 0.000795] [G loss: 8.345291]\n",
      "[Epoch 26/1000] [Batch 27/168] [D loss: 0.000569] [G loss: 8.262771]\n",
      "[Epoch 26/1000] [Batch 28/168] [D loss: 0.000651] [G loss: 8.360867]\n",
      "[Epoch 26/1000] [Batch 29/168] [D loss: 0.000630] [G loss: 8.104461]\n",
      "[Epoch 26/1000] [Batch 30/168] [D loss: 0.000541] [G loss: 8.085030]\n",
      "[Epoch 26/1000] [Batch 31/168] [D loss: 0.000437] [G loss: 8.115078]\n",
      "[Epoch 26/1000] [Batch 32/168] [D loss: 0.000756] [G loss: 8.169496]\n",
      "[Epoch 26/1000] [Batch 33/168] [D loss: 0.000429] [G loss: 8.211239]\n",
      "[Epoch 26/1000] [Batch 34/168] [D loss: 0.000458] [G loss: 8.397750]\n",
      "[Epoch 26/1000] [Batch 35/168] [D loss: 0.000810] [G loss: 8.054585]\n",
      "[Epoch 26/1000] [Batch 36/168] [D loss: 0.000469] [G loss: 8.039128]\n",
      "[Epoch 26/1000] [Batch 37/168] [D loss: 0.000476] [G loss: 8.295579]\n",
      "[Epoch 26/1000] [Batch 38/168] [D loss: 0.000669] [G loss: 8.094336]\n",
      "[Epoch 26/1000] [Batch 39/168] [D loss: 0.000614] [G loss: 8.372548]\n",
      "[Epoch 26/1000] [Batch 40/168] [D loss: 0.000500] [G loss: 8.038126]\n",
      "[Epoch 26/1000] [Batch 41/168] [D loss: 0.000580] [G loss: 8.133065]\n",
      "[Epoch 26/1000] [Batch 42/168] [D loss: 0.000373] [G loss: 8.144718]\n",
      "[Epoch 26/1000] [Batch 43/168] [D loss: 0.000505] [G loss: 8.333483]\n",
      "[Epoch 26/1000] [Batch 44/168] [D loss: 0.000589] [G loss: 8.397834]\n",
      "[Epoch 26/1000] [Batch 45/168] [D loss: 0.000584] [G loss: 8.041101]\n",
      "[Epoch 26/1000] [Batch 46/168] [D loss: 0.000644] [G loss: 8.149756]\n",
      "[Epoch 26/1000] [Batch 47/168] [D loss: 0.000494] [G loss: 8.209759]\n",
      "[Epoch 26/1000] [Batch 48/168] [D loss: 0.000580] [G loss: 8.390966]\n",
      "[Epoch 26/1000] [Batch 49/168] [D loss: 0.000331] [G loss: 8.138174]\n",
      "[Epoch 26/1000] [Batch 50/168] [D loss: 0.000708] [G loss: 8.101604]\n",
      "[Epoch 26/1000] [Batch 51/168] [D loss: 0.000441] [G loss: 8.334620]\n",
      "[Epoch 26/1000] [Batch 52/168] [D loss: 0.000556] [G loss: 8.329385]\n",
      "[Epoch 26/1000] [Batch 53/168] [D loss: 0.000461] [G loss: 8.421015]\n",
      "[Epoch 26/1000] [Batch 54/168] [D loss: 0.000362] [G loss: 8.433958]\n",
      "[Epoch 26/1000] [Batch 55/168] [D loss: 0.000362] [G loss: 8.345630]\n",
      "[Epoch 26/1000] [Batch 56/168] [D loss: 0.000510] [G loss: 8.442271]\n",
      "[Epoch 26/1000] [Batch 57/168] [D loss: 0.000452] [G loss: 8.237596]\n",
      "[Epoch 26/1000] [Batch 58/168] [D loss: 0.000372] [G loss: 8.463657]\n",
      "[Epoch 26/1000] [Batch 59/168] [D loss: 0.000696] [G loss: 8.060819]\n",
      "[Epoch 26/1000] [Batch 60/168] [D loss: 0.000431] [G loss: 8.434052]\n",
      "[Epoch 26/1000] [Batch 61/168] [D loss: 0.000556] [G loss: 8.581955]\n",
      "[Epoch 26/1000] [Batch 62/168] [D loss: 0.000593] [G loss: 8.371873]\n",
      "[Epoch 26/1000] [Batch 63/168] [D loss: 0.000610] [G loss: 8.493106]\n",
      "[Epoch 26/1000] [Batch 64/168] [D loss: 0.000538] [G loss: 8.148182]\n",
      "[Epoch 26/1000] [Batch 65/168] [D loss: 0.000487] [G loss: 8.292387]\n",
      "[Epoch 26/1000] [Batch 66/168] [D loss: 0.000409] [G loss: 8.378049]\n",
      "[Epoch 26/1000] [Batch 67/168] [D loss: 0.000469] [G loss: 8.545006]\n",
      "[Epoch 26/1000] [Batch 68/168] [D loss: 0.000488] [G loss: 8.320840]\n",
      "[Epoch 26/1000] [Batch 69/168] [D loss: 0.000784] [G loss: 7.984763]\n",
      "[Epoch 26/1000] [Batch 70/168] [D loss: 0.000711] [G loss: 8.375595]\n",
      "[Epoch 26/1000] [Batch 71/168] [D loss: 0.000545] [G loss: 8.349752]\n",
      "[Epoch 26/1000] [Batch 72/168] [D loss: 0.000432] [G loss: 8.071015]\n",
      "[Epoch 26/1000] [Batch 73/168] [D loss: 0.000443] [G loss: 8.078668]\n",
      "[Epoch 26/1000] [Batch 74/168] [D loss: 0.000542] [G loss: 8.300081]\n",
      "[Epoch 26/1000] [Batch 75/168] [D loss: 0.000411] [G loss: 8.350121]\n",
      "[Epoch 26/1000] [Batch 76/168] [D loss: 0.000442] [G loss: 8.388129]\n",
      "[Epoch 26/1000] [Batch 77/168] [D loss: 0.000363] [G loss: 8.432868]\n",
      "[Epoch 26/1000] [Batch 78/168] [D loss: 0.000361] [G loss: 8.518245]\n",
      "[Epoch 26/1000] [Batch 79/168] [D loss: 0.000339] [G loss: 8.508922]\n",
      "[Epoch 26/1000] [Batch 80/168] [D loss: 0.000672] [G loss: 8.453992]\n",
      "[Epoch 26/1000] [Batch 81/168] [D loss: 0.000478] [G loss: 8.310828]\n",
      "[Epoch 26/1000] [Batch 82/168] [D loss: 0.000659] [G loss: 8.534300]\n",
      "[Epoch 26/1000] [Batch 83/168] [D loss: 0.000625] [G loss: 8.344020]\n",
      "[Epoch 26/1000] [Batch 84/168] [D loss: 0.000588] [G loss: 7.956234]\n",
      "[Epoch 26/1000] [Batch 85/168] [D loss: 0.000489] [G loss: 8.190573]\n",
      "[Epoch 26/1000] [Batch 86/168] [D loss: 0.000488] [G loss: 8.239210]\n",
      "[Epoch 26/1000] [Batch 87/168] [D loss: 0.000503] [G loss: 8.182029]\n",
      "[Epoch 26/1000] [Batch 88/168] [D loss: 0.000486] [G loss: 8.221368]\n",
      "[Epoch 26/1000] [Batch 89/168] [D loss: 0.000660] [G loss: 8.164591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/1000] [Batch 90/168] [D loss: 0.000436] [G loss: 8.053765]\n",
      "[Epoch 26/1000] [Batch 91/168] [D loss: 0.000403] [G loss: 8.507367]\n",
      "[Epoch 26/1000] [Batch 92/168] [D loss: 0.000509] [G loss: 8.161836]\n",
      "[Epoch 26/1000] [Batch 93/168] [D loss: 0.000801] [G loss: 8.383947]\n",
      "[Epoch 26/1000] [Batch 94/168] [D loss: 0.000657] [G loss: 8.087810]\n",
      "[Epoch 26/1000] [Batch 95/168] [D loss: 0.000631] [G loss: 8.006345]\n",
      "[Epoch 26/1000] [Batch 96/168] [D loss: 0.000587] [G loss: 8.186792]\n",
      "[Epoch 26/1000] [Batch 97/168] [D loss: 0.000667] [G loss: 7.770875]\n",
      "[Epoch 26/1000] [Batch 98/168] [D loss: 0.000429] [G loss: 8.167505]\n",
      "[Epoch 26/1000] [Batch 99/168] [D loss: 0.000382] [G loss: 8.177539]\n",
      "[Epoch 26/1000] [Batch 100/168] [D loss: 0.000430] [G loss: 8.246576]\n",
      "[Epoch 26/1000] [Batch 101/168] [D loss: 0.000367] [G loss: 8.389843]\n",
      "[Epoch 26/1000] [Batch 102/168] [D loss: 0.000577] [G loss: 8.598829]\n",
      "[Epoch 26/1000] [Batch 103/168] [D loss: 0.000289] [G loss: 8.610213]\n",
      "[Epoch 26/1000] [Batch 104/168] [D loss: 0.000435] [G loss: 8.649084]\n",
      "[Epoch 26/1000] [Batch 105/168] [D loss: 0.000389] [G loss: 8.661592]\n",
      "[Epoch 26/1000] [Batch 106/168] [D loss: 0.000397] [G loss: 8.644489]\n",
      "[Epoch 26/1000] [Batch 107/168] [D loss: 0.000460] [G loss: 8.642634]\n",
      "[Epoch 26/1000] [Batch 108/168] [D loss: 0.000351] [G loss: 8.501537]\n",
      "[Epoch 26/1000] [Batch 109/168] [D loss: 0.000433] [G loss: 8.404214]\n",
      "[Epoch 26/1000] [Batch 110/168] [D loss: 0.000536] [G loss: 8.204450]\n",
      "[Epoch 26/1000] [Batch 111/168] [D loss: 0.000478] [G loss: 8.258934]\n",
      "[Epoch 26/1000] [Batch 112/168] [D loss: 0.000691] [G loss: 8.106236]\n",
      "[Epoch 26/1000] [Batch 113/168] [D loss: 0.000491] [G loss: 8.299807]\n",
      "[Epoch 26/1000] [Batch 114/168] [D loss: 0.000416] [G loss: 8.099352]\n",
      "[Epoch 26/1000] [Batch 115/168] [D loss: 0.000350] [G loss: 8.488136]\n",
      "[Epoch 26/1000] [Batch 116/168] [D loss: 0.000904] [G loss: 8.165033]\n",
      "[Epoch 26/1000] [Batch 117/168] [D loss: 0.000600] [G loss: 8.354838]\n",
      "[Epoch 26/1000] [Batch 118/168] [D loss: 0.000448] [G loss: 8.257471]\n",
      "[Epoch 26/1000] [Batch 119/168] [D loss: 0.000443] [G loss: 8.152519]\n",
      "[Epoch 26/1000] [Batch 120/168] [D loss: 0.000554] [G loss: 8.250153]\n",
      "[Epoch 26/1000] [Batch 121/168] [D loss: 0.000494] [G loss: 8.291430]\n",
      "[Epoch 26/1000] [Batch 122/168] [D loss: 0.000665] [G loss: 8.270384]\n",
      "[Epoch 26/1000] [Batch 123/168] [D loss: 0.000393] [G loss: 8.063391]\n",
      "[Epoch 26/1000] [Batch 124/168] [D loss: 0.000376] [G loss: 8.367908]\n",
      "[Epoch 26/1000] [Batch 125/168] [D loss: 0.000403] [G loss: 8.220428]\n",
      "[Epoch 26/1000] [Batch 126/168] [D loss: 0.000599] [G loss: 8.219053]\n",
      "[Epoch 26/1000] [Batch 127/168] [D loss: 0.000417] [G loss: 8.618994]\n",
      "[Epoch 26/1000] [Batch 128/168] [D loss: 0.000574] [G loss: 8.279561]\n",
      "[Epoch 26/1000] [Batch 129/168] [D loss: 0.000303] [G loss: 8.394540]\n",
      "[Epoch 26/1000] [Batch 130/168] [D loss: 0.000395] [G loss: 8.356668]\n",
      "[Epoch 26/1000] [Batch 131/168] [D loss: 0.000485] [G loss: 8.457678]\n",
      "[Epoch 26/1000] [Batch 132/168] [D loss: 0.000420] [G loss: 8.258739]\n",
      "[Epoch 26/1000] [Batch 133/168] [D loss: 0.000480] [G loss: 8.493934]\n",
      "[Epoch 26/1000] [Batch 134/168] [D loss: 0.000431] [G loss: 8.335209]\n",
      "[Epoch 26/1000] [Batch 135/168] [D loss: 0.000361] [G loss: 8.499605]\n",
      "[Epoch 26/1000] [Batch 136/168] [D loss: 0.000454] [G loss: 8.388421]\n",
      "[Epoch 26/1000] [Batch 137/168] [D loss: 0.000424] [G loss: 8.234579]\n",
      "[Epoch 26/1000] [Batch 138/168] [D loss: 0.000461] [G loss: 8.490257]\n",
      "[Epoch 26/1000] [Batch 139/168] [D loss: 0.000460] [G loss: 8.349147]\n",
      "[Epoch 26/1000] [Batch 140/168] [D loss: 0.000464] [G loss: 8.496854]\n",
      "[Epoch 26/1000] [Batch 141/168] [D loss: 0.000556] [G loss: 8.489589]\n",
      "[Epoch 26/1000] [Batch 142/168] [D loss: 0.000406] [G loss: 8.508512]\n",
      "[Epoch 26/1000] [Batch 143/168] [D loss: 0.000399] [G loss: 8.331051]\n",
      "[Epoch 26/1000] [Batch 144/168] [D loss: 0.000585] [G loss: 8.364480]\n",
      "[Epoch 26/1000] [Batch 145/168] [D loss: 0.000552] [G loss: 8.193388]\n",
      "[Epoch 26/1000] [Batch 146/168] [D loss: 0.000392] [G loss: 8.141328]\n",
      "[Epoch 26/1000] [Batch 147/168] [D loss: 0.000431] [G loss: 8.512852]\n",
      "[Epoch 26/1000] [Batch 148/168] [D loss: 0.000660] [G loss: 8.038193]\n",
      "[Epoch 26/1000] [Batch 149/168] [D loss: 0.000505] [G loss: 8.373482]\n",
      "[Epoch 26/1000] [Batch 150/168] [D loss: 0.000448] [G loss: 8.544659]\n",
      "[Epoch 26/1000] [Batch 151/168] [D loss: 0.000615] [G loss: 8.411785]\n",
      "[Epoch 26/1000] [Batch 152/168] [D loss: 0.000288] [G loss: 8.546233]\n",
      "[Epoch 26/1000] [Batch 153/168] [D loss: 0.000537] [G loss: 8.280687]\n",
      "[Epoch 26/1000] [Batch 154/168] [D loss: 0.000515] [G loss: 8.006413]\n",
      "[Epoch 26/1000] [Batch 155/168] [D loss: 0.000978] [G loss: 8.209520]\n",
      "[Epoch 26/1000] [Batch 156/168] [D loss: 0.000654] [G loss: 8.335862]\n",
      "[Epoch 26/1000] [Batch 157/168] [D loss: 0.000494] [G loss: 8.046495]\n",
      "[Epoch 26/1000] [Batch 158/168] [D loss: 0.000325] [G loss: 8.319653]\n",
      "[Epoch 26/1000] [Batch 159/168] [D loss: 0.000507] [G loss: 8.121210]\n",
      "[Epoch 26/1000] [Batch 160/168] [D loss: 0.000366] [G loss: 8.432666]\n",
      "[Epoch 26/1000] [Batch 161/168] [D loss: 0.000556] [G loss: 8.581821]\n",
      "[Epoch 26/1000] [Batch 162/168] [D loss: 0.000477] [G loss: 8.648498]\n",
      "[Epoch 26/1000] [Batch 163/168] [D loss: 0.000493] [G loss: 8.431423]\n",
      "[Epoch 26/1000] [Batch 164/168] [D loss: 0.000509] [G loss: 8.267328]\n",
      "[Epoch 26/1000] [Batch 165/168] [D loss: 0.000384] [G loss: 8.478510]\n",
      "[Epoch 26/1000] [Batch 166/168] [D loss: 0.000445] [G loss: 8.427287]\n",
      "[Epoch 26/1000] [Batch 167/168] [D loss: 0.000486] [G loss: 8.367031]\n",
      "[Epoch 26/1000] [Batch 168/168] [D loss: 0.000420] [G loss: 8.209420]\n",
      "[Epoch 27/1000] [Batch 1/168] [D loss: 0.000457] [G loss: 8.446082]\n",
      "[Epoch 27/1000] [Batch 2/168] [D loss: 0.000546] [G loss: 8.641154]\n",
      "[Epoch 27/1000] [Batch 3/168] [D loss: 0.000372] [G loss: 8.284505]\n",
      "[Epoch 27/1000] [Batch 4/168] [D loss: 0.000570] [G loss: 8.201862]\n",
      "[Epoch 27/1000] [Batch 5/168] [D loss: 0.000461] [G loss: 8.322409]\n",
      "[Epoch 27/1000] [Batch 6/168] [D loss: 0.000531] [G loss: 8.361568]\n",
      "[Epoch 27/1000] [Batch 7/168] [D loss: 0.000701] [G loss: 8.486019]\n",
      "[Epoch 27/1000] [Batch 8/168] [D loss: 0.000434] [G loss: 8.213004]\n",
      "[Epoch 27/1000] [Batch 9/168] [D loss: 0.000438] [G loss: 8.217343]\n",
      "[Epoch 27/1000] [Batch 10/168] [D loss: 0.000832] [G loss: 8.269967]\n",
      "[Epoch 27/1000] [Batch 11/168] [D loss: 0.000468] [G loss: 8.067916]\n",
      "[Epoch 27/1000] [Batch 12/168] [D loss: 0.000551] [G loss: 8.332247]\n",
      "[Epoch 27/1000] [Batch 13/168] [D loss: 0.000464] [G loss: 8.415543]\n",
      "[Epoch 27/1000] [Batch 14/168] [D loss: 0.000690] [G loss: 8.336523]\n",
      "[Epoch 27/1000] [Batch 15/168] [D loss: 0.000481] [G loss: 7.937346]\n",
      "[Epoch 27/1000] [Batch 16/168] [D loss: 0.000466] [G loss: 8.228554]\n",
      "[Epoch 27/1000] [Batch 17/168] [D loss: 0.000332] [G loss: 8.441745]\n",
      "[Epoch 27/1000] [Batch 18/168] [D loss: 0.000427] [G loss: 8.518339]\n",
      "[Epoch 27/1000] [Batch 19/168] [D loss: 0.000816] [G loss: 8.441250]\n",
      "[Epoch 27/1000] [Batch 20/168] [D loss: 0.000433] [G loss: 8.433566]\n",
      "[Epoch 27/1000] [Batch 21/168] [D loss: 0.000487] [G loss: 8.343412]\n",
      "[Epoch 27/1000] [Batch 22/168] [D loss: 0.000469] [G loss: 8.002664]\n",
      "[Epoch 27/1000] [Batch 23/168] [D loss: 0.000413] [G loss: 8.145965]\n",
      "[Epoch 27/1000] [Batch 24/168] [D loss: 0.000427] [G loss: 8.201831]\n",
      "[Epoch 27/1000] [Batch 25/168] [D loss: 0.000390] [G loss: 8.898313]\n",
      "[Epoch 27/1000] [Batch 26/168] [D loss: 0.000397] [G loss: 8.735191]\n",
      "[Epoch 27/1000] [Batch 27/168] [D loss: 0.000406] [G loss: 8.848598]\n",
      "[Epoch 27/1000] [Batch 28/168] [D loss: 0.000564] [G loss: 8.543894]\n",
      "[Epoch 27/1000] [Batch 29/168] [D loss: 0.000351] [G loss: 8.605084]\n",
      "[Epoch 27/1000] [Batch 30/168] [D loss: 0.000367] [G loss: 8.430025]\n",
      "[Epoch 27/1000] [Batch 31/168] [D loss: 0.000243] [G loss: 8.653941]\n",
      "[Epoch 27/1000] [Batch 32/168] [D loss: 0.000349] [G loss: 8.625311]\n",
      "[Epoch 27/1000] [Batch 33/168] [D loss: 0.000311] [G loss: 8.684144]\n",
      "[Epoch 27/1000] [Batch 34/168] [D loss: 0.000819] [G loss: 8.299890]\n",
      "[Epoch 27/1000] [Batch 35/168] [D loss: 0.000365] [G loss: 8.455084]\n",
      "[Epoch 27/1000] [Batch 36/168] [D loss: 0.000483] [G loss: 8.614625]\n",
      "[Epoch 27/1000] [Batch 37/168] [D loss: 0.000614] [G loss: 8.416967]\n",
      "[Epoch 27/1000] [Batch 38/168] [D loss: 0.000453] [G loss: 8.427254]\n",
      "[Epoch 27/1000] [Batch 39/168] [D loss: 0.000444] [G loss: 8.108218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/1000] [Batch 40/168] [D loss: 0.000469] [G loss: 8.190536]\n",
      "[Epoch 27/1000] [Batch 41/168] [D loss: 0.000418] [G loss: 8.649929]\n",
      "[Epoch 27/1000] [Batch 42/168] [D loss: 0.000396] [G loss: 8.388938]\n",
      "[Epoch 27/1000] [Batch 43/168] [D loss: 0.000385] [G loss: 8.377745]\n",
      "[Epoch 27/1000] [Batch 44/168] [D loss: 0.000386] [G loss: 8.463129]\n",
      "[Epoch 27/1000] [Batch 45/168] [D loss: 0.000486] [G loss: 8.695988]\n",
      "[Epoch 27/1000] [Batch 46/168] [D loss: 0.000522] [G loss: 8.447138]\n",
      "[Epoch 27/1000] [Batch 47/168] [D loss: 0.000697] [G loss: 8.575391]\n",
      "[Epoch 27/1000] [Batch 48/168] [D loss: 0.000433] [G loss: 8.307605]\n",
      "[Epoch 27/1000] [Batch 49/168] [D loss: 0.000341] [G loss: 8.509661]\n",
      "[Epoch 27/1000] [Batch 50/168] [D loss: 0.000550] [G loss: 8.732204]\n",
      "[Epoch 27/1000] [Batch 51/168] [D loss: 0.000529] [G loss: 8.410521]\n",
      "[Epoch 27/1000] [Batch 52/168] [D loss: 0.000480] [G loss: 8.223915]\n",
      "[Epoch 27/1000] [Batch 53/168] [D loss: 0.000374] [G loss: 8.213911]\n",
      "[Epoch 27/1000] [Batch 54/168] [D loss: 0.000615] [G loss: 8.328711]\n",
      "[Epoch 27/1000] [Batch 55/168] [D loss: 0.000586] [G loss: 8.037305]\n",
      "[Epoch 27/1000] [Batch 56/168] [D loss: 0.000393] [G loss: 8.346334]\n",
      "[Epoch 27/1000] [Batch 57/168] [D loss: 0.000568] [G loss: 8.398734]\n",
      "[Epoch 27/1000] [Batch 58/168] [D loss: 0.000565] [G loss: 8.391082]\n",
      "[Epoch 27/1000] [Batch 59/168] [D loss: 0.000737] [G loss: 8.253922]\n",
      "[Epoch 27/1000] [Batch 60/168] [D loss: 0.000435] [G loss: 8.392860]\n",
      "[Epoch 27/1000] [Batch 61/168] [D loss: 0.000489] [G loss: 8.634768]\n",
      "[Epoch 27/1000] [Batch 62/168] [D loss: 0.000480] [G loss: 8.065147]\n",
      "[Epoch 27/1000] [Batch 63/168] [D loss: 0.000442] [G loss: 8.325856]\n",
      "[Epoch 27/1000] [Batch 64/168] [D loss: 0.000575] [G loss: 8.344927]\n",
      "[Epoch 27/1000] [Batch 65/168] [D loss: 0.000670] [G loss: 8.050197]\n",
      "[Epoch 27/1000] [Batch 66/168] [D loss: 0.000424] [G loss: 8.497639]\n",
      "[Epoch 27/1000] [Batch 67/168] [D loss: 0.000388] [G loss: 8.198102]\n",
      "[Epoch 27/1000] [Batch 68/168] [D loss: 0.000485] [G loss: 8.485737]\n",
      "[Epoch 27/1000] [Batch 69/168] [D loss: 0.000569] [G loss: 8.113727]\n",
      "[Epoch 27/1000] [Batch 70/168] [D loss: 0.000457] [G loss: 8.645668]\n",
      "[Epoch 27/1000] [Batch 71/168] [D loss: 0.000765] [G loss: 8.446406]\n",
      "[Epoch 27/1000] [Batch 72/168] [D loss: 0.000369] [G loss: 8.574031]\n",
      "[Epoch 27/1000] [Batch 73/168] [D loss: 0.000508] [G loss: 8.092399]\n",
      "[Epoch 27/1000] [Batch 74/168] [D loss: 0.000592] [G loss: 7.840792]\n",
      "[Epoch 27/1000] [Batch 75/168] [D loss: 0.000534] [G loss: 8.287409]\n",
      "[Epoch 27/1000] [Batch 76/168] [D loss: 0.000545] [G loss: 8.555941]\n",
      "[Epoch 27/1000] [Batch 77/168] [D loss: 0.000370] [G loss: 8.372869]\n",
      "[Epoch 27/1000] [Batch 78/168] [D loss: 0.000365] [G loss: 8.444633]\n",
      "[Epoch 27/1000] [Batch 79/168] [D loss: 0.000311] [G loss: 8.679674]\n",
      "[Epoch 27/1000] [Batch 80/168] [D loss: 0.000768] [G loss: 8.355196]\n",
      "[Epoch 27/1000] [Batch 81/168] [D loss: 0.000473] [G loss: 8.308182]\n",
      "[Epoch 27/1000] [Batch 82/168] [D loss: 0.000364] [G loss: 8.669350]\n",
      "[Epoch 27/1000] [Batch 83/168] [D loss: 0.000584] [G loss: 8.328659]\n",
      "[Epoch 27/1000] [Batch 84/168] [D loss: 0.000352] [G loss: 8.456231]\n",
      "[Epoch 27/1000] [Batch 85/168] [D loss: 0.000385] [G loss: 8.472044]\n",
      "[Epoch 27/1000] [Batch 86/168] [D loss: 0.000470] [G loss: 8.444795]\n",
      "[Epoch 27/1000] [Batch 87/168] [D loss: 0.000509] [G loss: 8.532732]\n",
      "[Epoch 27/1000] [Batch 88/168] [D loss: 0.000342] [G loss: 8.758886]\n",
      "[Epoch 27/1000] [Batch 89/168] [D loss: 0.000556] [G loss: 8.223141]\n",
      "[Epoch 27/1000] [Batch 90/168] [D loss: 0.000439] [G loss: 8.633721]\n",
      "[Epoch 27/1000] [Batch 91/168] [D loss: 0.000989] [G loss: 8.136256]\n",
      "[Epoch 27/1000] [Batch 92/168] [D loss: 0.000339] [G loss: 8.398618]\n",
      "[Epoch 27/1000] [Batch 93/168] [D loss: 0.000593] [G loss: 8.334185]\n",
      "[Epoch 27/1000] [Batch 94/168] [D loss: 0.000506] [G loss: 7.992794]\n",
      "[Epoch 27/1000] [Batch 95/168] [D loss: 0.000454] [G loss: 8.223689]\n",
      "[Epoch 27/1000] [Batch 96/168] [D loss: 0.000405] [G loss: 8.491023]\n",
      "[Epoch 27/1000] [Batch 97/168] [D loss: 0.000289] [G loss: 8.572733]\n",
      "[Epoch 27/1000] [Batch 98/168] [D loss: 0.000417] [G loss: 8.459683]\n",
      "[Epoch 27/1000] [Batch 99/168] [D loss: 0.000294] [G loss: 8.593148]\n",
      "[Epoch 27/1000] [Batch 100/168] [D loss: 0.000485] [G loss: 8.313263]\n",
      "[Epoch 27/1000] [Batch 101/168] [D loss: 0.000325] [G loss: 8.497002]\n",
      "[Epoch 27/1000] [Batch 102/168] [D loss: 0.000623] [G loss: 8.592625]\n",
      "[Epoch 27/1000] [Batch 103/168] [D loss: 0.000606] [G loss: 8.538754]\n",
      "[Epoch 27/1000] [Batch 104/168] [D loss: 0.000378] [G loss: 8.372504]\n",
      "[Epoch 27/1000] [Batch 105/168] [D loss: 0.000355] [G loss: 8.535053]\n",
      "[Epoch 27/1000] [Batch 106/168] [D loss: 0.000486] [G loss: 8.529894]\n",
      "[Epoch 27/1000] [Batch 107/168] [D loss: 0.000396] [G loss: 8.287285]\n",
      "[Epoch 27/1000] [Batch 108/168] [D loss: 0.000356] [G loss: 8.317518]\n",
      "[Epoch 27/1000] [Batch 109/168] [D loss: 0.000657] [G loss: 8.227788]\n",
      "[Epoch 27/1000] [Batch 110/168] [D loss: 0.000702] [G loss: 8.387983]\n",
      "[Epoch 27/1000] [Batch 111/168] [D loss: 0.000545] [G loss: 8.147547]\n",
      "[Epoch 27/1000] [Batch 112/168] [D loss: 0.000486] [G loss: 8.209356]\n",
      "[Epoch 27/1000] [Batch 113/168] [D loss: 0.000414] [G loss: 8.308866]\n",
      "[Epoch 27/1000] [Batch 114/168] [D loss: 0.000460] [G loss: 8.429460]\n",
      "[Epoch 27/1000] [Batch 115/168] [D loss: 0.000387] [G loss: 8.290534]\n",
      "[Epoch 27/1000] [Batch 116/168] [D loss: 0.000405] [G loss: 8.110359]\n",
      "[Epoch 27/1000] [Batch 117/168] [D loss: 0.000364] [G loss: 8.642311]\n",
      "[Epoch 27/1000] [Batch 118/168] [D loss: 0.000368] [G loss: 8.372841]\n",
      "[Epoch 27/1000] [Batch 119/168] [D loss: 0.000293] [G loss: 8.951014]\n",
      "[Epoch 27/1000] [Batch 120/168] [D loss: 0.000353] [G loss: 8.669289]\n",
      "[Epoch 27/1000] [Batch 121/168] [D loss: 0.000341] [G loss: 8.639459]\n",
      "[Epoch 27/1000] [Batch 122/168] [D loss: 0.000621] [G loss: 9.247927]\n",
      "[Epoch 27/1000] [Batch 123/168] [D loss: 0.000268] [G loss: 8.527750]\n",
      "[Epoch 27/1000] [Batch 124/168] [D loss: 0.000568] [G loss: 8.390529]\n",
      "[Epoch 27/1000] [Batch 125/168] [D loss: 0.000765] [G loss: 8.115877]\n",
      "[Epoch 27/1000] [Batch 126/168] [D loss: 0.000454] [G loss: 8.429125]\n",
      "[Epoch 27/1000] [Batch 127/168] [D loss: 0.000333] [G loss: 8.678845]\n",
      "[Epoch 27/1000] [Batch 128/168] [D loss: 0.000640] [G loss: 8.194400]\n",
      "[Epoch 27/1000] [Batch 129/168] [D loss: 0.000373] [G loss: 8.575504]\n",
      "[Epoch 27/1000] [Batch 130/168] [D loss: 0.000482] [G loss: 8.443461]\n",
      "[Epoch 27/1000] [Batch 131/168] [D loss: 0.000343] [G loss: 8.543228]\n",
      "[Epoch 27/1000] [Batch 132/168] [D loss: 0.000607] [G loss: 8.303110]\n",
      "[Epoch 27/1000] [Batch 133/168] [D loss: 0.000369] [G loss: 8.465446]\n",
      "[Epoch 27/1000] [Batch 134/168] [D loss: 0.000342] [G loss: 8.507908]\n",
      "[Epoch 27/1000] [Batch 135/168] [D loss: 0.000484] [G loss: 8.852496]\n",
      "[Epoch 27/1000] [Batch 136/168] [D loss: 0.000415] [G loss: 8.654765]\n",
      "[Epoch 27/1000] [Batch 137/168] [D loss: 0.000439] [G loss: 8.660021]\n",
      "[Epoch 27/1000] [Batch 138/168] [D loss: 0.000413] [G loss: 8.700476]\n",
      "[Epoch 27/1000] [Batch 139/168] [D loss: 0.000493] [G loss: 8.269071]\n",
      "[Epoch 27/1000] [Batch 140/168] [D loss: 0.000511] [G loss: 8.512978]\n",
      "[Epoch 27/1000] [Batch 141/168] [D loss: 0.000558] [G loss: 8.198387]\n",
      "[Epoch 27/1000] [Batch 142/168] [D loss: 0.000462] [G loss: 8.748936]\n",
      "[Epoch 27/1000] [Batch 143/168] [D loss: 0.000343] [G loss: 8.411896]\n",
      "[Epoch 27/1000] [Batch 144/168] [D loss: 0.000587] [G loss: 8.058578]\n",
      "[Epoch 27/1000] [Batch 145/168] [D loss: 0.000478] [G loss: 8.343086]\n",
      "[Epoch 27/1000] [Batch 146/168] [D loss: 0.000477] [G loss: 8.684424]\n",
      "[Epoch 27/1000] [Batch 147/168] [D loss: 0.000400] [G loss: 8.253588]\n",
      "[Epoch 27/1000] [Batch 148/168] [D loss: 0.000586] [G loss: 8.328060]\n",
      "[Epoch 27/1000] [Batch 149/168] [D loss: 0.000575] [G loss: 8.227011]\n",
      "[Epoch 27/1000] [Batch 150/168] [D loss: 0.000413] [G loss: 8.608248]\n",
      "[Epoch 27/1000] [Batch 151/168] [D loss: 0.000677] [G loss: 8.596391]\n",
      "[Epoch 27/1000] [Batch 152/168] [D loss: 0.000545] [G loss: 8.395511]\n",
      "[Epoch 27/1000] [Batch 153/168] [D loss: 0.000569] [G loss: 8.480402]\n",
      "[Epoch 27/1000] [Batch 154/168] [D loss: 0.000540] [G loss: 7.918095]\n",
      "[Epoch 27/1000] [Batch 155/168] [D loss: 0.000462] [G loss: 8.260051]\n",
      "[Epoch 27/1000] [Batch 156/168] [D loss: 0.000544] [G loss: 8.389790]\n",
      "[Epoch 27/1000] [Batch 157/168] [D loss: 0.000528] [G loss: 8.651834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/1000] [Batch 158/168] [D loss: 0.000370] [G loss: 8.501406]\n",
      "[Epoch 27/1000] [Batch 159/168] [D loss: 0.001144] [G loss: 8.709527]\n",
      "[Epoch 27/1000] [Batch 160/168] [D loss: 0.000524] [G loss: 8.011278]\n",
      "[Epoch 27/1000] [Batch 161/168] [D loss: 0.000513] [G loss: 8.063300]\n",
      "[Epoch 27/1000] [Batch 162/168] [D loss: 0.000542] [G loss: 8.065793]\n",
      "[Epoch 27/1000] [Batch 163/168] [D loss: 0.000614] [G loss: 8.211088]\n",
      "[Epoch 27/1000] [Batch 164/168] [D loss: 0.000644] [G loss: 8.481770]\n",
      "[Epoch 27/1000] [Batch 165/168] [D loss: 0.000557] [G loss: 8.162621]\n",
      "[Epoch 27/1000] [Batch 166/168] [D loss: 0.000446] [G loss: 8.299098]\n",
      "[Epoch 27/1000] [Batch 167/168] [D loss: 0.000516] [G loss: 8.417705]\n",
      "[Epoch 27/1000] [Batch 168/168] [D loss: 0.000627] [G loss: 8.530554]\n",
      "[Epoch 28/1000] [Batch 1/168] [D loss: 0.000384] [G loss: 8.277906]\n",
      "[Epoch 28/1000] [Batch 2/168] [D loss: 0.000283] [G loss: 8.651781]\n",
      "[Epoch 28/1000] [Batch 3/168] [D loss: 0.000412] [G loss: 8.467127]\n",
      "[Epoch 28/1000] [Batch 4/168] [D loss: 0.000457] [G loss: 8.409491]\n",
      "[Epoch 28/1000] [Batch 5/168] [D loss: 0.000527] [G loss: 8.665249]\n",
      "[Epoch 28/1000] [Batch 6/168] [D loss: 0.000413] [G loss: 8.531986]\n",
      "[Epoch 28/1000] [Batch 7/168] [D loss: 0.000447] [G loss: 8.395630]\n",
      "[Epoch 28/1000] [Batch 8/168] [D loss: 0.000670] [G loss: 8.652179]\n",
      "[Epoch 28/1000] [Batch 9/168] [D loss: 0.000426] [G loss: 8.819797]\n",
      "[Epoch 28/1000] [Batch 10/168] [D loss: 0.000639] [G loss: 8.241932]\n",
      "[Epoch 28/1000] [Batch 11/168] [D loss: 0.000482] [G loss: 8.036040]\n",
      "[Epoch 28/1000] [Batch 12/168] [D loss: 0.000339] [G loss: 8.542405]\n",
      "[Epoch 28/1000] [Batch 13/168] [D loss: 0.000481] [G loss: 8.472641]\n",
      "[Epoch 28/1000] [Batch 14/168] [D loss: 0.000417] [G loss: 8.693701]\n",
      "[Epoch 28/1000] [Batch 15/168] [D loss: 0.000484] [G loss: 8.331808]\n",
      "[Epoch 28/1000] [Batch 16/168] [D loss: 0.000533] [G loss: 8.327999]\n",
      "[Epoch 28/1000] [Batch 17/168] [D loss: 0.000428] [G loss: 8.303617]\n",
      "[Epoch 28/1000] [Batch 18/168] [D loss: 0.000728] [G loss: 8.358231]\n",
      "[Epoch 28/1000] [Batch 19/168] [D loss: 0.000449] [G loss: 8.389811]\n",
      "[Epoch 28/1000] [Batch 20/168] [D loss: 0.000468] [G loss: 8.315836]\n",
      "[Epoch 28/1000] [Batch 21/168] [D loss: 0.000403] [G loss: 8.701353]\n",
      "[Epoch 28/1000] [Batch 22/168] [D loss: 0.000334] [G loss: 8.416505]\n",
      "[Epoch 28/1000] [Batch 23/168] [D loss: 0.000624] [G loss: 8.802507]\n",
      "[Epoch 28/1000] [Batch 24/168] [D loss: 0.000409] [G loss: 8.210216]\n",
      "[Epoch 28/1000] [Batch 25/168] [D loss: 0.000670] [G loss: 8.428512]\n",
      "[Epoch 28/1000] [Batch 26/168] [D loss: 0.000478] [G loss: 8.463228]\n",
      "[Epoch 28/1000] [Batch 27/168] [D loss: 0.000489] [G loss: 8.192986]\n",
      "[Epoch 28/1000] [Batch 28/168] [D loss: 0.000567] [G loss: 8.387050]\n",
      "[Epoch 28/1000] [Batch 29/168] [D loss: 0.000405] [G loss: 8.564727]\n",
      "[Epoch 28/1000] [Batch 30/168] [D loss: 0.000669] [G loss: 8.122741]\n",
      "[Epoch 28/1000] [Batch 31/168] [D loss: 0.000445] [G loss: 8.312045]\n",
      "[Epoch 28/1000] [Batch 32/168] [D loss: 0.000417] [G loss: 8.831043]\n",
      "[Epoch 28/1000] [Batch 33/168] [D loss: 0.000511] [G loss: 8.476204]\n",
      "[Epoch 28/1000] [Batch 34/168] [D loss: 0.000669] [G loss: 8.385395]\n",
      "[Epoch 28/1000] [Batch 35/168] [D loss: 0.000444] [G loss: 8.345680]\n",
      "[Epoch 28/1000] [Batch 36/168] [D loss: 0.000444] [G loss: 8.588952]\n",
      "[Epoch 28/1000] [Batch 37/168] [D loss: 0.000557] [G loss: 8.372278]\n",
      "[Epoch 28/1000] [Batch 38/168] [D loss: 0.000555] [G loss: 8.471259]\n",
      "[Epoch 28/1000] [Batch 39/168] [D loss: 0.000582] [G loss: 8.488334]\n",
      "[Epoch 28/1000] [Batch 40/168] [D loss: 0.000383] [G loss: 8.482003]\n",
      "[Epoch 28/1000] [Batch 41/168] [D loss: 0.000989] [G loss: 8.415999]\n",
      "[Epoch 28/1000] [Batch 42/168] [D loss: 0.000669] [G loss: 7.878711]\n",
      "[Epoch 28/1000] [Batch 43/168] [D loss: 0.000563] [G loss: 8.239352]\n",
      "[Epoch 28/1000] [Batch 44/168] [D loss: 0.000581] [G loss: 8.561317]\n",
      "[Epoch 28/1000] [Batch 45/168] [D loss: 0.000609] [G loss: 8.208449]\n",
      "[Epoch 28/1000] [Batch 46/168] [D loss: 0.000473] [G loss: 8.035204]\n",
      "[Epoch 28/1000] [Batch 47/168] [D loss: 0.000659] [G loss: 8.485459]\n",
      "[Epoch 28/1000] [Batch 48/168] [D loss: 0.000474] [G loss: 8.115833]\n",
      "[Epoch 28/1000] [Batch 49/168] [D loss: 0.000672] [G loss: 7.945674]\n",
      "[Epoch 28/1000] [Batch 50/168] [D loss: 0.000336] [G loss: 8.498981]\n",
      "[Epoch 28/1000] [Batch 51/168] [D loss: 0.000636] [G loss: 8.331351]\n",
      "[Epoch 28/1000] [Batch 52/168] [D loss: 0.000315] [G loss: 8.732875]\n",
      "[Epoch 28/1000] [Batch 53/168] [D loss: 0.000432] [G loss: 8.358105]\n",
      "[Epoch 28/1000] [Batch 54/168] [D loss: 0.001287] [G loss: 8.501299]\n",
      "[Epoch 28/1000] [Batch 55/168] [D loss: 0.000732] [G loss: 7.779867]\n",
      "[Epoch 28/1000] [Batch 56/168] [D loss: 0.000497] [G loss: 8.433265]\n",
      "[Epoch 28/1000] [Batch 57/168] [D loss: 0.000452] [G loss: 8.290001]\n",
      "[Epoch 28/1000] [Batch 58/168] [D loss: 0.000577] [G loss: 8.365480]\n",
      "[Epoch 28/1000] [Batch 59/168] [D loss: 0.000413] [G loss: 8.315847]\n",
      "[Epoch 28/1000] [Batch 60/168] [D loss: 0.000682] [G loss: 8.512894]\n",
      "[Epoch 28/1000] [Batch 61/168] [D loss: 0.000467] [G loss: 8.644562]\n",
      "[Epoch 28/1000] [Batch 62/168] [D loss: 0.000457] [G loss: 8.475736]\n",
      "[Epoch 28/1000] [Batch 63/168] [D loss: 0.000781] [G loss: 8.492012]\n",
      "[Epoch 28/1000] [Batch 64/168] [D loss: 0.000766] [G loss: 8.199958]\n",
      "[Epoch 28/1000] [Batch 65/168] [D loss: 0.000391] [G loss: 8.193576]\n",
      "[Epoch 28/1000] [Batch 66/168] [D loss: 0.000841] [G loss: 8.237684]\n",
      "[Epoch 28/1000] [Batch 67/168] [D loss: 0.000582] [G loss: 8.070265]\n",
      "[Epoch 28/1000] [Batch 68/168] [D loss: 0.000477] [G loss: 8.251862]\n",
      "[Epoch 28/1000] [Batch 69/168] [D loss: 0.000497] [G loss: 8.306751]\n",
      "[Epoch 28/1000] [Batch 70/168] [D loss: 0.000305] [G loss: 8.592822]\n",
      "[Epoch 28/1000] [Batch 71/168] [D loss: 0.000534] [G loss: 8.230319]\n",
      "[Epoch 28/1000] [Batch 72/168] [D loss: 0.000481] [G loss: 8.522972]\n",
      "[Epoch 28/1000] [Batch 73/168] [D loss: 0.000422] [G loss: 8.499494]\n",
      "[Epoch 28/1000] [Batch 74/168] [D loss: 0.000418] [G loss: 8.856018]\n",
      "[Epoch 28/1000] [Batch 75/168] [D loss: 0.000498] [G loss: 8.666360]\n",
      "[Epoch 28/1000] [Batch 76/168] [D loss: 0.000382] [G loss: 8.554687]\n",
      "[Epoch 28/1000] [Batch 77/168] [D loss: 0.000467] [G loss: 8.615261]\n",
      "[Epoch 28/1000] [Batch 78/168] [D loss: 0.000665] [G loss: 8.308628]\n",
      "[Epoch 28/1000] [Batch 79/168] [D loss: 0.000433] [G loss: 8.440680]\n",
      "[Epoch 28/1000] [Batch 80/168] [D loss: 0.000367] [G loss: 8.334206]\n",
      "[Epoch 28/1000] [Batch 81/168] [D loss: 0.000637] [G loss: 8.319573]\n",
      "[Epoch 28/1000] [Batch 82/168] [D loss: 0.000485] [G loss: 8.177580]\n",
      "[Epoch 28/1000] [Batch 83/168] [D loss: 0.002296] [G loss: 8.312569]\n",
      "[Epoch 28/1000] [Batch 84/168] [D loss: 0.001034] [G loss: 7.404514]\n",
      "[Epoch 28/1000] [Batch 85/168] [D loss: 0.000756] [G loss: 7.409811]\n",
      "[Epoch 28/1000] [Batch 86/168] [D loss: 0.000737] [G loss: 7.916238]\n",
      "[Epoch 28/1000] [Batch 87/168] [D loss: 0.000634] [G loss: 8.112220]\n",
      "[Epoch 28/1000] [Batch 88/168] [D loss: 0.000470] [G loss: 8.005827]\n",
      "[Epoch 28/1000] [Batch 89/168] [D loss: 0.000560] [G loss: 8.338043]\n",
      "[Epoch 28/1000] [Batch 90/168] [D loss: 0.000349] [G loss: 8.702867]\n",
      "[Epoch 28/1000] [Batch 91/168] [D loss: 0.000372] [G loss: 8.768494]\n",
      "[Epoch 28/1000] [Batch 92/168] [D loss: 0.000348] [G loss: 8.846899]\n",
      "[Epoch 28/1000] [Batch 93/168] [D loss: 0.000438] [G loss: 8.865011]\n",
      "[Epoch 28/1000] [Batch 94/168] [D loss: 0.000321] [G loss: 8.933422]\n",
      "[Epoch 28/1000] [Batch 95/168] [D loss: 0.000503] [G loss: 8.632922]\n",
      "[Epoch 28/1000] [Batch 96/168] [D loss: 0.000441] [G loss: 8.385029]\n",
      "[Epoch 28/1000] [Batch 97/168] [D loss: 0.000435] [G loss: 8.354500]\n",
      "[Epoch 28/1000] [Batch 98/168] [D loss: 0.000381] [G loss: 8.492300]\n",
      "[Epoch 28/1000] [Batch 99/168] [D loss: 0.000611] [G loss: 8.535074]\n",
      "[Epoch 28/1000] [Batch 100/168] [D loss: 0.000502] [G loss: 8.078192]\n",
      "[Epoch 28/1000] [Batch 101/168] [D loss: 0.000415] [G loss: 8.473263]\n",
      "[Epoch 28/1000] [Batch 102/168] [D loss: 0.000311] [G loss: 8.764384]\n",
      "[Epoch 28/1000] [Batch 103/168] [D loss: 0.000461] [G loss: 8.484109]\n",
      "[Epoch 28/1000] [Batch 104/168] [D loss: 0.000383] [G loss: 8.498766]\n",
      "[Epoch 28/1000] [Batch 105/168] [D loss: 0.000398] [G loss: 8.533744]\n",
      "[Epoch 28/1000] [Batch 106/168] [D loss: 0.000521] [G loss: 8.550884]\n",
      "[Epoch 28/1000] [Batch 107/168] [D loss: 0.000459] [G loss: 8.549487]\n",
      "[Epoch 28/1000] [Batch 108/168] [D loss: 0.000546] [G loss: 8.797501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/1000] [Batch 109/168] [D loss: 0.000470] [G loss: 8.460011]\n",
      "[Epoch 28/1000] [Batch 110/168] [D loss: 0.000396] [G loss: 8.112253]\n",
      "[Epoch 28/1000] [Batch 111/168] [D loss: 0.000378] [G loss: 8.638383]\n",
      "[Epoch 28/1000] [Batch 112/168] [D loss: 0.000342] [G loss: 8.340549]\n",
      "[Epoch 28/1000] [Batch 113/168] [D loss: 0.000489] [G loss: 8.217099]\n",
      "[Epoch 28/1000] [Batch 114/168] [D loss: 0.000417] [G loss: 8.249196]\n",
      "[Epoch 28/1000] [Batch 115/168] [D loss: 0.000541] [G loss: 8.553991]\n",
      "[Epoch 28/1000] [Batch 116/168] [D loss: 0.000416] [G loss: 8.567523]\n",
      "[Epoch 28/1000] [Batch 117/168] [D loss: 0.000550] [G loss: 8.676160]\n",
      "[Epoch 28/1000] [Batch 118/168] [D loss: 0.000506] [G loss: 8.636462]\n",
      "[Epoch 28/1000] [Batch 119/168] [D loss: 0.000582] [G loss: 8.849718]\n",
      "[Epoch 28/1000] [Batch 120/168] [D loss: 0.000429] [G loss: 8.403985]\n",
      "[Epoch 28/1000] [Batch 121/168] [D loss: 0.000416] [G loss: 8.345261]\n",
      "[Epoch 28/1000] [Batch 122/168] [D loss: 0.000462] [G loss: 8.239815]\n",
      "[Epoch 28/1000] [Batch 123/168] [D loss: 0.000499] [G loss: 8.255811]\n",
      "[Epoch 28/1000] [Batch 124/168] [D loss: 0.000613] [G loss: 8.320472]\n",
      "[Epoch 28/1000] [Batch 125/168] [D loss: 0.000564] [G loss: 8.185245]\n",
      "[Epoch 28/1000] [Batch 126/168] [D loss: 0.000810] [G loss: 8.275767]\n",
      "[Epoch 28/1000] [Batch 127/168] [D loss: 0.000486] [G loss: 8.561277]\n",
      "[Epoch 28/1000] [Batch 128/168] [D loss: 0.000585] [G loss: 8.187656]\n",
      "[Epoch 28/1000] [Batch 129/168] [D loss: 0.000303] [G loss: 8.602498]\n",
      "[Epoch 28/1000] [Batch 130/168] [D loss: 0.000375] [G loss: 8.941591]\n",
      "[Epoch 28/1000] [Batch 131/168] [D loss: 0.000401] [G loss: 8.847752]\n",
      "[Epoch 28/1000] [Batch 132/168] [D loss: 0.000416] [G loss: 8.776665]\n",
      "[Epoch 28/1000] [Batch 133/168] [D loss: 0.000691] [G loss: 8.342509]\n",
      "[Epoch 28/1000] [Batch 134/168] [D loss: 0.000488] [G loss: 8.342938]\n",
      "[Epoch 28/1000] [Batch 135/168] [D loss: 0.000430] [G loss: 8.709458]\n",
      "[Epoch 28/1000] [Batch 136/168] [D loss: 0.000421] [G loss: 8.374941]\n",
      "[Epoch 28/1000] [Batch 137/168] [D loss: 0.000378] [G loss: 8.521277]\n",
      "[Epoch 28/1000] [Batch 138/168] [D loss: 0.000387] [G loss: 8.754115]\n",
      "[Epoch 28/1000] [Batch 139/168] [D loss: 0.000402] [G loss: 8.472640]\n",
      "[Epoch 28/1000] [Batch 140/168] [D loss: 0.000334] [G loss: 8.455501]\n",
      "[Epoch 28/1000] [Batch 141/168] [D loss: 0.000416] [G loss: 8.797205]\n",
      "[Epoch 28/1000] [Batch 142/168] [D loss: 0.000456] [G loss: 8.599384]\n",
      "[Epoch 28/1000] [Batch 143/168] [D loss: 0.000325] [G loss: 8.941504]\n",
      "[Epoch 28/1000] [Batch 144/168] [D loss: 0.000944] [G loss: 8.677886]\n",
      "[Epoch 28/1000] [Batch 145/168] [D loss: 0.000831] [G loss: 8.162016]\n",
      "[Epoch 28/1000] [Batch 146/168] [D loss: 0.000500] [G loss: 8.068572]\n",
      "[Epoch 28/1000] [Batch 147/168] [D loss: 0.000434] [G loss: 8.192299]\n",
      "[Epoch 28/1000] [Batch 148/168] [D loss: 0.000340] [G loss: 8.360958]\n",
      "[Epoch 28/1000] [Batch 149/168] [D loss: 0.000379] [G loss: 8.423740]\n",
      "[Epoch 28/1000] [Batch 150/168] [D loss: 0.000300] [G loss: 8.791862]\n",
      "[Epoch 28/1000] [Batch 151/168] [D loss: 0.000580] [G loss: 8.963158]\n",
      "[Epoch 28/1000] [Batch 152/168] [D loss: 0.000400] [G loss: 8.425954]\n",
      "[Epoch 28/1000] [Batch 153/168] [D loss: 0.000341] [G loss: 8.711753]\n",
      "[Epoch 28/1000] [Batch 154/168] [D loss: 0.000400] [G loss: 8.777188]\n",
      "[Epoch 28/1000] [Batch 155/168] [D loss: 0.000344] [G loss: 8.670339]\n",
      "[Epoch 28/1000] [Batch 156/168] [D loss: 0.000403] [G loss: 8.585848]\n",
      "[Epoch 28/1000] [Batch 157/168] [D loss: 0.000461] [G loss: 8.668907]\n",
      "[Epoch 28/1000] [Batch 158/168] [D loss: 0.000224] [G loss: 8.773151]\n",
      "[Epoch 28/1000] [Batch 159/168] [D loss: 0.000458] [G loss: 8.401878]\n",
      "[Epoch 28/1000] [Batch 160/168] [D loss: 0.000275] [G loss: 8.573093]\n",
      "[Epoch 28/1000] [Batch 161/168] [D loss: 0.000482] [G loss: 8.633455]\n",
      "[Epoch 28/1000] [Batch 162/168] [D loss: 0.000351] [G loss: 8.893878]\n",
      "[Epoch 28/1000] [Batch 163/168] [D loss: 0.000555] [G loss: 8.414061]\n",
      "[Epoch 28/1000] [Batch 164/168] [D loss: 0.000389] [G loss: 8.615150]\n",
      "[Epoch 28/1000] [Batch 165/168] [D loss: 0.000298] [G loss: 8.899670]\n",
      "[Epoch 28/1000] [Batch 166/168] [D loss: 0.000258] [G loss: 8.795867]\n",
      "[Epoch 28/1000] [Batch 167/168] [D loss: 0.000484] [G loss: 8.615597]\n",
      "[Epoch 28/1000] [Batch 168/168] [D loss: 0.000518] [G loss: 8.601376]\n",
      "[Epoch 29/1000] [Batch 1/168] [D loss: 0.000549] [G loss: 8.370121]\n",
      "[Epoch 29/1000] [Batch 2/168] [D loss: 0.000408] [G loss: 8.340555]\n",
      "[Epoch 29/1000] [Batch 3/168] [D loss: 0.000386] [G loss: 8.588694]\n",
      "[Epoch 29/1000] [Batch 4/168] [D loss: 0.000197] [G loss: 9.167970]\n",
      "[Epoch 29/1000] [Batch 5/168] [D loss: 0.000293] [G loss: 8.915999]\n",
      "[Epoch 29/1000] [Batch 6/168] [D loss: 0.000242] [G loss: 9.168945]\n",
      "[Epoch 29/1000] [Batch 7/168] [D loss: 0.000465] [G loss: 8.673283]\n",
      "[Epoch 29/1000] [Batch 8/168] [D loss: 0.000410] [G loss: 9.255909]\n",
      "[Epoch 29/1000] [Batch 9/168] [D loss: 0.000304] [G loss: 8.697425]\n",
      "[Epoch 29/1000] [Batch 10/168] [D loss: 0.000219] [G loss: 8.653819]\n",
      "[Epoch 29/1000] [Batch 11/168] [D loss: 0.000591] [G loss: 8.672503]\n",
      "[Epoch 29/1000] [Batch 12/168] [D loss: 0.000421] [G loss: 8.631797]\n",
      "[Epoch 29/1000] [Batch 13/168] [D loss: 0.000275] [G loss: 8.978329]\n",
      "[Epoch 29/1000] [Batch 14/168] [D loss: 0.000354] [G loss: 8.412992]\n",
      "[Epoch 29/1000] [Batch 15/168] [D loss: 0.000484] [G loss: 8.876472]\n",
      "[Epoch 29/1000] [Batch 16/168] [D loss: 0.000304] [G loss: 8.713346]\n",
      "[Epoch 29/1000] [Batch 17/168] [D loss: 0.000256] [G loss: 8.723211]\n",
      "[Epoch 29/1000] [Batch 18/168] [D loss: 0.000341] [G loss: 8.662526]\n",
      "[Epoch 29/1000] [Batch 19/168] [D loss: 0.000334] [G loss: 8.893423]\n",
      "[Epoch 29/1000] [Batch 20/168] [D loss: 0.000238] [G loss: 8.919333]\n",
      "[Epoch 29/1000] [Batch 21/168] [D loss: 0.000500] [G loss: 8.620154]\n",
      "[Epoch 29/1000] [Batch 22/168] [D loss: 0.000244] [G loss: 8.873791]\n",
      "[Epoch 29/1000] [Batch 23/168] [D loss: 0.000437] [G loss: 8.548800]\n",
      "[Epoch 29/1000] [Batch 24/168] [D loss: 0.000480] [G loss: 8.287914]\n",
      "[Epoch 29/1000] [Batch 25/168] [D loss: 0.000345] [G loss: 8.750469]\n",
      "[Epoch 29/1000] [Batch 26/168] [D loss: 0.000334] [G loss: 8.728121]\n",
      "[Epoch 29/1000] [Batch 27/168] [D loss: 0.000307] [G loss: 8.626011]\n",
      "[Epoch 29/1000] [Batch 28/168] [D loss: 0.000305] [G loss: 8.751478]\n",
      "[Epoch 29/1000] [Batch 29/168] [D loss: 0.000394] [G loss: 8.672630]\n",
      "[Epoch 29/1000] [Batch 30/168] [D loss: 0.000374] [G loss: 8.676670]\n",
      "[Epoch 29/1000] [Batch 31/168] [D loss: 0.000483] [G loss: 8.947022]\n",
      "[Epoch 29/1000] [Batch 32/168] [D loss: 0.000316] [G loss: 8.864796]\n",
      "[Epoch 29/1000] [Batch 33/168] [D loss: 0.000303] [G loss: 8.620039]\n",
      "[Epoch 29/1000] [Batch 34/168] [D loss: 0.000427] [G loss: 8.649554]\n",
      "[Epoch 29/1000] [Batch 35/168] [D loss: 0.000257] [G loss: 8.975080]\n",
      "[Epoch 29/1000] [Batch 36/168] [D loss: 0.000358] [G loss: 8.640493]\n",
      "[Epoch 29/1000] [Batch 37/168] [D loss: 0.000265] [G loss: 8.744410]\n",
      "[Epoch 29/1000] [Batch 38/168] [D loss: 0.000302] [G loss: 8.826563]\n",
      "[Epoch 29/1000] [Batch 39/168] [D loss: 0.000373] [G loss: 8.575170]\n",
      "[Epoch 29/1000] [Batch 40/168] [D loss: 0.000322] [G loss: 8.910678]\n",
      "[Epoch 29/1000] [Batch 41/168] [D loss: 0.000607] [G loss: 9.017487]\n",
      "[Epoch 29/1000] [Batch 42/168] [D loss: 0.000457] [G loss: 8.694276]\n",
      "[Epoch 29/1000] [Batch 43/168] [D loss: 0.000362] [G loss: 8.430391]\n",
      "[Epoch 29/1000] [Batch 44/168] [D loss: 0.000424] [G loss: 8.478997]\n",
      "[Epoch 29/1000] [Batch 45/168] [D loss: 0.000378] [G loss: 8.421521]\n",
      "[Epoch 29/1000] [Batch 46/168] [D loss: 0.000293] [G loss: 8.702071]\n",
      "[Epoch 29/1000] [Batch 47/168] [D loss: 0.000363] [G loss: 8.406041]\n",
      "[Epoch 29/1000] [Batch 48/168] [D loss: 0.000272] [G loss: 8.895075]\n",
      "[Epoch 29/1000] [Batch 49/168] [D loss: 0.000337] [G loss: 8.795424]\n",
      "[Epoch 29/1000] [Batch 50/168] [D loss: 0.000338] [G loss: 8.690935]\n",
      "[Epoch 29/1000] [Batch 51/168] [D loss: 0.000337] [G loss: 9.199727]\n",
      "[Epoch 29/1000] [Batch 52/168] [D loss: 0.000685] [G loss: 8.668242]\n",
      "[Epoch 29/1000] [Batch 53/168] [D loss: 0.000260] [G loss: 8.854246]\n",
      "[Epoch 29/1000] [Batch 54/168] [D loss: 0.000262] [G loss: 8.553327]\n",
      "[Epoch 29/1000] [Batch 55/168] [D loss: 0.000294] [G loss: 8.540402]\n",
      "[Epoch 29/1000] [Batch 56/168] [D loss: 0.000451] [G loss: 8.216284]\n",
      "[Epoch 29/1000] [Batch 57/168] [D loss: 0.000358] [G loss: 8.513572]\n",
      "[Epoch 29/1000] [Batch 58/168] [D loss: 0.000233] [G loss: 8.757049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/1000] [Batch 59/168] [D loss: 0.000371] [G loss: 8.929214]\n",
      "[Epoch 29/1000] [Batch 60/168] [D loss: 0.000209] [G loss: 8.951159]\n",
      "[Epoch 29/1000] [Batch 61/168] [D loss: 0.000445] [G loss: 8.890018]\n",
      "[Epoch 29/1000] [Batch 62/168] [D loss: 0.000400] [G loss: 8.789726]\n",
      "[Epoch 29/1000] [Batch 63/168] [D loss: 0.000616] [G loss: 8.459973]\n",
      "[Epoch 29/1000] [Batch 64/168] [D loss: 0.000443] [G loss: 8.992684]\n",
      "[Epoch 29/1000] [Batch 65/168] [D loss: 0.000294] [G loss: 8.513374]\n",
      "[Epoch 29/1000] [Batch 66/168] [D loss: 0.000393] [G loss: 8.556027]\n",
      "[Epoch 29/1000] [Batch 67/168] [D loss: 0.000315] [G loss: 8.543043]\n",
      "[Epoch 29/1000] [Batch 68/168] [D loss: 0.000763] [G loss: 9.080618]\n",
      "[Epoch 29/1000] [Batch 69/168] [D loss: 0.000310] [G loss: 8.734696]\n",
      "[Epoch 29/1000] [Batch 70/168] [D loss: 0.000314] [G loss: 8.519166]\n",
      "[Epoch 29/1000] [Batch 71/168] [D loss: 0.000269] [G loss: 8.674669]\n",
      "[Epoch 29/1000] [Batch 72/168] [D loss: 0.000384] [G loss: 8.870930]\n",
      "[Epoch 29/1000] [Batch 73/168] [D loss: 0.000427] [G loss: 8.820384]\n",
      "[Epoch 29/1000] [Batch 74/168] [D loss: 0.000328] [G loss: 8.709138]\n",
      "[Epoch 29/1000] [Batch 75/168] [D loss: 0.000273] [G loss: 8.473564]\n",
      "[Epoch 29/1000] [Batch 76/168] [D loss: 0.000326] [G loss: 8.669859]\n",
      "[Epoch 29/1000] [Batch 77/168] [D loss: 0.000227] [G loss: 9.033552]\n",
      "[Epoch 29/1000] [Batch 78/168] [D loss: 0.000326] [G loss: 9.131459]\n",
      "[Epoch 29/1000] [Batch 79/168] [D loss: 0.000745] [G loss: 8.616039]\n",
      "[Epoch 29/1000] [Batch 80/168] [D loss: 0.000288] [G loss: 8.658907]\n",
      "[Epoch 29/1000] [Batch 81/168] [D loss: 0.000413] [G loss: 8.173536]\n",
      "[Epoch 29/1000] [Batch 82/168] [D loss: 0.000307] [G loss: 8.584718]\n",
      "[Epoch 29/1000] [Batch 83/168] [D loss: 0.000309] [G loss: 8.475687]\n",
      "[Epoch 29/1000] [Batch 84/168] [D loss: 0.000283] [G loss: 8.762077]\n",
      "[Epoch 29/1000] [Batch 85/168] [D loss: 0.000271] [G loss: 8.770140]\n",
      "[Epoch 29/1000] [Batch 86/168] [D loss: 0.000286] [G loss: 9.207334]\n",
      "[Epoch 29/1000] [Batch 87/168] [D loss: 0.000322] [G loss: 8.501860]\n",
      "[Epoch 29/1000] [Batch 88/168] [D loss: 0.000363] [G loss: 8.730704]\n",
      "[Epoch 29/1000] [Batch 89/168] [D loss: 0.000354] [G loss: 9.096483]\n",
      "[Epoch 29/1000] [Batch 90/168] [D loss: 0.000281] [G loss: 8.643639]\n",
      "[Epoch 29/1000] [Batch 91/168] [D loss: 0.000324] [G loss: 8.743558]\n",
      "[Epoch 29/1000] [Batch 92/168] [D loss: 0.000237] [G loss: 8.803017]\n",
      "[Epoch 29/1000] [Batch 93/168] [D loss: 0.000304] [G loss: 8.949406]\n",
      "[Epoch 29/1000] [Batch 94/168] [D loss: 0.000366] [G loss: 8.767959]\n",
      "[Epoch 29/1000] [Batch 95/168] [D loss: 0.000269] [G loss: 8.850313]\n",
      "[Epoch 29/1000] [Batch 96/168] [D loss: 0.000307] [G loss: 8.965167]\n",
      "[Epoch 29/1000] [Batch 97/168] [D loss: 0.000492] [G loss: 8.908922]\n",
      "[Epoch 29/1000] [Batch 98/168] [D loss: 0.000245] [G loss: 8.953842]\n",
      "[Epoch 29/1000] [Batch 99/168] [D loss: 0.000308] [G loss: 8.771431]\n",
      "[Epoch 29/1000] [Batch 100/168] [D loss: 0.000379] [G loss: 8.941182]\n",
      "[Epoch 29/1000] [Batch 101/168] [D loss: 0.000327] [G loss: 8.547059]\n",
      "[Epoch 29/1000] [Batch 102/168] [D loss: 0.000498] [G loss: 8.897843]\n",
      "[Epoch 29/1000] [Batch 103/168] [D loss: 0.000376] [G loss: 8.868439]\n",
      "[Epoch 29/1000] [Batch 104/168] [D loss: 0.000290] [G loss: 8.573757]\n",
      "[Epoch 29/1000] [Batch 105/168] [D loss: 0.000390] [G loss: 8.730514]\n",
      "[Epoch 29/1000] [Batch 106/168] [D loss: 0.000354] [G loss: 8.819440]\n",
      "[Epoch 29/1000] [Batch 107/168] [D loss: 0.000382] [G loss: 8.523190]\n",
      "[Epoch 29/1000] [Batch 108/168] [D loss: 0.000415] [G loss: 8.582399]\n",
      "[Epoch 29/1000] [Batch 109/168] [D loss: 0.000321] [G loss: 8.650537]\n",
      "[Epoch 29/1000] [Batch 110/168] [D loss: 0.000376] [G loss: 8.595356]\n",
      "[Epoch 29/1000] [Batch 111/168] [D loss: 0.000219] [G loss: 9.176446]\n",
      "[Epoch 29/1000] [Batch 112/168] [D loss: 0.000243] [G loss: 9.045103]\n",
      "[Epoch 29/1000] [Batch 113/168] [D loss: 0.000472] [G loss: 8.551948]\n",
      "[Epoch 29/1000] [Batch 114/168] [D loss: 0.000275] [G loss: 8.784272]\n",
      "[Epoch 29/1000] [Batch 115/168] [D loss: 0.000231] [G loss: 8.588549]\n",
      "[Epoch 29/1000] [Batch 116/168] [D loss: 0.000344] [G loss: 8.938655]\n",
      "[Epoch 29/1000] [Batch 117/168] [D loss: 0.000363] [G loss: 8.746960]\n",
      "[Epoch 29/1000] [Batch 118/168] [D loss: 0.000610] [G loss: 8.784231]\n",
      "[Epoch 29/1000] [Batch 119/168] [D loss: 0.000286] [G loss: 8.856810]\n",
      "[Epoch 29/1000] [Batch 120/168] [D loss: 0.000408] [G loss: 8.757608]\n",
      "[Epoch 29/1000] [Batch 121/168] [D loss: 0.000366] [G loss: 8.918158]\n",
      "[Epoch 29/1000] [Batch 122/168] [D loss: 0.000414] [G loss: 8.700372]\n",
      "[Epoch 29/1000] [Batch 123/168] [D loss: 0.000375] [G loss: 8.761973]\n",
      "[Epoch 29/1000] [Batch 124/168] [D loss: 0.000485] [G loss: 8.665795]\n",
      "[Epoch 29/1000] [Batch 125/168] [D loss: 0.000262] [G loss: 8.725169]\n",
      "[Epoch 29/1000] [Batch 126/168] [D loss: 0.000236] [G loss: 8.763918]\n",
      "[Epoch 29/1000] [Batch 127/168] [D loss: 0.000307] [G loss: 8.893745]\n",
      "[Epoch 29/1000] [Batch 128/168] [D loss: 0.000298] [G loss: 8.752826]\n",
      "[Epoch 29/1000] [Batch 129/168] [D loss: 0.000281] [G loss: 8.667112]\n",
      "[Epoch 29/1000] [Batch 130/168] [D loss: 0.000257] [G loss: 8.943941]\n",
      "[Epoch 29/1000] [Batch 131/168] [D loss: 0.000337] [G loss: 8.951982]\n",
      "[Epoch 29/1000] [Batch 132/168] [D loss: 0.000468] [G loss: 9.061522]\n",
      "[Epoch 29/1000] [Batch 133/168] [D loss: 0.000513] [G loss: 8.635874]\n",
      "[Epoch 29/1000] [Batch 134/168] [D loss: 0.000343] [G loss: 8.756912]\n",
      "[Epoch 29/1000] [Batch 135/168] [D loss: 0.001222] [G loss: 8.752245]\n",
      "[Epoch 29/1000] [Batch 136/168] [D loss: 0.000459] [G loss: 8.243182]\n",
      "[Epoch 29/1000] [Batch 137/168] [D loss: 0.000429] [G loss: 8.134859]\n",
      "[Epoch 29/1000] [Batch 138/168] [D loss: 0.000300] [G loss: 8.573982]\n",
      "[Epoch 29/1000] [Batch 139/168] [D loss: 0.000372] [G loss: 8.576956]\n",
      "[Epoch 29/1000] [Batch 140/168] [D loss: 0.000334] [G loss: 8.672581]\n",
      "[Epoch 29/1000] [Batch 141/168] [D loss: 0.000269] [G loss: 8.954029]\n",
      "[Epoch 29/1000] [Batch 142/168] [D loss: 0.000346] [G loss: 8.974282]\n",
      "[Epoch 29/1000] [Batch 143/168] [D loss: 0.000238] [G loss: 9.199815]\n",
      "[Epoch 29/1000] [Batch 144/168] [D loss: 0.000244] [G loss: 8.923081]\n",
      "[Epoch 29/1000] [Batch 145/168] [D loss: 0.000309] [G loss: 9.160296]\n",
      "[Epoch 29/1000] [Batch 146/168] [D loss: 0.000330] [G loss: 8.970467]\n",
      "[Epoch 29/1000] [Batch 147/168] [D loss: 0.000212] [G loss: 8.925437]\n",
      "[Epoch 29/1000] [Batch 148/168] [D loss: 0.000353] [G loss: 8.814312]\n",
      "[Epoch 29/1000] [Batch 149/168] [D loss: 0.000511] [G loss: 8.413609]\n",
      "[Epoch 29/1000] [Batch 150/168] [D loss: 0.000514] [G loss: 8.819084]\n",
      "[Epoch 29/1000] [Batch 151/168] [D loss: 0.000386] [G loss: 9.041087]\n",
      "[Epoch 29/1000] [Batch 152/168] [D loss: 0.000428] [G loss: 8.778699]\n",
      "[Epoch 29/1000] [Batch 153/168] [D loss: 0.000369] [G loss: 8.341663]\n",
      "[Epoch 29/1000] [Batch 154/168] [D loss: 0.000410] [G loss: 8.665035]\n",
      "[Epoch 29/1000] [Batch 155/168] [D loss: 0.000424] [G loss: 8.593735]\n",
      "[Epoch 29/1000] [Batch 156/168] [D loss: 0.000448] [G loss: 8.503496]\n",
      "[Epoch 29/1000] [Batch 157/168] [D loss: 0.000341] [G loss: 8.766168]\n",
      "[Epoch 29/1000] [Batch 158/168] [D loss: 0.000291] [G loss: 9.119287]\n",
      "[Epoch 29/1000] [Batch 159/168] [D loss: 0.000564] [G loss: 8.793103]\n",
      "[Epoch 29/1000] [Batch 160/168] [D loss: 0.000411] [G loss: 8.796420]\n",
      "[Epoch 29/1000] [Batch 161/168] [D loss: 0.000478] [G loss: 8.488480]\n",
      "[Epoch 29/1000] [Batch 162/168] [D loss: 0.000326] [G loss: 8.718884]\n",
      "[Epoch 29/1000] [Batch 163/168] [D loss: 0.000296] [G loss: 8.728485]\n",
      "[Epoch 29/1000] [Batch 164/168] [D loss: 0.000383] [G loss: 8.658181]\n",
      "[Epoch 29/1000] [Batch 165/168] [D loss: 0.000327] [G loss: 8.889000]\n",
      "[Epoch 29/1000] [Batch 166/168] [D loss: 0.000440] [G loss: 9.067620]\n",
      "[Epoch 29/1000] [Batch 167/168] [D loss: 0.000259] [G loss: 9.155493]\n",
      "[Epoch 29/1000] [Batch 168/168] [D loss: 0.000343] [G loss: 9.197251]\n",
      "[Epoch 30/1000] [Batch 1/168] [D loss: 0.000359] [G loss: 8.709977]\n",
      "[Epoch 30/1000] [Batch 2/168] [D loss: 0.000308] [G loss: 8.816398]\n",
      "[Epoch 30/1000] [Batch 3/168] [D loss: 0.000322] [G loss: 8.751233]\n",
      "[Epoch 30/1000] [Batch 4/168] [D loss: 0.000247] [G loss: 8.815981]\n",
      "[Epoch 30/1000] [Batch 5/168] [D loss: 0.000334] [G loss: 8.763412]\n",
      "[Epoch 30/1000] [Batch 6/168] [D loss: 0.000559] [G loss: 8.623416]\n",
      "[Epoch 30/1000] [Batch 7/168] [D loss: 0.000394] [G loss: 8.545534]\n",
      "[Epoch 30/1000] [Batch 8/168] [D loss: 0.000245] [G loss: 9.045456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/1000] [Batch 9/168] [D loss: 0.000352] [G loss: 9.199453]\n",
      "[Epoch 30/1000] [Batch 10/168] [D loss: 0.000405] [G loss: 8.772798]\n",
      "[Epoch 30/1000] [Batch 11/168] [D loss: 0.000569] [G loss: 8.674746]\n",
      "[Epoch 30/1000] [Batch 12/168] [D loss: 0.000438] [G loss: 8.310442]\n",
      "[Epoch 30/1000] [Batch 13/168] [D loss: 0.000242] [G loss: 8.626033]\n",
      "[Epoch 30/1000] [Batch 14/168] [D loss: 0.000483] [G loss: 8.532143]\n",
      "[Epoch 30/1000] [Batch 15/168] [D loss: 0.000533] [G loss: 8.444804]\n",
      "[Epoch 30/1000] [Batch 16/168] [D loss: 0.000315] [G loss: 9.251121]\n",
      "[Epoch 30/1000] [Batch 17/168] [D loss: 0.000540] [G loss: 8.473965]\n",
      "[Epoch 30/1000] [Batch 18/168] [D loss: 0.000674] [G loss: 9.026064]\n",
      "[Epoch 30/1000] [Batch 19/168] [D loss: 0.000443] [G loss: 8.178172]\n",
      "[Epoch 30/1000] [Batch 20/168] [D loss: 0.000384] [G loss: 8.596731]\n",
      "[Epoch 30/1000] [Batch 21/168] [D loss: 0.000320] [G loss: 8.932280]\n",
      "[Epoch 30/1000] [Batch 22/168] [D loss: 0.000290] [G loss: 9.103477]\n",
      "[Epoch 30/1000] [Batch 23/168] [D loss: 0.000408] [G loss: 8.753384]\n",
      "[Epoch 30/1000] [Batch 24/168] [D loss: 0.000337] [G loss: 8.895287]\n",
      "[Epoch 30/1000] [Batch 25/168] [D loss: 0.000200] [G loss: 8.730895]\n",
      "[Epoch 30/1000] [Batch 26/168] [D loss: 0.000382] [G loss: 8.495096]\n",
      "[Epoch 30/1000] [Batch 27/168] [D loss: 0.000321] [G loss: 9.065028]\n",
      "[Epoch 30/1000] [Batch 28/168] [D loss: 0.000418] [G loss: 8.603113]\n",
      "[Epoch 30/1000] [Batch 29/168] [D loss: 0.000273] [G loss: 8.863461]\n",
      "[Epoch 30/1000] [Batch 30/168] [D loss: 0.000392] [G loss: 8.818526]\n",
      "[Epoch 30/1000] [Batch 31/168] [D loss: 0.000325] [G loss: 8.673204]\n",
      "[Epoch 30/1000] [Batch 32/168] [D loss: 0.000373] [G loss: 8.380537]\n",
      "[Epoch 30/1000] [Batch 33/168] [D loss: 0.000445] [G loss: 8.642836]\n",
      "[Epoch 30/1000] [Batch 34/168] [D loss: 0.000548] [G loss: 8.614001]\n",
      "[Epoch 30/1000] [Batch 35/168] [D loss: 0.000437] [G loss: 8.428542]\n",
      "[Epoch 30/1000] [Batch 36/168] [D loss: 0.000391] [G loss: 8.981071]\n",
      "[Epoch 30/1000] [Batch 37/168] [D loss: 0.000434] [G loss: 8.632646]\n",
      "[Epoch 30/1000] [Batch 38/168] [D loss: 0.000317] [G loss: 8.473846]\n",
      "[Epoch 30/1000] [Batch 39/168] [D loss: 0.000698] [G loss: 8.986180]\n",
      "[Epoch 30/1000] [Batch 40/168] [D loss: 0.000231] [G loss: 8.767303]\n",
      "[Epoch 30/1000] [Batch 41/168] [D loss: 0.000419] [G loss: 8.558565]\n",
      "[Epoch 30/1000] [Batch 42/168] [D loss: 0.000422] [G loss: 8.230029]\n",
      "[Epoch 30/1000] [Batch 43/168] [D loss: 0.000469] [G loss: 8.369368]\n",
      "[Epoch 30/1000] [Batch 44/168] [D loss: 0.000566] [G loss: 8.679163]\n",
      "[Epoch 30/1000] [Batch 45/168] [D loss: 0.000435] [G loss: 8.769593]\n",
      "[Epoch 30/1000] [Batch 46/168] [D loss: 0.000372] [G loss: 8.732337]\n",
      "[Epoch 30/1000] [Batch 47/168] [D loss: 0.000387] [G loss: 8.996960]\n",
      "[Epoch 30/1000] [Batch 48/168] [D loss: 0.000347] [G loss: 8.419893]\n",
      "[Epoch 30/1000] [Batch 49/168] [D loss: 0.000283] [G loss: 9.077900]\n",
      "[Epoch 30/1000] [Batch 50/168] [D loss: 0.000367] [G loss: 8.947056]\n",
      "[Epoch 30/1000] [Batch 51/168] [D loss: 0.000414] [G loss: 8.980927]\n",
      "[Epoch 30/1000] [Batch 52/168] [D loss: 0.000633] [G loss: 8.535531]\n",
      "[Epoch 30/1000] [Batch 53/168] [D loss: 0.000569] [G loss: 8.208120]\n",
      "[Epoch 30/1000] [Batch 54/168] [D loss: 0.000453] [G loss: 8.458635]\n",
      "[Epoch 30/1000] [Batch 55/168] [D loss: 0.000381] [G loss: 8.199348]\n",
      "[Epoch 30/1000] [Batch 56/168] [D loss: 0.000334] [G loss: 8.742900]\n",
      "[Epoch 30/1000] [Batch 57/168] [D loss: 0.000293] [G loss: 8.683289]\n",
      "[Epoch 30/1000] [Batch 58/168] [D loss: 0.000289] [G loss: 9.139985]\n",
      "[Epoch 30/1000] [Batch 59/168] [D loss: 0.000371] [G loss: 8.833246]\n",
      "[Epoch 30/1000] [Batch 60/168] [D loss: 0.000422] [G loss: 8.610298]\n",
      "[Epoch 30/1000] [Batch 61/168] [D loss: 0.000284] [G loss: 8.933494]\n",
      "[Epoch 30/1000] [Batch 62/168] [D loss: 0.000684] [G loss: 8.915378]\n",
      "[Epoch 30/1000] [Batch 63/168] [D loss: 0.000341] [G loss: 8.486008]\n",
      "[Epoch 30/1000] [Batch 64/168] [D loss: 0.000429] [G loss: 8.396575]\n",
      "[Epoch 30/1000] [Batch 65/168] [D loss: 0.000270] [G loss: 8.838850]\n",
      "[Epoch 30/1000] [Batch 66/168] [D loss: 0.000322] [G loss: 8.659790]\n",
      "[Epoch 30/1000] [Batch 67/168] [D loss: 0.000248] [G loss: 8.992905]\n",
      "[Epoch 30/1000] [Batch 68/168] [D loss: 0.000379] [G loss: 8.883054]\n",
      "[Epoch 30/1000] [Batch 69/168] [D loss: 0.000316] [G loss: 9.036736]\n",
      "[Epoch 30/1000] [Batch 70/168] [D loss: 0.000308] [G loss: 8.665709]\n",
      "[Epoch 30/1000] [Batch 71/168] [D loss: 0.000293] [G loss: 8.758182]\n",
      "[Epoch 30/1000] [Batch 72/168] [D loss: 0.000356] [G loss: 8.666883]\n",
      "[Epoch 30/1000] [Batch 73/168] [D loss: 0.000234] [G loss: 9.143220]\n",
      "[Epoch 30/1000] [Batch 74/168] [D loss: 0.000460] [G loss: 8.757890]\n",
      "[Epoch 30/1000] [Batch 75/168] [D loss: 0.000312] [G loss: 9.237476]\n",
      "[Epoch 30/1000] [Batch 76/168] [D loss: 0.000337] [G loss: 8.987333]\n",
      "[Epoch 30/1000] [Batch 77/168] [D loss: 0.000287] [G loss: 8.900666]\n",
      "[Epoch 30/1000] [Batch 78/168] [D loss: 0.000523] [G loss: 8.899908]\n",
      "[Epoch 30/1000] [Batch 79/168] [D loss: 0.000404] [G loss: 8.711588]\n",
      "[Epoch 30/1000] [Batch 80/168] [D loss: 0.000330] [G loss: 8.828569]\n",
      "[Epoch 30/1000] [Batch 81/168] [D loss: 0.000312] [G loss: 8.634048]\n",
      "[Epoch 30/1000] [Batch 82/168] [D loss: 0.000383] [G loss: 8.833152]\n",
      "[Epoch 30/1000] [Batch 83/168] [D loss: 0.000389] [G loss: 8.941790]\n",
      "[Epoch 30/1000] [Batch 84/168] [D loss: 0.000343] [G loss: 8.839767]\n",
      "[Epoch 30/1000] [Batch 85/168] [D loss: 0.000336] [G loss: 8.450899]\n",
      "[Epoch 30/1000] [Batch 86/168] [D loss: 0.000288] [G loss: 8.510282]\n",
      "[Epoch 30/1000] [Batch 87/168] [D loss: 0.000329] [G loss: 8.456205]\n",
      "[Epoch 30/1000] [Batch 88/168] [D loss: 0.000366] [G loss: 8.767700]\n",
      "[Epoch 30/1000] [Batch 89/168] [D loss: 0.000224] [G loss: 9.075971]\n",
      "[Epoch 30/1000] [Batch 90/168] [D loss: 0.000237] [G loss: 8.840196]\n",
      "[Epoch 30/1000] [Batch 91/168] [D loss: 0.000341] [G loss: 9.171071]\n",
      "[Epoch 30/1000] [Batch 92/168] [D loss: 0.000369] [G loss: 9.047295]\n",
      "[Epoch 30/1000] [Batch 93/168] [D loss: 0.000420] [G loss: 9.032939]\n",
      "[Epoch 30/1000] [Batch 94/168] [D loss: 0.000474] [G loss: 8.751822]\n",
      "[Epoch 30/1000] [Batch 95/168] [D loss: 0.000531] [G loss: 8.400079]\n",
      "[Epoch 30/1000] [Batch 96/168] [D loss: 0.000442] [G loss: 8.290598]\n",
      "[Epoch 30/1000] [Batch 97/168] [D loss: 0.000455] [G loss: 8.653516]\n",
      "[Epoch 30/1000] [Batch 98/168] [D loss: 0.000249] [G loss: 8.760518]\n",
      "[Epoch 30/1000] [Batch 99/168] [D loss: 0.000331] [G loss: 8.573792]\n",
      "[Epoch 30/1000] [Batch 100/168] [D loss: 0.000400] [G loss: 8.594627]\n",
      "[Epoch 30/1000] [Batch 101/168] [D loss: 0.000249] [G loss: 8.870911]\n",
      "[Epoch 30/1000] [Batch 102/168] [D loss: 0.000401] [G loss: 8.849589]\n",
      "[Epoch 30/1000] [Batch 103/168] [D loss: 0.000279] [G loss: 9.031794]\n",
      "[Epoch 30/1000] [Batch 104/168] [D loss: 0.000207] [G loss: 9.462226]\n",
      "[Epoch 30/1000] [Batch 105/168] [D loss: 0.000282] [G loss: 9.032390]\n",
      "[Epoch 30/1000] [Batch 106/168] [D loss: 0.000340] [G loss: 8.985538]\n",
      "[Epoch 30/1000] [Batch 107/168] [D loss: 0.000383] [G loss: 9.244456]\n",
      "[Epoch 30/1000] [Batch 108/168] [D loss: 0.000366] [G loss: 8.751713]\n",
      "[Epoch 30/1000] [Batch 109/168] [D loss: 0.000448] [G loss: 8.680552]\n",
      "[Epoch 30/1000] [Batch 110/168] [D loss: 0.000263] [G loss: 8.652046]\n",
      "[Epoch 30/1000] [Batch 111/168] [D loss: 0.000320] [G loss: 8.684481]\n",
      "[Epoch 30/1000] [Batch 112/168] [D loss: 0.000521] [G loss: 8.434797]\n",
      "[Epoch 30/1000] [Batch 113/168] [D loss: 0.000476] [G loss: 8.667248]\n",
      "[Epoch 30/1000] [Batch 114/168] [D loss: 0.000429] [G loss: 8.517467]\n",
      "[Epoch 30/1000] [Batch 115/168] [D loss: 0.000397] [G loss: 8.830319]\n",
      "[Epoch 30/1000] [Batch 116/168] [D loss: 0.000448] [G loss: 8.739523]\n",
      "[Epoch 30/1000] [Batch 117/168] [D loss: 0.000360] [G loss: 8.472807]\n",
      "[Epoch 30/1000] [Batch 118/168] [D loss: 0.000597] [G loss: 8.668612]\n",
      "[Epoch 30/1000] [Batch 119/168] [D loss: 0.000346] [G loss: 8.410807]\n",
      "[Epoch 30/1000] [Batch 120/168] [D loss: 0.000403] [G loss: 8.342026]\n",
      "[Epoch 30/1000] [Batch 121/168] [D loss: 0.000378] [G loss: 8.867181]\n",
      "[Epoch 30/1000] [Batch 122/168] [D loss: 0.000345] [G loss: 8.419791]\n",
      "[Epoch 30/1000] [Batch 123/168] [D loss: 0.000300] [G loss: 8.957886]\n",
      "[Epoch 30/1000] [Batch 124/168] [D loss: 0.000304] [G loss: 8.745494]\n",
      "[Epoch 30/1000] [Batch 125/168] [D loss: 0.000264] [G loss: 8.829863]\n",
      "[Epoch 30/1000] [Batch 126/168] [D loss: 0.000275] [G loss: 9.005723]\n",
      "[Epoch 30/1000] [Batch 127/168] [D loss: 0.000486] [G loss: 9.097142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/1000] [Batch 128/168] [D loss: 0.000425] [G loss: 8.732138]\n",
      "[Epoch 30/1000] [Batch 129/168] [D loss: 0.000466] [G loss: 8.296530]\n",
      "[Epoch 30/1000] [Batch 130/168] [D loss: 0.000259] [G loss: 8.656733]\n",
      "[Epoch 30/1000] [Batch 131/168] [D loss: 0.000324] [G loss: 8.813291]\n",
      "[Epoch 30/1000] [Batch 132/168] [D loss: 0.000524] [G loss: 8.827327]\n",
      "[Epoch 30/1000] [Batch 133/168] [D loss: 0.000269] [G loss: 8.631803]\n",
      "[Epoch 30/1000] [Batch 134/168] [D loss: 0.000348] [G loss: 8.830381]\n",
      "[Epoch 30/1000] [Batch 135/168] [D loss: 0.000276] [G loss: 8.644653]\n",
      "[Epoch 30/1000] [Batch 136/168] [D loss: 0.000330] [G loss: 8.625535]\n",
      "[Epoch 30/1000] [Batch 137/168] [D loss: 0.000276] [G loss: 9.170856]\n",
      "[Epoch 30/1000] [Batch 138/168] [D loss: 0.000215] [G loss: 9.089348]\n",
      "[Epoch 30/1000] [Batch 139/168] [D loss: 0.000304] [G loss: 9.086517]\n",
      "[Epoch 30/1000] [Batch 140/168] [D loss: 0.000242] [G loss: 9.245080]\n",
      "[Epoch 30/1000] [Batch 141/168] [D loss: 0.000622] [G loss: 8.663781]\n",
      "[Epoch 30/1000] [Batch 142/168] [D loss: 0.000363] [G loss: 8.686056]\n",
      "[Epoch 30/1000] [Batch 143/168] [D loss: 0.000364] [G loss: 8.382253]\n",
      "[Epoch 30/1000] [Batch 144/168] [D loss: 0.000279] [G loss: 8.592775]\n",
      "[Epoch 30/1000] [Batch 145/168] [D loss: 0.000292] [G loss: 8.704766]\n",
      "[Epoch 30/1000] [Batch 146/168] [D loss: 0.000402] [G loss: 9.013085]\n",
      "[Epoch 30/1000] [Batch 147/168] [D loss: 0.000294] [G loss: 8.795895]\n",
      "[Epoch 30/1000] [Batch 148/168] [D loss: 0.000309] [G loss: 8.760788]\n",
      "[Epoch 30/1000] [Batch 149/168] [D loss: 0.000536] [G loss: 8.756824]\n",
      "[Epoch 30/1000] [Batch 150/168] [D loss: 0.000307] [G loss: 8.668396]\n",
      "[Epoch 30/1000] [Batch 151/168] [D loss: 0.000345] [G loss: 8.799198]\n",
      "[Epoch 30/1000] [Batch 152/168] [D loss: 0.000230] [G loss: 8.909160]\n",
      "[Epoch 30/1000] [Batch 153/168] [D loss: 0.000363] [G loss: 8.929925]\n",
      "[Epoch 30/1000] [Batch 154/168] [D loss: 0.000325] [G loss: 9.307419]\n",
      "[Epoch 30/1000] [Batch 155/168] [D loss: 0.000250] [G loss: 8.817768]\n",
      "[Epoch 30/1000] [Batch 156/168] [D loss: 0.000460] [G loss: 8.444059]\n",
      "[Epoch 30/1000] [Batch 157/168] [D loss: 0.000343] [G loss: 8.612367]\n",
      "[Epoch 30/1000] [Batch 158/168] [D loss: 0.000655] [G loss: 8.930861]\n",
      "[Epoch 30/1000] [Batch 159/168] [D loss: 0.000323] [G loss: 8.640024]\n",
      "[Epoch 30/1000] [Batch 160/168] [D loss: 0.000452] [G loss: 8.977937]\n",
      "[Epoch 30/1000] [Batch 161/168] [D loss: 0.000168] [G loss: 9.076550]\n",
      "[Epoch 30/1000] [Batch 162/168] [D loss: 0.000267] [G loss: 8.575201]\n",
      "[Epoch 30/1000] [Batch 163/168] [D loss: 0.000261] [G loss: 9.001979]\n",
      "[Epoch 30/1000] [Batch 164/168] [D loss: 0.000220] [G loss: 8.897418]\n",
      "[Epoch 30/1000] [Batch 165/168] [D loss: 0.000311] [G loss: 8.998495]\n",
      "[Epoch 30/1000] [Batch 166/168] [D loss: 0.000460] [G loss: 8.750418]\n",
      "[Epoch 30/1000] [Batch 167/168] [D loss: 0.000453] [G loss: 9.147097]\n",
      "[Epoch 30/1000] [Batch 168/168] [D loss: 0.000621] [G loss: 8.647091]\n",
      "[Epoch 31/1000] [Batch 1/168] [D loss: 0.000416] [G loss: 8.457212]\n",
      "[Epoch 31/1000] [Batch 2/168] [D loss: 0.000239] [G loss: 8.864481]\n",
      "[Epoch 31/1000] [Batch 3/168] [D loss: 0.000259] [G loss: 9.100262]\n",
      "[Epoch 31/1000] [Batch 4/168] [D loss: 0.000300] [G loss: 8.922951]\n",
      "[Epoch 31/1000] [Batch 5/168] [D loss: 0.000214] [G loss: 9.122025]\n",
      "[Epoch 31/1000] [Batch 6/168] [D loss: 0.000296] [G loss: 9.324442]\n",
      "[Epoch 31/1000] [Batch 7/168] [D loss: 0.000251] [G loss: 9.246934]\n",
      "[Epoch 31/1000] [Batch 8/168] [D loss: 0.000199] [G loss: 9.359987]\n",
      "[Epoch 31/1000] [Batch 9/168] [D loss: 0.000268] [G loss: 8.883208]\n",
      "[Epoch 31/1000] [Batch 10/168] [D loss: 0.000227] [G loss: 9.315533]\n",
      "[Epoch 31/1000] [Batch 11/168] [D loss: 0.000237] [G loss: 9.926496]\n",
      "[Epoch 31/1000] [Batch 12/168] [D loss: 0.000158] [G loss: 9.701876]\n",
      "[Epoch 31/1000] [Batch 13/168] [D loss: 0.000140] [G loss: 9.606487]\n",
      "[Epoch 31/1000] [Batch 14/168] [D loss: 0.000198] [G loss: 9.475090]\n",
      "[Epoch 31/1000] [Batch 15/168] [D loss: 0.000159] [G loss: 9.462117]\n",
      "[Epoch 31/1000] [Batch 16/168] [D loss: 0.000195] [G loss: 9.428440]\n",
      "[Epoch 31/1000] [Batch 17/168] [D loss: 0.000201] [G loss: 9.646190]\n",
      "[Epoch 31/1000] [Batch 18/168] [D loss: 0.000150] [G loss: 9.793937]\n",
      "[Epoch 31/1000] [Batch 19/168] [D loss: 0.000164] [G loss: 9.577836]\n",
      "[Epoch 31/1000] [Batch 20/168] [D loss: 0.000150] [G loss: 9.658125]\n",
      "[Epoch 31/1000] [Batch 21/168] [D loss: 0.000144] [G loss: 9.684065]\n",
      "[Epoch 31/1000] [Batch 22/168] [D loss: 0.000100] [G loss: 9.513083]\n",
      "[Epoch 31/1000] [Batch 23/168] [D loss: 0.000143] [G loss: 9.457264]\n",
      "[Epoch 31/1000] [Batch 24/168] [D loss: 0.000147] [G loss: 9.823141]\n",
      "[Epoch 31/1000] [Batch 25/168] [D loss: 0.000216] [G loss: 9.624777]\n",
      "[Epoch 31/1000] [Batch 26/168] [D loss: 0.000208] [G loss: 9.870197]\n",
      "[Epoch 31/1000] [Batch 27/168] [D loss: 0.000135] [G loss: 9.821100]\n",
      "[Epoch 31/1000] [Batch 28/168] [D loss: 0.000162] [G loss: 9.993017]\n",
      "[Epoch 31/1000] [Batch 29/168] [D loss: 0.000127] [G loss: 9.571630]\n",
      "[Epoch 31/1000] [Batch 30/168] [D loss: 0.000132] [G loss: 9.684401]\n",
      "[Epoch 31/1000] [Batch 31/168] [D loss: 0.000108] [G loss: 9.922163]\n",
      "[Epoch 31/1000] [Batch 32/168] [D loss: 0.000221] [G loss: 9.771891]\n",
      "[Epoch 31/1000] [Batch 33/168] [D loss: 0.000110] [G loss: 9.819305]\n",
      "[Epoch 31/1000] [Batch 34/168] [D loss: 0.000197] [G loss: 9.856526]\n",
      "[Epoch 31/1000] [Batch 35/168] [D loss: 0.000109] [G loss: 9.826419]\n",
      "[Epoch 31/1000] [Batch 36/168] [D loss: 0.000134] [G loss: 9.870925]\n",
      "[Epoch 31/1000] [Batch 37/168] [D loss: 0.000185] [G loss: 9.365421]\n",
      "[Epoch 31/1000] [Batch 38/168] [D loss: 0.000102] [G loss: 9.750553]\n",
      "[Epoch 31/1000] [Batch 39/168] [D loss: 0.000148] [G loss: 9.852985]\n",
      "[Epoch 31/1000] [Batch 40/168] [D loss: 0.000098] [G loss: 9.901115]\n",
      "[Epoch 31/1000] [Batch 41/168] [D loss: 0.000116] [G loss: 9.950027]\n",
      "[Epoch 31/1000] [Batch 42/168] [D loss: 0.000096] [G loss: 10.045706]\n",
      "[Epoch 31/1000] [Batch 43/168] [D loss: 0.000097] [G loss: 9.899065]\n",
      "[Epoch 31/1000] [Batch 44/168] [D loss: 0.000151] [G loss: 10.264115]\n",
      "[Epoch 31/1000] [Batch 45/168] [D loss: 0.000093] [G loss: 10.167697]\n",
      "[Epoch 31/1000] [Batch 46/168] [D loss: 0.000073] [G loss: 10.148787]\n",
      "[Epoch 31/1000] [Batch 47/168] [D loss: 0.000105] [G loss: 10.014762]\n",
      "[Epoch 31/1000] [Batch 48/168] [D loss: 0.000114] [G loss: 10.204270]\n",
      "[Epoch 31/1000] [Batch 49/168] [D loss: 0.000106] [G loss: 9.967598]\n",
      "[Epoch 31/1000] [Batch 50/168] [D loss: 0.000137] [G loss: 9.873727]\n",
      "[Epoch 31/1000] [Batch 51/168] [D loss: 0.000113] [G loss: 10.090557]\n",
      "[Epoch 31/1000] [Batch 52/168] [D loss: 0.000102] [G loss: 9.902111]\n",
      "[Epoch 31/1000] [Batch 53/168] [D loss: 0.000068] [G loss: 10.059117]\n",
      "[Epoch 31/1000] [Batch 54/168] [D loss: 0.000120] [G loss: 10.259600]\n",
      "[Epoch 31/1000] [Batch 55/168] [D loss: 0.000162] [G loss: 9.989944]\n",
      "[Epoch 31/1000] [Batch 56/168] [D loss: 0.000096] [G loss: 9.910459]\n",
      "[Epoch 31/1000] [Batch 57/168] [D loss: 0.000097] [G loss: 10.216076]\n",
      "[Epoch 31/1000] [Batch 58/168] [D loss: 0.000096] [G loss: 10.233571]\n",
      "[Epoch 31/1000] [Batch 59/168] [D loss: 0.000091] [G loss: 10.054486]\n",
      "[Epoch 31/1000] [Batch 60/168] [D loss: 0.000091] [G loss: 10.170792]\n",
      "[Epoch 31/1000] [Batch 61/168] [D loss: 0.000072] [G loss: 10.348576]\n",
      "[Epoch 31/1000] [Batch 62/168] [D loss: 0.000077] [G loss: 10.422634]\n",
      "[Epoch 31/1000] [Batch 63/168] [D loss: 0.000074] [G loss: 10.243200]\n",
      "[Epoch 31/1000] [Batch 64/168] [D loss: 0.000090] [G loss: 9.941226]\n",
      "[Epoch 31/1000] [Batch 65/168] [D loss: 0.000080] [G loss: 10.221927]\n",
      "[Epoch 31/1000] [Batch 66/168] [D loss: 0.000072] [G loss: 10.062711]\n",
      "[Epoch 31/1000] [Batch 67/168] [D loss: 0.000054] [G loss: 10.386144]\n",
      "[Epoch 31/1000] [Batch 68/168] [D loss: 0.000116] [G loss: 10.185483]\n",
      "[Epoch 31/1000] [Batch 69/168] [D loss: 0.000083] [G loss: 10.313267]\n",
      "[Epoch 31/1000] [Batch 70/168] [D loss: 0.000082] [G loss: 10.182733]\n",
      "[Epoch 31/1000] [Batch 71/168] [D loss: 0.000087] [G loss: 10.510747]\n",
      "[Epoch 31/1000] [Batch 72/168] [D loss: 0.000150] [G loss: 10.327334]\n",
      "[Epoch 31/1000] [Batch 73/168] [D loss: 0.000099] [G loss: 10.330050]\n",
      "[Epoch 31/1000] [Batch 74/168] [D loss: 0.000050] [G loss: 10.318679]\n",
      "[Epoch 31/1000] [Batch 75/168] [D loss: 0.000091] [G loss: 10.120370]\n",
      "[Epoch 31/1000] [Batch 76/168] [D loss: 0.000107] [G loss: 10.159161]\n",
      "[Epoch 31/1000] [Batch 77/168] [D loss: 0.000062] [G loss: 10.224307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/1000] [Batch 78/168] [D loss: 0.000079] [G loss: 10.103688]\n",
      "[Epoch 31/1000] [Batch 79/168] [D loss: 0.000083] [G loss: 10.167372]\n",
      "[Epoch 31/1000] [Batch 80/168] [D loss: 0.000106] [G loss: 10.553068]\n",
      "[Epoch 31/1000] [Batch 81/168] [D loss: 0.000067] [G loss: 10.283652]\n",
      "[Epoch 31/1000] [Batch 82/168] [D loss: 0.000118] [G loss: 10.357889]\n",
      "[Epoch 31/1000] [Batch 83/168] [D loss: 0.000064] [G loss: 10.345210]\n",
      "[Epoch 31/1000] [Batch 84/168] [D loss: 0.000113] [G loss: 9.929458]\n",
      "[Epoch 31/1000] [Batch 85/168] [D loss: 0.000096] [G loss: 10.362576]\n",
      "[Epoch 31/1000] [Batch 86/168] [D loss: 0.000050] [G loss: 10.549810]\n",
      "[Epoch 31/1000] [Batch 87/168] [D loss: 0.000083] [G loss: 10.286466]\n",
      "[Epoch 31/1000] [Batch 88/168] [D loss: 0.000076] [G loss: 10.285123]\n",
      "[Epoch 31/1000] [Batch 89/168] [D loss: 0.000076] [G loss: 10.393740]\n",
      "[Epoch 31/1000] [Batch 90/168] [D loss: 0.000082] [G loss: 10.383395]\n",
      "[Epoch 31/1000] [Batch 91/168] [D loss: 0.000087] [G loss: 10.191484]\n",
      "[Epoch 31/1000] [Batch 92/168] [D loss: 0.000078] [G loss: 10.607682]\n",
      "[Epoch 31/1000] [Batch 93/168] [D loss: 0.000132] [G loss: 10.066726]\n",
      "[Epoch 31/1000] [Batch 94/168] [D loss: 0.000101] [G loss: 10.314062]\n",
      "[Epoch 31/1000] [Batch 95/168] [D loss: 0.000081] [G loss: 10.404295]\n",
      "[Epoch 31/1000] [Batch 96/168] [D loss: 0.000074] [G loss: 10.216024]\n",
      "[Epoch 31/1000] [Batch 97/168] [D loss: 0.000061] [G loss: 10.394093]\n",
      "[Epoch 31/1000] [Batch 98/168] [D loss: 0.000093] [G loss: 10.165425]\n",
      "[Epoch 31/1000] [Batch 99/168] [D loss: 0.000072] [G loss: 10.283278]\n",
      "[Epoch 31/1000] [Batch 100/168] [D loss: 0.000102] [G loss: 10.463448]\n",
      "[Epoch 31/1000] [Batch 101/168] [D loss: 0.000083] [G loss: 10.360225]\n",
      "[Epoch 31/1000] [Batch 102/168] [D loss: 0.000068] [G loss: 10.165580]\n",
      "[Epoch 31/1000] [Batch 103/168] [D loss: 0.000079] [G loss: 10.318531]\n",
      "[Epoch 31/1000] [Batch 104/168] [D loss: 0.000087] [G loss: 10.413012]\n",
      "[Epoch 31/1000] [Batch 105/168] [D loss: 0.000060] [G loss: 10.336744]\n",
      "[Epoch 31/1000] [Batch 106/168] [D loss: 0.000056] [G loss: 10.398161]\n",
      "[Epoch 31/1000] [Batch 107/168] [D loss: 0.000116] [G loss: 10.317863]\n",
      "[Epoch 31/1000] [Batch 108/168] [D loss: 0.000055] [G loss: 10.468849]\n",
      "[Epoch 31/1000] [Batch 109/168] [D loss: 0.000068] [G loss: 10.370206]\n",
      "[Epoch 31/1000] [Batch 110/168] [D loss: 0.000058] [G loss: 10.324094]\n",
      "[Epoch 31/1000] [Batch 111/168] [D loss: 0.000092] [G loss: 10.447618]\n",
      "[Epoch 31/1000] [Batch 112/168] [D loss: 0.000064] [G loss: 10.397585]\n",
      "[Epoch 31/1000] [Batch 113/168] [D loss: 0.000080] [G loss: 10.579092]\n",
      "[Epoch 31/1000] [Batch 114/168] [D loss: 0.000065] [G loss: 10.514501]\n",
      "[Epoch 31/1000] [Batch 115/168] [D loss: 0.000035] [G loss: 10.728141]\n",
      "[Epoch 31/1000] [Batch 116/168] [D loss: 0.000050] [G loss: 10.661077]\n",
      "[Epoch 31/1000] [Batch 117/168] [D loss: 0.000071] [G loss: 10.673656]\n",
      "[Epoch 31/1000] [Batch 118/168] [D loss: 0.000052] [G loss: 10.485712]\n",
      "[Epoch 31/1000] [Batch 119/168] [D loss: 0.000051] [G loss: 10.472924]\n",
      "[Epoch 31/1000] [Batch 120/168] [D loss: 0.000048] [G loss: 10.859007]\n",
      "[Epoch 31/1000] [Batch 121/168] [D loss: 0.000071] [G loss: 10.499122]\n",
      "[Epoch 31/1000] [Batch 122/168] [D loss: 0.000059] [G loss: 10.595998]\n",
      "[Epoch 31/1000] [Batch 123/168] [D loss: 0.000052] [G loss: 10.596457]\n",
      "[Epoch 31/1000] [Batch 124/168] [D loss: 0.000058] [G loss: 10.713402]\n",
      "[Epoch 31/1000] [Batch 125/168] [D loss: 0.000044] [G loss: 10.596745]\n",
      "[Epoch 31/1000] [Batch 126/168] [D loss: 0.000058] [G loss: 10.533267]\n",
      "[Epoch 31/1000] [Batch 127/168] [D loss: 0.000063] [G loss: 10.514690]\n",
      "[Epoch 31/1000] [Batch 128/168] [D loss: 0.000050] [G loss: 10.805308]\n",
      "[Epoch 31/1000] [Batch 129/168] [D loss: 0.000070] [G loss: 10.386915]\n",
      "[Epoch 31/1000] [Batch 130/168] [D loss: 0.000065] [G loss: 10.888292]\n",
      "[Epoch 31/1000] [Batch 131/168] [D loss: 0.000047] [G loss: 10.944515]\n",
      "[Epoch 31/1000] [Batch 132/168] [D loss: 0.000075] [G loss: 10.537322]\n",
      "[Epoch 31/1000] [Batch 133/168] [D loss: 0.000058] [G loss: 10.838537]\n",
      "[Epoch 31/1000] [Batch 134/168] [D loss: 0.000047] [G loss: 11.007740]\n",
      "[Epoch 31/1000] [Batch 135/168] [D loss: 0.000056] [G loss: 11.151047]\n",
      "[Epoch 31/1000] [Batch 136/168] [D loss: 0.000086] [G loss: 10.650096]\n",
      "[Epoch 31/1000] [Batch 137/168] [D loss: 0.000054] [G loss: 10.770739]\n",
      "[Epoch 31/1000] [Batch 138/168] [D loss: 0.000041] [G loss: 10.844673]\n",
      "[Epoch 31/1000] [Batch 139/168] [D loss: 0.000066] [G loss: 10.628984]\n",
      "[Epoch 31/1000] [Batch 140/168] [D loss: 0.000055] [G loss: 10.617177]\n",
      "[Epoch 31/1000] [Batch 141/168] [D loss: 0.000038] [G loss: 11.051362]\n",
      "[Epoch 31/1000] [Batch 142/168] [D loss: 0.000050] [G loss: 10.958212]\n",
      "[Epoch 31/1000] [Batch 143/168] [D loss: 0.000076] [G loss: 10.602102]\n",
      "[Epoch 31/1000] [Batch 144/168] [D loss: 0.000042] [G loss: 10.686579]\n",
      "[Epoch 31/1000] [Batch 145/168] [D loss: 0.000098] [G loss: 10.304302]\n",
      "[Epoch 31/1000] [Batch 146/168] [D loss: 0.000076] [G loss: 10.338195]\n",
      "[Epoch 31/1000] [Batch 147/168] [D loss: 0.000043] [G loss: 10.612621]\n",
      "[Epoch 31/1000] [Batch 148/168] [D loss: 0.000046] [G loss: 10.874778]\n",
      "[Epoch 31/1000] [Batch 149/168] [D loss: 0.000076] [G loss: 10.608304]\n",
      "[Epoch 31/1000] [Batch 150/168] [D loss: 0.000073] [G loss: 10.554888]\n",
      "[Epoch 31/1000] [Batch 151/168] [D loss: 0.000059] [G loss: 10.559589]\n",
      "[Epoch 31/1000] [Batch 152/168] [D loss: 0.000080] [G loss: 10.469664]\n",
      "[Epoch 31/1000] [Batch 153/168] [D loss: 0.000049] [G loss: 10.743660]\n",
      "[Epoch 31/1000] [Batch 154/168] [D loss: 0.000050] [G loss: 10.807162]\n",
      "[Epoch 31/1000] [Batch 155/168] [D loss: 0.000054] [G loss: 10.616549]\n",
      "[Epoch 31/1000] [Batch 156/168] [D loss: 0.000065] [G loss: 10.518820]\n",
      "[Epoch 31/1000] [Batch 157/168] [D loss: 0.000061] [G loss: 10.857412]\n",
      "[Epoch 31/1000] [Batch 158/168] [D loss: 0.000045] [G loss: 10.696408]\n",
      "[Epoch 31/1000] [Batch 159/168] [D loss: 0.000035] [G loss: 10.819489]\n",
      "[Epoch 31/1000] [Batch 160/168] [D loss: 0.000043] [G loss: 10.887942]\n",
      "[Epoch 31/1000] [Batch 161/168] [D loss: 0.000047] [G loss: 10.763489]\n",
      "[Epoch 31/1000] [Batch 162/168] [D loss: 0.000052] [G loss: 10.935473]\n",
      "[Epoch 31/1000] [Batch 163/168] [D loss: 0.000054] [G loss: 10.929489]\n",
      "[Epoch 31/1000] [Batch 164/168] [D loss: 0.000060] [G loss: 10.801150]\n",
      "[Epoch 31/1000] [Batch 165/168] [D loss: 0.000045] [G loss: 10.773998]\n",
      "[Epoch 31/1000] [Batch 166/168] [D loss: 0.000058] [G loss: 10.858698]\n",
      "[Epoch 31/1000] [Batch 167/168] [D loss: 0.000064] [G loss: 10.852522]\n",
      "[Epoch 31/1000] [Batch 168/168] [D loss: 0.000052] [G loss: 10.541040]\n",
      "[Epoch 32/1000] [Batch 1/168] [D loss: 0.000047] [G loss: 11.004467]\n",
      "[Epoch 32/1000] [Batch 2/168] [D loss: 0.000044] [G loss: 10.817475]\n",
      "[Epoch 32/1000] [Batch 3/168] [D loss: 0.000065] [G loss: 10.698957]\n",
      "[Epoch 32/1000] [Batch 4/168] [D loss: 0.000033] [G loss: 11.054029]\n",
      "[Epoch 32/1000] [Batch 5/168] [D loss: 0.000073] [G loss: 10.905348]\n",
      "[Epoch 32/1000] [Batch 6/168] [D loss: 0.000066] [G loss: 10.678555]\n",
      "[Epoch 32/1000] [Batch 7/168] [D loss: 0.000053] [G loss: 10.670473]\n",
      "[Epoch 32/1000] [Batch 8/168] [D loss: 0.000053] [G loss: 10.944171]\n",
      "[Epoch 32/1000] [Batch 9/168] [D loss: 0.000053] [G loss: 10.695338]\n",
      "[Epoch 32/1000] [Batch 10/168] [D loss: 0.000042] [G loss: 10.694610]\n",
      "[Epoch 32/1000] [Batch 11/168] [D loss: 0.000072] [G loss: 10.689294]\n",
      "[Epoch 32/1000] [Batch 12/168] [D loss: 0.000050] [G loss: 10.688104]\n",
      "[Epoch 32/1000] [Batch 13/168] [D loss: 0.000046] [G loss: 10.790354]\n",
      "[Epoch 32/1000] [Batch 14/168] [D loss: 0.000078] [G loss: 10.639664]\n",
      "[Epoch 32/1000] [Batch 15/168] [D loss: 0.000046] [G loss: 10.871814]\n",
      "[Epoch 32/1000] [Batch 16/168] [D loss: 0.000058] [G loss: 10.812401]\n",
      "[Epoch 32/1000] [Batch 17/168] [D loss: 0.000067] [G loss: 10.658063]\n",
      "[Epoch 32/1000] [Batch 18/168] [D loss: 0.000056] [G loss: 10.818390]\n",
      "[Epoch 32/1000] [Batch 19/168] [D loss: 0.000057] [G loss: 10.904680]\n",
      "[Epoch 32/1000] [Batch 20/168] [D loss: 0.000055] [G loss: 10.494328]\n",
      "[Epoch 32/1000] [Batch 21/168] [D loss: 0.000031] [G loss: 10.895754]\n",
      "[Epoch 32/1000] [Batch 22/168] [D loss: 0.000053] [G loss: 10.659468]\n",
      "[Epoch 32/1000] [Batch 23/168] [D loss: 0.000080] [G loss: 11.130959]\n",
      "[Epoch 32/1000] [Batch 24/168] [D loss: 0.000062] [G loss: 10.707893]\n",
      "[Epoch 32/1000] [Batch 25/168] [D loss: 0.000053] [G loss: 11.001447]\n",
      "[Epoch 32/1000] [Batch 26/168] [D loss: 0.000046] [G loss: 10.713596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/1000] [Batch 27/168] [D loss: 0.000029] [G loss: 10.828520]\n",
      "[Epoch 32/1000] [Batch 28/168] [D loss: 0.000046] [G loss: 10.583347]\n",
      "[Epoch 32/1000] [Batch 29/168] [D loss: 0.000052] [G loss: 10.816652]\n",
      "[Epoch 32/1000] [Batch 30/168] [D loss: 0.000046] [G loss: 10.766822]\n",
      "[Epoch 32/1000] [Batch 31/168] [D loss: 0.000040] [G loss: 11.148413]\n",
      "[Epoch 32/1000] [Batch 32/168] [D loss: 0.000031] [G loss: 10.860266]\n",
      "[Epoch 32/1000] [Batch 33/168] [D loss: 0.000062] [G loss: 10.819033]\n",
      "[Epoch 32/1000] [Batch 34/168] [D loss: 0.000057] [G loss: 10.923343]\n",
      "[Epoch 32/1000] [Batch 35/168] [D loss: 0.000025] [G loss: 11.076019]\n",
      "[Epoch 32/1000] [Batch 36/168] [D loss: 0.000044] [G loss: 10.998753]\n",
      "[Epoch 32/1000] [Batch 37/168] [D loss: 0.000051] [G loss: 10.878044]\n",
      "[Epoch 32/1000] [Batch 38/168] [D loss: 0.000105] [G loss: 10.962172]\n",
      "[Epoch 32/1000] [Batch 39/168] [D loss: 0.000075] [G loss: 10.633167]\n",
      "[Epoch 32/1000] [Batch 40/168] [D loss: 0.000044] [G loss: 10.938080]\n",
      "[Epoch 32/1000] [Batch 41/168] [D loss: 0.000045] [G loss: 10.725562]\n",
      "[Epoch 32/1000] [Batch 42/168] [D loss: 0.000065] [G loss: 10.903259]\n",
      "[Epoch 32/1000] [Batch 43/168] [D loss: 0.000034] [G loss: 11.065948]\n",
      "[Epoch 32/1000] [Batch 44/168] [D loss: 0.000045] [G loss: 10.541168]\n",
      "[Epoch 32/1000] [Batch 45/168] [D loss: 0.000045] [G loss: 11.094008]\n",
      "[Epoch 32/1000] [Batch 46/168] [D loss: 0.000036] [G loss: 10.777972]\n",
      "[Epoch 32/1000] [Batch 47/168] [D loss: 0.000047] [G loss: 10.810554]\n",
      "[Epoch 32/1000] [Batch 48/168] [D loss: 0.000045] [G loss: 10.960398]\n",
      "[Epoch 32/1000] [Batch 49/168] [D loss: 0.000042] [G loss: 10.808552]\n",
      "[Epoch 32/1000] [Batch 50/168] [D loss: 0.000077] [G loss: 10.775418]\n",
      "[Epoch 32/1000] [Batch 51/168] [D loss: 0.000032] [G loss: 10.978737]\n",
      "[Epoch 32/1000] [Batch 52/168] [D loss: 0.000041] [G loss: 10.919453]\n",
      "[Epoch 32/1000] [Batch 53/168] [D loss: 0.000057] [G loss: 10.775812]\n",
      "[Epoch 32/1000] [Batch 54/168] [D loss: 0.000040] [G loss: 10.714791]\n",
      "[Epoch 32/1000] [Batch 55/168] [D loss: 0.000032] [G loss: 11.007069]\n",
      "[Epoch 32/1000] [Batch 56/168] [D loss: 0.000037] [G loss: 11.012452]\n",
      "[Epoch 32/1000] [Batch 57/168] [D loss: 0.000040] [G loss: 10.899466]\n",
      "[Epoch 32/1000] [Batch 58/168] [D loss: 0.000055] [G loss: 10.926946]\n",
      "[Epoch 32/1000] [Batch 59/168] [D loss: 0.000066] [G loss: 10.837692]\n",
      "[Epoch 32/1000] [Batch 60/168] [D loss: 0.000037] [G loss: 10.920932]\n",
      "[Epoch 32/1000] [Batch 61/168] [D loss: 0.000059] [G loss: 10.933778]\n",
      "[Epoch 32/1000] [Batch 62/168] [D loss: 0.000041] [G loss: 11.022034]\n",
      "[Epoch 32/1000] [Batch 63/168] [D loss: 0.000050] [G loss: 10.870405]\n",
      "[Epoch 32/1000] [Batch 64/168] [D loss: 0.000049] [G loss: 11.138111]\n",
      "[Epoch 32/1000] [Batch 65/168] [D loss: 0.000030] [G loss: 11.072492]\n",
      "[Epoch 32/1000] [Batch 66/168] [D loss: 0.000034] [G loss: 11.104393]\n",
      "[Epoch 32/1000] [Batch 67/168] [D loss: 0.000042] [G loss: 11.422747]\n",
      "[Epoch 32/1000] [Batch 68/168] [D loss: 0.000038] [G loss: 10.934188]\n",
      "[Epoch 32/1000] [Batch 69/168] [D loss: 0.000039] [G loss: 10.922110]\n",
      "[Epoch 32/1000] [Batch 70/168] [D loss: 0.000047] [G loss: 10.915878]\n",
      "[Epoch 32/1000] [Batch 71/168] [D loss: 0.000032] [G loss: 10.882933]\n",
      "[Epoch 32/1000] [Batch 72/168] [D loss: 0.000039] [G loss: 10.876172]\n",
      "[Epoch 32/1000] [Batch 73/168] [D loss: 0.000047] [G loss: 11.231324]\n",
      "[Epoch 32/1000] [Batch 74/168] [D loss: 0.000043] [G loss: 10.763763]\n",
      "[Epoch 32/1000] [Batch 75/168] [D loss: 0.000054] [G loss: 11.188545]\n",
      "[Epoch 32/1000] [Batch 76/168] [D loss: 0.000044] [G loss: 10.780640]\n",
      "[Epoch 32/1000] [Batch 77/168] [D loss: 0.000038] [G loss: 10.954370]\n",
      "[Epoch 32/1000] [Batch 78/168] [D loss: 0.000058] [G loss: 10.921667]\n",
      "[Epoch 32/1000] [Batch 79/168] [D loss: 0.000033] [G loss: 11.267604]\n",
      "[Epoch 32/1000] [Batch 80/168] [D loss: 0.000048] [G loss: 11.382206]\n",
      "[Epoch 32/1000] [Batch 81/168] [D loss: 0.000046] [G loss: 10.833628]\n",
      "[Epoch 32/1000] [Batch 82/168] [D loss: 0.000055] [G loss: 10.915338]\n",
      "[Epoch 32/1000] [Batch 83/168] [D loss: 0.000035] [G loss: 10.837733]\n",
      "[Epoch 32/1000] [Batch 84/168] [D loss: 0.000035] [G loss: 10.910753]\n",
      "[Epoch 32/1000] [Batch 85/168] [D loss: 0.000044] [G loss: 11.063147]\n",
      "[Epoch 32/1000] [Batch 86/168] [D loss: 0.000052] [G loss: 10.968477]\n",
      "[Epoch 32/1000] [Batch 87/168] [D loss: 0.000047] [G loss: 10.573981]\n",
      "[Epoch 32/1000] [Batch 88/168] [D loss: 0.000034] [G loss: 11.058459]\n",
      "[Epoch 32/1000] [Batch 89/168] [D loss: 0.000051] [G loss: 10.991885]\n",
      "[Epoch 32/1000] [Batch 90/168] [D loss: 0.000040] [G loss: 11.031186]\n",
      "[Epoch 32/1000] [Batch 91/168] [D loss: 0.000031] [G loss: 11.042206]\n",
      "[Epoch 32/1000] [Batch 92/168] [D loss: 0.000032] [G loss: 11.136661]\n",
      "[Epoch 32/1000] [Batch 93/168] [D loss: 0.000052] [G loss: 11.015136]\n",
      "[Epoch 32/1000] [Batch 94/168] [D loss: 0.000039] [G loss: 10.974797]\n",
      "[Epoch 32/1000] [Batch 95/168] [D loss: 0.000043] [G loss: 10.818214]\n",
      "[Epoch 32/1000] [Batch 96/168] [D loss: 0.000028] [G loss: 11.371390]\n",
      "[Epoch 32/1000] [Batch 97/168] [D loss: 0.000046] [G loss: 11.075031]\n",
      "[Epoch 32/1000] [Batch 98/168] [D loss: 0.000038] [G loss: 10.878559]\n",
      "[Epoch 32/1000] [Batch 99/168] [D loss: 0.000027] [G loss: 11.130498]\n",
      "[Epoch 32/1000] [Batch 100/168] [D loss: 0.000045] [G loss: 11.053827]\n",
      "[Epoch 32/1000] [Batch 101/168] [D loss: 0.000041] [G loss: 11.093264]\n",
      "[Epoch 32/1000] [Batch 102/168] [D loss: 0.000031] [G loss: 11.194856]\n",
      "[Epoch 32/1000] [Batch 103/168] [D loss: 0.000051] [G loss: 10.823895]\n",
      "[Epoch 32/1000] [Batch 104/168] [D loss: 0.000039] [G loss: 11.219945]\n",
      "[Epoch 32/1000] [Batch 105/168] [D loss: 0.000037] [G loss: 11.189334]\n",
      "[Epoch 32/1000] [Batch 106/168] [D loss: 0.000042] [G loss: 10.956971]\n",
      "[Epoch 32/1000] [Batch 107/168] [D loss: 0.000035] [G loss: 11.335257]\n",
      "[Epoch 32/1000] [Batch 108/168] [D loss: 0.000059] [G loss: 11.084868]\n",
      "[Epoch 32/1000] [Batch 109/168] [D loss: 0.000036] [G loss: 10.904336]\n",
      "[Epoch 32/1000] [Batch 110/168] [D loss: 0.000031] [G loss: 11.130838]\n",
      "[Epoch 32/1000] [Batch 111/168] [D loss: 0.000042] [G loss: 10.876139]\n",
      "[Epoch 32/1000] [Batch 112/168] [D loss: 0.000036] [G loss: 10.915854]\n",
      "[Epoch 32/1000] [Batch 113/168] [D loss: 0.000065] [G loss: 11.114594]\n",
      "[Epoch 32/1000] [Batch 114/168] [D loss: 0.000043] [G loss: 11.365348]\n",
      "[Epoch 32/1000] [Batch 115/168] [D loss: 0.000039] [G loss: 11.006484]\n",
      "[Epoch 32/1000] [Batch 116/168] [D loss: 0.000055] [G loss: 11.360869]\n",
      "[Epoch 32/1000] [Batch 117/168] [D loss: 0.000047] [G loss: 11.041782]\n",
      "[Epoch 32/1000] [Batch 118/168] [D loss: 0.000034] [G loss: 11.141302]\n",
      "[Epoch 32/1000] [Batch 119/168] [D loss: 0.000036] [G loss: 10.887528]\n",
      "[Epoch 32/1000] [Batch 120/168] [D loss: 0.000036] [G loss: 10.864504]\n",
      "[Epoch 32/1000] [Batch 121/168] [D loss: 0.000034] [G loss: 10.777356]\n",
      "[Epoch 32/1000] [Batch 122/168] [D loss: 0.000026] [G loss: 11.057507]\n",
      "[Epoch 32/1000] [Batch 123/168] [D loss: 0.000028] [G loss: 11.292746]\n",
      "[Epoch 32/1000] [Batch 124/168] [D loss: 0.000049] [G loss: 10.890976]\n",
      "[Epoch 32/1000] [Batch 125/168] [D loss: 0.000031] [G loss: 10.972155]\n",
      "[Epoch 32/1000] [Batch 126/168] [D loss: 0.000052] [G loss: 10.906555]\n",
      "[Epoch 32/1000] [Batch 127/168] [D loss: 0.000039] [G loss: 11.108956]\n",
      "[Epoch 32/1000] [Batch 128/168] [D loss: 0.000029] [G loss: 11.267527]\n",
      "[Epoch 32/1000] [Batch 129/168] [D loss: 0.000025] [G loss: 11.202291]\n",
      "[Epoch 32/1000] [Batch 130/168] [D loss: 0.000044] [G loss: 11.186411]\n",
      "[Epoch 32/1000] [Batch 131/168] [D loss: 0.000041] [G loss: 10.888759]\n",
      "[Epoch 32/1000] [Batch 132/168] [D loss: 0.000027] [G loss: 11.333948]\n",
      "[Epoch 32/1000] [Batch 133/168] [D loss: 0.000034] [G loss: 10.980614]\n",
      "[Epoch 32/1000] [Batch 134/168] [D loss: 0.000032] [G loss: 11.073073]\n",
      "[Epoch 32/1000] [Batch 135/168] [D loss: 0.000048] [G loss: 11.104976]\n",
      "[Epoch 32/1000] [Batch 136/168] [D loss: 0.000034] [G loss: 11.140734]\n",
      "[Epoch 32/1000] [Batch 137/168] [D loss: 0.000030] [G loss: 11.050107]\n",
      "[Epoch 32/1000] [Batch 138/168] [D loss: 0.000034] [G loss: 11.080225]\n",
      "[Epoch 32/1000] [Batch 139/168] [D loss: 0.000037] [G loss: 11.095823]\n",
      "[Epoch 32/1000] [Batch 140/168] [D loss: 0.000047] [G loss: 11.160510]\n",
      "[Epoch 32/1000] [Batch 141/168] [D loss: 0.000077] [G loss: 11.165835]\n",
      "[Epoch 32/1000] [Batch 142/168] [D loss: 0.000038] [G loss: 11.026834]\n",
      "[Epoch 32/1000] [Batch 143/168] [D loss: 0.000052] [G loss: 11.255663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/1000] [Batch 144/168] [D loss: 0.000036] [G loss: 11.135014]\n",
      "[Epoch 32/1000] [Batch 145/168] [D loss: 0.000040] [G loss: 10.685048]\n",
      "[Epoch 32/1000] [Batch 146/168] [D loss: 0.000021] [G loss: 11.446675]\n",
      "[Epoch 32/1000] [Batch 147/168] [D loss: 0.000053] [G loss: 11.302175]\n",
      "[Epoch 32/1000] [Batch 148/168] [D loss: 0.000045] [G loss: 11.280955]\n",
      "[Epoch 32/1000] [Batch 149/168] [D loss: 0.000028] [G loss: 11.251177]\n",
      "[Epoch 32/1000] [Batch 150/168] [D loss: 0.000044] [G loss: 11.202728]\n",
      "[Epoch 32/1000] [Batch 151/168] [D loss: 0.000039] [G loss: 11.141804]\n",
      "[Epoch 32/1000] [Batch 152/168] [D loss: 0.000048] [G loss: 10.924110]\n",
      "[Epoch 32/1000] [Batch 153/168] [D loss: 0.000042] [G loss: 11.188582]\n",
      "[Epoch 32/1000] [Batch 154/168] [D loss: 0.000034] [G loss: 10.944687]\n",
      "[Epoch 32/1000] [Batch 155/168] [D loss: 0.000051] [G loss: 10.954058]\n",
      "[Epoch 32/1000] [Batch 156/168] [D loss: 0.000021] [G loss: 11.160007]\n",
      "[Epoch 32/1000] [Batch 157/168] [D loss: 0.000027] [G loss: 10.975973]\n",
      "[Epoch 32/1000] [Batch 158/168] [D loss: 0.000028] [G loss: 11.016041]\n",
      "[Epoch 32/1000] [Batch 159/168] [D loss: 0.000030] [G loss: 11.234592]\n",
      "[Epoch 32/1000] [Batch 160/168] [D loss: 0.000026] [G loss: 11.002190]\n",
      "[Epoch 32/1000] [Batch 161/168] [D loss: 0.000024] [G loss: 11.184727]\n",
      "[Epoch 32/1000] [Batch 162/168] [D loss: 0.000044] [G loss: 10.827744]\n",
      "[Epoch 32/1000] [Batch 163/168] [D loss: 0.000036] [G loss: 11.123909]\n",
      "[Epoch 32/1000] [Batch 164/168] [D loss: 0.000026] [G loss: 11.208779]\n",
      "[Epoch 32/1000] [Batch 165/168] [D loss: 0.000043] [G loss: 11.339333]\n",
      "[Epoch 32/1000] [Batch 166/168] [D loss: 0.000022] [G loss: 11.358049]\n",
      "[Epoch 32/1000] [Batch 167/168] [D loss: 0.000067] [G loss: 11.067572]\n",
      "[Epoch 32/1000] [Batch 168/168] [D loss: 0.000021] [G loss: 11.278482]\n",
      "[Epoch 33/1000] [Batch 1/168] [D loss: 0.000039] [G loss: 11.255548]\n",
      "[Epoch 33/1000] [Batch 2/168] [D loss: 0.000038] [G loss: 11.369290]\n",
      "[Epoch 33/1000] [Batch 3/168] [D loss: 0.000061] [G loss: 11.102701]\n",
      "[Epoch 33/1000] [Batch 4/168] [D loss: 0.000053] [G loss: 11.120468]\n",
      "[Epoch 33/1000] [Batch 5/168] [D loss: 0.000034] [G loss: 11.209561]\n",
      "[Epoch 33/1000] [Batch 6/168] [D loss: 0.000056] [G loss: 11.127407]\n",
      "[Epoch 33/1000] [Batch 7/168] [D loss: 0.000029] [G loss: 11.062960]\n",
      "[Epoch 33/1000] [Batch 8/168] [D loss: 0.000025] [G loss: 11.213056]\n",
      "[Epoch 33/1000] [Batch 9/168] [D loss: 0.000026] [G loss: 11.445852]\n",
      "[Epoch 33/1000] [Batch 10/168] [D loss: 0.000017] [G loss: 11.519604]\n",
      "[Epoch 33/1000] [Batch 11/168] [D loss: 0.000053] [G loss: 11.175636]\n",
      "[Epoch 33/1000] [Batch 12/168] [D loss: 0.000049] [G loss: 11.400293]\n",
      "[Epoch 33/1000] [Batch 13/168] [D loss: 0.000040] [G loss: 11.264084]\n",
      "[Epoch 33/1000] [Batch 14/168] [D loss: 0.000041] [G loss: 10.965739]\n",
      "[Epoch 33/1000] [Batch 15/168] [D loss: 0.000027] [G loss: 11.242466]\n",
      "[Epoch 33/1000] [Batch 16/168] [D loss: 0.000052] [G loss: 11.116118]\n",
      "[Epoch 33/1000] [Batch 17/168] [D loss: 0.000047] [G loss: 10.851574]\n",
      "[Epoch 33/1000] [Batch 18/168] [D loss: 0.000037] [G loss: 10.959814]\n",
      "[Epoch 33/1000] [Batch 19/168] [D loss: 0.000025] [G loss: 11.427158]\n",
      "[Epoch 33/1000] [Batch 20/168] [D loss: 0.000045] [G loss: 11.058218]\n",
      "[Epoch 33/1000] [Batch 21/168] [D loss: 0.000044] [G loss: 11.126592]\n",
      "[Epoch 33/1000] [Batch 22/168] [D loss: 0.000055] [G loss: 11.125080]\n",
      "[Epoch 33/1000] [Batch 23/168] [D loss: 0.000040] [G loss: 11.171857]\n",
      "[Epoch 33/1000] [Batch 24/168] [D loss: 0.000034] [G loss: 11.021379]\n",
      "[Epoch 33/1000] [Batch 25/168] [D loss: 0.000029] [G loss: 11.020369]\n",
      "[Epoch 33/1000] [Batch 26/168] [D loss: 0.000040] [G loss: 10.987560]\n",
      "[Epoch 33/1000] [Batch 27/168] [D loss: 0.000044] [G loss: 11.469982]\n",
      "[Epoch 33/1000] [Batch 28/168] [D loss: 0.000017] [G loss: 11.358628]\n",
      "[Epoch 33/1000] [Batch 29/168] [D loss: 0.000036] [G loss: 11.309058]\n",
      "[Epoch 33/1000] [Batch 30/168] [D loss: 0.000029] [G loss: 11.442707]\n",
      "[Epoch 33/1000] [Batch 31/168] [D loss: 0.000034] [G loss: 11.298133]\n",
      "[Epoch 33/1000] [Batch 32/168] [D loss: 0.000041] [G loss: 11.204708]\n",
      "[Epoch 33/1000] [Batch 33/168] [D loss: 0.000023] [G loss: 11.093610]\n",
      "[Epoch 33/1000] [Batch 34/168] [D loss: 0.000027] [G loss: 11.185759]\n",
      "[Epoch 33/1000] [Batch 35/168] [D loss: 0.000048] [G loss: 11.231406]\n",
      "[Epoch 33/1000] [Batch 36/168] [D loss: 0.000040] [G loss: 10.969501]\n",
      "[Epoch 33/1000] [Batch 37/168] [D loss: 0.000047] [G loss: 11.433332]\n",
      "[Epoch 33/1000] [Batch 38/168] [D loss: 0.000028] [G loss: 11.348326]\n",
      "[Epoch 33/1000] [Batch 39/168] [D loss: 0.000032] [G loss: 11.368373]\n",
      "[Epoch 33/1000] [Batch 40/168] [D loss: 0.000039] [G loss: 10.973850]\n",
      "[Epoch 33/1000] [Batch 41/168] [D loss: 0.000027] [G loss: 11.164352]\n",
      "[Epoch 33/1000] [Batch 42/168] [D loss: 0.000025] [G loss: 11.164748]\n",
      "[Epoch 33/1000] [Batch 43/168] [D loss: 0.000070] [G loss: 11.186552]\n",
      "[Epoch 33/1000] [Batch 44/168] [D loss: 0.000030] [G loss: 11.096220]\n",
      "[Epoch 33/1000] [Batch 45/168] [D loss: 0.000044] [G loss: 11.336831]\n",
      "[Epoch 33/1000] [Batch 46/168] [D loss: 0.000031] [G loss: 11.422410]\n",
      "[Epoch 33/1000] [Batch 47/168] [D loss: 0.000020] [G loss: 11.421189]\n",
      "[Epoch 33/1000] [Batch 48/168] [D loss: 0.000027] [G loss: 11.475962]\n",
      "[Epoch 33/1000] [Batch 49/168] [D loss: 0.000020] [G loss: 11.464062]\n",
      "[Epoch 33/1000] [Batch 50/168] [D loss: 0.000018] [G loss: 11.397135]\n",
      "[Epoch 33/1000] [Batch 51/168] [D loss: 0.000031] [G loss: 11.348767]\n",
      "[Epoch 33/1000] [Batch 52/168] [D loss: 0.000027] [G loss: 11.538155]\n",
      "[Epoch 33/1000] [Batch 53/168] [D loss: 0.000037] [G loss: 11.482594]\n",
      "[Epoch 33/1000] [Batch 54/168] [D loss: 0.000027] [G loss: 11.290892]\n",
      "[Epoch 33/1000] [Batch 55/168] [D loss: 0.000036] [G loss: 11.420855]\n",
      "[Epoch 33/1000] [Batch 56/168] [D loss: 0.000030] [G loss: 11.171413]\n",
      "[Epoch 33/1000] [Batch 57/168] [D loss: 0.000109] [G loss: 11.556617]\n",
      "[Epoch 33/1000] [Batch 58/168] [D loss: 0.000017] [G loss: 11.509244]\n",
      "[Epoch 33/1000] [Batch 59/168] [D loss: 0.000044] [G loss: 11.189665]\n",
      "[Epoch 33/1000] [Batch 60/168] [D loss: 0.000024] [G loss: 11.149773]\n",
      "[Epoch 33/1000] [Batch 61/168] [D loss: 0.000033] [G loss: 10.940040]\n",
      "[Epoch 33/1000] [Batch 62/168] [D loss: 0.000028] [G loss: 11.139459]\n",
      "[Epoch 33/1000] [Batch 63/168] [D loss: 0.000027] [G loss: 11.290172]\n",
      "[Epoch 33/1000] [Batch 64/168] [D loss: 0.000038] [G loss: 11.430758]\n",
      "[Epoch 33/1000] [Batch 65/168] [D loss: 0.000029] [G loss: 11.240813]\n",
      "[Epoch 33/1000] [Batch 66/168] [D loss: 0.000033] [G loss: 11.414107]\n",
      "[Epoch 33/1000] [Batch 67/168] [D loss: 0.000031] [G loss: 11.035355]\n",
      "[Epoch 33/1000] [Batch 68/168] [D loss: 0.000044] [G loss: 11.063560]\n",
      "[Epoch 33/1000] [Batch 69/168] [D loss: 0.000043] [G loss: 11.365778]\n",
      "[Epoch 33/1000] [Batch 70/168] [D loss: 0.000031] [G loss: 11.441160]\n",
      "[Epoch 33/1000] [Batch 71/168] [D loss: 0.000034] [G loss: 10.848580]\n",
      "[Epoch 33/1000] [Batch 72/168] [D loss: 0.000048] [G loss: 11.208780]\n",
      "[Epoch 33/1000] [Batch 73/168] [D loss: 0.000029] [G loss: 11.307037]\n",
      "[Epoch 33/1000] [Batch 74/168] [D loss: 0.000039] [G loss: 11.280791]\n",
      "[Epoch 33/1000] [Batch 75/168] [D loss: 0.000034] [G loss: 11.402335]\n",
      "[Epoch 33/1000] [Batch 76/168] [D loss: 0.000027] [G loss: 11.278691]\n",
      "[Epoch 33/1000] [Batch 77/168] [D loss: 0.000029] [G loss: 11.242108]\n",
      "[Epoch 33/1000] [Batch 78/168] [D loss: 0.000032] [G loss: 11.367681]\n",
      "[Epoch 33/1000] [Batch 79/168] [D loss: 0.000038] [G loss: 11.128349]\n",
      "[Epoch 33/1000] [Batch 80/168] [D loss: 0.000040] [G loss: 11.242451]\n",
      "[Epoch 33/1000] [Batch 81/168] [D loss: 0.000025] [G loss: 11.128129]\n",
      "[Epoch 33/1000] [Batch 82/168] [D loss: 0.000050] [G loss: 11.184182]\n",
      "[Epoch 33/1000] [Batch 83/168] [D loss: 0.000040] [G loss: 11.135446]\n",
      "[Epoch 33/1000] [Batch 84/168] [D loss: 0.000032] [G loss: 11.110304]\n",
      "[Epoch 33/1000] [Batch 85/168] [D loss: 0.000029] [G loss: 11.140066]\n",
      "[Epoch 33/1000] [Batch 86/168] [D loss: 0.000051] [G loss: 11.232256]\n",
      "[Epoch 33/1000] [Batch 87/168] [D loss: 0.000023] [G loss: 11.229891]\n",
      "[Epoch 33/1000] [Batch 88/168] [D loss: 0.000023] [G loss: 11.269862]\n",
      "[Epoch 33/1000] [Batch 89/168] [D loss: 0.000024] [G loss: 10.965576]\n",
      "[Epoch 33/1000] [Batch 90/168] [D loss: 0.000048] [G loss: 10.963774]\n",
      "[Epoch 33/1000] [Batch 91/168] [D loss: 0.000032] [G loss: 11.437871]\n",
      "[Epoch 33/1000] [Batch 92/168] [D loss: 0.000038] [G loss: 11.301314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/1000] [Batch 93/168] [D loss: 0.000052] [G loss: 11.042933]\n",
      "[Epoch 33/1000] [Batch 94/168] [D loss: 0.000053] [G loss: 11.188034]\n",
      "[Epoch 33/1000] [Batch 95/168] [D loss: 0.000040] [G loss: 11.067691]\n",
      "[Epoch 33/1000] [Batch 96/168] [D loss: 0.000034] [G loss: 11.221898]\n",
      "[Epoch 33/1000] [Batch 97/168] [D loss: 0.000019] [G loss: 11.402328]\n",
      "[Epoch 33/1000] [Batch 98/168] [D loss: 0.000020] [G loss: 11.388859]\n",
      "[Epoch 33/1000] [Batch 99/168] [D loss: 0.000019] [G loss: 11.252481]\n",
      "[Epoch 33/1000] [Batch 100/168] [D loss: 0.000027] [G loss: 11.388668]\n",
      "[Epoch 33/1000] [Batch 101/168] [D loss: 0.000021] [G loss: 11.247182]\n",
      "[Epoch 33/1000] [Batch 102/168] [D loss: 0.000041] [G loss: 11.086984]\n",
      "[Epoch 33/1000] [Batch 103/168] [D loss: 0.000065] [G loss: 11.239811]\n",
      "[Epoch 33/1000] [Batch 104/168] [D loss: 0.000025] [G loss: 11.363207]\n",
      "[Epoch 33/1000] [Batch 105/168] [D loss: 0.000027] [G loss: 11.521242]\n",
      "[Epoch 33/1000] [Batch 106/168] [D loss: 0.000031] [G loss: 11.313599]\n",
      "[Epoch 33/1000] [Batch 107/168] [D loss: 0.000021] [G loss: 11.739358]\n",
      "[Epoch 33/1000] [Batch 108/168] [D loss: 0.000032] [G loss: 11.487235]\n",
      "[Epoch 33/1000] [Batch 109/168] [D loss: 0.000021] [G loss: 11.716621]\n",
      "[Epoch 33/1000] [Batch 110/168] [D loss: 0.000031] [G loss: 11.361103]\n",
      "[Epoch 33/1000] [Batch 111/168] [D loss: 0.000034] [G loss: 11.278428]\n",
      "[Epoch 33/1000] [Batch 112/168] [D loss: 0.000037] [G loss: 11.350243]\n",
      "[Epoch 33/1000] [Batch 113/168] [D loss: 0.000060] [G loss: 11.250014]\n",
      "[Epoch 33/1000] [Batch 114/168] [D loss: 0.000043] [G loss: 11.611913]\n",
      "[Epoch 33/1000] [Batch 115/168] [D loss: 0.000044] [G loss: 11.077400]\n",
      "[Epoch 33/1000] [Batch 116/168] [D loss: 0.000029] [G loss: 11.333195]\n",
      "[Epoch 33/1000] [Batch 117/168] [D loss: 0.000023] [G loss: 11.356943]\n",
      "[Epoch 33/1000] [Batch 118/168] [D loss: 0.000028] [G loss: 11.255445]\n",
      "[Epoch 33/1000] [Batch 119/168] [D loss: 0.000018] [G loss: 11.370463]\n",
      "[Epoch 33/1000] [Batch 120/168] [D loss: 0.000041] [G loss: 11.345153]\n",
      "[Epoch 33/1000] [Batch 121/168] [D loss: 0.000021] [G loss: 11.381912]\n",
      "[Epoch 33/1000] [Batch 122/168] [D loss: 0.000025] [G loss: 11.327188]\n",
      "[Epoch 33/1000] [Batch 123/168] [D loss: 0.000024] [G loss: 11.164573]\n",
      "[Epoch 33/1000] [Batch 124/168] [D loss: 0.000024] [G loss: 11.535138]\n",
      "[Epoch 33/1000] [Batch 125/168] [D loss: 0.000036] [G loss: 11.666536]\n",
      "[Epoch 33/1000] [Batch 126/168] [D loss: 0.000028] [G loss: 11.568665]\n",
      "[Epoch 33/1000] [Batch 127/168] [D loss: 0.000031] [G loss: 10.973051]\n",
      "[Epoch 33/1000] [Batch 128/168] [D loss: 0.000021] [G loss: 11.716325]\n",
      "[Epoch 33/1000] [Batch 129/168] [D loss: 0.000031] [G loss: 11.314608]\n",
      "[Epoch 33/1000] [Batch 130/168] [D loss: 0.000026] [G loss: 11.477081]\n",
      "[Epoch 33/1000] [Batch 131/168] [D loss: 0.000030] [G loss: 11.148152]\n",
      "[Epoch 33/1000] [Batch 132/168] [D loss: 0.000040] [G loss: 11.270285]\n",
      "[Epoch 33/1000] [Batch 133/168] [D loss: 0.000031] [G loss: 11.433853]\n",
      "[Epoch 33/1000] [Batch 134/168] [D loss: 0.000042] [G loss: 11.138607]\n",
      "[Epoch 33/1000] [Batch 135/168] [D loss: 0.000043] [G loss: 11.481838]\n",
      "[Epoch 33/1000] [Batch 136/168] [D loss: 0.000024] [G loss: 11.323109]\n",
      "[Epoch 33/1000] [Batch 137/168] [D loss: 0.000029] [G loss: 11.177326]\n",
      "[Epoch 33/1000] [Batch 138/168] [D loss: 0.000044] [G loss: 10.953844]\n",
      "[Epoch 33/1000] [Batch 139/168] [D loss: 0.000075] [G loss: 11.453539]\n",
      "[Epoch 33/1000] [Batch 140/168] [D loss: 0.000043] [G loss: 11.468483]\n",
      "[Epoch 33/1000] [Batch 141/168] [D loss: 0.000021] [G loss: 11.576709]\n",
      "[Epoch 33/1000] [Batch 142/168] [D loss: 0.000053] [G loss: 11.139844]\n",
      "[Epoch 33/1000] [Batch 143/168] [D loss: 0.000020] [G loss: 11.293644]\n",
      "[Epoch 33/1000] [Batch 144/168] [D loss: 0.000036] [G loss: 11.326249]\n",
      "[Epoch 33/1000] [Batch 145/168] [D loss: 0.000038] [G loss: 11.381210]\n",
      "[Epoch 33/1000] [Batch 146/168] [D loss: 0.000023] [G loss: 11.384870]\n",
      "[Epoch 33/1000] [Batch 147/168] [D loss: 0.000027] [G loss: 11.422842]\n",
      "[Epoch 33/1000] [Batch 148/168] [D loss: 0.000031] [G loss: 11.769712]\n",
      "[Epoch 33/1000] [Batch 149/168] [D loss: 0.000020] [G loss: 11.261334]\n",
      "[Epoch 33/1000] [Batch 150/168] [D loss: 0.000022] [G loss: 11.455703]\n",
      "[Epoch 33/1000] [Batch 151/168] [D loss: 0.000035] [G loss: 11.066694]\n",
      "[Epoch 33/1000] [Batch 152/168] [D loss: 0.000027] [G loss: 11.476982]\n",
      "[Epoch 33/1000] [Batch 153/168] [D loss: 0.000019] [G loss: 11.525017]\n",
      "[Epoch 33/1000] [Batch 154/168] [D loss: 0.000023] [G loss: 11.429886]\n",
      "[Epoch 33/1000] [Batch 155/168] [D loss: 0.000037] [G loss: 11.090353]\n",
      "[Epoch 33/1000] [Batch 156/168] [D loss: 0.000025] [G loss: 11.420263]\n",
      "[Epoch 33/1000] [Batch 157/168] [D loss: 0.000019] [G loss: 11.643694]\n",
      "[Epoch 33/1000] [Batch 158/168] [D loss: 0.000022] [G loss: 11.252235]\n",
      "[Epoch 33/1000] [Batch 159/168] [D loss: 0.000031] [G loss: 11.561320]\n",
      "[Epoch 33/1000] [Batch 160/168] [D loss: 0.000028] [G loss: 11.595987]\n",
      "[Epoch 33/1000] [Batch 161/168] [D loss: 0.000027] [G loss: 11.335301]\n",
      "[Epoch 33/1000] [Batch 162/168] [D loss: 0.000031] [G loss: 11.302484]\n",
      "[Epoch 33/1000] [Batch 163/168] [D loss: 0.000046] [G loss: 11.469639]\n",
      "[Epoch 33/1000] [Batch 164/168] [D loss: 0.000031] [G loss: 11.461740]\n",
      "[Epoch 33/1000] [Batch 165/168] [D loss: 0.000039] [G loss: 11.159663]\n",
      "[Epoch 33/1000] [Batch 166/168] [D loss: 0.000024] [G loss: 11.206300]\n",
      "[Epoch 33/1000] [Batch 167/168] [D loss: 0.000023] [G loss: 11.367134]\n",
      "[Epoch 33/1000] [Batch 168/168] [D loss: 0.000017] [G loss: 11.531964]\n",
      "[Epoch 34/1000] [Batch 1/168] [D loss: 0.000032] [G loss: 11.721559]\n",
      "[Epoch 34/1000] [Batch 2/168] [D loss: 0.000019] [G loss: 11.347976]\n",
      "[Epoch 34/1000] [Batch 3/168] [D loss: 0.000026] [G loss: 11.271628]\n",
      "[Epoch 34/1000] [Batch 4/168] [D loss: 0.000023] [G loss: 11.535881]\n",
      "[Epoch 34/1000] [Batch 5/168] [D loss: 0.000027] [G loss: 11.793971]\n",
      "[Epoch 34/1000] [Batch 6/168] [D loss: 0.000024] [G loss: 11.480841]\n",
      "[Epoch 34/1000] [Batch 7/168] [D loss: 0.000039] [G loss: 11.282004]\n",
      "[Epoch 34/1000] [Batch 8/168] [D loss: 0.000020] [G loss: 11.719160]\n",
      "[Epoch 34/1000] [Batch 9/168] [D loss: 0.000017] [G loss: 11.537653]\n",
      "[Epoch 34/1000] [Batch 10/168] [D loss: 0.000023] [G loss: 11.374887]\n",
      "[Epoch 34/1000] [Batch 11/168] [D loss: 0.000036] [G loss: 11.499728]\n",
      "[Epoch 34/1000] [Batch 12/168] [D loss: 0.000027] [G loss: 11.644711]\n",
      "[Epoch 34/1000] [Batch 13/168] [D loss: 0.000020] [G loss: 11.517140]\n",
      "[Epoch 34/1000] [Batch 14/168] [D loss: 0.000041] [G loss: 11.408276]\n",
      "[Epoch 34/1000] [Batch 15/168] [D loss: 0.000024] [G loss: 11.323596]\n",
      "[Epoch 34/1000] [Batch 16/168] [D loss: 0.000040] [G loss: 11.314986]\n",
      "[Epoch 34/1000] [Batch 17/168] [D loss: 0.000023] [G loss: 11.447163]\n",
      "[Epoch 34/1000] [Batch 18/168] [D loss: 0.000024] [G loss: 11.358789]\n",
      "[Epoch 34/1000] [Batch 19/168] [D loss: 0.000029] [G loss: 11.486837]\n",
      "[Epoch 34/1000] [Batch 20/168] [D loss: 0.000043] [G loss: 11.363989]\n",
      "[Epoch 34/1000] [Batch 21/168] [D loss: 0.000051] [G loss: 11.394020]\n",
      "[Epoch 34/1000] [Batch 22/168] [D loss: 0.000027] [G loss: 11.191669]\n",
      "[Epoch 34/1000] [Batch 23/168] [D loss: 0.000029] [G loss: 11.412817]\n",
      "[Epoch 34/1000] [Batch 24/168] [D loss: 0.000027] [G loss: 11.494826]\n",
      "[Epoch 34/1000] [Batch 25/168] [D loss: 0.000023] [G loss: 11.399159]\n",
      "[Epoch 34/1000] [Batch 26/168] [D loss: 0.000043] [G loss: 10.977304]\n",
      "[Epoch 34/1000] [Batch 27/168] [D loss: 0.000016] [G loss: 11.557713]\n",
      "[Epoch 34/1000] [Batch 28/168] [D loss: 0.000028] [G loss: 11.180041]\n",
      "[Epoch 34/1000] [Batch 29/168] [D loss: 0.000051] [G loss: 11.458726]\n",
      "[Epoch 34/1000] [Batch 30/168] [D loss: 0.000026] [G loss: 11.323133]\n",
      "[Epoch 34/1000] [Batch 31/168] [D loss: 0.000029] [G loss: 11.365092]\n",
      "[Epoch 34/1000] [Batch 32/168] [D loss: 0.000024] [G loss: 11.214667]\n",
      "[Epoch 34/1000] [Batch 33/168] [D loss: 0.000026] [G loss: 11.309223]\n",
      "[Epoch 34/1000] [Batch 34/168] [D loss: 0.000041] [G loss: 11.389373]\n",
      "[Epoch 34/1000] [Batch 35/168] [D loss: 0.000027] [G loss: 11.253678]\n",
      "[Epoch 34/1000] [Batch 36/168] [D loss: 0.000029] [G loss: 11.182404]\n",
      "[Epoch 34/1000] [Batch 37/168] [D loss: 0.000046] [G loss: 11.322989]\n",
      "[Epoch 34/1000] [Batch 38/168] [D loss: 0.000030] [G loss: 11.273111]\n",
      "[Epoch 34/1000] [Batch 39/168] [D loss: 0.000021] [G loss: 11.685881]\n",
      "[Epoch 34/1000] [Batch 40/168] [D loss: 0.000024] [G loss: 11.339481]\n",
      "[Epoch 34/1000] [Batch 41/168] [D loss: 0.000028] [G loss: 11.427116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] [Batch 42/168] [D loss: 0.000020] [G loss: 11.628366]\n",
      "[Epoch 34/1000] [Batch 43/168] [D loss: 0.000031] [G loss: 11.073106]\n",
      "[Epoch 34/1000] [Batch 44/168] [D loss: 0.000024] [G loss: 11.344671]\n",
      "[Epoch 34/1000] [Batch 45/168] [D loss: 0.000032] [G loss: 11.176655]\n",
      "[Epoch 34/1000] [Batch 46/168] [D loss: 0.000019] [G loss: 11.466202]\n",
      "[Epoch 34/1000] [Batch 47/168] [D loss: 0.000020] [G loss: 11.512747]\n",
      "[Epoch 34/1000] [Batch 48/168] [D loss: 0.000019] [G loss: 11.409136]\n",
      "[Epoch 34/1000] [Batch 49/168] [D loss: 0.000024] [G loss: 11.571486]\n",
      "[Epoch 34/1000] [Batch 50/168] [D loss: 0.000026] [G loss: 11.518242]\n",
      "[Epoch 34/1000] [Batch 51/168] [D loss: 0.000024] [G loss: 11.416967]\n",
      "[Epoch 34/1000] [Batch 52/168] [D loss: 0.000025] [G loss: 11.725456]\n",
      "[Epoch 34/1000] [Batch 53/168] [D loss: 0.000019] [G loss: 11.386272]\n",
      "[Epoch 34/1000] [Batch 54/168] [D loss: 0.000025] [G loss: 11.552052]\n",
      "[Epoch 34/1000] [Batch 55/168] [D loss: 0.000039] [G loss: 11.170535]\n",
      "[Epoch 34/1000] [Batch 56/168] [D loss: 0.000050] [G loss: 11.321783]\n",
      "[Epoch 34/1000] [Batch 57/168] [D loss: 0.000025] [G loss: 11.370903]\n",
      "[Epoch 34/1000] [Batch 58/168] [D loss: 0.000021] [G loss: 11.435261]\n",
      "[Epoch 34/1000] [Batch 59/168] [D loss: 0.000052] [G loss: 11.350314]\n",
      "[Epoch 34/1000] [Batch 60/168] [D loss: 0.000018] [G loss: 11.611320]\n",
      "[Epoch 34/1000] [Batch 61/168] [D loss: 0.000023] [G loss: 11.422141]\n",
      "[Epoch 34/1000] [Batch 62/168] [D loss: 0.000039] [G loss: 11.461254]\n",
      "[Epoch 34/1000] [Batch 63/168] [D loss: 0.000029] [G loss: 11.607684]\n",
      "[Epoch 34/1000] [Batch 64/168] [D loss: 0.000024] [G loss: 11.280435]\n",
      "[Epoch 34/1000] [Batch 65/168] [D loss: 0.000030] [G loss: 11.374729]\n",
      "[Epoch 34/1000] [Batch 66/168] [D loss: 0.000043] [G loss: 11.054037]\n",
      "[Epoch 34/1000] [Batch 67/168] [D loss: 0.000026] [G loss: 11.307417]\n",
      "[Epoch 34/1000] [Batch 68/168] [D loss: 0.000029] [G loss: 11.213468]\n",
      "[Epoch 34/1000] [Batch 69/168] [D loss: 0.000027] [G loss: 11.309383]\n",
      "[Epoch 34/1000] [Batch 70/168] [D loss: 0.000024] [G loss: 11.539530]\n",
      "[Epoch 34/1000] [Batch 71/168] [D loss: 0.000032] [G loss: 11.398498]\n",
      "[Epoch 34/1000] [Batch 72/168] [D loss: 0.000042] [G loss: 11.536658]\n",
      "[Epoch 34/1000] [Batch 73/168] [D loss: 0.000022] [G loss: 11.775826]\n",
      "[Epoch 34/1000] [Batch 74/168] [D loss: 0.000020] [G loss: 11.285171]\n",
      "[Epoch 34/1000] [Batch 75/168] [D loss: 0.000025] [G loss: 11.460463]\n",
      "[Epoch 34/1000] [Batch 76/168] [D loss: 0.000026] [G loss: 11.244041]\n",
      "[Epoch 34/1000] [Batch 77/168] [D loss: 0.000035] [G loss: 11.228278]\n",
      "[Epoch 34/1000] [Batch 78/168] [D loss: 0.000021] [G loss: 11.485571]\n",
      "[Epoch 34/1000] [Batch 79/168] [D loss: 0.000017] [G loss: 11.824358]\n",
      "[Epoch 34/1000] [Batch 80/168] [D loss: 0.000049] [G loss: 10.869897]\n",
      "[Epoch 34/1000] [Batch 81/168] [D loss: 0.000025] [G loss: 11.572649]\n",
      "[Epoch 34/1000] [Batch 82/168] [D loss: 0.000026] [G loss: 11.335018]\n",
      "[Epoch 34/1000] [Batch 83/168] [D loss: 0.000025] [G loss: 11.408967]\n",
      "[Epoch 34/1000] [Batch 84/168] [D loss: 0.000042] [G loss: 11.335497]\n",
      "[Epoch 34/1000] [Batch 85/168] [D loss: 0.000046] [G loss: 11.132766]\n",
      "[Epoch 34/1000] [Batch 86/168] [D loss: 0.000025] [G loss: 11.243790]\n",
      "[Epoch 34/1000] [Batch 87/168] [D loss: 0.000024] [G loss: 11.269781]\n",
      "[Epoch 34/1000] [Batch 88/168] [D loss: 0.000021] [G loss: 11.477741]\n",
      "[Epoch 34/1000] [Batch 89/168] [D loss: 0.000024] [G loss: 11.470593]\n",
      "[Epoch 34/1000] [Batch 90/168] [D loss: 0.000036] [G loss: 11.303933]\n",
      "[Epoch 34/1000] [Batch 91/168] [D loss: 0.000036] [G loss: 11.559762]\n",
      "[Epoch 34/1000] [Batch 92/168] [D loss: 0.000036] [G loss: 11.528180]\n",
      "[Epoch 34/1000] [Batch 93/168] [D loss: 0.000017] [G loss: 11.579828]\n",
      "[Epoch 34/1000] [Batch 94/168] [D loss: 0.000023] [G loss: 11.416145]\n",
      "[Epoch 34/1000] [Batch 95/168] [D loss: 0.000026] [G loss: 11.327286]\n",
      "[Epoch 34/1000] [Batch 96/168] [D loss: 0.000025] [G loss: 11.677210]\n",
      "[Epoch 34/1000] [Batch 97/168] [D loss: 0.000024] [G loss: 11.461596]\n",
      "[Epoch 34/1000] [Batch 98/168] [D loss: 0.000020] [G loss: 11.585951]\n",
      "[Epoch 34/1000] [Batch 99/168] [D loss: 0.000022] [G loss: 11.397730]\n",
      "[Epoch 34/1000] [Batch 100/168] [D loss: 0.000023] [G loss: 11.490726]\n",
      "[Epoch 34/1000] [Batch 101/168] [D loss: 0.000025] [G loss: 11.856549]\n",
      "[Epoch 34/1000] [Batch 102/168] [D loss: 0.000023] [G loss: 11.244913]\n",
      "[Epoch 34/1000] [Batch 103/168] [D loss: 0.000020] [G loss: 11.578389]\n",
      "[Epoch 34/1000] [Batch 104/168] [D loss: 0.000029] [G loss: 11.356083]\n",
      "[Epoch 34/1000] [Batch 105/168] [D loss: 0.000016] [G loss: 11.488294]\n",
      "[Epoch 34/1000] [Batch 106/168] [D loss: 0.000034] [G loss: 11.373035]\n",
      "[Epoch 34/1000] [Batch 107/168] [D loss: 0.000031] [G loss: 11.305541]\n",
      "[Epoch 34/1000] [Batch 108/168] [D loss: 0.000030] [G loss: 11.189573]\n",
      "[Epoch 34/1000] [Batch 109/168] [D loss: 0.000020] [G loss: 11.372630]\n",
      "[Epoch 34/1000] [Batch 110/168] [D loss: 0.000021] [G loss: 11.509888]\n",
      "[Epoch 34/1000] [Batch 111/168] [D loss: 0.000027] [G loss: 11.588659]\n",
      "[Epoch 34/1000] [Batch 112/168] [D loss: 0.000033] [G loss: 11.357222]\n",
      "[Epoch 34/1000] [Batch 113/168] [D loss: 0.000032] [G loss: 11.738945]\n",
      "[Epoch 34/1000] [Batch 114/168] [D loss: 0.000020] [G loss: 11.287136]\n",
      "[Epoch 34/1000] [Batch 115/168] [D loss: 0.000026] [G loss: 11.276042]\n",
      "[Epoch 34/1000] [Batch 116/168] [D loss: 0.000022] [G loss: 11.733914]\n",
      "[Epoch 34/1000] [Batch 117/168] [D loss: 0.000027] [G loss: 11.462360]\n",
      "[Epoch 34/1000] [Batch 118/168] [D loss: 0.000033] [G loss: 11.247090]\n",
      "[Epoch 34/1000] [Batch 119/168] [D loss: 0.000031] [G loss: 11.353357]\n",
      "[Epoch 34/1000] [Batch 120/168] [D loss: 0.000026] [G loss: 11.727912]\n",
      "[Epoch 34/1000] [Batch 121/168] [D loss: 0.000016] [G loss: 11.581118]\n",
      "[Epoch 34/1000] [Batch 122/168] [D loss: 0.000022] [G loss: 11.467422]\n",
      "[Epoch 34/1000] [Batch 123/168] [D loss: 0.000024] [G loss: 11.710901]\n",
      "[Epoch 34/1000] [Batch 124/168] [D loss: 0.000033] [G loss: 11.113132]\n",
      "[Epoch 34/1000] [Batch 125/168] [D loss: 0.000026] [G loss: 11.594512]\n",
      "[Epoch 34/1000] [Batch 126/168] [D loss: 0.000025] [G loss: 11.677430]\n",
      "[Epoch 34/1000] [Batch 127/168] [D loss: 0.000028] [G loss: 11.434124]\n",
      "[Epoch 34/1000] [Batch 128/168] [D loss: 0.000021] [G loss: 11.608353]\n",
      "[Epoch 34/1000] [Batch 129/168] [D loss: 0.000030] [G loss: 11.238670]\n",
      "[Epoch 34/1000] [Batch 130/168] [D loss: 0.000021] [G loss: 11.678016]\n",
      "[Epoch 34/1000] [Batch 131/168] [D loss: 0.000023] [G loss: 11.693370]\n",
      "[Epoch 34/1000] [Batch 132/168] [D loss: 0.000027] [G loss: 11.556333]\n",
      "[Epoch 34/1000] [Batch 133/168] [D loss: 0.000032] [G loss: 11.370070]\n",
      "[Epoch 34/1000] [Batch 134/168] [D loss: 0.000016] [G loss: 11.785981]\n",
      "[Epoch 34/1000] [Batch 135/168] [D loss: 0.000020] [G loss: 11.707829]\n",
      "[Epoch 34/1000] [Batch 136/168] [D loss: 0.000027] [G loss: 11.619844]\n",
      "[Epoch 34/1000] [Batch 137/168] [D loss: 0.000024] [G loss: 11.525246]\n",
      "[Epoch 34/1000] [Batch 138/168] [D loss: 0.000019] [G loss: 11.644034]\n",
      "[Epoch 34/1000] [Batch 139/168] [D loss: 0.000021] [G loss: 11.985650]\n",
      "[Epoch 34/1000] [Batch 140/168] [D loss: 0.000020] [G loss: 11.527325]\n",
      "[Epoch 34/1000] [Batch 141/168] [D loss: 0.000035] [G loss: 11.577928]\n",
      "[Epoch 34/1000] [Batch 142/168] [D loss: 0.000023] [G loss: 11.267061]\n",
      "[Epoch 34/1000] [Batch 143/168] [D loss: 0.000027] [G loss: 11.385117]\n",
      "[Epoch 34/1000] [Batch 144/168] [D loss: 0.000018] [G loss: 11.726985]\n",
      "[Epoch 34/1000] [Batch 145/168] [D loss: 0.000017] [G loss: 11.274925]\n",
      "[Epoch 34/1000] [Batch 146/168] [D loss: 0.000024] [G loss: 11.255967]\n",
      "[Epoch 34/1000] [Batch 147/168] [D loss: 0.000030] [G loss: 11.577675]\n",
      "[Epoch 34/1000] [Batch 148/168] [D loss: 0.000023] [G loss: 11.788892]\n",
      "[Epoch 34/1000] [Batch 149/168] [D loss: 0.000030] [G loss: 11.430467]\n",
      "[Epoch 34/1000] [Batch 150/168] [D loss: 0.000025] [G loss: 11.637358]\n",
      "[Epoch 34/1000] [Batch 151/168] [D loss: 0.000027] [G loss: 10.987803]\n",
      "[Epoch 34/1000] [Batch 152/168] [D loss: 0.000018] [G loss: 11.784270]\n",
      "[Epoch 34/1000] [Batch 153/168] [D loss: 0.000038] [G loss: 11.612509]\n",
      "[Epoch 34/1000] [Batch 154/168] [D loss: 0.000024] [G loss: 11.304944]\n",
      "[Epoch 34/1000] [Batch 155/168] [D loss: 0.000020] [G loss: 11.723016]\n",
      "[Epoch 34/1000] [Batch 156/168] [D loss: 0.000026] [G loss: 11.592686]\n",
      "[Epoch 34/1000] [Batch 157/168] [D loss: 0.000035] [G loss: 11.788760]\n",
      "[Epoch 34/1000] [Batch 158/168] [D loss: 0.000025] [G loss: 11.390462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] [Batch 159/168] [D loss: 0.000018] [G loss: 11.503783]\n",
      "[Epoch 34/1000] [Batch 160/168] [D loss: 0.000021] [G loss: 11.349321]\n",
      "[Epoch 34/1000] [Batch 161/168] [D loss: 0.000022] [G loss: 11.606789]\n",
      "[Epoch 34/1000] [Batch 162/168] [D loss: 0.000032] [G loss: 11.458105]\n",
      "[Epoch 34/1000] [Batch 163/168] [D loss: 0.000027] [G loss: 11.495538]\n",
      "[Epoch 34/1000] [Batch 164/168] [D loss: 0.000014] [G loss: 11.664432]\n",
      "[Epoch 34/1000] [Batch 165/168] [D loss: 0.000018] [G loss: 11.558553]\n",
      "[Epoch 34/1000] [Batch 166/168] [D loss: 0.000024] [G loss: 11.690863]\n",
      "[Epoch 34/1000] [Batch 167/168] [D loss: 0.000031] [G loss: 11.274969]\n",
      "[Epoch 34/1000] [Batch 168/168] [D loss: 0.000031] [G loss: 11.313490]\n",
      "[Epoch 35/1000] [Batch 1/168] [D loss: 0.000018] [G loss: 11.461966]\n",
      "[Epoch 35/1000] [Batch 2/168] [D loss: 0.000019] [G loss: 11.460739]\n",
      "[Epoch 35/1000] [Batch 3/168] [D loss: 0.000035] [G loss: 11.468603]\n",
      "[Epoch 35/1000] [Batch 4/168] [D loss: 0.000029] [G loss: 11.299449]\n",
      "[Epoch 35/1000] [Batch 5/168] [D loss: 0.000017] [G loss: 11.893741]\n",
      "[Epoch 35/1000] [Batch 6/168] [D loss: 0.000038] [G loss: 11.401684]\n",
      "[Epoch 35/1000] [Batch 7/168] [D loss: 0.000020] [G loss: 11.693552]\n",
      "[Epoch 35/1000] [Batch 8/168] [D loss: 0.000033] [G loss: 11.457652]\n",
      "[Epoch 35/1000] [Batch 9/168] [D loss: 0.000016] [G loss: 11.443648]\n",
      "[Epoch 35/1000] [Batch 10/168] [D loss: 0.000034] [G loss: 11.512284]\n",
      "[Epoch 35/1000] [Batch 11/168] [D loss: 0.000021] [G loss: 11.385841]\n",
      "[Epoch 35/1000] [Batch 12/168] [D loss: 0.000038] [G loss: 11.170143]\n",
      "[Epoch 35/1000] [Batch 13/168] [D loss: 0.000033] [G loss: 11.480798]\n",
      "[Epoch 35/1000] [Batch 14/168] [D loss: 0.000028] [G loss: 11.480640]\n",
      "[Epoch 35/1000] [Batch 15/168] [D loss: 0.000017] [G loss: 11.776955]\n",
      "[Epoch 35/1000] [Batch 16/168] [D loss: 0.000022] [G loss: 11.522698]\n",
      "[Epoch 35/1000] [Batch 17/168] [D loss: 0.000032] [G loss: 11.252901]\n",
      "[Epoch 35/1000] [Batch 18/168] [D loss: 0.000024] [G loss: 11.568480]\n",
      "[Epoch 35/1000] [Batch 19/168] [D loss: 0.000031] [G loss: 11.190899]\n",
      "[Epoch 35/1000] [Batch 20/168] [D loss: 0.000017] [G loss: 11.586981]\n",
      "[Epoch 35/1000] [Batch 21/168] [D loss: 0.000028] [G loss: 11.610739]\n",
      "[Epoch 35/1000] [Batch 22/168] [D loss: 0.000020] [G loss: 11.638247]\n",
      "[Epoch 35/1000] [Batch 23/168] [D loss: 0.000028] [G loss: 11.270130]\n",
      "[Epoch 35/1000] [Batch 24/168] [D loss: 0.000022] [G loss: 11.596090]\n",
      "[Epoch 35/1000] [Batch 25/168] [D loss: 0.000025] [G loss: 11.357643]\n",
      "[Epoch 35/1000] [Batch 26/168] [D loss: 0.000029] [G loss: 11.384673]\n",
      "[Epoch 35/1000] [Batch 27/168] [D loss: 0.000020] [G loss: 11.515647]\n",
      "[Epoch 35/1000] [Batch 28/168] [D loss: 0.000039] [G loss: 11.189915]\n",
      "[Epoch 35/1000] [Batch 29/168] [D loss: 0.000022] [G loss: 11.681325]\n",
      "[Epoch 35/1000] [Batch 30/168] [D loss: 0.000028] [G loss: 11.457195]\n",
      "[Epoch 35/1000] [Batch 31/168] [D loss: 0.000027] [G loss: 11.481314]\n",
      "[Epoch 35/1000] [Batch 32/168] [D loss: 0.000024] [G loss: 11.526302]\n",
      "[Epoch 35/1000] [Batch 33/168] [D loss: 0.000017] [G loss: 11.424582]\n",
      "[Epoch 35/1000] [Batch 34/168] [D loss: 0.000037] [G loss: 11.498606]\n",
      "[Epoch 35/1000] [Batch 35/168] [D loss: 0.000027] [G loss: 11.535680]\n",
      "[Epoch 35/1000] [Batch 36/168] [D loss: 0.000025] [G loss: 11.391661]\n",
      "[Epoch 35/1000] [Batch 37/168] [D loss: 0.000018] [G loss: 11.511698]\n",
      "[Epoch 35/1000] [Batch 38/168] [D loss: 0.000025] [G loss: 11.630396]\n",
      "[Epoch 35/1000] [Batch 39/168] [D loss: 0.000024] [G loss: 11.668353]\n",
      "[Epoch 35/1000] [Batch 40/168] [D loss: 0.000029] [G loss: 11.713960]\n",
      "[Epoch 35/1000] [Batch 41/168] [D loss: 0.000025] [G loss: 11.651527]\n",
      "[Epoch 35/1000] [Batch 42/168] [D loss: 0.000022] [G loss: 11.582502]\n",
      "[Epoch 35/1000] [Batch 43/168] [D loss: 0.000026] [G loss: 11.682093]\n",
      "[Epoch 35/1000] [Batch 44/168] [D loss: 0.000048] [G loss: 11.367348]\n",
      "[Epoch 35/1000] [Batch 45/168] [D loss: 0.000020] [G loss: 11.805291]\n",
      "[Epoch 35/1000] [Batch 46/168] [D loss: 0.000017] [G loss: 11.776203]\n",
      "[Epoch 35/1000] [Batch 47/168] [D loss: 0.000024] [G loss: 11.724158]\n",
      "[Epoch 35/1000] [Batch 48/168] [D loss: 0.000021] [G loss: 11.502224]\n",
      "[Epoch 35/1000] [Batch 49/168] [D loss: 0.000021] [G loss: 11.474248]\n",
      "[Epoch 35/1000] [Batch 50/168] [D loss: 0.000027] [G loss: 11.532307]\n",
      "[Epoch 35/1000] [Batch 51/168] [D loss: 0.000020] [G loss: 11.788041]\n",
      "[Epoch 35/1000] [Batch 52/168] [D loss: 0.000020] [G loss: 11.828012]\n",
      "[Epoch 35/1000] [Batch 53/168] [D loss: 0.000040] [G loss: 11.369471]\n",
      "[Epoch 35/1000] [Batch 54/168] [D loss: 0.000046] [G loss: 11.529415]\n",
      "[Epoch 35/1000] [Batch 55/168] [D loss: 0.000030] [G loss: 11.312880]\n",
      "[Epoch 35/1000] [Batch 56/168] [D loss: 0.000035] [G loss: 11.231118]\n",
      "[Epoch 35/1000] [Batch 57/168] [D loss: 0.000023] [G loss: 11.480083]\n",
      "[Epoch 35/1000] [Batch 58/168] [D loss: 0.000020] [G loss: 11.413552]\n",
      "[Epoch 35/1000] [Batch 59/168] [D loss: 0.000021] [G loss: 11.795289]\n",
      "[Epoch 35/1000] [Batch 60/168] [D loss: 0.000020] [G loss: 11.636360]\n",
      "[Epoch 35/1000] [Batch 61/168] [D loss: 0.000012] [G loss: 11.757600]\n",
      "[Epoch 35/1000] [Batch 62/168] [D loss: 0.000022] [G loss: 11.529061]\n",
      "[Epoch 35/1000] [Batch 63/168] [D loss: 0.000024] [G loss: 11.769878]\n",
      "[Epoch 35/1000] [Batch 64/168] [D loss: 0.000028] [G loss: 11.497682]\n",
      "[Epoch 35/1000] [Batch 65/168] [D loss: 0.000048] [G loss: 11.651083]\n",
      "[Epoch 35/1000] [Batch 66/168] [D loss: 0.000018] [G loss: 11.462663]\n",
      "[Epoch 35/1000] [Batch 67/168] [D loss: 0.000021] [G loss: 11.414735]\n",
      "[Epoch 35/1000] [Batch 68/168] [D loss: 0.000021] [G loss: 11.603596]\n",
      "[Epoch 35/1000] [Batch 69/168] [D loss: 0.000021] [G loss: 11.402184]\n",
      "[Epoch 35/1000] [Batch 70/168] [D loss: 0.000021] [G loss: 11.870662]\n",
      "[Epoch 35/1000] [Batch 71/168] [D loss: 0.000036] [G loss: 11.416656]\n",
      "[Epoch 35/1000] [Batch 72/168] [D loss: 0.000021] [G loss: 11.178823]\n",
      "[Epoch 35/1000] [Batch 73/168] [D loss: 0.000029] [G loss: 11.276008]\n",
      "[Epoch 35/1000] [Batch 74/168] [D loss: 0.000029] [G loss: 11.365705]\n",
      "[Epoch 35/1000] [Batch 75/168] [D loss: 0.000023] [G loss: 11.750640]\n",
      "[Epoch 35/1000] [Batch 76/168] [D loss: 0.000021] [G loss: 11.679069]\n",
      "[Epoch 35/1000] [Batch 77/168] [D loss: 0.000023] [G loss: 11.874915]\n",
      "[Epoch 35/1000] [Batch 78/168] [D loss: 0.000017] [G loss: 11.520681]\n",
      "[Epoch 35/1000] [Batch 79/168] [D loss: 0.000034] [G loss: 11.640281]\n",
      "[Epoch 35/1000] [Batch 80/168] [D loss: 0.000024] [G loss: 11.506088]\n",
      "[Epoch 35/1000] [Batch 81/168] [D loss: 0.000024] [G loss: 11.265148]\n",
      "[Epoch 35/1000] [Batch 82/168] [D loss: 0.000030] [G loss: 11.476665]\n",
      "[Epoch 35/1000] [Batch 83/168] [D loss: 0.000020] [G loss: 11.711680]\n",
      "[Epoch 35/1000] [Batch 84/168] [D loss: 0.000020] [G loss: 11.751198]\n",
      "[Epoch 35/1000] [Batch 85/168] [D loss: 0.000031] [G loss: 11.635850]\n",
      "[Epoch 35/1000] [Batch 86/168] [D loss: 0.000020] [G loss: 11.544555]\n",
      "[Epoch 35/1000] [Batch 87/168] [D loss: 0.000017] [G loss: 11.488995]\n",
      "[Epoch 35/1000] [Batch 88/168] [D loss: 0.000019] [G loss: 11.616158]\n",
      "[Epoch 35/1000] [Batch 89/168] [D loss: 0.000011] [G loss: 11.977413]\n",
      "[Epoch 35/1000] [Batch 90/168] [D loss: 0.000031] [G loss: 11.520178]\n",
      "[Epoch 35/1000] [Batch 91/168] [D loss: 0.000032] [G loss: 11.387314]\n",
      "[Epoch 35/1000] [Batch 92/168] [D loss: 0.000020] [G loss: 11.620539]\n",
      "[Epoch 35/1000] [Batch 93/168] [D loss: 0.000022] [G loss: 11.436352]\n",
      "[Epoch 35/1000] [Batch 94/168] [D loss: 0.000018] [G loss: 11.654478]\n",
      "[Epoch 35/1000] [Batch 95/168] [D loss: 0.000026] [G loss: 11.538343]\n",
      "[Epoch 35/1000] [Batch 96/168] [D loss: 0.000025] [G loss: 11.426113]\n",
      "[Epoch 35/1000] [Batch 97/168] [D loss: 0.000021] [G loss: 11.684874]\n",
      "[Epoch 35/1000] [Batch 98/168] [D loss: 0.000019] [G loss: 11.055482]\n",
      "[Epoch 35/1000] [Batch 99/168] [D loss: 0.000025] [G loss: 11.416836]\n",
      "[Epoch 35/1000] [Batch 100/168] [D loss: 0.000023] [G loss: 11.677220]\n",
      "[Epoch 35/1000] [Batch 101/168] [D loss: 0.000023] [G loss: 11.658692]\n",
      "[Epoch 35/1000] [Batch 102/168] [D loss: 0.000021] [G loss: 12.300571]\n",
      "[Epoch 35/1000] [Batch 103/168] [D loss: 0.000031] [G loss: 11.379527]\n",
      "[Epoch 35/1000] [Batch 104/168] [D loss: 0.000021] [G loss: 11.597957]\n",
      "[Epoch 35/1000] [Batch 105/168] [D loss: 0.000042] [G loss: 11.499412]\n",
      "[Epoch 35/1000] [Batch 106/168] [D loss: 0.000029] [G loss: 11.411674]\n",
      "[Epoch 35/1000] [Batch 107/168] [D loss: 0.000028] [G loss: 11.447300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/1000] [Batch 108/168] [D loss: 0.000023] [G loss: 11.375754]\n",
      "[Epoch 35/1000] [Batch 109/168] [D loss: 0.000023] [G loss: 11.605668]\n",
      "[Epoch 35/1000] [Batch 110/168] [D loss: 0.000026] [G loss: 11.397840]\n",
      "[Epoch 35/1000] [Batch 111/168] [D loss: 0.000019] [G loss: 11.390490]\n",
      "[Epoch 35/1000] [Batch 112/168] [D loss: 0.000018] [G loss: 11.424893]\n",
      "[Epoch 35/1000] [Batch 113/168] [D loss: 0.000029] [G loss: 11.735311]\n",
      "[Epoch 35/1000] [Batch 114/168] [D loss: 0.000019] [G loss: 11.360087]\n",
      "[Epoch 35/1000] [Batch 115/168] [D loss: 0.000025] [G loss: 11.606607]\n",
      "[Epoch 35/1000] [Batch 116/168] [D loss: 0.000019] [G loss: 11.531836]\n",
      "[Epoch 35/1000] [Batch 117/168] [D loss: 0.000016] [G loss: 11.588804]\n",
      "[Epoch 35/1000] [Batch 118/168] [D loss: 0.000029] [G loss: 11.406029]\n",
      "[Epoch 35/1000] [Batch 119/168] [D loss: 0.000034] [G loss: 11.437860]\n",
      "[Epoch 35/1000] [Batch 120/168] [D loss: 0.000019] [G loss: 11.704698]\n",
      "[Epoch 35/1000] [Batch 121/168] [D loss: 0.000024] [G loss: 11.655316]\n",
      "[Epoch 35/1000] [Batch 122/168] [D loss: 0.000028] [G loss: 11.863572]\n",
      "[Epoch 35/1000] [Batch 123/168] [D loss: 0.000018] [G loss: 11.569306]\n",
      "[Epoch 35/1000] [Batch 124/168] [D loss: 0.000033] [G loss: 11.436451]\n",
      "[Epoch 35/1000] [Batch 125/168] [D loss: 0.000029] [G loss: 11.408671]\n",
      "[Epoch 35/1000] [Batch 126/168] [D loss: 0.000020] [G loss: 11.452696]\n",
      "[Epoch 35/1000] [Batch 127/168] [D loss: 0.000017] [G loss: 11.675901]\n",
      "[Epoch 35/1000] [Batch 128/168] [D loss: 0.000032] [G loss: 11.486409]\n",
      "[Epoch 35/1000] [Batch 129/168] [D loss: 0.000026] [G loss: 11.636804]\n",
      "[Epoch 35/1000] [Batch 130/168] [D loss: 0.000014] [G loss: 11.607559]\n",
      "[Epoch 35/1000] [Batch 131/168] [D loss: 0.000019] [G loss: 11.521816]\n",
      "[Epoch 35/1000] [Batch 132/168] [D loss: 0.000016] [G loss: 11.510515]\n",
      "[Epoch 35/1000] [Batch 133/168] [D loss: 0.000030] [G loss: 11.751177]\n",
      "[Epoch 35/1000] [Batch 134/168] [D loss: 0.000024] [G loss: 11.103867]\n",
      "[Epoch 35/1000] [Batch 135/168] [D loss: 0.000020] [G loss: 11.882503]\n",
      "[Epoch 35/1000] [Batch 136/168] [D loss: 0.000018] [G loss: 11.612387]\n",
      "[Epoch 35/1000] [Batch 137/168] [D loss: 0.000023] [G loss: 11.787111]\n",
      "[Epoch 35/1000] [Batch 138/168] [D loss: 0.000041] [G loss: 11.557980]\n",
      "[Epoch 35/1000] [Batch 139/168] [D loss: 0.000022] [G loss: 11.650715]\n",
      "[Epoch 35/1000] [Batch 140/168] [D loss: 0.000023] [G loss: 11.550838]\n",
      "[Epoch 35/1000] [Batch 141/168] [D loss: 0.000015] [G loss: 11.592102]\n",
      "[Epoch 35/1000] [Batch 142/168] [D loss: 0.000021] [G loss: 11.831132]\n",
      "[Epoch 35/1000] [Batch 143/168] [D loss: 0.000021] [G loss: 11.748247]\n",
      "[Epoch 35/1000] [Batch 144/168] [D loss: 0.000041] [G loss: 11.343631]\n",
      "[Epoch 35/1000] [Batch 145/168] [D loss: 0.000015] [G loss: 11.822190]\n",
      "[Epoch 35/1000] [Batch 146/168] [D loss: 0.000022] [G loss: 11.566136]\n",
      "[Epoch 35/1000] [Batch 147/168] [D loss: 0.000019] [G loss: 11.618690]\n",
      "[Epoch 35/1000] [Batch 148/168] [D loss: 0.000023] [G loss: 11.457632]\n",
      "[Epoch 35/1000] [Batch 149/168] [D loss: 0.000029] [G loss: 11.389727]\n",
      "[Epoch 35/1000] [Batch 150/168] [D loss: 0.000027] [G loss: 11.592224]\n",
      "[Epoch 35/1000] [Batch 151/168] [D loss: 0.000031] [G loss: 11.521931]\n",
      "[Epoch 35/1000] [Batch 152/168] [D loss: 0.000017] [G loss: 11.830005]\n",
      "[Epoch 35/1000] [Batch 153/168] [D loss: 0.000023] [G loss: 11.836429]\n",
      "[Epoch 35/1000] [Batch 154/168] [D loss: 0.000037] [G loss: 11.283953]\n",
      "[Epoch 35/1000] [Batch 155/168] [D loss: 0.000022] [G loss: 11.642988]\n",
      "[Epoch 35/1000] [Batch 156/168] [D loss: 0.000028] [G loss: 11.572915]\n",
      "[Epoch 35/1000] [Batch 157/168] [D loss: 0.000019] [G loss: 11.502332]\n",
      "[Epoch 35/1000] [Batch 158/168] [D loss: 0.000017] [G loss: 11.809948]\n",
      "[Epoch 35/1000] [Batch 159/168] [D loss: 0.000022] [G loss: 11.356261]\n",
      "[Epoch 35/1000] [Batch 160/168] [D loss: 0.000022] [G loss: 11.529067]\n",
      "[Epoch 35/1000] [Batch 161/168] [D loss: 0.000024] [G loss: 11.496374]\n",
      "[Epoch 35/1000] [Batch 162/168] [D loss: 0.000021] [G loss: 11.733123]\n",
      "[Epoch 35/1000] [Batch 163/168] [D loss: 0.000024] [G loss: 11.808626]\n",
      "[Epoch 35/1000] [Batch 164/168] [D loss: 0.000041] [G loss: 11.423484]\n",
      "[Epoch 35/1000] [Batch 165/168] [D loss: 0.000018] [G loss: 11.892050]\n",
      "[Epoch 35/1000] [Batch 166/168] [D loss: 0.000026] [G loss: 11.300106]\n",
      "[Epoch 35/1000] [Batch 167/168] [D loss: 0.000013] [G loss: 11.930943]\n",
      "[Epoch 35/1000] [Batch 168/168] [D loss: 0.000021] [G loss: 11.657657]\n",
      "[Epoch 36/1000] [Batch 1/168] [D loss: 0.000026] [G loss: 11.563442]\n",
      "[Epoch 36/1000] [Batch 2/168] [D loss: 0.000020] [G loss: 11.487709]\n",
      "[Epoch 36/1000] [Batch 3/168] [D loss: 0.000019] [G loss: 11.467252]\n",
      "[Epoch 36/1000] [Batch 4/168] [D loss: 0.000022] [G loss: 11.767149]\n",
      "[Epoch 36/1000] [Batch 5/168] [D loss: 0.000023] [G loss: 11.567107]\n",
      "[Epoch 36/1000] [Batch 6/168] [D loss: 0.000032] [G loss: 11.329670]\n",
      "[Epoch 36/1000] [Batch 7/168] [D loss: 0.000016] [G loss: 11.638350]\n",
      "[Epoch 36/1000] [Batch 8/168] [D loss: 0.000019] [G loss: 11.652822]\n",
      "[Epoch 36/1000] [Batch 9/168] [D loss: 0.000024] [G loss: 11.574595]\n",
      "[Epoch 36/1000] [Batch 10/168] [D loss: 0.000019] [G loss: 11.722441]\n",
      "[Epoch 36/1000] [Batch 11/168] [D loss: 0.000026] [G loss: 11.550850]\n",
      "[Epoch 36/1000] [Batch 12/168] [D loss: 0.000021] [G loss: 11.934493]\n",
      "[Epoch 36/1000] [Batch 13/168] [D loss: 0.000018] [G loss: 11.738543]\n",
      "[Epoch 36/1000] [Batch 14/168] [D loss: 0.000028] [G loss: 11.671734]\n",
      "[Epoch 36/1000] [Batch 15/168] [D loss: 0.000028] [G loss: 11.522195]\n",
      "[Epoch 36/1000] [Batch 16/168] [D loss: 0.000019] [G loss: 11.754251]\n",
      "[Epoch 36/1000] [Batch 17/168] [D loss: 0.000023] [G loss: 11.380526]\n",
      "[Epoch 36/1000] [Batch 18/168] [D loss: 0.000030] [G loss: 11.623884]\n",
      "[Epoch 36/1000] [Batch 19/168] [D loss: 0.000017] [G loss: 11.796041]\n",
      "[Epoch 36/1000] [Batch 20/168] [D loss: 0.000019] [G loss: 11.461734]\n",
      "[Epoch 36/1000] [Batch 21/168] [D loss: 0.000024] [G loss: 11.356206]\n",
      "[Epoch 36/1000] [Batch 22/168] [D loss: 0.000022] [G loss: 11.371843]\n",
      "[Epoch 36/1000] [Batch 23/168] [D loss: 0.000021] [G loss: 11.609144]\n",
      "[Epoch 36/1000] [Batch 24/168] [D loss: 0.000027] [G loss: 11.810456]\n",
      "[Epoch 36/1000] [Batch 25/168] [D loss: 0.000018] [G loss: 11.775807]\n",
      "[Epoch 36/1000] [Batch 26/168] [D loss: 0.000027] [G loss: 11.789298]\n",
      "[Epoch 36/1000] [Batch 27/168] [D loss: 0.000025] [G loss: 11.732688]\n",
      "[Epoch 36/1000] [Batch 28/168] [D loss: 0.000023] [G loss: 11.496562]\n",
      "[Epoch 36/1000] [Batch 29/168] [D loss: 0.000024] [G loss: 11.515295]\n",
      "[Epoch 36/1000] [Batch 30/168] [D loss: 0.000031] [G loss: 11.781370]\n",
      "[Epoch 36/1000] [Batch 31/168] [D loss: 0.000016] [G loss: 11.611833]\n",
      "[Epoch 36/1000] [Batch 32/168] [D loss: 0.000020] [G loss: 11.421835]\n",
      "[Epoch 36/1000] [Batch 33/168] [D loss: 0.000026] [G loss: 11.633085]\n",
      "[Epoch 36/1000] [Batch 34/168] [D loss: 0.000019] [G loss: 11.602118]\n",
      "[Epoch 36/1000] [Batch 35/168] [D loss: 0.000030] [G loss: 11.511482]\n",
      "[Epoch 36/1000] [Batch 36/168] [D loss: 0.000024] [G loss: 11.216868]\n",
      "[Epoch 36/1000] [Batch 37/168] [D loss: 0.000036] [G loss: 11.629742]\n",
      "[Epoch 36/1000] [Batch 38/168] [D loss: 0.000021] [G loss: 11.469254]\n",
      "[Epoch 36/1000] [Batch 39/168] [D loss: 0.000019] [G loss: 11.367102]\n",
      "[Epoch 36/1000] [Batch 40/168] [D loss: 0.000012] [G loss: 11.675318]\n",
      "[Epoch 36/1000] [Batch 41/168] [D loss: 0.000012] [G loss: 11.872215]\n",
      "[Epoch 36/1000] [Batch 42/168] [D loss: 0.000023] [G loss: 11.639467]\n",
      "[Epoch 36/1000] [Batch 43/168] [D loss: 0.000025] [G loss: 11.690416]\n",
      "[Epoch 36/1000] [Batch 44/168] [D loss: 0.000036] [G loss: 11.670188]\n",
      "[Epoch 36/1000] [Batch 45/168] [D loss: 0.000028] [G loss: 11.364738]\n",
      "[Epoch 36/1000] [Batch 46/168] [D loss: 0.000017] [G loss: 11.772307]\n",
      "[Epoch 36/1000] [Batch 47/168] [D loss: 0.000017] [G loss: 11.596080]\n",
      "[Epoch 36/1000] [Batch 48/168] [D loss: 0.000025] [G loss: 11.649245]\n",
      "[Epoch 36/1000] [Batch 49/168] [D loss: 0.000018] [G loss: 11.638729]\n",
      "[Epoch 36/1000] [Batch 50/168] [D loss: 0.000026] [G loss: 11.664305]\n",
      "[Epoch 36/1000] [Batch 51/168] [D loss: 0.000044] [G loss: 11.581087]\n",
      "[Epoch 36/1000] [Batch 52/168] [D loss: 0.000030] [G loss: 11.438042]\n",
      "[Epoch 36/1000] [Batch 53/168] [D loss: 0.000013] [G loss: 11.830469]\n",
      "[Epoch 36/1000] [Batch 54/168] [D loss: 0.000023] [G loss: 11.497603]\n",
      "[Epoch 36/1000] [Batch 55/168] [D loss: 0.000025] [G loss: 11.392421]\n",
      "[Epoch 36/1000] [Batch 56/168] [D loss: 0.000031] [G loss: 11.790511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/1000] [Batch 57/168] [D loss: 0.000026] [G loss: 11.563772]\n",
      "[Epoch 36/1000] [Batch 58/168] [D loss: 0.000042] [G loss: 11.473441]\n",
      "[Epoch 36/1000] [Batch 59/168] [D loss: 0.000021] [G loss: 11.615630]\n",
      "[Epoch 36/1000] [Batch 60/168] [D loss: 0.000017] [G loss: 11.628366]\n",
      "[Epoch 36/1000] [Batch 61/168] [D loss: 0.000021] [G loss: 11.999520]\n",
      "[Epoch 36/1000] [Batch 62/168] [D loss: 0.000021] [G loss: 11.637619]\n",
      "[Epoch 36/1000] [Batch 63/168] [D loss: 0.000018] [G loss: 11.557817]\n",
      "[Epoch 36/1000] [Batch 64/168] [D loss: 0.000021] [G loss: 11.630054]\n",
      "[Epoch 36/1000] [Batch 65/168] [D loss: 0.000017] [G loss: 11.929356]\n",
      "[Epoch 36/1000] [Batch 66/168] [D loss: 0.000037] [G loss: 11.596419]\n",
      "[Epoch 36/1000] [Batch 67/168] [D loss: 0.000020] [G loss: 11.464906]\n",
      "[Epoch 36/1000] [Batch 68/168] [D loss: 0.000039] [G loss: 11.320760]\n",
      "[Epoch 36/1000] [Batch 69/168] [D loss: 0.000026] [G loss: 11.463430]\n",
      "[Epoch 36/1000] [Batch 70/168] [D loss: 0.000017] [G loss: 11.890579]\n",
      "[Epoch 36/1000] [Batch 71/168] [D loss: 0.000031] [G loss: 11.773331]\n",
      "[Epoch 36/1000] [Batch 72/168] [D loss: 0.000016] [G loss: 11.931833]\n",
      "[Epoch 36/1000] [Batch 73/168] [D loss: 0.000027] [G loss: 11.591476]\n",
      "[Epoch 36/1000] [Batch 74/168] [D loss: 0.000021] [G loss: 11.520972]\n",
      "[Epoch 36/1000] [Batch 75/168] [D loss: 0.000021] [G loss: 11.669942]\n",
      "[Epoch 36/1000] [Batch 76/168] [D loss: 0.000016] [G loss: 11.628219]\n",
      "[Epoch 36/1000] [Batch 77/168] [D loss: 0.000021] [G loss: 12.204002]\n",
      "[Epoch 36/1000] [Batch 78/168] [D loss: 0.000020] [G loss: 11.621436]\n",
      "[Epoch 36/1000] [Batch 79/168] [D loss: 0.000040] [G loss: 11.352201]\n",
      "[Epoch 36/1000] [Batch 80/168] [D loss: 0.000021] [G loss: 11.863365]\n",
      "[Epoch 36/1000] [Batch 81/168] [D loss: 0.000017] [G loss: 11.594075]\n",
      "[Epoch 36/1000] [Batch 82/168] [D loss: 0.000015] [G loss: 11.699650]\n",
      "[Epoch 36/1000] [Batch 83/168] [D loss: 0.000016] [G loss: 11.612673]\n",
      "[Epoch 36/1000] [Batch 84/168] [D loss: 0.000017] [G loss: 11.786017]\n",
      "[Epoch 36/1000] [Batch 85/168] [D loss: 0.000027] [G loss: 11.595748]\n",
      "[Epoch 36/1000] [Batch 86/168] [D loss: 0.000019] [G loss: 11.477892]\n",
      "[Epoch 36/1000] [Batch 87/168] [D loss: 0.000016] [G loss: 11.652525]\n",
      "[Epoch 36/1000] [Batch 88/168] [D loss: 0.000024] [G loss: 11.385632]\n",
      "[Epoch 36/1000] [Batch 89/168] [D loss: 0.000022] [G loss: 11.704703]\n",
      "[Epoch 36/1000] [Batch 90/168] [D loss: 0.000025] [G loss: 11.758812]\n",
      "[Epoch 36/1000] [Batch 91/168] [D loss: 0.000019] [G loss: 11.551942]\n",
      "[Epoch 36/1000] [Batch 92/168] [D loss: 0.000020] [G loss: 11.594496]\n",
      "[Epoch 36/1000] [Batch 93/168] [D loss: 0.000020] [G loss: 11.789430]\n",
      "[Epoch 36/1000] [Batch 94/168] [D loss: 0.000016] [G loss: 11.672852]\n",
      "[Epoch 36/1000] [Batch 95/168] [D loss: 0.000020] [G loss: 11.676270]\n",
      "[Epoch 36/1000] [Batch 96/168] [D loss: 0.000015] [G loss: 11.669090]\n",
      "[Epoch 36/1000] [Batch 97/168] [D loss: 0.000019] [G loss: 11.585434]\n",
      "[Epoch 36/1000] [Batch 98/168] [D loss: 0.000014] [G loss: 11.933721]\n",
      "[Epoch 36/1000] [Batch 99/168] [D loss: 0.000019] [G loss: 11.567331]\n",
      "[Epoch 36/1000] [Batch 100/168] [D loss: 0.000025] [G loss: 11.904873]\n",
      "[Epoch 36/1000] [Batch 101/168] [D loss: 0.000020] [G loss: 11.888790]\n",
      "[Epoch 36/1000] [Batch 102/168] [D loss: 0.000029] [G loss: 11.862887]\n",
      "[Epoch 36/1000] [Batch 103/168] [D loss: 0.000021] [G loss: 11.576380]\n",
      "[Epoch 36/1000] [Batch 104/168] [D loss: 0.000035] [G loss: 11.540824]\n",
      "[Epoch 36/1000] [Batch 105/168] [D loss: 0.000020] [G loss: 11.475491]\n",
      "[Epoch 36/1000] [Batch 106/168] [D loss: 0.000014] [G loss: 11.561384]\n",
      "[Epoch 36/1000] [Batch 107/168] [D loss: 0.000015] [G loss: 11.606948]\n",
      "[Epoch 36/1000] [Batch 108/168] [D loss: 0.000017] [G loss: 11.482440]\n",
      "[Epoch 36/1000] [Batch 109/168] [D loss: 0.000019] [G loss: 11.896103]\n",
      "[Epoch 36/1000] [Batch 110/168] [D loss: 0.000017] [G loss: 11.702802]\n",
      "[Epoch 36/1000] [Batch 111/168] [D loss: 0.000019] [G loss: 11.751913]\n",
      "[Epoch 36/1000] [Batch 112/168] [D loss: 0.000026] [G loss: 11.477677]\n",
      "[Epoch 36/1000] [Batch 113/168] [D loss: 0.000030] [G loss: 11.572709]\n",
      "[Epoch 36/1000] [Batch 114/168] [D loss: 0.000025] [G loss: 11.737049]\n",
      "[Epoch 36/1000] [Batch 115/168] [D loss: 0.000013] [G loss: 11.777639]\n",
      "[Epoch 36/1000] [Batch 116/168] [D loss: 0.000023] [G loss: 11.789928]\n",
      "[Epoch 36/1000] [Batch 117/168] [D loss: 0.000025] [G loss: 11.636938]\n",
      "[Epoch 36/1000] [Batch 118/168] [D loss: 0.000024] [G loss: 11.388341]\n",
      "[Epoch 36/1000] [Batch 119/168] [D loss: 0.000031] [G loss: 11.555196]\n",
      "[Epoch 36/1000] [Batch 120/168] [D loss: 0.000013] [G loss: 11.615182]\n",
      "[Epoch 36/1000] [Batch 121/168] [D loss: 0.000026] [G loss: 11.633618]\n",
      "[Epoch 36/1000] [Batch 122/168] [D loss: 0.000029] [G loss: 11.671297]\n",
      "[Epoch 36/1000] [Batch 123/168] [D loss: 0.000024] [G loss: 11.466841]\n",
      "[Epoch 36/1000] [Batch 124/168] [D loss: 0.000021] [G loss: 11.721640]\n",
      "[Epoch 36/1000] [Batch 125/168] [D loss: 0.000021] [G loss: 11.662321]\n",
      "[Epoch 36/1000] [Batch 126/168] [D loss: 0.000023] [G loss: 11.910986]\n",
      "[Epoch 36/1000] [Batch 127/168] [D loss: 0.000025] [G loss: 11.406651]\n",
      "[Epoch 36/1000] [Batch 128/168] [D loss: 0.000028] [G loss: 11.598716]\n",
      "[Epoch 36/1000] [Batch 129/168] [D loss: 0.000021] [G loss: 11.953266]\n",
      "[Epoch 36/1000] [Batch 130/168] [D loss: 0.000014] [G loss: 12.092915]\n",
      "[Epoch 36/1000] [Batch 131/168] [D loss: 0.000022] [G loss: 11.288453]\n",
      "[Epoch 36/1000] [Batch 132/168] [D loss: 0.000017] [G loss: 11.929244]\n",
      "[Epoch 36/1000] [Batch 133/168] [D loss: 0.000039] [G loss: 11.764610]\n",
      "[Epoch 36/1000] [Batch 134/168] [D loss: 0.000029] [G loss: 11.703303]\n",
      "[Epoch 36/1000] [Batch 135/168] [D loss: 0.000022] [G loss: 11.783086]\n",
      "[Epoch 36/1000] [Batch 136/168] [D loss: 0.000019] [G loss: 11.891889]\n",
      "[Epoch 36/1000] [Batch 137/168] [D loss: 0.000015] [G loss: 11.406852]\n",
      "[Epoch 36/1000] [Batch 138/168] [D loss: 0.000025] [G loss: 11.508813]\n",
      "[Epoch 36/1000] [Batch 139/168] [D loss: 0.000020] [G loss: 11.527118]\n",
      "[Epoch 36/1000] [Batch 140/168] [D loss: 0.000022] [G loss: 11.616318]\n",
      "[Epoch 36/1000] [Batch 141/168] [D loss: 0.000027] [G loss: 11.562469]\n",
      "[Epoch 36/1000] [Batch 142/168] [D loss: 0.000039] [G loss: 11.561701]\n",
      "[Epoch 36/1000] [Batch 143/168] [D loss: 0.000012] [G loss: 12.048932]\n",
      "[Epoch 36/1000] [Batch 144/168] [D loss: 0.000018] [G loss: 11.557198]\n",
      "[Epoch 36/1000] [Batch 145/168] [D loss: 0.000019] [G loss: 11.712905]\n",
      "[Epoch 36/1000] [Batch 146/168] [D loss: 0.000015] [G loss: 11.639162]\n",
      "[Epoch 36/1000] [Batch 147/168] [D loss: 0.000020] [G loss: 11.388798]\n",
      "[Epoch 36/1000] [Batch 148/168] [D loss: 0.000020] [G loss: 11.942871]\n",
      "[Epoch 36/1000] [Batch 149/168] [D loss: 0.000035] [G loss: 11.440327]\n",
      "[Epoch 36/1000] [Batch 150/168] [D loss: 0.000030] [G loss: 11.793087]\n",
      "[Epoch 36/1000] [Batch 151/168] [D loss: 0.000034] [G loss: 11.330030]\n",
      "[Epoch 36/1000] [Batch 152/168] [D loss: 0.000021] [G loss: 11.481803]\n",
      "[Epoch 36/1000] [Batch 153/168] [D loss: 0.000030] [G loss: 11.378794]\n",
      "[Epoch 36/1000] [Batch 154/168] [D loss: 0.000024] [G loss: 11.608021]\n",
      "[Epoch 36/1000] [Batch 155/168] [D loss: 0.000024] [G loss: 11.612294]\n",
      "[Epoch 36/1000] [Batch 156/168] [D loss: 0.000022] [G loss: 11.620418]\n",
      "[Epoch 36/1000] [Batch 157/168] [D loss: 0.000017] [G loss: 11.820420]\n",
      "[Epoch 36/1000] [Batch 158/168] [D loss: 0.000020] [G loss: 11.446305]\n",
      "[Epoch 36/1000] [Batch 159/168] [D loss: 0.000020] [G loss: 11.872531]\n",
      "[Epoch 36/1000] [Batch 160/168] [D loss: 0.000021] [G loss: 11.721450]\n",
      "[Epoch 36/1000] [Batch 161/168] [D loss: 0.000017] [G loss: 11.613903]\n",
      "[Epoch 36/1000] [Batch 162/168] [D loss: 0.000026] [G loss: 11.779892]\n",
      "[Epoch 36/1000] [Batch 163/168] [D loss: 0.000024] [G loss: 11.639530]\n",
      "[Epoch 36/1000] [Batch 164/168] [D loss: 0.000013] [G loss: 11.940956]\n",
      "[Epoch 36/1000] [Batch 165/168] [D loss: 0.000016] [G loss: 11.842566]\n",
      "[Epoch 36/1000] [Batch 166/168] [D loss: 0.000024] [G loss: 11.224770]\n",
      "[Epoch 36/1000] [Batch 167/168] [D loss: 0.000017] [G loss: 11.894825]\n",
      "[Epoch 36/1000] [Batch 168/168] [D loss: 0.000020] [G loss: 11.960098]\n",
      "[Epoch 37/1000] [Batch 1/168] [D loss: 0.000013] [G loss: 11.731592]\n",
      "[Epoch 37/1000] [Batch 2/168] [D loss: 0.000019] [G loss: 11.779863]\n",
      "[Epoch 37/1000] [Batch 3/168] [D loss: 0.000027] [G loss: 11.649219]\n",
      "[Epoch 37/1000] [Batch 4/168] [D loss: 0.000019] [G loss: 11.571332]\n",
      "[Epoch 37/1000] [Batch 5/168] [D loss: 0.000015] [G loss: 11.943546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/1000] [Batch 6/168] [D loss: 0.000019] [G loss: 11.581984]\n",
      "[Epoch 37/1000] [Batch 7/168] [D loss: 0.000018] [G loss: 11.710254]\n",
      "[Epoch 37/1000] [Batch 8/168] [D loss: 0.000022] [G loss: 11.902805]\n",
      "[Epoch 37/1000] [Batch 9/168] [D loss: 0.000019] [G loss: 11.628750]\n",
      "[Epoch 37/1000] [Batch 10/168] [D loss: 0.000016] [G loss: 11.596702]\n",
      "[Epoch 37/1000] [Batch 11/168] [D loss: 0.000018] [G loss: 11.718349]\n",
      "[Epoch 37/1000] [Batch 12/168] [D loss: 0.000040] [G loss: 11.656377]\n",
      "[Epoch 37/1000] [Batch 13/168] [D loss: 0.000026] [G loss: 11.816794]\n",
      "[Epoch 37/1000] [Batch 14/168] [D loss: 0.000015] [G loss: 11.879395]\n",
      "[Epoch 37/1000] [Batch 15/168] [D loss: 0.000031] [G loss: 11.692254]\n",
      "[Epoch 37/1000] [Batch 16/168] [D loss: 0.000029] [G loss: 11.466883]\n",
      "[Epoch 37/1000] [Batch 17/168] [D loss: 0.000014] [G loss: 11.689395]\n",
      "[Epoch 37/1000] [Batch 18/168] [D loss: 0.000025] [G loss: 11.469442]\n",
      "[Epoch 37/1000] [Batch 19/168] [D loss: 0.000020] [G loss: 11.842468]\n",
      "[Epoch 37/1000] [Batch 20/168] [D loss: 0.000019] [G loss: 11.541460]\n",
      "[Epoch 37/1000] [Batch 21/168] [D loss: 0.000023] [G loss: 11.682220]\n",
      "[Epoch 37/1000] [Batch 22/168] [D loss: 0.000030] [G loss: 11.590229]\n",
      "[Epoch 37/1000] [Batch 23/168] [D loss: 0.000022] [G loss: 11.651625]\n",
      "[Epoch 37/1000] [Batch 24/168] [D loss: 0.000018] [G loss: 11.523017]\n",
      "[Epoch 37/1000] [Batch 25/168] [D loss: 0.000026] [G loss: 11.631306]\n",
      "[Epoch 37/1000] [Batch 26/168] [D loss: 0.000030] [G loss: 11.512606]\n",
      "[Epoch 37/1000] [Batch 27/168] [D loss: 0.000017] [G loss: 11.686783]\n",
      "[Epoch 37/1000] [Batch 28/168] [D loss: 0.000017] [G loss: 11.315489]\n",
      "[Epoch 37/1000] [Batch 29/168] [D loss: 0.000019] [G loss: 11.447337]\n",
      "[Epoch 37/1000] [Batch 30/168] [D loss: 0.000018] [G loss: 11.731782]\n",
      "[Epoch 37/1000] [Batch 31/168] [D loss: 0.000022] [G loss: 11.457089]\n",
      "[Epoch 37/1000] [Batch 32/168] [D loss: 0.000032] [G loss: 11.807066]\n",
      "[Epoch 37/1000] [Batch 33/168] [D loss: 0.000021] [G loss: 11.529110]\n",
      "[Epoch 37/1000] [Batch 34/168] [D loss: 0.000020] [G loss: 11.843684]\n",
      "[Epoch 37/1000] [Batch 35/168] [D loss: 0.000021] [G loss: 11.572966]\n",
      "[Epoch 37/1000] [Batch 36/168] [D loss: 0.000030] [G loss: 11.369509]\n",
      "[Epoch 37/1000] [Batch 37/168] [D loss: 0.000021] [G loss: 11.736296]\n",
      "[Epoch 37/1000] [Batch 38/168] [D loss: 0.000013] [G loss: 11.680668]\n",
      "[Epoch 37/1000] [Batch 39/168] [D loss: 0.000031] [G loss: 11.520990]\n",
      "[Epoch 37/1000] [Batch 40/168] [D loss: 0.000010] [G loss: 12.130257]\n",
      "[Epoch 37/1000] [Batch 41/168] [D loss: 0.000015] [G loss: 11.726576]\n",
      "[Epoch 37/1000] [Batch 42/168] [D loss: 0.000023] [G loss: 11.742283]\n",
      "[Epoch 37/1000] [Batch 43/168] [D loss: 0.000013] [G loss: 11.781395]\n",
      "[Epoch 37/1000] [Batch 44/168] [D loss: 0.000021] [G loss: 11.551742]\n",
      "[Epoch 37/1000] [Batch 45/168] [D loss: 0.000031] [G loss: 11.669392]\n",
      "[Epoch 37/1000] [Batch 46/168] [D loss: 0.000020] [G loss: 11.615953]\n",
      "[Epoch 37/1000] [Batch 47/168] [D loss: 0.000022] [G loss: 11.558434]\n",
      "[Epoch 37/1000] [Batch 48/168] [D loss: 0.000027] [G loss: 11.570574]\n",
      "[Epoch 37/1000] [Batch 49/168] [D loss: 0.000020] [G loss: 11.778298]\n",
      "[Epoch 37/1000] [Batch 50/168] [D loss: 0.000026] [G loss: 11.817211]\n",
      "[Epoch 37/1000] [Batch 51/168] [D loss: 0.000021] [G loss: 11.564785]\n",
      "[Epoch 37/1000] [Batch 52/168] [D loss: 0.000020] [G loss: 11.485373]\n",
      "[Epoch 37/1000] [Batch 53/168] [D loss: 0.000023] [G loss: 11.511847]\n",
      "[Epoch 37/1000] [Batch 54/168] [D loss: 0.000020] [G loss: 11.377449]\n",
      "[Epoch 37/1000] [Batch 55/168] [D loss: 0.000017] [G loss: 11.795249]\n",
      "[Epoch 37/1000] [Batch 56/168] [D loss: 0.000027] [G loss: 11.761204]\n",
      "[Epoch 37/1000] [Batch 57/168] [D loss: 0.000018] [G loss: 12.036831]\n",
      "[Epoch 37/1000] [Batch 58/168] [D loss: 0.000015] [G loss: 11.653769]\n",
      "[Epoch 37/1000] [Batch 59/168] [D loss: 0.000026] [G loss: 11.730045]\n",
      "[Epoch 37/1000] [Batch 60/168] [D loss: 0.000021] [G loss: 11.813343]\n",
      "[Epoch 37/1000] [Batch 61/168] [D loss: 0.000017] [G loss: 11.765800]\n",
      "[Epoch 37/1000] [Batch 62/168] [D loss: 0.000028] [G loss: 11.944759]\n",
      "[Epoch 37/1000] [Batch 63/168] [D loss: 0.000020] [G loss: 11.901151]\n",
      "[Epoch 37/1000] [Batch 64/168] [D loss: 0.000016] [G loss: 11.852607]\n",
      "[Epoch 37/1000] [Batch 65/168] [D loss: 0.000013] [G loss: 12.159193]\n",
      "[Epoch 37/1000] [Batch 66/168] [D loss: 0.000023] [G loss: 11.714623]\n",
      "[Epoch 37/1000] [Batch 67/168] [D loss: 0.000034] [G loss: 11.891611]\n",
      "[Epoch 37/1000] [Batch 68/168] [D loss: 0.000017] [G loss: 11.947427]\n",
      "[Epoch 37/1000] [Batch 69/168] [D loss: 0.000020] [G loss: 11.719349]\n",
      "[Epoch 37/1000] [Batch 70/168] [D loss: 0.000026] [G loss: 11.805840]\n",
      "[Epoch 37/1000] [Batch 71/168] [D loss: 0.000035] [G loss: 11.606650]\n",
      "[Epoch 37/1000] [Batch 72/168] [D loss: 0.000020] [G loss: 11.678025]\n",
      "[Epoch 37/1000] [Batch 73/168] [D loss: 0.000013] [G loss: 11.982945]\n",
      "[Epoch 37/1000] [Batch 74/168] [D loss: 0.000018] [G loss: 11.441923]\n",
      "[Epoch 37/1000] [Batch 75/168] [D loss: 0.000030] [G loss: 11.478163]\n",
      "[Epoch 37/1000] [Batch 76/168] [D loss: 0.000018] [G loss: 11.608652]\n",
      "[Epoch 37/1000] [Batch 77/168] [D loss: 0.000016] [G loss: 11.811070]\n",
      "[Epoch 37/1000] [Batch 78/168] [D loss: 0.000024] [G loss: 11.873333]\n",
      "[Epoch 37/1000] [Batch 79/168] [D loss: 0.000014] [G loss: 11.920780]\n",
      "[Epoch 37/1000] [Batch 80/168] [D loss: 0.000023] [G loss: 11.657191]\n",
      "[Epoch 37/1000] [Batch 81/168] [D loss: 0.000020] [G loss: 11.838092]\n",
      "[Epoch 37/1000] [Batch 82/168] [D loss: 0.000021] [G loss: 11.674193]\n",
      "[Epoch 37/1000] [Batch 83/168] [D loss: 0.000021] [G loss: 11.733566]\n",
      "[Epoch 37/1000] [Batch 84/168] [D loss: 0.000038] [G loss: 11.747010]\n",
      "[Epoch 37/1000] [Batch 85/168] [D loss: 0.000017] [G loss: 11.708164]\n",
      "[Epoch 37/1000] [Batch 86/168] [D loss: 0.000025] [G loss: 11.665812]\n",
      "[Epoch 37/1000] [Batch 87/168] [D loss: 0.000022] [G loss: 11.410013]\n",
      "[Epoch 37/1000] [Batch 88/168] [D loss: 0.000024] [G loss: 11.626628]\n",
      "[Epoch 37/1000] [Batch 89/168] [D loss: 0.000021] [G loss: 11.805808]\n",
      "[Epoch 37/1000] [Batch 90/168] [D loss: 0.000016] [G loss: 11.518601]\n",
      "[Epoch 37/1000] [Batch 91/168] [D loss: 0.000034] [G loss: 11.553217]\n",
      "[Epoch 37/1000] [Batch 92/168] [D loss: 0.000043] [G loss: 11.451002]\n",
      "[Epoch 37/1000] [Batch 93/168] [D loss: 0.000018] [G loss: 11.660275]\n",
      "[Epoch 37/1000] [Batch 94/168] [D loss: 0.000030] [G loss: 12.064042]\n",
      "[Epoch 37/1000] [Batch 95/168] [D loss: 0.000030] [G loss: 11.908772]\n",
      "[Epoch 37/1000] [Batch 96/168] [D loss: 0.000025] [G loss: 11.255625]\n",
      "[Epoch 37/1000] [Batch 97/168] [D loss: 0.000016] [G loss: 11.672013]\n",
      "[Epoch 37/1000] [Batch 98/168] [D loss: 0.000017] [G loss: 11.537477]\n",
      "[Epoch 37/1000] [Batch 99/168] [D loss: 0.000021] [G loss: 11.900112]\n",
      "[Epoch 37/1000] [Batch 100/168] [D loss: 0.000020] [G loss: 11.671923]\n",
      "[Epoch 37/1000] [Batch 101/168] [D loss: 0.000022] [G loss: 11.959873]\n",
      "[Epoch 37/1000] [Batch 102/168] [D loss: 0.000014] [G loss: 11.863953]\n",
      "[Epoch 37/1000] [Batch 103/168] [D loss: 0.000023] [G loss: 11.546585]\n",
      "[Epoch 37/1000] [Batch 104/168] [D loss: 0.000017] [G loss: 11.759867]\n",
      "[Epoch 37/1000] [Batch 105/168] [D loss: 0.000024] [G loss: 11.231476]\n",
      "[Epoch 37/1000] [Batch 106/168] [D loss: 0.000014] [G loss: 11.778323]\n",
      "[Epoch 37/1000] [Batch 107/168] [D loss: 0.000013] [G loss: 11.838261]\n",
      "[Epoch 37/1000] [Batch 108/168] [D loss: 0.000017] [G loss: 11.457407]\n",
      "[Epoch 37/1000] [Batch 109/168] [D loss: 0.000015] [G loss: 11.746584]\n",
      "[Epoch 37/1000] [Batch 110/168] [D loss: 0.000026] [G loss: 11.673854]\n",
      "[Epoch 37/1000] [Batch 111/168] [D loss: 0.000022] [G loss: 11.437431]\n",
      "[Epoch 37/1000] [Batch 112/168] [D loss: 0.000016] [G loss: 11.822856]\n",
      "[Epoch 37/1000] [Batch 113/168] [D loss: 0.000021] [G loss: 11.807752]\n",
      "[Epoch 37/1000] [Batch 114/168] [D loss: 0.000018] [G loss: 11.697550]\n",
      "[Epoch 37/1000] [Batch 115/168] [D loss: 0.000015] [G loss: 11.849277]\n",
      "[Epoch 37/1000] [Batch 116/168] [D loss: 0.000025] [G loss: 11.751184]\n",
      "[Epoch 37/1000] [Batch 117/168] [D loss: 0.000020] [G loss: 11.812021]\n",
      "[Epoch 37/1000] [Batch 118/168] [D loss: 0.000025] [G loss: 11.553313]\n",
      "[Epoch 37/1000] [Batch 119/168] [D loss: 0.000020] [G loss: 11.717978]\n",
      "[Epoch 37/1000] [Batch 120/168] [D loss: 0.000024] [G loss: 11.924635]\n",
      "[Epoch 37/1000] [Batch 121/168] [D loss: 0.000016] [G loss: 11.697980]\n",
      "[Epoch 37/1000] [Batch 122/168] [D loss: 0.000014] [G loss: 11.796963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/1000] [Batch 123/168] [D loss: 0.000028] [G loss: 11.849291]\n",
      "[Epoch 37/1000] [Batch 124/168] [D loss: 0.000017] [G loss: 11.653752]\n",
      "[Epoch 37/1000] [Batch 125/168] [D loss: 0.000019] [G loss: 11.739553]\n",
      "[Epoch 37/1000] [Batch 126/168] [D loss: 0.000012] [G loss: 11.738035]\n",
      "[Epoch 37/1000] [Batch 127/168] [D loss: 0.000021] [G loss: 11.799215]\n",
      "[Epoch 37/1000] [Batch 128/168] [D loss: 0.000022] [G loss: 11.822466]\n",
      "[Epoch 37/1000] [Batch 129/168] [D loss: 0.000017] [G loss: 11.670727]\n",
      "[Epoch 37/1000] [Batch 130/168] [D loss: 0.000017] [G loss: 11.873829]\n",
      "[Epoch 37/1000] [Batch 131/168] [D loss: 0.000020] [G loss: 11.675582]\n",
      "[Epoch 37/1000] [Batch 132/168] [D loss: 0.000016] [G loss: 11.969309]\n",
      "[Epoch 37/1000] [Batch 133/168] [D loss: 0.000022] [G loss: 11.761760]\n",
      "[Epoch 37/1000] [Batch 134/168] [D loss: 0.000023] [G loss: 11.505285]\n",
      "[Epoch 37/1000] [Batch 135/168] [D loss: 0.000018] [G loss: 11.806709]\n",
      "[Epoch 37/1000] [Batch 136/168] [D loss: 0.000027] [G loss: 11.489052]\n",
      "[Epoch 37/1000] [Batch 137/168] [D loss: 0.000015] [G loss: 11.727365]\n",
      "[Epoch 37/1000] [Batch 138/168] [D loss: 0.000015] [G loss: 11.585596]\n",
      "[Epoch 37/1000] [Batch 139/168] [D loss: 0.000022] [G loss: 11.896085]\n",
      "[Epoch 37/1000] [Batch 140/168] [D loss: 0.000015] [G loss: 11.856457]\n",
      "[Epoch 37/1000] [Batch 141/168] [D loss: 0.000019] [G loss: 11.721182]\n",
      "[Epoch 37/1000] [Batch 142/168] [D loss: 0.000018] [G loss: 11.861684]\n",
      "[Epoch 37/1000] [Batch 143/168] [D loss: 0.000014] [G loss: 12.059320]\n",
      "[Epoch 37/1000] [Batch 144/168] [D loss: 0.000024] [G loss: 11.808567]\n",
      "[Epoch 37/1000] [Batch 145/168] [D loss: 0.000026] [G loss: 11.611820]\n",
      "[Epoch 37/1000] [Batch 146/168] [D loss: 0.000021] [G loss: 11.697164]\n",
      "[Epoch 37/1000] [Batch 147/168] [D loss: 0.000015] [G loss: 11.736597]\n",
      "[Epoch 37/1000] [Batch 148/168] [D loss: 0.000021] [G loss: 11.840498]\n",
      "[Epoch 37/1000] [Batch 149/168] [D loss: 0.000018] [G loss: 11.715294]\n",
      "[Epoch 37/1000] [Batch 150/168] [D loss: 0.000017] [G loss: 11.755893]\n",
      "[Epoch 37/1000] [Batch 151/168] [D loss: 0.000021] [G loss: 11.825459]\n",
      "[Epoch 37/1000] [Batch 152/168] [D loss: 0.000018] [G loss: 11.623686]\n",
      "[Epoch 37/1000] [Batch 153/168] [D loss: 0.000017] [G loss: 11.695496]\n",
      "[Epoch 37/1000] [Batch 154/168] [D loss: 0.000047] [G loss: 11.545711]\n",
      "[Epoch 37/1000] [Batch 155/168] [D loss: 0.000020] [G loss: 11.669384]\n",
      "[Epoch 37/1000] [Batch 156/168] [D loss: 0.000021] [G loss: 11.719623]\n",
      "[Epoch 37/1000] [Batch 157/168] [D loss: 0.000014] [G loss: 11.963647]\n",
      "[Epoch 37/1000] [Batch 158/168] [D loss: 0.000013] [G loss: 11.855616]\n",
      "[Epoch 37/1000] [Batch 159/168] [D loss: 0.000017] [G loss: 11.965530]\n",
      "[Epoch 37/1000] [Batch 160/168] [D loss: 0.000016] [G loss: 11.436118]\n",
      "[Epoch 37/1000] [Batch 161/168] [D loss: 0.000012] [G loss: 12.081370]\n",
      "[Epoch 37/1000] [Batch 162/168] [D loss: 0.000013] [G loss: 11.810534]\n",
      "[Epoch 37/1000] [Batch 163/168] [D loss: 0.000015] [G loss: 11.818498]\n",
      "[Epoch 37/1000] [Batch 164/168] [D loss: 0.000020] [G loss: 11.707376]\n",
      "[Epoch 37/1000] [Batch 165/168] [D loss: 0.000019] [G loss: 11.932141]\n",
      "[Epoch 37/1000] [Batch 166/168] [D loss: 0.000018] [G loss: 11.672378]\n",
      "[Epoch 37/1000] [Batch 167/168] [D loss: 0.000016] [G loss: 12.063935]\n",
      "[Epoch 37/1000] [Batch 168/168] [D loss: 0.000012] [G loss: 11.835514]\n",
      "[Epoch 38/1000] [Batch 1/168] [D loss: 0.000031] [G loss: 11.694598]\n",
      "[Epoch 38/1000] [Batch 2/168] [D loss: 0.000016] [G loss: 11.799465]\n",
      "[Epoch 38/1000] [Batch 3/168] [D loss: 0.000013] [G loss: 12.182063]\n",
      "[Epoch 38/1000] [Batch 4/168] [D loss: 0.000023] [G loss: 11.671760]\n",
      "[Epoch 38/1000] [Batch 5/168] [D loss: 0.000016] [G loss: 11.860914]\n",
      "[Epoch 38/1000] [Batch 6/168] [D loss: 0.000025] [G loss: 11.934646]\n",
      "[Epoch 38/1000] [Batch 7/168] [D loss: 0.000016] [G loss: 11.867164]\n",
      "[Epoch 38/1000] [Batch 8/168] [D loss: 0.000023] [G loss: 12.074623]\n",
      "[Epoch 38/1000] [Batch 9/168] [D loss: 0.000020] [G loss: 11.940331]\n",
      "[Epoch 38/1000] [Batch 10/168] [D loss: 0.000020] [G loss: 11.687363]\n",
      "[Epoch 38/1000] [Batch 11/168] [D loss: 0.000014] [G loss: 12.091413]\n",
      "[Epoch 38/1000] [Batch 12/168] [D loss: 0.000023] [G loss: 11.626920]\n",
      "[Epoch 38/1000] [Batch 13/168] [D loss: 0.000019] [G loss: 11.828074]\n",
      "[Epoch 38/1000] [Batch 14/168] [D loss: 0.000016] [G loss: 11.952162]\n",
      "[Epoch 38/1000] [Batch 15/168] [D loss: 0.000024] [G loss: 11.911369]\n",
      "[Epoch 38/1000] [Batch 16/168] [D loss: 0.000013] [G loss: 11.879400]\n",
      "[Epoch 38/1000] [Batch 17/168] [D loss: 0.000016] [G loss: 11.397503]\n",
      "[Epoch 38/1000] [Batch 18/168] [D loss: 0.000018] [G loss: 11.694407]\n",
      "[Epoch 38/1000] [Batch 19/168] [D loss: 0.000024] [G loss: 11.711974]\n",
      "[Epoch 38/1000] [Batch 20/168] [D loss: 0.000016] [G loss: 11.989432]\n",
      "[Epoch 38/1000] [Batch 21/168] [D loss: 0.000020] [G loss: 11.687677]\n",
      "[Epoch 38/1000] [Batch 22/168] [D loss: 0.000019] [G loss: 11.897745]\n",
      "[Epoch 38/1000] [Batch 23/168] [D loss: 0.000018] [G loss: 11.652330]\n",
      "[Epoch 38/1000] [Batch 24/168] [D loss: 0.000020] [G loss: 11.718925]\n",
      "[Epoch 38/1000] [Batch 25/168] [D loss: 0.000022] [G loss: 11.701960]\n",
      "[Epoch 38/1000] [Batch 26/168] [D loss: 0.000015] [G loss: 11.614855]\n",
      "[Epoch 38/1000] [Batch 27/168] [D loss: 0.000012] [G loss: 11.889979]\n",
      "[Epoch 38/1000] [Batch 28/168] [D loss: 0.000021] [G loss: 11.406633]\n",
      "[Epoch 38/1000] [Batch 29/168] [D loss: 0.000014] [G loss: 12.106747]\n",
      "[Epoch 38/1000] [Batch 30/168] [D loss: 0.000023] [G loss: 11.545635]\n",
      "[Epoch 38/1000] [Batch 31/168] [D loss: 0.000014] [G loss: 12.164172]\n",
      "[Epoch 38/1000] [Batch 32/168] [D loss: 0.000026] [G loss: 11.403225]\n",
      "[Epoch 38/1000] [Batch 33/168] [D loss: 0.000020] [G loss: 11.898611]\n",
      "[Epoch 38/1000] [Batch 34/168] [D loss: 0.000015] [G loss: 12.116392]\n",
      "[Epoch 38/1000] [Batch 35/168] [D loss: 0.000016] [G loss: 11.658687]\n",
      "[Epoch 38/1000] [Batch 36/168] [D loss: 0.000018] [G loss: 11.778946]\n",
      "[Epoch 38/1000] [Batch 37/168] [D loss: 0.000025] [G loss: 11.391617]\n",
      "[Epoch 38/1000] [Batch 38/168] [D loss: 0.000016] [G loss: 11.992035]\n",
      "[Epoch 38/1000] [Batch 39/168] [D loss: 0.000014] [G loss: 11.844677]\n",
      "[Epoch 38/1000] [Batch 40/168] [D loss: 0.000029] [G loss: 11.773453]\n",
      "[Epoch 38/1000] [Batch 41/168] [D loss: 0.000017] [G loss: 11.972528]\n",
      "[Epoch 38/1000] [Batch 42/168] [D loss: 0.000019] [G loss: 11.785437]\n",
      "[Epoch 38/1000] [Batch 43/168] [D loss: 0.000019] [G loss: 11.742317]\n",
      "[Epoch 38/1000] [Batch 44/168] [D loss: 0.000018] [G loss: 11.949000]\n",
      "[Epoch 38/1000] [Batch 45/168] [D loss: 0.000017] [G loss: 11.916073]\n",
      "[Epoch 38/1000] [Batch 46/168] [D loss: 0.000018] [G loss: 12.166615]\n",
      "[Epoch 38/1000] [Batch 47/168] [D loss: 0.000016] [G loss: 11.454199]\n",
      "[Epoch 38/1000] [Batch 48/168] [D loss: 0.000017] [G loss: 11.732594]\n",
      "[Epoch 38/1000] [Batch 49/168] [D loss: 0.000012] [G loss: 11.920361]\n",
      "[Epoch 38/1000] [Batch 50/168] [D loss: 0.000021] [G loss: 11.967150]\n",
      "[Epoch 38/1000] [Batch 51/168] [D loss: 0.000027] [G loss: 11.822028]\n",
      "[Epoch 38/1000] [Batch 52/168] [D loss: 0.000018] [G loss: 11.898476]\n",
      "[Epoch 38/1000] [Batch 53/168] [D loss: 0.000018] [G loss: 11.573795]\n",
      "[Epoch 38/1000] [Batch 54/168] [D loss: 0.000033] [G loss: 11.445259]\n",
      "[Epoch 38/1000] [Batch 55/168] [D loss: 0.000029] [G loss: 11.849123]\n",
      "[Epoch 38/1000] [Batch 56/168] [D loss: 0.000029] [G loss: 11.806026]\n",
      "[Epoch 38/1000] [Batch 57/168] [D loss: 0.000023] [G loss: 12.004040]\n",
      "[Epoch 38/1000] [Batch 58/168] [D loss: 0.000022] [G loss: 11.536510]\n",
      "[Epoch 38/1000] [Batch 59/168] [D loss: 0.000020] [G loss: 11.690748]\n",
      "[Epoch 38/1000] [Batch 60/168] [D loss: 0.000016] [G loss: 11.521025]\n",
      "[Epoch 38/1000] [Batch 61/168] [D loss: 0.000022] [G loss: 11.550330]\n",
      "[Epoch 38/1000] [Batch 62/168] [D loss: 0.000029] [G loss: 11.627346]\n",
      "[Epoch 38/1000] [Batch 63/168] [D loss: 0.000015] [G loss: 11.797218]\n",
      "[Epoch 38/1000] [Batch 64/168] [D loss: 0.000020] [G loss: 12.015638]\n",
      "[Epoch 38/1000] [Batch 65/168] [D loss: 0.000011] [G loss: 11.868613]\n",
      "[Epoch 38/1000] [Batch 66/168] [D loss: 0.000020] [G loss: 11.717506]\n",
      "[Epoch 38/1000] [Batch 67/168] [D loss: 0.000027] [G loss: 11.844507]\n",
      "[Epoch 38/1000] [Batch 68/168] [D loss: 0.000030] [G loss: 11.755178]\n",
      "[Epoch 38/1000] [Batch 69/168] [D loss: 0.000020] [G loss: 11.763495]\n",
      "[Epoch 38/1000] [Batch 70/168] [D loss: 0.000019] [G loss: 11.991111]\n",
      "[Epoch 38/1000] [Batch 71/168] [D loss: 0.000019] [G loss: 11.636859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/1000] [Batch 72/168] [D loss: 0.000023] [G loss: 11.801748]\n",
      "[Epoch 38/1000] [Batch 73/168] [D loss: 0.000023] [G loss: 11.490807]\n",
      "[Epoch 38/1000] [Batch 74/168] [D loss: 0.000026] [G loss: 11.918014]\n",
      "[Epoch 38/1000] [Batch 75/168] [D loss: 0.000021] [G loss: 11.536857]\n",
      "[Epoch 38/1000] [Batch 76/168] [D loss: 0.000028] [G loss: 11.799116]\n",
      "[Epoch 38/1000] [Batch 77/168] [D loss: 0.000019] [G loss: 11.664843]\n",
      "[Epoch 38/1000] [Batch 78/168] [D loss: 0.000019] [G loss: 11.762459]\n",
      "[Epoch 38/1000] [Batch 79/168] [D loss: 0.000017] [G loss: 11.368245]\n",
      "[Epoch 38/1000] [Batch 80/168] [D loss: 0.000015] [G loss: 11.844608]\n",
      "[Epoch 38/1000] [Batch 81/168] [D loss: 0.000011] [G loss: 11.863526]\n",
      "[Epoch 38/1000] [Batch 82/168] [D loss: 0.000015] [G loss: 11.804914]\n",
      "[Epoch 38/1000] [Batch 83/168] [D loss: 0.000019] [G loss: 11.507390]\n",
      "[Epoch 38/1000] [Batch 84/168] [D loss: 0.000015] [G loss: 11.990361]\n",
      "[Epoch 38/1000] [Batch 85/168] [D loss: 0.000012] [G loss: 11.861698]\n",
      "[Epoch 38/1000] [Batch 86/168] [D loss: 0.000019] [G loss: 11.490906]\n",
      "[Epoch 38/1000] [Batch 87/168] [D loss: 0.000020] [G loss: 11.950396]\n",
      "[Epoch 38/1000] [Batch 88/168] [D loss: 0.000012] [G loss: 12.096372]\n",
      "[Epoch 38/1000] [Batch 89/168] [D loss: 0.000014] [G loss: 11.790718]\n",
      "[Epoch 38/1000] [Batch 90/168] [D loss: 0.000013] [G loss: 11.799983]\n",
      "[Epoch 38/1000] [Batch 91/168] [D loss: 0.000022] [G loss: 11.454288]\n",
      "[Epoch 38/1000] [Batch 92/168] [D loss: 0.000017] [G loss: 11.678854]\n",
      "[Epoch 38/1000] [Batch 93/168] [D loss: 0.000030] [G loss: 11.386660]\n",
      "[Epoch 38/1000] [Batch 94/168] [D loss: 0.000013] [G loss: 11.898096]\n",
      "[Epoch 38/1000] [Batch 95/168] [D loss: 0.000024] [G loss: 11.680359]\n",
      "[Epoch 38/1000] [Batch 96/168] [D loss: 0.000020] [G loss: 11.984527]\n",
      "[Epoch 38/1000] [Batch 97/168] [D loss: 0.000016] [G loss: 11.932600]\n",
      "[Epoch 38/1000] [Batch 98/168] [D loss: 0.000014] [G loss: 11.814283]\n",
      "[Epoch 38/1000] [Batch 99/168] [D loss: 0.000016] [G loss: 11.963739]\n",
      "[Epoch 38/1000] [Batch 100/168] [D loss: 0.000019] [G loss: 11.909502]\n",
      "[Epoch 38/1000] [Batch 101/168] [D loss: 0.000021] [G loss: 11.794371]\n",
      "[Epoch 38/1000] [Batch 102/168] [D loss: 0.000011] [G loss: 12.034622]\n",
      "[Epoch 38/1000] [Batch 103/168] [D loss: 0.000022] [G loss: 11.899860]\n",
      "[Epoch 38/1000] [Batch 104/168] [D loss: 0.000014] [G loss: 11.815333]\n",
      "[Epoch 38/1000] [Batch 105/168] [D loss: 0.000014] [G loss: 11.867734]\n",
      "[Epoch 38/1000] [Batch 106/168] [D loss: 0.000013] [G loss: 12.059265]\n",
      "[Epoch 38/1000] [Batch 107/168] [D loss: 0.000020] [G loss: 11.968233]\n",
      "[Epoch 38/1000] [Batch 108/168] [D loss: 0.000015] [G loss: 11.737632]\n",
      "[Epoch 38/1000] [Batch 109/168] [D loss: 0.000016] [G loss: 11.771648]\n",
      "[Epoch 38/1000] [Batch 110/168] [D loss: 0.000020] [G loss: 12.030360]\n",
      "[Epoch 38/1000] [Batch 111/168] [D loss: 0.000015] [G loss: 11.855925]\n",
      "[Epoch 38/1000] [Batch 112/168] [D loss: 0.000032] [G loss: 11.471345]\n",
      "[Epoch 38/1000] [Batch 113/168] [D loss: 0.000023] [G loss: 11.597088]\n",
      "[Epoch 38/1000] [Batch 114/168] [D loss: 0.000014] [G loss: 11.901409]\n",
      "[Epoch 38/1000] [Batch 115/168] [D loss: 0.000019] [G loss: 11.797636]\n",
      "[Epoch 38/1000] [Batch 116/168] [D loss: 0.000019] [G loss: 12.025061]\n",
      "[Epoch 38/1000] [Batch 117/168] [D loss: 0.000015] [G loss: 12.111720]\n",
      "[Epoch 38/1000] [Batch 118/168] [D loss: 0.000021] [G loss: 11.607989]\n",
      "[Epoch 38/1000] [Batch 119/168] [D loss: 0.000026] [G loss: 11.411633]\n",
      "[Epoch 38/1000] [Batch 120/168] [D loss: 0.000018] [G loss: 11.583559]\n",
      "[Epoch 38/1000] [Batch 121/168] [D loss: 0.000021] [G loss: 11.898390]\n",
      "[Epoch 38/1000] [Batch 122/168] [D loss: 0.000018] [G loss: 11.966588]\n",
      "[Epoch 38/1000] [Batch 123/168] [D loss: 0.000021] [G loss: 11.570663]\n",
      "[Epoch 38/1000] [Batch 124/168] [D loss: 0.000015] [G loss: 11.613305]\n",
      "[Epoch 38/1000] [Batch 125/168] [D loss: 0.000013] [G loss: 11.937964]\n",
      "[Epoch 38/1000] [Batch 126/168] [D loss: 0.000023] [G loss: 11.438470]\n",
      "[Epoch 38/1000] [Batch 127/168] [D loss: 0.000018] [G loss: 11.839913]\n",
      "[Epoch 38/1000] [Batch 128/168] [D loss: 0.000019] [G loss: 11.639516]\n",
      "[Epoch 38/1000] [Batch 129/168] [D loss: 0.000014] [G loss: 11.915882]\n",
      "[Epoch 38/1000] [Batch 130/168] [D loss: 0.000023] [G loss: 11.951488]\n",
      "[Epoch 38/1000] [Batch 131/168] [D loss: 0.000015] [G loss: 12.003613]\n",
      "[Epoch 38/1000] [Batch 132/168] [D loss: 0.000017] [G loss: 11.698706]\n",
      "[Epoch 38/1000] [Batch 133/168] [D loss: 0.000012] [G loss: 12.108582]\n",
      "[Epoch 38/1000] [Batch 134/168] [D loss: 0.000016] [G loss: 11.564792]\n",
      "[Epoch 38/1000] [Batch 135/168] [D loss: 0.000022] [G loss: 11.851031]\n",
      "[Epoch 38/1000] [Batch 136/168] [D loss: 0.000021] [G loss: 12.033441]\n",
      "[Epoch 38/1000] [Batch 137/168] [D loss: 0.000025] [G loss: 11.888270]\n",
      "[Epoch 38/1000] [Batch 138/168] [D loss: 0.000019] [G loss: 11.625824]\n",
      "[Epoch 38/1000] [Batch 139/168] [D loss: 0.000018] [G loss: 11.588734]\n",
      "[Epoch 38/1000] [Batch 140/168] [D loss: 0.000018] [G loss: 12.023835]\n",
      "[Epoch 38/1000] [Batch 141/168] [D loss: 0.000015] [G loss: 11.883632]\n",
      "[Epoch 38/1000] [Batch 142/168] [D loss: 0.000013] [G loss: 12.124315]\n",
      "[Epoch 38/1000] [Batch 143/168] [D loss: 0.000019] [G loss: 11.748829]\n",
      "[Epoch 38/1000] [Batch 144/168] [D loss: 0.000014] [G loss: 11.774601]\n",
      "[Epoch 38/1000] [Batch 145/168] [D loss: 0.000021] [G loss: 11.526692]\n",
      "[Epoch 38/1000] [Batch 146/168] [D loss: 0.000017] [G loss: 11.932583]\n",
      "[Epoch 38/1000] [Batch 147/168] [D loss: 0.000016] [G loss: 11.693053]\n",
      "[Epoch 38/1000] [Batch 148/168] [D loss: 0.000012] [G loss: 12.107685]\n",
      "[Epoch 38/1000] [Batch 149/168] [D loss: 0.000025] [G loss: 11.310599]\n",
      "[Epoch 38/1000] [Batch 150/168] [D loss: 0.000021] [G loss: 11.756730]\n",
      "[Epoch 38/1000] [Batch 151/168] [D loss: 0.000017] [G loss: 11.798306]\n",
      "[Epoch 38/1000] [Batch 152/168] [D loss: 0.000016] [G loss: 11.864377]\n",
      "[Epoch 38/1000] [Batch 153/168] [D loss: 0.000017] [G loss: 11.871354]\n",
      "[Epoch 38/1000] [Batch 154/168] [D loss: 0.000014] [G loss: 11.997690]\n",
      "[Epoch 38/1000] [Batch 155/168] [D loss: 0.000020] [G loss: 12.021914]\n",
      "[Epoch 38/1000] [Batch 156/168] [D loss: 0.000018] [G loss: 11.512444]\n",
      "[Epoch 38/1000] [Batch 157/168] [D loss: 0.000021] [G loss: 11.845216]\n",
      "[Epoch 38/1000] [Batch 158/168] [D loss: 0.000018] [G loss: 11.778776]\n",
      "[Epoch 38/1000] [Batch 159/168] [D loss: 0.000014] [G loss: 11.820360]\n",
      "[Epoch 38/1000] [Batch 160/168] [D loss: 0.000013] [G loss: 12.133158]\n",
      "[Epoch 38/1000] [Batch 161/168] [D loss: 0.000023] [G loss: 12.015727]\n",
      "[Epoch 38/1000] [Batch 162/168] [D loss: 0.000021] [G loss: 11.538914]\n",
      "[Epoch 38/1000] [Batch 163/168] [D loss: 0.000280] [G loss: 11.507573]\n",
      "[Epoch 38/1000] [Batch 164/168] [D loss: 0.000017] [G loss: 12.393303]\n",
      "[Epoch 38/1000] [Batch 165/168] [D loss: 0.000030] [G loss: 12.237354]\n",
      "[Epoch 38/1000] [Batch 166/168] [D loss: 0.000045] [G loss: 12.845737]\n",
      "[Epoch 38/1000] [Batch 167/168] [D loss: 0.000027] [G loss: 12.636272]\n",
      "[Epoch 38/1000] [Batch 168/168] [D loss: 0.000020] [G loss: 12.317389]\n",
      "[Epoch 39/1000] [Batch 1/168] [D loss: 0.000019] [G loss: 12.917220]\n",
      "[Epoch 39/1000] [Batch 2/168] [D loss: 0.000017] [G loss: 12.453571]\n",
      "[Epoch 39/1000] [Batch 3/168] [D loss: 0.000022] [G loss: 12.432203]\n",
      "[Epoch 39/1000] [Batch 4/168] [D loss: 0.000016] [G loss: 12.529062]\n",
      "[Epoch 39/1000] [Batch 5/168] [D loss: 0.000026] [G loss: 12.460042]\n",
      "[Epoch 39/1000] [Batch 6/168] [D loss: 0.000016] [G loss: 12.231732]\n",
      "[Epoch 39/1000] [Batch 7/168] [D loss: 0.000018] [G loss: 12.647779]\n",
      "[Epoch 39/1000] [Batch 8/168] [D loss: 0.000012] [G loss: 12.200602]\n",
      "[Epoch 39/1000] [Batch 9/168] [D loss: 0.000027] [G loss: 12.161855]\n",
      "[Epoch 39/1000] [Batch 10/168] [D loss: 0.000020] [G loss: 12.694766]\n",
      "[Epoch 39/1000] [Batch 11/168] [D loss: 0.000017] [G loss: 12.473599]\n",
      "[Epoch 39/1000] [Batch 12/168] [D loss: 0.000017] [G loss: 11.911192]\n",
      "[Epoch 39/1000] [Batch 13/168] [D loss: 0.000022] [G loss: 12.049324]\n",
      "[Epoch 39/1000] [Batch 14/168] [D loss: 0.000016] [G loss: 12.071291]\n",
      "[Epoch 39/1000] [Batch 15/168] [D loss: 0.000029] [G loss: 12.234775]\n",
      "[Epoch 39/1000] [Batch 16/168] [D loss: 0.000017] [G loss: 11.944282]\n",
      "[Epoch 39/1000] [Batch 17/168] [D loss: 0.000026] [G loss: 12.260060]\n",
      "[Epoch 39/1000] [Batch 18/168] [D loss: 0.000020] [G loss: 11.725910]\n",
      "[Epoch 39/1000] [Batch 19/168] [D loss: 0.000018] [G loss: 11.903315]\n",
      "[Epoch 39/1000] [Batch 20/168] [D loss: 0.000025] [G loss: 11.649256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/1000] [Batch 21/168] [D loss: 0.000017] [G loss: 11.930672]\n",
      "[Epoch 39/1000] [Batch 22/168] [D loss: 0.000016] [G loss: 12.171135]\n",
      "[Epoch 39/1000] [Batch 23/168] [D loss: 0.000014] [G loss: 12.075614]\n",
      "[Epoch 39/1000] [Batch 24/168] [D loss: 0.000014] [G loss: 12.156332]\n",
      "[Epoch 39/1000] [Batch 25/168] [D loss: 0.000026] [G loss: 12.330343]\n",
      "[Epoch 39/1000] [Batch 26/168] [D loss: 0.000013] [G loss: 12.127632]\n",
      "[Epoch 39/1000] [Batch 27/168] [D loss: 0.000013] [G loss: 12.073841]\n",
      "[Epoch 39/1000] [Batch 28/168] [D loss: 0.000024] [G loss: 11.796027]\n",
      "[Epoch 39/1000] [Batch 29/168] [D loss: 0.000018] [G loss: 11.785159]\n",
      "[Epoch 39/1000] [Batch 30/168] [D loss: 0.000020] [G loss: 11.939312]\n",
      "[Epoch 39/1000] [Batch 31/168] [D loss: 0.000018] [G loss: 11.913978]\n",
      "[Epoch 39/1000] [Batch 32/168] [D loss: 0.000014] [G loss: 12.061785]\n",
      "[Epoch 39/1000] [Batch 33/168] [D loss: 0.000016] [G loss: 11.922239]\n",
      "[Epoch 39/1000] [Batch 34/168] [D loss: 0.000034] [G loss: 12.372688]\n",
      "[Epoch 39/1000] [Batch 35/168] [D loss: 0.000016] [G loss: 11.867710]\n",
      "[Epoch 39/1000] [Batch 36/168] [D loss: 0.000014] [G loss: 11.972623]\n",
      "[Epoch 39/1000] [Batch 37/168] [D loss: 0.000023] [G loss: 11.888927]\n",
      "[Epoch 39/1000] [Batch 38/168] [D loss: 0.000017] [G loss: 11.505161]\n",
      "[Epoch 39/1000] [Batch 39/168] [D loss: 0.000021] [G loss: 11.870991]\n",
      "[Epoch 39/1000] [Batch 40/168] [D loss: 0.000027] [G loss: 11.459467]\n",
      "[Epoch 39/1000] [Batch 41/168] [D loss: 0.000018] [G loss: 11.730044]\n",
      "[Epoch 39/1000] [Batch 42/168] [D loss: 0.000018] [G loss: 12.031301]\n",
      "[Epoch 39/1000] [Batch 43/168] [D loss: 0.000015] [G loss: 12.022677]\n",
      "[Epoch 39/1000] [Batch 44/168] [D loss: 0.000020] [G loss: 11.935603]\n",
      "[Epoch 39/1000] [Batch 45/168] [D loss: 0.000017] [G loss: 12.011396]\n",
      "[Epoch 39/1000] [Batch 46/168] [D loss: 0.000022] [G loss: 11.968393]\n",
      "[Epoch 39/1000] [Batch 47/168] [D loss: 0.000017] [G loss: 12.299622]\n",
      "[Epoch 39/1000] [Batch 48/168] [D loss: 0.000014] [G loss: 11.904335]\n",
      "[Epoch 39/1000] [Batch 49/168] [D loss: 0.000015] [G loss: 12.049139]\n",
      "[Epoch 39/1000] [Batch 50/168] [D loss: 0.000015] [G loss: 11.806033]\n",
      "[Epoch 39/1000] [Batch 51/168] [D loss: 0.000013] [G loss: 11.991790]\n",
      "[Epoch 39/1000] [Batch 52/168] [D loss: 0.000029] [G loss: 12.139091]\n",
      "[Epoch 39/1000] [Batch 53/168] [D loss: 0.000030] [G loss: 11.680076]\n",
      "[Epoch 39/1000] [Batch 54/168] [D loss: 0.000019] [G loss: 11.611552]\n",
      "[Epoch 39/1000] [Batch 55/168] [D loss: 0.000022] [G loss: 11.703478]\n",
      "[Epoch 39/1000] [Batch 56/168] [D loss: 0.000021] [G loss: 11.803071]\n",
      "[Epoch 39/1000] [Batch 57/168] [D loss: 0.000016] [G loss: 11.561125]\n",
      "[Epoch 39/1000] [Batch 58/168] [D loss: 0.000015] [G loss: 11.511869]\n",
      "[Epoch 39/1000] [Batch 59/168] [D loss: 0.000013] [G loss: 11.869699]\n",
      "[Epoch 39/1000] [Batch 60/168] [D loss: 0.000015] [G loss: 11.597916]\n",
      "[Epoch 39/1000] [Batch 61/168] [D loss: 0.000022] [G loss: 11.549397]\n",
      "[Epoch 39/1000] [Batch 62/168] [D loss: 0.000020] [G loss: 12.009574]\n",
      "[Epoch 39/1000] [Batch 63/168] [D loss: 0.000023] [G loss: 12.165239]\n",
      "[Epoch 39/1000] [Batch 64/168] [D loss: 0.000021] [G loss: 11.574713]\n",
      "[Epoch 39/1000] [Batch 65/168] [D loss: 0.000016] [G loss: 11.818094]\n",
      "[Epoch 39/1000] [Batch 66/168] [D loss: 0.000017] [G loss: 11.926987]\n",
      "[Epoch 39/1000] [Batch 67/168] [D loss: 0.000028] [G loss: 11.924629]\n",
      "[Epoch 39/1000] [Batch 68/168] [D loss: 0.000011] [G loss: 12.111620]\n",
      "[Epoch 39/1000] [Batch 69/168] [D loss: 0.000036] [G loss: 12.048435]\n",
      "[Epoch 39/1000] [Batch 70/168] [D loss: 0.000021] [G loss: 11.687804]\n",
      "[Epoch 39/1000] [Batch 71/168] [D loss: 0.000013] [G loss: 12.002745]\n",
      "[Epoch 39/1000] [Batch 72/168] [D loss: 0.000013] [G loss: 11.776554]\n",
      "[Epoch 39/1000] [Batch 73/168] [D loss: 0.000018] [G loss: 11.878466]\n",
      "[Epoch 39/1000] [Batch 74/168] [D loss: 0.000013] [G loss: 11.915002]\n",
      "[Epoch 39/1000] [Batch 75/168] [D loss: 0.000014] [G loss: 11.980512]\n",
      "[Epoch 39/1000] [Batch 76/168] [D loss: 0.000019] [G loss: 11.588978]\n",
      "[Epoch 39/1000] [Batch 77/168] [D loss: 0.000018] [G loss: 11.593123]\n",
      "[Epoch 39/1000] [Batch 78/168] [D loss: 0.000013] [G loss: 11.950679]\n",
      "[Epoch 39/1000] [Batch 79/168] [D loss: 0.000014] [G loss: 11.502110]\n",
      "[Epoch 39/1000] [Batch 80/168] [D loss: 0.000020] [G loss: 11.648294]\n",
      "[Epoch 39/1000] [Batch 81/168] [D loss: 0.000012] [G loss: 12.076756]\n",
      "[Epoch 39/1000] [Batch 82/168] [D loss: 0.000017] [G loss: 11.891627]\n",
      "[Epoch 39/1000] [Batch 83/168] [D loss: 0.000012] [G loss: 11.812571]\n",
      "[Epoch 39/1000] [Batch 84/168] [D loss: 0.000015] [G loss: 12.090065]\n",
      "[Epoch 39/1000] [Batch 85/168] [D loss: 0.000012] [G loss: 11.869531]\n",
      "[Epoch 39/1000] [Batch 86/168] [D loss: 0.000018] [G loss: 11.731573]\n",
      "[Epoch 39/1000] [Batch 87/168] [D loss: 0.000019] [G loss: 12.018661]\n",
      "[Epoch 39/1000] [Batch 88/168] [D loss: 0.000010] [G loss: 12.257516]\n",
      "[Epoch 39/1000] [Batch 89/168] [D loss: 0.000015] [G loss: 11.923662]\n",
      "[Epoch 39/1000] [Batch 90/168] [D loss: 0.000018] [G loss: 11.793218]\n",
      "[Epoch 39/1000] [Batch 91/168] [D loss: 0.000018] [G loss: 11.803705]\n",
      "[Epoch 39/1000] [Batch 92/168] [D loss: 0.000020] [G loss: 12.091261]\n",
      "[Epoch 39/1000] [Batch 93/168] [D loss: 0.000014] [G loss: 11.694594]\n",
      "[Epoch 39/1000] [Batch 94/168] [D loss: 0.000021] [G loss: 11.707460]\n",
      "[Epoch 39/1000] [Batch 95/168] [D loss: 0.000027] [G loss: 11.746526]\n",
      "[Epoch 39/1000] [Batch 96/168] [D loss: 0.000017] [G loss: 12.002283]\n",
      "[Epoch 39/1000] [Batch 97/168] [D loss: 0.000012] [G loss: 11.859022]\n",
      "[Epoch 39/1000] [Batch 98/168] [D loss: 0.000019] [G loss: 11.824635]\n",
      "[Epoch 39/1000] [Batch 99/168] [D loss: 0.000018] [G loss: 11.883805]\n",
      "[Epoch 39/1000] [Batch 100/168] [D loss: 0.000017] [G loss: 11.839483]\n",
      "[Epoch 39/1000] [Batch 101/168] [D loss: 0.000013] [G loss: 12.011375]\n",
      "[Epoch 39/1000] [Batch 102/168] [D loss: 0.000016] [G loss: 11.678648]\n",
      "[Epoch 39/1000] [Batch 103/168] [D loss: 0.000017] [G loss: 11.547058]\n",
      "[Epoch 39/1000] [Batch 104/168] [D loss: 0.000026] [G loss: 11.931170]\n",
      "[Epoch 39/1000] [Batch 105/168] [D loss: 0.000020] [G loss: 11.853560]\n",
      "[Epoch 39/1000] [Batch 106/168] [D loss: 0.000019] [G loss: 11.293393]\n",
      "[Epoch 39/1000] [Batch 107/168] [D loss: 0.000017] [G loss: 11.482022]\n",
      "[Epoch 39/1000] [Batch 108/168] [D loss: 0.000012] [G loss: 11.927721]\n",
      "[Epoch 39/1000] [Batch 109/168] [D loss: 0.000017] [G loss: 11.803775]\n",
      "[Epoch 39/1000] [Batch 110/168] [D loss: 0.000020] [G loss: 11.593896]\n",
      "[Epoch 39/1000] [Batch 111/168] [D loss: 0.000012] [G loss: 12.035356]\n",
      "[Epoch 39/1000] [Batch 112/168] [D loss: 0.000015] [G loss: 11.938363]\n",
      "[Epoch 39/1000] [Batch 113/168] [D loss: 0.000023] [G loss: 12.192012]\n",
      "[Epoch 39/1000] [Batch 114/168] [D loss: 0.000010] [G loss: 11.994915]\n",
      "[Epoch 39/1000] [Batch 115/168] [D loss: 0.000010] [G loss: 12.117847]\n",
      "[Epoch 39/1000] [Batch 116/168] [D loss: 0.000018] [G loss: 11.826524]\n",
      "[Epoch 39/1000] [Batch 117/168] [D loss: 0.000022] [G loss: 11.867348]\n",
      "[Epoch 39/1000] [Batch 118/168] [D loss: 0.000018] [G loss: 11.426868]\n",
      "[Epoch 39/1000] [Batch 119/168] [D loss: 0.000011] [G loss: 11.900351]\n",
      "[Epoch 39/1000] [Batch 120/168] [D loss: 0.000019] [G loss: 11.958841]\n",
      "[Epoch 39/1000] [Batch 121/168] [D loss: 0.000016] [G loss: 11.918426]\n",
      "[Epoch 39/1000] [Batch 122/168] [D loss: 0.000013] [G loss: 11.870955]\n",
      "[Epoch 39/1000] [Batch 123/168] [D loss: 0.000014] [G loss: 11.880879]\n",
      "[Epoch 39/1000] [Batch 124/168] [D loss: 0.000016] [G loss: 11.772278]\n",
      "[Epoch 39/1000] [Batch 125/168] [D loss: 0.000017] [G loss: 11.714189]\n",
      "[Epoch 39/1000] [Batch 126/168] [D loss: 0.000020] [G loss: 11.998293]\n",
      "[Epoch 39/1000] [Batch 127/168] [D loss: 0.000022] [G loss: 12.149074]\n",
      "[Epoch 39/1000] [Batch 128/168] [D loss: 0.000019] [G loss: 11.473614]\n",
      "[Epoch 39/1000] [Batch 129/168] [D loss: 0.000020] [G loss: 11.605213]\n",
      "[Epoch 39/1000] [Batch 130/168] [D loss: 0.000023] [G loss: 11.766088]\n",
      "[Epoch 39/1000] [Batch 131/168] [D loss: 0.000015] [G loss: 11.966635]\n",
      "[Epoch 39/1000] [Batch 132/168] [D loss: 0.000016] [G loss: 11.918261]\n",
      "[Epoch 39/1000] [Batch 133/168] [D loss: 0.000024] [G loss: 12.021854]\n",
      "[Epoch 39/1000] [Batch 134/168] [D loss: 0.000014] [G loss: 11.686693]\n",
      "[Epoch 39/1000] [Batch 135/168] [D loss: 0.000020] [G loss: 11.742488]\n",
      "[Epoch 39/1000] [Batch 136/168] [D loss: 0.000025] [G loss: 11.713299]\n",
      "[Epoch 39/1000] [Batch 137/168] [D loss: 0.000008] [G loss: 12.363753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/1000] [Batch 138/168] [D loss: 0.000012] [G loss: 11.963565]\n",
      "[Epoch 39/1000] [Batch 139/168] [D loss: 0.000021] [G loss: 11.933308]\n",
      "[Epoch 39/1000] [Batch 140/168] [D loss: 0.000017] [G loss: 11.764365]\n",
      "[Epoch 39/1000] [Batch 141/168] [D loss: 0.000015] [G loss: 12.045383]\n",
      "[Epoch 39/1000] [Batch 142/168] [D loss: 0.000015] [G loss: 11.500928]\n",
      "[Epoch 39/1000] [Batch 143/168] [D loss: 0.000014] [G loss: 11.884672]\n",
      "[Epoch 39/1000] [Batch 144/168] [D loss: 0.000037] [G loss: 11.852939]\n",
      "[Epoch 39/1000] [Batch 145/168] [D loss: 0.000014] [G loss: 11.836846]\n",
      "[Epoch 39/1000] [Batch 146/168] [D loss: 0.000023] [G loss: 11.837674]\n",
      "[Epoch 39/1000] [Batch 147/168] [D loss: 0.000016] [G loss: 12.037802]\n",
      "[Epoch 39/1000] [Batch 148/168] [D loss: 0.000015] [G loss: 11.926153]\n",
      "[Epoch 39/1000] [Batch 149/168] [D loss: 0.000014] [G loss: 11.906578]\n",
      "[Epoch 39/1000] [Batch 150/168] [D loss: 0.000016] [G loss: 11.954802]\n",
      "[Epoch 39/1000] [Batch 151/168] [D loss: 0.000020] [G loss: 11.590385]\n",
      "[Epoch 39/1000] [Batch 152/168] [D loss: 0.000018] [G loss: 11.670023]\n",
      "[Epoch 39/1000] [Batch 153/168] [D loss: 0.000024] [G loss: 11.821519]\n",
      "[Epoch 39/1000] [Batch 154/168] [D loss: 0.000014] [G loss: 12.103785]\n",
      "[Epoch 39/1000] [Batch 155/168] [D loss: 0.000018] [G loss: 11.855494]\n",
      "[Epoch 39/1000] [Batch 156/168] [D loss: 0.000024] [G loss: 12.025361]\n",
      "[Epoch 39/1000] [Batch 157/168] [D loss: 0.000016] [G loss: 11.876565]\n",
      "[Epoch 39/1000] [Batch 158/168] [D loss: 0.000016] [G loss: 11.848603]\n",
      "[Epoch 39/1000] [Batch 159/168] [D loss: 0.000021] [G loss: 11.663602]\n",
      "[Epoch 39/1000] [Batch 160/168] [D loss: 0.000015] [G loss: 11.838731]\n",
      "[Epoch 39/1000] [Batch 161/168] [D loss: 0.000017] [G loss: 11.732539]\n",
      "[Epoch 39/1000] [Batch 162/168] [D loss: 0.000029] [G loss: 11.565496]\n",
      "[Epoch 39/1000] [Batch 163/168] [D loss: 0.000014] [G loss: 11.588376]\n",
      "[Epoch 39/1000] [Batch 164/168] [D loss: 0.000009] [G loss: 12.282770]\n",
      "[Epoch 39/1000] [Batch 165/168] [D loss: 0.000016] [G loss: 11.819809]\n",
      "[Epoch 39/1000] [Batch 166/168] [D loss: 0.000021] [G loss: 11.890418]\n",
      "[Epoch 39/1000] [Batch 167/168] [D loss: 0.000022] [G loss: 11.741408]\n",
      "[Epoch 39/1000] [Batch 168/168] [D loss: 0.000018] [G loss: 11.980419]\n",
      "[Epoch 40/1000] [Batch 1/168] [D loss: 0.000018] [G loss: 11.980740]\n",
      "[Epoch 40/1000] [Batch 2/168] [D loss: 0.000017] [G loss: 12.203106]\n",
      "[Epoch 40/1000] [Batch 3/168] [D loss: 0.000024] [G loss: 11.724129]\n",
      "[Epoch 40/1000] [Batch 4/168] [D loss: 0.000023] [G loss: 12.074539]\n",
      "[Epoch 40/1000] [Batch 5/168] [D loss: 0.000010] [G loss: 12.148484]\n",
      "[Epoch 40/1000] [Batch 6/168] [D loss: 0.000024] [G loss: 11.790361]\n",
      "[Epoch 40/1000] [Batch 7/168] [D loss: 0.000027] [G loss: 11.807748]\n",
      "[Epoch 40/1000] [Batch 8/168] [D loss: 0.000017] [G loss: 12.016064]\n",
      "[Epoch 40/1000] [Batch 9/168] [D loss: 0.000017] [G loss: 11.689341]\n",
      "[Epoch 40/1000] [Batch 10/168] [D loss: 0.000019] [G loss: 11.912173]\n",
      "[Epoch 40/1000] [Batch 11/168] [D loss: 0.000014] [G loss: 12.017624]\n",
      "[Epoch 40/1000] [Batch 12/168] [D loss: 0.000015] [G loss: 11.626554]\n",
      "[Epoch 40/1000] [Batch 13/168] [D loss: 0.000020] [G loss: 11.781126]\n",
      "[Epoch 40/1000] [Batch 14/168] [D loss: 0.000014] [G loss: 11.939955]\n",
      "[Epoch 40/1000] [Batch 15/168] [D loss: 0.000014] [G loss: 11.674262]\n",
      "[Epoch 40/1000] [Batch 16/168] [D loss: 0.000018] [G loss: 11.693985]\n",
      "[Epoch 40/1000] [Batch 17/168] [D loss: 0.000018] [G loss: 11.552756]\n",
      "[Epoch 40/1000] [Batch 18/168] [D loss: 0.000016] [G loss: 11.985723]\n",
      "[Epoch 40/1000] [Batch 19/168] [D loss: 0.000014] [G loss: 12.010750]\n",
      "[Epoch 40/1000] [Batch 20/168] [D loss: 0.000016] [G loss: 11.848186]\n",
      "[Epoch 40/1000] [Batch 21/168] [D loss: 0.000017] [G loss: 11.560940]\n",
      "[Epoch 40/1000] [Batch 22/168] [D loss: 0.000014] [G loss: 11.705804]\n",
      "[Epoch 40/1000] [Batch 23/168] [D loss: 0.000025] [G loss: 12.021894]\n",
      "[Epoch 40/1000] [Batch 24/168] [D loss: 0.000012] [G loss: 11.868385]\n",
      "[Epoch 40/1000] [Batch 25/168] [D loss: 0.000029] [G loss: 12.171917]\n",
      "[Epoch 40/1000] [Batch 26/168] [D loss: 0.000012] [G loss: 11.838523]\n",
      "[Epoch 40/1000] [Batch 27/168] [D loss: 0.000015] [G loss: 11.789993]\n",
      "[Epoch 40/1000] [Batch 28/168] [D loss: 0.000016] [G loss: 11.798519]\n",
      "[Epoch 40/1000] [Batch 29/168] [D loss: 0.000017] [G loss: 11.828738]\n",
      "[Epoch 40/1000] [Batch 30/168] [D loss: 0.000016] [G loss: 11.806538]\n",
      "[Epoch 40/1000] [Batch 31/168] [D loss: 0.000016] [G loss: 11.856777]\n",
      "[Epoch 40/1000] [Batch 32/168] [D loss: 0.000013] [G loss: 12.188045]\n",
      "[Epoch 40/1000] [Batch 33/168] [D loss: 0.000024] [G loss: 11.902786]\n",
      "[Epoch 40/1000] [Batch 34/168] [D loss: 0.000031] [G loss: 11.535556]\n",
      "[Epoch 40/1000] [Batch 35/168] [D loss: 0.000018] [G loss: 11.849853]\n",
      "[Epoch 40/1000] [Batch 36/168] [D loss: 0.000014] [G loss: 11.908361]\n",
      "[Epoch 40/1000] [Batch 37/168] [D loss: 0.000011] [G loss: 12.161231]\n",
      "[Epoch 40/1000] [Batch 38/168] [D loss: 0.000015] [G loss: 11.656392]\n",
      "[Epoch 40/1000] [Batch 39/168] [D loss: 0.000019] [G loss: 11.780466]\n",
      "[Epoch 40/1000] [Batch 40/168] [D loss: 0.000029] [G loss: 11.888755]\n",
      "[Epoch 40/1000] [Batch 41/168] [D loss: 0.000013] [G loss: 11.959619]\n",
      "[Epoch 40/1000] [Batch 42/168] [D loss: 0.000017] [G loss: 11.800933]\n",
      "[Epoch 40/1000] [Batch 43/168] [D loss: 0.000016] [G loss: 11.713449]\n",
      "[Epoch 40/1000] [Batch 44/168] [D loss: 0.000018] [G loss: 11.548959]\n",
      "[Epoch 40/1000] [Batch 45/168] [D loss: 0.000017] [G loss: 11.842879]\n",
      "[Epoch 40/1000] [Batch 46/168] [D loss: 0.000014] [G loss: 11.659338]\n",
      "[Epoch 40/1000] [Batch 47/168] [D loss: 0.000015] [G loss: 12.181928]\n",
      "[Epoch 40/1000] [Batch 48/168] [D loss: 0.000016] [G loss: 11.898358]\n",
      "[Epoch 40/1000] [Batch 49/168] [D loss: 0.000017] [G loss: 11.736603]\n",
      "[Epoch 40/1000] [Batch 50/168] [D loss: 0.000014] [G loss: 11.965162]\n",
      "[Epoch 40/1000] [Batch 51/168] [D loss: 0.000014] [G loss: 11.933006]\n",
      "[Epoch 40/1000] [Batch 52/168] [D loss: 0.000013] [G loss: 11.860660]\n",
      "[Epoch 40/1000] [Batch 53/168] [D loss: 0.000014] [G loss: 11.961518]\n",
      "[Epoch 40/1000] [Batch 54/168] [D loss: 0.000016] [G loss: 11.692831]\n",
      "[Epoch 40/1000] [Batch 55/168] [D loss: 0.000012] [G loss: 12.126410]\n",
      "[Epoch 40/1000] [Batch 56/168] [D loss: 0.000021] [G loss: 11.711973]\n",
      "[Epoch 40/1000] [Batch 57/168] [D loss: 0.000023] [G loss: 11.880427]\n",
      "[Epoch 40/1000] [Batch 58/168] [D loss: 0.000013] [G loss: 12.011270]\n",
      "[Epoch 40/1000] [Batch 59/168] [D loss: 0.000019] [G loss: 11.753690]\n",
      "[Epoch 40/1000] [Batch 60/168] [D loss: 0.000013] [G loss: 12.221189]\n",
      "[Epoch 40/1000] [Batch 61/168] [D loss: 0.000012] [G loss: 11.899573]\n",
      "[Epoch 40/1000] [Batch 62/168] [D loss: 0.000014] [G loss: 12.063392]\n",
      "[Epoch 40/1000] [Batch 63/168] [D loss: 0.000017] [G loss: 11.706673]\n",
      "[Epoch 40/1000] [Batch 64/168] [D loss: 0.000018] [G loss: 11.757548]\n",
      "[Epoch 40/1000] [Batch 65/168] [D loss: 0.000010] [G loss: 12.208635]\n",
      "[Epoch 40/1000] [Batch 66/168] [D loss: 0.000012] [G loss: 12.137380]\n",
      "[Epoch 40/1000] [Batch 67/168] [D loss: 0.000009] [G loss: 12.086510]\n",
      "[Epoch 40/1000] [Batch 68/168] [D loss: 0.000013] [G loss: 11.942366]\n",
      "[Epoch 40/1000] [Batch 69/168] [D loss: 0.000017] [G loss: 11.906275]\n",
      "[Epoch 40/1000] [Batch 70/168] [D loss: 0.000025] [G loss: 11.780064]\n",
      "[Epoch 40/1000] [Batch 71/168] [D loss: 0.000013] [G loss: 11.738914]\n",
      "[Epoch 40/1000] [Batch 72/168] [D loss: 0.000021] [G loss: 11.733345]\n",
      "[Epoch 40/1000] [Batch 73/168] [D loss: 0.000019] [G loss: 11.732080]\n",
      "[Epoch 40/1000] [Batch 74/168] [D loss: 0.000021] [G loss: 12.003201]\n",
      "[Epoch 40/1000] [Batch 75/168] [D loss: 0.000013] [G loss: 12.130767]\n",
      "[Epoch 40/1000] [Batch 76/168] [D loss: 0.000014] [G loss: 11.939567]\n",
      "[Epoch 40/1000] [Batch 77/168] [D loss: 0.000009] [G loss: 12.214347]\n",
      "[Epoch 40/1000] [Batch 78/168] [D loss: 0.000017] [G loss: 12.046392]\n",
      "[Epoch 40/1000] [Batch 79/168] [D loss: 0.000015] [G loss: 12.143692]\n",
      "[Epoch 40/1000] [Batch 80/168] [D loss: 0.000011] [G loss: 12.093085]\n",
      "[Epoch 40/1000] [Batch 81/168] [D loss: 0.000013] [G loss: 12.068855]\n",
      "[Epoch 40/1000] [Batch 82/168] [D loss: 0.000019] [G loss: 12.052056]\n",
      "[Epoch 40/1000] [Batch 83/168] [D loss: 0.000020] [G loss: 11.837759]\n",
      "[Epoch 40/1000] [Batch 84/168] [D loss: 0.000013] [G loss: 11.832379]\n",
      "[Epoch 40/1000] [Batch 85/168] [D loss: 0.000018] [G loss: 11.965626]\n",
      "[Epoch 40/1000] [Batch 86/168] [D loss: 0.000018] [G loss: 12.012043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/1000] [Batch 87/168] [D loss: 0.000013] [G loss: 11.996694]\n",
      "[Epoch 40/1000] [Batch 88/168] [D loss: 0.000017] [G loss: 12.094541]\n",
      "[Epoch 40/1000] [Batch 89/168] [D loss: 0.000023] [G loss: 11.984206]\n",
      "[Epoch 40/1000] [Batch 90/168] [D loss: 0.000025] [G loss: 12.104861]\n",
      "[Epoch 40/1000] [Batch 91/168] [D loss: 0.000018] [G loss: 12.269262]\n",
      "[Epoch 40/1000] [Batch 92/168] [D loss: 0.000013] [G loss: 11.692258]\n",
      "[Epoch 40/1000] [Batch 93/168] [D loss: 0.000014] [G loss: 12.179628]\n",
      "[Epoch 40/1000] [Batch 94/168] [D loss: 0.000013] [G loss: 11.946569]\n",
      "[Epoch 40/1000] [Batch 95/168] [D loss: 0.000027] [G loss: 11.597672]\n",
      "[Epoch 40/1000] [Batch 96/168] [D loss: 0.000011] [G loss: 11.943983]\n",
      "[Epoch 40/1000] [Batch 97/168] [D loss: 0.000015] [G loss: 11.883213]\n",
      "[Epoch 40/1000] [Batch 98/168] [D loss: 0.000015] [G loss: 11.820059]\n",
      "[Epoch 40/1000] [Batch 99/168] [D loss: 0.000019] [G loss: 11.892159]\n",
      "[Epoch 40/1000] [Batch 100/168] [D loss: 0.000015] [G loss: 11.881049]\n",
      "[Epoch 40/1000] [Batch 101/168] [D loss: 0.000015] [G loss: 11.966349]\n",
      "[Epoch 40/1000] [Batch 102/168] [D loss: 0.000015] [G loss: 11.908047]\n",
      "[Epoch 40/1000] [Batch 103/168] [D loss: 0.000017] [G loss: 11.773828]\n",
      "[Epoch 40/1000] [Batch 104/168] [D loss: 0.000010] [G loss: 12.098185]\n",
      "[Epoch 40/1000] [Batch 105/168] [D loss: 0.000013] [G loss: 11.772779]\n",
      "[Epoch 40/1000] [Batch 106/168] [D loss: 0.000017] [G loss: 11.508859]\n",
      "[Epoch 40/1000] [Batch 107/168] [D loss: 0.000024] [G loss: 11.638896]\n",
      "[Epoch 40/1000] [Batch 108/168] [D loss: 0.000013] [G loss: 12.193649]\n",
      "[Epoch 40/1000] [Batch 109/168] [D loss: 0.000021] [G loss: 11.619637]\n",
      "[Epoch 40/1000] [Batch 110/168] [D loss: 0.000017] [G loss: 11.995106]\n",
      "[Epoch 40/1000] [Batch 111/168] [D loss: 0.000017] [G loss: 12.050026]\n",
      "[Epoch 40/1000] [Batch 112/168] [D loss: 0.000016] [G loss: 11.941607]\n",
      "[Epoch 40/1000] [Batch 113/168] [D loss: 0.000020] [G loss: 11.936513]\n",
      "[Epoch 40/1000] [Batch 114/168] [D loss: 0.000011] [G loss: 11.797851]\n",
      "[Epoch 40/1000] [Batch 115/168] [D loss: 0.000023] [G loss: 12.169279]\n",
      "[Epoch 40/1000] [Batch 116/168] [D loss: 0.000019] [G loss: 11.830059]\n",
      "[Epoch 40/1000] [Batch 117/168] [D loss: 0.000014] [G loss: 12.032205]\n",
      "[Epoch 40/1000] [Batch 118/168] [D loss: 0.000013] [G loss: 12.057122]\n",
      "[Epoch 40/1000] [Batch 119/168] [D loss: 0.000014] [G loss: 11.634411]\n",
      "[Epoch 40/1000] [Batch 120/168] [D loss: 0.000025] [G loss: 11.512595]\n",
      "[Epoch 40/1000] [Batch 121/168] [D loss: 0.000013] [G loss: 11.861868]\n",
      "[Epoch 40/1000] [Batch 122/168] [D loss: 0.000008] [G loss: 12.237830]\n",
      "[Epoch 40/1000] [Batch 123/168] [D loss: 0.000020] [G loss: 12.216719]\n",
      "[Epoch 40/1000] [Batch 124/168] [D loss: 0.000031] [G loss: 11.969127]\n",
      "[Epoch 40/1000] [Batch 125/168] [D loss: 0.000013] [G loss: 12.007810]\n",
      "[Epoch 40/1000] [Batch 126/168] [D loss: 0.000010] [G loss: 11.932530]\n",
      "[Epoch 40/1000] [Batch 127/168] [D loss: 0.000016] [G loss: 11.915030]\n",
      "[Epoch 40/1000] [Batch 128/168] [D loss: 0.000014] [G loss: 11.973807]\n",
      "[Epoch 40/1000] [Batch 129/168] [D loss: 0.000014] [G loss: 11.791725]\n",
      "[Epoch 40/1000] [Batch 130/168] [D loss: 0.000021] [G loss: 11.547033]\n",
      "[Epoch 40/1000] [Batch 131/168] [D loss: 0.000028] [G loss: 11.534606]\n",
      "[Epoch 40/1000] [Batch 132/168] [D loss: 0.000018] [G loss: 11.795525]\n",
      "[Epoch 40/1000] [Batch 133/168] [D loss: 0.000032] [G loss: 11.562018]\n",
      "[Epoch 40/1000] [Batch 134/168] [D loss: 0.000012] [G loss: 12.256043]\n",
      "[Epoch 40/1000] [Batch 135/168] [D loss: 0.000018] [G loss: 11.793317]\n",
      "[Epoch 40/1000] [Batch 136/168] [D loss: 0.000021] [G loss: 12.082590]\n",
      "[Epoch 40/1000] [Batch 137/168] [D loss: 0.000010] [G loss: 12.182810]\n",
      "[Epoch 40/1000] [Batch 138/168] [D loss: 0.000013] [G loss: 11.932169]\n",
      "[Epoch 40/1000] [Batch 139/168] [D loss: 0.000012] [G loss: 12.233039]\n",
      "[Epoch 40/1000] [Batch 140/168] [D loss: 0.000017] [G loss: 11.897754]\n",
      "[Epoch 40/1000] [Batch 141/168] [D loss: 0.000012] [G loss: 12.240627]\n",
      "[Epoch 40/1000] [Batch 142/168] [D loss: 0.000021] [G loss: 11.853202]\n",
      "[Epoch 40/1000] [Batch 143/168] [D loss: 0.000014] [G loss: 12.039120]\n",
      "[Epoch 40/1000] [Batch 144/168] [D loss: 0.000018] [G loss: 11.865941]\n",
      "[Epoch 40/1000] [Batch 145/168] [D loss: 0.000016] [G loss: 11.526767]\n",
      "[Epoch 40/1000] [Batch 146/168] [D loss: 0.000021] [G loss: 11.584944]\n",
      "[Epoch 40/1000] [Batch 147/168] [D loss: 0.000013] [G loss: 11.996641]\n",
      "[Epoch 40/1000] [Batch 148/168] [D loss: 0.000013] [G loss: 11.847431]\n",
      "[Epoch 40/1000] [Batch 149/168] [D loss: 0.000013] [G loss: 12.041938]\n",
      "[Epoch 40/1000] [Batch 150/168] [D loss: 0.000015] [G loss: 12.233437]\n",
      "[Epoch 40/1000] [Batch 151/168] [D loss: 0.000010] [G loss: 12.086262]\n",
      "[Epoch 40/1000] [Batch 152/168] [D loss: 0.000013] [G loss: 11.901140]\n",
      "[Epoch 40/1000] [Batch 153/168] [D loss: 0.000010] [G loss: 12.190737]\n",
      "[Epoch 40/1000] [Batch 154/168] [D loss: 0.000016] [G loss: 11.821781]\n",
      "[Epoch 40/1000] [Batch 155/168] [D loss: 0.000011] [G loss: 12.100371]\n",
      "[Epoch 40/1000] [Batch 156/168] [D loss: 0.000017] [G loss: 12.074360]\n",
      "[Epoch 40/1000] [Batch 157/168] [D loss: 0.000013] [G loss: 12.006835]\n",
      "[Epoch 40/1000] [Batch 158/168] [D loss: 0.000013] [G loss: 11.851020]\n",
      "[Epoch 40/1000] [Batch 159/168] [D loss: 0.000013] [G loss: 11.946244]\n",
      "[Epoch 40/1000] [Batch 160/168] [D loss: 0.000015] [G loss: 11.636860]\n",
      "[Epoch 40/1000] [Batch 161/168] [D loss: 0.000018] [G loss: 11.728994]\n",
      "[Epoch 40/1000] [Batch 162/168] [D loss: 0.000014] [G loss: 11.975696]\n",
      "[Epoch 40/1000] [Batch 163/168] [D loss: 0.000012] [G loss: 12.136747]\n",
      "[Epoch 40/1000] [Batch 164/168] [D loss: 0.000014] [G loss: 11.994289]\n",
      "[Epoch 40/1000] [Batch 165/168] [D loss: 0.000024] [G loss: 11.986667]\n",
      "[Epoch 40/1000] [Batch 166/168] [D loss: 0.000009] [G loss: 12.069613]\n",
      "[Epoch 40/1000] [Batch 167/168] [D loss: 0.000022] [G loss: 11.355242]\n",
      "[Epoch 40/1000] [Batch 168/168] [D loss: 0.000015] [G loss: 11.993918]\n",
      "[Epoch 41/1000] [Batch 1/168] [D loss: 0.000030] [G loss: 11.974447]\n",
      "[Epoch 41/1000] [Batch 2/168] [D loss: 0.000015] [G loss: 11.934361]\n",
      "[Epoch 41/1000] [Batch 3/168] [D loss: 0.000021] [G loss: 11.777192]\n",
      "[Epoch 41/1000] [Batch 4/168] [D loss: 0.000011] [G loss: 12.151185]\n",
      "[Epoch 41/1000] [Batch 5/168] [D loss: 0.000023] [G loss: 11.789148]\n",
      "[Epoch 41/1000] [Batch 6/168] [D loss: 0.000012] [G loss: 11.900839]\n",
      "[Epoch 41/1000] [Batch 7/168] [D loss: 0.000015] [G loss: 11.775788]\n",
      "[Epoch 41/1000] [Batch 8/168] [D loss: 0.000015] [G loss: 12.051293]\n",
      "[Epoch 41/1000] [Batch 9/168] [D loss: 0.000012] [G loss: 12.016321]\n",
      "[Epoch 41/1000] [Batch 10/168] [D loss: 0.000017] [G loss: 11.864652]\n",
      "[Epoch 41/1000] [Batch 11/168] [D loss: 0.000011] [G loss: 12.087616]\n",
      "[Epoch 41/1000] [Batch 12/168] [D loss: 0.000018] [G loss: 11.864731]\n",
      "[Epoch 41/1000] [Batch 13/168] [D loss: 0.000011] [G loss: 12.198003]\n",
      "[Epoch 41/1000] [Batch 14/168] [D loss: 0.000017] [G loss: 12.205398]\n",
      "[Epoch 41/1000] [Batch 15/168] [D loss: 0.000018] [G loss: 11.977351]\n",
      "[Epoch 41/1000] [Batch 16/168] [D loss: 0.000019] [G loss: 12.404055]\n",
      "[Epoch 41/1000] [Batch 17/168] [D loss: 0.000017] [G loss: 12.127524]\n",
      "[Epoch 41/1000] [Batch 18/168] [D loss: 0.000016] [G loss: 12.113026]\n",
      "[Epoch 41/1000] [Batch 19/168] [D loss: 0.000011] [G loss: 11.849000]\n",
      "[Epoch 41/1000] [Batch 20/168] [D loss: 0.000018] [G loss: 11.589673]\n",
      "[Epoch 41/1000] [Batch 21/168] [D loss: 0.000016] [G loss: 11.945381]\n",
      "[Epoch 41/1000] [Batch 22/168] [D loss: 0.000013] [G loss: 11.790068]\n",
      "[Epoch 41/1000] [Batch 23/168] [D loss: 0.000012] [G loss: 12.023640]\n",
      "[Epoch 41/1000] [Batch 24/168] [D loss: 0.000016] [G loss: 12.255733]\n",
      "[Epoch 41/1000] [Batch 25/168] [D loss: 0.000017] [G loss: 12.023524]\n",
      "[Epoch 41/1000] [Batch 26/168] [D loss: 0.000008] [G loss: 12.169368]\n",
      "[Epoch 41/1000] [Batch 27/168] [D loss: 0.000022] [G loss: 12.446950]\n",
      "[Epoch 41/1000] [Batch 28/168] [D loss: 0.000014] [G loss: 12.020663]\n",
      "[Epoch 41/1000] [Batch 29/168] [D loss: 0.000014] [G loss: 12.066494]\n",
      "[Epoch 41/1000] [Batch 30/168] [D loss: 0.000009] [G loss: 12.234820]\n",
      "[Epoch 41/1000] [Batch 31/168] [D loss: 0.000014] [G loss: 12.444382]\n",
      "[Epoch 41/1000] [Batch 32/168] [D loss: 0.000016] [G loss: 12.059110]\n",
      "[Epoch 41/1000] [Batch 33/168] [D loss: 0.000009] [G loss: 12.339438]\n",
      "[Epoch 41/1000] [Batch 34/168] [D loss: 0.000014] [G loss: 11.872657]\n",
      "[Epoch 41/1000] [Batch 35/168] [D loss: 0.000019] [G loss: 11.927072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/1000] [Batch 36/168] [D loss: 0.000025] [G loss: 12.271877]\n",
      "[Epoch 41/1000] [Batch 37/168] [D loss: 0.000031] [G loss: 11.891665]\n",
      "[Epoch 41/1000] [Batch 38/168] [D loss: 0.000015] [G loss: 12.225909]\n",
      "[Epoch 41/1000] [Batch 39/168] [D loss: 0.000023] [G loss: 12.051900]\n",
      "[Epoch 41/1000] [Batch 40/168] [D loss: 0.000018] [G loss: 11.834425]\n",
      "[Epoch 41/1000] [Batch 41/168] [D loss: 0.000019] [G loss: 11.600556]\n",
      "[Epoch 41/1000] [Batch 42/168] [D loss: 0.000010] [G loss: 11.942270]\n",
      "[Epoch 41/1000] [Batch 43/168] [D loss: 0.000010] [G loss: 11.881701]\n",
      "[Epoch 41/1000] [Batch 44/168] [D loss: 0.000012] [G loss: 11.965333]\n",
      "[Epoch 41/1000] [Batch 45/168] [D loss: 0.000012] [G loss: 12.321202]\n",
      "[Epoch 41/1000] [Batch 46/168] [D loss: 0.000014] [G loss: 12.154972]\n",
      "[Epoch 41/1000] [Batch 47/168] [D loss: 0.000010] [G loss: 12.027665]\n",
      "[Epoch 41/1000] [Batch 48/168] [D loss: 0.000010] [G loss: 12.066218]\n",
      "[Epoch 41/1000] [Batch 49/168] [D loss: 0.000012] [G loss: 12.094155]\n",
      "[Epoch 41/1000] [Batch 50/168] [D loss: 0.000008] [G loss: 12.209760]\n",
      "[Epoch 41/1000] [Batch 51/168] [D loss: 0.000018] [G loss: 12.386095]\n",
      "[Epoch 41/1000] [Batch 52/168] [D loss: 0.000011] [G loss: 12.632851]\n",
      "[Epoch 41/1000] [Batch 53/168] [D loss: 0.000008] [G loss: 12.414959]\n",
      "[Epoch 41/1000] [Batch 54/168] [D loss: 0.000013] [G loss: 11.904598]\n",
      "[Epoch 41/1000] [Batch 55/168] [D loss: 0.000009] [G loss: 12.160876]\n",
      "[Epoch 41/1000] [Batch 56/168] [D loss: 0.000009] [G loss: 12.205389]\n",
      "[Epoch 41/1000] [Batch 57/168] [D loss: 0.000012] [G loss: 12.027582]\n",
      "[Epoch 41/1000] [Batch 58/168] [D loss: 0.000015] [G loss: 11.750461]\n",
      "[Epoch 41/1000] [Batch 59/168] [D loss: 0.000011] [G loss: 11.927261]\n",
      "[Epoch 41/1000] [Batch 60/168] [D loss: 0.000016] [G loss: 12.301846]\n",
      "[Epoch 41/1000] [Batch 61/168] [D loss: 0.000015] [G loss: 12.187252]\n",
      "[Epoch 41/1000] [Batch 62/168] [D loss: 0.000021] [G loss: 12.223086]\n",
      "[Epoch 41/1000] [Batch 63/168] [D loss: 0.000016] [G loss: 12.366416]\n",
      "[Epoch 41/1000] [Batch 64/168] [D loss: 0.000011] [G loss: 12.401503]\n",
      "[Epoch 41/1000] [Batch 65/168] [D loss: 0.000011] [G loss: 12.237523]\n",
      "[Epoch 41/1000] [Batch 66/168] [D loss: 0.000012] [G loss: 12.281950]\n",
      "[Epoch 41/1000] [Batch 67/168] [D loss: 0.000008] [G loss: 12.488111]\n",
      "[Epoch 41/1000] [Batch 68/168] [D loss: 0.000011] [G loss: 12.265470]\n",
      "[Epoch 41/1000] [Batch 69/168] [D loss: 0.000018] [G loss: 11.954220]\n",
      "[Epoch 41/1000] [Batch 70/168] [D loss: 0.000022] [G loss: 12.002996]\n",
      "[Epoch 41/1000] [Batch 71/168] [D loss: 0.000016] [G loss: 12.329573]\n",
      "[Epoch 41/1000] [Batch 72/168] [D loss: 0.000011] [G loss: 12.050831]\n",
      "[Epoch 41/1000] [Batch 73/168] [D loss: 0.000011] [G loss: 12.305427]\n",
      "[Epoch 41/1000] [Batch 74/168] [D loss: 0.000013] [G loss: 12.087648]\n",
      "[Epoch 41/1000] [Batch 75/168] [D loss: 0.000011] [G loss: 12.407040]\n",
      "[Epoch 41/1000] [Batch 76/168] [D loss: 0.000013] [G loss: 12.079898]\n",
      "[Epoch 41/1000] [Batch 77/168] [D loss: 0.000014] [G loss: 12.299210]\n",
      "[Epoch 41/1000] [Batch 78/168] [D loss: 0.000008] [G loss: 12.493732]\n",
      "[Epoch 41/1000] [Batch 79/168] [D loss: 0.000008] [G loss: 12.513325]\n",
      "[Epoch 41/1000] [Batch 80/168] [D loss: 0.000015] [G loss: 12.502713]\n",
      "[Epoch 41/1000] [Batch 81/168] [D loss: 0.000011] [G loss: 12.331429]\n",
      "[Epoch 41/1000] [Batch 82/168] [D loss: 0.000011] [G loss: 12.441631]\n",
      "[Epoch 41/1000] [Batch 83/168] [D loss: 0.000011] [G loss: 12.075668]\n",
      "[Epoch 41/1000] [Batch 84/168] [D loss: 0.000013] [G loss: 12.034341]\n",
      "[Epoch 41/1000] [Batch 85/168] [D loss: 0.000011] [G loss: 12.282908]\n",
      "[Epoch 41/1000] [Batch 86/168] [D loss: 0.000011] [G loss: 12.463353]\n",
      "[Epoch 41/1000] [Batch 87/168] [D loss: 0.000007] [G loss: 12.517078]\n",
      "[Epoch 41/1000] [Batch 88/168] [D loss: 0.000011] [G loss: 12.225636]\n",
      "[Epoch 41/1000] [Batch 89/168] [D loss: 0.000012] [G loss: 12.511915]\n",
      "[Epoch 41/1000] [Batch 90/168] [D loss: 0.000008] [G loss: 12.522654]\n",
      "[Epoch 41/1000] [Batch 91/168] [D loss: 0.000012] [G loss: 12.113733]\n",
      "[Epoch 41/1000] [Batch 92/168] [D loss: 0.000008] [G loss: 12.486457]\n",
      "[Epoch 41/1000] [Batch 93/168] [D loss: 0.000009] [G loss: 12.432254]\n",
      "[Epoch 41/1000] [Batch 94/168] [D loss: 0.000009] [G loss: 12.586847]\n",
      "[Epoch 41/1000] [Batch 95/168] [D loss: 0.000019] [G loss: 12.697953]\n",
      "[Epoch 41/1000] [Batch 96/168] [D loss: 0.000010] [G loss: 12.285469]\n",
      "[Epoch 41/1000] [Batch 97/168] [D loss: 0.000007] [G loss: 12.559536]\n",
      "[Epoch 41/1000] [Batch 98/168] [D loss: 0.000008] [G loss: 12.647920]\n",
      "[Epoch 41/1000] [Batch 99/168] [D loss: 0.000012] [G loss: 12.732598]\n",
      "[Epoch 41/1000] [Batch 100/168] [D loss: 0.000010] [G loss: 12.518904]\n",
      "[Epoch 41/1000] [Batch 101/168] [D loss: 0.000010] [G loss: 12.482042]\n",
      "[Epoch 41/1000] [Batch 102/168] [D loss: 0.000010] [G loss: 12.618276]\n",
      "[Epoch 41/1000] [Batch 103/168] [D loss: 0.000010] [G loss: 12.580110]\n",
      "[Epoch 41/1000] [Batch 104/168] [D loss: 0.000008] [G loss: 12.687634]\n",
      "[Epoch 41/1000] [Batch 105/168] [D loss: 0.000011] [G loss: 12.670533]\n",
      "[Epoch 41/1000] [Batch 106/168] [D loss: 0.000018] [G loss: 12.556811]\n",
      "[Epoch 41/1000] [Batch 107/168] [D loss: 0.000010] [G loss: 12.398882]\n",
      "[Epoch 41/1000] [Batch 108/168] [D loss: 0.000009] [G loss: 12.363811]\n",
      "[Epoch 41/1000] [Batch 109/168] [D loss: 0.000009] [G loss: 12.566743]\n",
      "[Epoch 41/1000] [Batch 110/168] [D loss: 0.000010] [G loss: 12.665318]\n",
      "[Epoch 41/1000] [Batch 111/168] [D loss: 0.000009] [G loss: 12.582878]\n",
      "[Epoch 41/1000] [Batch 112/168] [D loss: 0.000013] [G loss: 13.120663]\n",
      "[Epoch 41/1000] [Batch 113/168] [D loss: 0.000011] [G loss: 12.713417]\n",
      "[Epoch 41/1000] [Batch 114/168] [D loss: 0.000011] [G loss: 12.506974]\n",
      "[Epoch 41/1000] [Batch 115/168] [D loss: 0.000008] [G loss: 12.795467]\n",
      "[Epoch 41/1000] [Batch 116/168] [D loss: 0.000016] [G loss: 12.255653]\n",
      "[Epoch 41/1000] [Batch 117/168] [D loss: 0.000007] [G loss: 12.557549]\n",
      "[Epoch 41/1000] [Batch 118/168] [D loss: 0.000007] [G loss: 12.455651]\n",
      "[Epoch 41/1000] [Batch 119/168] [D loss: 0.000009] [G loss: 12.632525]\n",
      "[Epoch 41/1000] [Batch 120/168] [D loss: 0.000013] [G loss: 12.266277]\n",
      "[Epoch 41/1000] [Batch 121/168] [D loss: 0.000008] [G loss: 12.513329]\n",
      "[Epoch 41/1000] [Batch 122/168] [D loss: 0.000012] [G loss: 12.617888]\n",
      "[Epoch 41/1000] [Batch 123/168] [D loss: 0.000009] [G loss: 12.613328]\n",
      "[Epoch 41/1000] [Batch 124/168] [D loss: 0.000007] [G loss: 13.064804]\n",
      "[Epoch 41/1000] [Batch 125/168] [D loss: 0.000007] [G loss: 12.387028]\n",
      "[Epoch 41/1000] [Batch 126/168] [D loss: 0.000013] [G loss: 12.334176]\n",
      "[Epoch 41/1000] [Batch 127/168] [D loss: 0.000009] [G loss: 12.643898]\n",
      "[Epoch 41/1000] [Batch 128/168] [D loss: 0.000009] [G loss: 12.510408]\n",
      "[Epoch 41/1000] [Batch 129/168] [D loss: 0.000011] [G loss: 12.600126]\n",
      "[Epoch 41/1000] [Batch 130/168] [D loss: 0.000010] [G loss: 12.815741]\n",
      "[Epoch 41/1000] [Batch 131/168] [D loss: 0.000007] [G loss: 12.429663]\n",
      "[Epoch 41/1000] [Batch 132/168] [D loss: 0.000008] [G loss: 12.477318]\n",
      "[Epoch 41/1000] [Batch 133/168] [D loss: 0.000011] [G loss: 12.656270]\n",
      "[Epoch 41/1000] [Batch 134/168] [D loss: 0.000007] [G loss: 12.665665]\n",
      "[Epoch 41/1000] [Batch 135/168] [D loss: 0.000018] [G loss: 12.484493]\n",
      "[Epoch 41/1000] [Batch 136/168] [D loss: 0.000012] [G loss: 13.110663]\n",
      "[Epoch 41/1000] [Batch 137/168] [D loss: 0.000015] [G loss: 12.359970]\n",
      "[Epoch 41/1000] [Batch 138/168] [D loss: 0.000007] [G loss: 12.534358]\n",
      "[Epoch 41/1000] [Batch 139/168] [D loss: 0.000009] [G loss: 12.702940]\n",
      "[Epoch 41/1000] [Batch 140/168] [D loss: 0.000016] [G loss: 12.438338]\n",
      "[Epoch 41/1000] [Batch 141/168] [D loss: 0.000010] [G loss: 12.608678]\n",
      "[Epoch 41/1000] [Batch 142/168] [D loss: 0.000009] [G loss: 12.179933]\n",
      "[Epoch 41/1000] [Batch 143/168] [D loss: 0.000009] [G loss: 12.472402]\n",
      "[Epoch 41/1000] [Batch 144/168] [D loss: 0.000008] [G loss: 12.581172]\n",
      "[Epoch 41/1000] [Batch 145/168] [D loss: 0.000015] [G loss: 12.521344]\n",
      "[Epoch 41/1000] [Batch 146/168] [D loss: 0.000009] [G loss: 12.319231]\n",
      "[Epoch 41/1000] [Batch 147/168] [D loss: 0.000010] [G loss: 12.370224]\n",
      "[Epoch 41/1000] [Batch 148/168] [D loss: 0.000008] [G loss: 12.679718]\n",
      "[Epoch 41/1000] [Batch 149/168] [D loss: 0.000009] [G loss: 12.506560]\n",
      "[Epoch 41/1000] [Batch 150/168] [D loss: 0.000014] [G loss: 12.370845]\n",
      "[Epoch 41/1000] [Batch 151/168] [D loss: 0.000013] [G loss: 12.222633]\n",
      "[Epoch 41/1000] [Batch 152/168] [D loss: 0.000010] [G loss: 12.588793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/1000] [Batch 153/168] [D loss: 0.000009] [G loss: 12.310004]\n",
      "[Epoch 41/1000] [Batch 154/168] [D loss: 0.000012] [G loss: 12.445266]\n",
      "[Epoch 41/1000] [Batch 155/168] [D loss: 0.000007] [G loss: 12.587372]\n",
      "[Epoch 41/1000] [Batch 156/168] [D loss: 0.000007] [G loss: 12.741930]\n",
      "[Epoch 41/1000] [Batch 157/168] [D loss: 0.000007] [G loss: 12.855420]\n",
      "[Epoch 41/1000] [Batch 158/168] [D loss: 0.000008] [G loss: 12.987158]\n",
      "[Epoch 41/1000] [Batch 159/168] [D loss: 0.000008] [G loss: 12.695980]\n",
      "[Epoch 41/1000] [Batch 160/168] [D loss: 0.000006] [G loss: 12.710111]\n",
      "[Epoch 41/1000] [Batch 161/168] [D loss: 0.000008] [G loss: 12.363397]\n",
      "[Epoch 41/1000] [Batch 162/168] [D loss: 0.000013] [G loss: 12.827594]\n",
      "[Epoch 41/1000] [Batch 163/168] [D loss: 0.000015] [G loss: 12.279791]\n",
      "[Epoch 41/1000] [Batch 164/168] [D loss: 0.000013] [G loss: 12.815691]\n",
      "[Epoch 41/1000] [Batch 165/168] [D loss: 0.000013] [G loss: 12.608019]\n",
      "[Epoch 41/1000] [Batch 166/168] [D loss: 0.000010] [G loss: 12.403943]\n",
      "[Epoch 41/1000] [Batch 167/168] [D loss: 0.000010] [G loss: 12.241600]\n",
      "[Epoch 41/1000] [Batch 168/168] [D loss: 0.000012] [G loss: 12.172116]\n",
      "[Epoch 42/1000] [Batch 1/168] [D loss: 0.000009] [G loss: 12.535961]\n",
      "[Epoch 42/1000] [Batch 2/168] [D loss: 0.000009] [G loss: 12.771437]\n",
      "[Epoch 42/1000] [Batch 3/168] [D loss: 0.000011] [G loss: 13.031851]\n",
      "[Epoch 42/1000] [Batch 4/168] [D loss: 0.000011] [G loss: 12.528537]\n",
      "[Epoch 42/1000] [Batch 5/168] [D loss: 0.000012] [G loss: 12.575848]\n",
      "[Epoch 42/1000] [Batch 6/168] [D loss: 0.000009] [G loss: 12.709199]\n",
      "[Epoch 42/1000] [Batch 7/168] [D loss: 0.000013] [G loss: 12.325468]\n",
      "[Epoch 42/1000] [Batch 8/168] [D loss: 0.000005] [G loss: 12.667244]\n",
      "[Epoch 42/1000] [Batch 9/168] [D loss: 0.000015] [G loss: 12.550413]\n",
      "[Epoch 42/1000] [Batch 10/168] [D loss: 0.000011] [G loss: 12.291013]\n",
      "[Epoch 42/1000] [Batch 11/168] [D loss: 0.000007] [G loss: 12.718355]\n",
      "[Epoch 42/1000] [Batch 12/168] [D loss: 0.000009] [G loss: 12.643287]\n",
      "[Epoch 42/1000] [Batch 13/168] [D loss: 0.000009] [G loss: 12.856470]\n",
      "[Epoch 42/1000] [Batch 14/168] [D loss: 0.000006] [G loss: 12.549635]\n",
      "[Epoch 42/1000] [Batch 15/168] [D loss: 0.000006] [G loss: 12.772340]\n",
      "[Epoch 42/1000] [Batch 16/168] [D loss: 0.000007] [G loss: 12.403872]\n",
      "[Epoch 42/1000] [Batch 17/168] [D loss: 0.000007] [G loss: 12.781730]\n",
      "[Epoch 42/1000] [Batch 18/168] [D loss: 0.000010] [G loss: 12.847804]\n",
      "[Epoch 42/1000] [Batch 19/168] [D loss: 0.000007] [G loss: 12.608727]\n",
      "[Epoch 42/1000] [Batch 20/168] [D loss: 0.000009] [G loss: 12.646377]\n",
      "[Epoch 42/1000] [Batch 21/168] [D loss: 0.000007] [G loss: 12.802186]\n",
      "[Epoch 42/1000] [Batch 22/168] [D loss: 0.000012] [G loss: 12.757200]\n",
      "[Epoch 42/1000] [Batch 23/168] [D loss: 0.000008] [G loss: 12.779587]\n",
      "[Epoch 42/1000] [Batch 24/168] [D loss: 0.000011] [G loss: 12.831296]\n",
      "[Epoch 42/1000] [Batch 25/168] [D loss: 0.000006] [G loss: 12.894976]\n",
      "[Epoch 42/1000] [Batch 26/168] [D loss: 0.000009] [G loss: 12.712766]\n",
      "[Epoch 42/1000] [Batch 27/168] [D loss: 0.000010] [G loss: 12.500711]\n",
      "[Epoch 42/1000] [Batch 28/168] [D loss: 0.000006] [G loss: 12.850336]\n",
      "[Epoch 42/1000] [Batch 29/168] [D loss: 0.000013] [G loss: 12.610770]\n",
      "[Epoch 42/1000] [Batch 30/168] [D loss: 0.000008] [G loss: 12.832420]\n",
      "[Epoch 42/1000] [Batch 31/168] [D loss: 0.000009] [G loss: 12.698256]\n",
      "[Epoch 42/1000] [Batch 32/168] [D loss: 0.000010] [G loss: 13.009926]\n",
      "[Epoch 42/1000] [Batch 33/168] [D loss: 0.000009] [G loss: 12.460699]\n",
      "[Epoch 42/1000] [Batch 34/168] [D loss: 0.000007] [G loss: 12.685002]\n",
      "[Epoch 42/1000] [Batch 35/168] [D loss: 0.000009] [G loss: 12.335148]\n",
      "[Epoch 42/1000] [Batch 36/168] [D loss: 0.000008] [G loss: 12.390072]\n",
      "[Epoch 42/1000] [Batch 37/168] [D loss: 0.000007] [G loss: 13.023047]\n",
      "[Epoch 42/1000] [Batch 38/168] [D loss: 0.000006] [G loss: 12.839403]\n",
      "[Epoch 42/1000] [Batch 39/168] [D loss: 0.000008] [G loss: 12.775669]\n",
      "[Epoch 42/1000] [Batch 40/168] [D loss: 0.000009] [G loss: 12.743953]\n",
      "[Epoch 42/1000] [Batch 41/168] [D loss: 0.000009] [G loss: 12.456126]\n",
      "[Epoch 42/1000] [Batch 42/168] [D loss: 0.000008] [G loss: 13.079906]\n",
      "[Epoch 42/1000] [Batch 43/168] [D loss: 0.000008] [G loss: 12.718534]\n",
      "[Epoch 42/1000] [Batch 44/168] [D loss: 0.000011] [G loss: 13.079231]\n",
      "[Epoch 42/1000] [Batch 45/168] [D loss: 0.000008] [G loss: 12.612938]\n",
      "[Epoch 42/1000] [Batch 46/168] [D loss: 0.000005] [G loss: 12.567058]\n",
      "[Epoch 42/1000] [Batch 47/168] [D loss: 0.000007] [G loss: 13.209517]\n",
      "[Epoch 42/1000] [Batch 48/168] [D loss: 0.000008] [G loss: 12.932205]\n",
      "[Epoch 42/1000] [Batch 49/168] [D loss: 0.000009] [G loss: 12.668533]\n",
      "[Epoch 42/1000] [Batch 50/168] [D loss: 0.000010] [G loss: 12.387518]\n",
      "[Epoch 42/1000] [Batch 51/168] [D loss: 0.000005] [G loss: 13.093959]\n",
      "[Epoch 42/1000] [Batch 52/168] [D loss: 0.000006] [G loss: 12.877480]\n",
      "[Epoch 42/1000] [Batch 53/168] [D loss: 0.000009] [G loss: 12.960131]\n",
      "[Epoch 42/1000] [Batch 54/168] [D loss: 0.000007] [G loss: 12.481764]\n",
      "[Epoch 42/1000] [Batch 55/168] [D loss: 0.000009] [G loss: 12.798364]\n",
      "[Epoch 42/1000] [Batch 56/168] [D loss: 0.000006] [G loss: 12.400795]\n",
      "[Epoch 42/1000] [Batch 57/168] [D loss: 0.000006] [G loss: 12.541824]\n",
      "[Epoch 42/1000] [Batch 58/168] [D loss: 0.000005] [G loss: 12.916696]\n",
      "[Epoch 42/1000] [Batch 59/168] [D loss: 0.000009] [G loss: 12.863861]\n",
      "[Epoch 42/1000] [Batch 60/168] [D loss: 0.000016] [G loss: 12.463198]\n",
      "[Epoch 42/1000] [Batch 61/168] [D loss: 0.000010] [G loss: 12.684581]\n",
      "[Epoch 42/1000] [Batch 62/168] [D loss: 0.000007] [G loss: 12.636605]\n",
      "[Epoch 42/1000] [Batch 63/168] [D loss: 0.000011] [G loss: 12.785661]\n",
      "[Epoch 42/1000] [Batch 64/168] [D loss: 0.000007] [G loss: 12.673866]\n",
      "[Epoch 42/1000] [Batch 65/168] [D loss: 0.000006] [G loss: 12.773579]\n",
      "[Epoch 42/1000] [Batch 66/168] [D loss: 0.000007] [G loss: 12.772200]\n",
      "[Epoch 42/1000] [Batch 67/168] [D loss: 0.000005] [G loss: 13.113648]\n",
      "[Epoch 42/1000] [Batch 68/168] [D loss: 0.000011] [G loss: 13.124114]\n",
      "[Epoch 42/1000] [Batch 69/168] [D loss: 0.000006] [G loss: 12.762938]\n",
      "[Epoch 42/1000] [Batch 70/168] [D loss: 0.000003] [G loss: 13.236240]\n",
      "[Epoch 42/1000] [Batch 71/168] [D loss: 0.000009] [G loss: 12.962181]\n",
      "[Epoch 42/1000] [Batch 72/168] [D loss: 0.000006] [G loss: 12.717161]\n",
      "[Epoch 42/1000] [Batch 73/168] [D loss: 0.000013] [G loss: 12.652344]\n",
      "[Epoch 42/1000] [Batch 74/168] [D loss: 0.000006] [G loss: 12.891461]\n",
      "[Epoch 42/1000] [Batch 75/168] [D loss: 0.000006] [G loss: 12.725823]\n",
      "[Epoch 42/1000] [Batch 76/168] [D loss: 0.000007] [G loss: 12.752934]\n",
      "[Epoch 42/1000] [Batch 77/168] [D loss: 0.000007] [G loss: 12.595350]\n",
      "[Epoch 42/1000] [Batch 78/168] [D loss: 0.000008] [G loss: 12.786516]\n",
      "[Epoch 42/1000] [Batch 79/168] [D loss: 0.000007] [G loss: 12.745989]\n",
      "[Epoch 42/1000] [Batch 80/168] [D loss: 0.000010] [G loss: 12.891392]\n",
      "[Epoch 42/1000] [Batch 81/168] [D loss: 0.000008] [G loss: 12.715351]\n",
      "[Epoch 42/1000] [Batch 82/168] [D loss: 0.000012] [G loss: 12.605923]\n",
      "[Epoch 42/1000] [Batch 83/168] [D loss: 0.000007] [G loss: 13.143204]\n",
      "[Epoch 42/1000] [Batch 84/168] [D loss: 0.000005] [G loss: 13.038898]\n",
      "[Epoch 42/1000] [Batch 85/168] [D loss: 0.000004] [G loss: 12.961321]\n",
      "[Epoch 42/1000] [Batch 86/168] [D loss: 0.000012] [G loss: 12.171144]\n",
      "[Epoch 42/1000] [Batch 87/168] [D loss: 0.000005] [G loss: 13.043184]\n",
      "[Epoch 42/1000] [Batch 88/168] [D loss: 0.000014] [G loss: 12.935334]\n",
      "[Epoch 42/1000] [Batch 89/168] [D loss: 0.000008] [G loss: 12.868140]\n",
      "[Epoch 42/1000] [Batch 90/168] [D loss: 0.000005] [G loss: 12.900912]\n",
      "[Epoch 42/1000] [Batch 91/168] [D loss: 0.000007] [G loss: 12.935108]\n",
      "[Epoch 42/1000] [Batch 92/168] [D loss: 0.000004] [G loss: 12.901561]\n",
      "[Epoch 42/1000] [Batch 93/168] [D loss: 0.000008] [G loss: 12.479655]\n",
      "[Epoch 42/1000] [Batch 94/168] [D loss: 0.000010] [G loss: 12.602599]\n",
      "[Epoch 42/1000] [Batch 95/168] [D loss: 0.000013] [G loss: 12.679789]\n",
      "[Epoch 42/1000] [Batch 96/168] [D loss: 0.000008] [G loss: 13.077890]\n",
      "[Epoch 42/1000] [Batch 97/168] [D loss: 0.000007] [G loss: 12.628791]\n",
      "[Epoch 42/1000] [Batch 98/168] [D loss: 0.000007] [G loss: 12.973540]\n",
      "[Epoch 42/1000] [Batch 99/168] [D loss: 0.000009] [G loss: 12.859997]\n",
      "[Epoch 42/1000] [Batch 100/168] [D loss: 0.000009] [G loss: 12.639508]\n",
      "[Epoch 42/1000] [Batch 101/168] [D loss: 0.000010] [G loss: 12.914905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/1000] [Batch 102/168] [D loss: 0.000006] [G loss: 12.766811]\n",
      "[Epoch 42/1000] [Batch 103/168] [D loss: 0.000005] [G loss: 12.607973]\n",
      "[Epoch 42/1000] [Batch 104/168] [D loss: 0.000010] [G loss: 12.394646]\n",
      "[Epoch 42/1000] [Batch 105/168] [D loss: 0.000006] [G loss: 12.656170]\n",
      "[Epoch 42/1000] [Batch 106/168] [D loss: 0.000008] [G loss: 12.980929]\n",
      "[Epoch 42/1000] [Batch 107/168] [D loss: 0.000006] [G loss: 12.989824]\n",
      "[Epoch 42/1000] [Batch 108/168] [D loss: 0.000008] [G loss: 12.969160]\n",
      "[Epoch 42/1000] [Batch 109/168] [D loss: 0.000005] [G loss: 12.914368]\n",
      "[Epoch 42/1000] [Batch 110/168] [D loss: 0.000007] [G loss: 12.795400]\n",
      "[Epoch 42/1000] [Batch 111/168] [D loss: 0.000012] [G loss: 12.763491]\n",
      "[Epoch 42/1000] [Batch 112/168] [D loss: 0.000011] [G loss: 12.820323]\n",
      "[Epoch 42/1000] [Batch 113/168] [D loss: 0.000007] [G loss: 13.029149]\n",
      "[Epoch 42/1000] [Batch 114/168] [D loss: 0.000006] [G loss: 12.955110]\n",
      "[Epoch 42/1000] [Batch 115/168] [D loss: 0.000004] [G loss: 13.168283]\n",
      "[Epoch 42/1000] [Batch 116/168] [D loss: 0.000006] [G loss: 12.842568]\n",
      "[Epoch 42/1000] [Batch 117/168] [D loss: 0.000009] [G loss: 12.812790]\n",
      "[Epoch 42/1000] [Batch 118/168] [D loss: 0.000007] [G loss: 13.170257]\n",
      "[Epoch 42/1000] [Batch 119/168] [D loss: 0.000008] [G loss: 12.974224]\n",
      "[Epoch 42/1000] [Batch 120/168] [D loss: 0.000007] [G loss: 13.019944]\n",
      "[Epoch 42/1000] [Batch 121/168] [D loss: 0.000004] [G loss: 13.098479]\n",
      "[Epoch 42/1000] [Batch 122/168] [D loss: 0.000014] [G loss: 12.863994]\n",
      "[Epoch 42/1000] [Batch 123/168] [D loss: 0.000006] [G loss: 12.980233]\n",
      "[Epoch 42/1000] [Batch 124/168] [D loss: 0.000006] [G loss: 12.566463]\n",
      "[Epoch 42/1000] [Batch 125/168] [D loss: 0.000008] [G loss: 12.756248]\n",
      "[Epoch 42/1000] [Batch 126/168] [D loss: 0.000006] [G loss: 12.786241]\n",
      "[Epoch 42/1000] [Batch 127/168] [D loss: 0.000007] [G loss: 12.697584]\n",
      "[Epoch 42/1000] [Batch 128/168] [D loss: 0.000007] [G loss: 12.852280]\n",
      "[Epoch 42/1000] [Batch 129/168] [D loss: 0.000007] [G loss: 13.056050]\n",
      "[Epoch 42/1000] [Batch 130/168] [D loss: 0.000008] [G loss: 12.881075]\n",
      "[Epoch 42/1000] [Batch 131/168] [D loss: 0.000008] [G loss: 12.810257]\n",
      "[Epoch 42/1000] [Batch 132/168] [D loss: 0.000013] [G loss: 13.082445]\n",
      "[Epoch 42/1000] [Batch 133/168] [D loss: 0.000006] [G loss: 12.855453]\n",
      "[Epoch 42/1000] [Batch 134/168] [D loss: 0.000005] [G loss: 13.288462]\n",
      "[Epoch 42/1000] [Batch 135/168] [D loss: 0.000009] [G loss: 12.954122]\n",
      "[Epoch 42/1000] [Batch 136/168] [D loss: 0.000014] [G loss: 12.958737]\n",
      "[Epoch 42/1000] [Batch 137/168] [D loss: 0.000011] [G loss: 12.962511]\n",
      "[Epoch 42/1000] [Batch 138/168] [D loss: 0.000006] [G loss: 12.855530]\n",
      "[Epoch 42/1000] [Batch 139/168] [D loss: 0.000014] [G loss: 12.996307]\n",
      "[Epoch 42/1000] [Batch 140/168] [D loss: 0.000005] [G loss: 13.111732]\n",
      "[Epoch 42/1000] [Batch 141/168] [D loss: 0.000005] [G loss: 12.804869]\n",
      "[Epoch 42/1000] [Batch 142/168] [D loss: 0.000009] [G loss: 12.781781]\n",
      "[Epoch 42/1000] [Batch 143/168] [D loss: 0.000009] [G loss: 12.873398]\n",
      "[Epoch 42/1000] [Batch 144/168] [D loss: 0.000006] [G loss: 12.877540]\n",
      "[Epoch 42/1000] [Batch 145/168] [D loss: 0.000006] [G loss: 12.841154]\n",
      "[Epoch 42/1000] [Batch 146/168] [D loss: 0.000007] [G loss: 12.731691]\n",
      "[Epoch 42/1000] [Batch 147/168] [D loss: 0.000009] [G loss: 13.145875]\n",
      "[Epoch 42/1000] [Batch 148/168] [D loss: 0.000006] [G loss: 13.076796]\n",
      "[Epoch 42/1000] [Batch 149/168] [D loss: 0.000005] [G loss: 12.929679]\n",
      "[Epoch 42/1000] [Batch 150/168] [D loss: 0.000006] [G loss: 12.931950]\n",
      "[Epoch 42/1000] [Batch 151/168] [D loss: 0.000009] [G loss: 13.158947]\n",
      "[Epoch 42/1000] [Batch 152/168] [D loss: 0.000007] [G loss: 12.994911]\n",
      "[Epoch 42/1000] [Batch 153/168] [D loss: 0.000006] [G loss: 13.013801]\n",
      "[Epoch 42/1000] [Batch 154/168] [D loss: 0.000006] [G loss: 12.760340]\n",
      "[Epoch 42/1000] [Batch 155/168] [D loss: 0.000004] [G loss: 12.926705]\n",
      "[Epoch 42/1000] [Batch 156/168] [D loss: 0.000006] [G loss: 12.875351]\n",
      "[Epoch 42/1000] [Batch 157/168] [D loss: 0.000005] [G loss: 13.004554]\n",
      "[Epoch 42/1000] [Batch 158/168] [D loss: 0.000006] [G loss: 12.949518]\n",
      "[Epoch 42/1000] [Batch 159/168] [D loss: 0.000006] [G loss: 13.077273]\n",
      "[Epoch 42/1000] [Batch 160/168] [D loss: 0.000012] [G loss: 12.817294]\n",
      "[Epoch 42/1000] [Batch 161/168] [D loss: 0.000006] [G loss: 13.343266]\n",
      "[Epoch 42/1000] [Batch 162/168] [D loss: 0.000006] [G loss: 12.898584]\n",
      "[Epoch 42/1000] [Batch 163/168] [D loss: 0.000007] [G loss: 12.934174]\n",
      "[Epoch 42/1000] [Batch 164/168] [D loss: 0.000008] [G loss: 12.810523]\n",
      "[Epoch 42/1000] [Batch 165/168] [D loss: 0.000004] [G loss: 12.973179]\n",
      "[Epoch 42/1000] [Batch 166/168] [D loss: 0.000005] [G loss: 13.047697]\n",
      "[Epoch 42/1000] [Batch 167/168] [D loss: 0.000006] [G loss: 12.759838]\n",
      "[Epoch 42/1000] [Batch 168/168] [D loss: 0.000008] [G loss: 13.205208]\n",
      "[Epoch 43/1000] [Batch 1/168] [D loss: 0.000007] [G loss: 12.808258]\n",
      "[Epoch 43/1000] [Batch 2/168] [D loss: 0.000007] [G loss: 13.232725]\n",
      "[Epoch 43/1000] [Batch 3/168] [D loss: 0.000006] [G loss: 12.782150]\n",
      "[Epoch 43/1000] [Batch 4/168] [D loss: 0.000005] [G loss: 12.680035]\n",
      "[Epoch 43/1000] [Batch 5/168] [D loss: 0.000007] [G loss: 12.659329]\n",
      "[Epoch 43/1000] [Batch 6/168] [D loss: 0.000005] [G loss: 13.009558]\n",
      "[Epoch 43/1000] [Batch 7/168] [D loss: 0.000007] [G loss: 12.816920]\n",
      "[Epoch 43/1000] [Batch 8/168] [D loss: 0.000006] [G loss: 13.132132]\n",
      "[Epoch 43/1000] [Batch 9/168] [D loss: 0.000006] [G loss: 13.015461]\n",
      "[Epoch 43/1000] [Batch 10/168] [D loss: 0.000007] [G loss: 13.071293]\n",
      "[Epoch 43/1000] [Batch 11/168] [D loss: 0.000006] [G loss: 13.284472]\n",
      "[Epoch 43/1000] [Batch 12/168] [D loss: 0.000004] [G loss: 13.401005]\n",
      "[Epoch 43/1000] [Batch 13/168] [D loss: 0.000006] [G loss: 12.919295]\n",
      "[Epoch 43/1000] [Batch 14/168] [D loss: 0.000007] [G loss: 13.205564]\n",
      "[Epoch 43/1000] [Batch 15/168] [D loss: 0.000007] [G loss: 12.858634]\n",
      "[Epoch 43/1000] [Batch 16/168] [D loss: 0.000004] [G loss: 13.160103]\n",
      "[Epoch 43/1000] [Batch 17/168] [D loss: 0.000005] [G loss: 12.849180]\n",
      "[Epoch 43/1000] [Batch 18/168] [D loss: 0.000009] [G loss: 12.760505]\n",
      "[Epoch 43/1000] [Batch 19/168] [D loss: 0.000011] [G loss: 13.006926]\n",
      "[Epoch 43/1000] [Batch 20/168] [D loss: 0.000010] [G loss: 12.873174]\n",
      "[Epoch 43/1000] [Batch 21/168] [D loss: 0.000007] [G loss: 12.884597]\n",
      "[Epoch 43/1000] [Batch 22/168] [D loss: 0.000006] [G loss: 12.922850]\n",
      "[Epoch 43/1000] [Batch 23/168] [D loss: 0.000006] [G loss: 13.168530]\n",
      "[Epoch 43/1000] [Batch 24/168] [D loss: 0.000005] [G loss: 12.772195]\n",
      "[Epoch 43/1000] [Batch 25/168] [D loss: 0.000007] [G loss: 13.102777]\n",
      "[Epoch 43/1000] [Batch 26/168] [D loss: 0.000006] [G loss: 13.267715]\n",
      "[Epoch 43/1000] [Batch 27/168] [D loss: 0.000012] [G loss: 12.878913]\n",
      "[Epoch 43/1000] [Batch 28/168] [D loss: 0.000011] [G loss: 12.975242]\n",
      "[Epoch 43/1000] [Batch 29/168] [D loss: 0.000009] [G loss: 13.194541]\n",
      "[Epoch 43/1000] [Batch 30/168] [D loss: 0.000009] [G loss: 13.146969]\n",
      "[Epoch 43/1000] [Batch 31/168] [D loss: 0.000004] [G loss: 13.362124]\n",
      "[Epoch 43/1000] [Batch 32/168] [D loss: 0.000004] [G loss: 12.942787]\n",
      "[Epoch 43/1000] [Batch 33/168] [D loss: 0.000006] [G loss: 13.070506]\n",
      "[Epoch 43/1000] [Batch 34/168] [D loss: 0.000007] [G loss: 12.740845]\n",
      "[Epoch 43/1000] [Batch 35/168] [D loss: 0.000004] [G loss: 13.002862]\n",
      "[Epoch 43/1000] [Batch 36/168] [D loss: 0.000006] [G loss: 12.915149]\n",
      "[Epoch 43/1000] [Batch 37/168] [D loss: 0.000006] [G loss: 13.293259]\n",
      "[Epoch 43/1000] [Batch 38/168] [D loss: 0.000007] [G loss: 13.218885]\n",
      "[Epoch 43/1000] [Batch 39/168] [D loss: 0.000008] [G loss: 13.321871]\n",
      "[Epoch 43/1000] [Batch 40/168] [D loss: 0.000005] [G loss: 12.784315]\n",
      "[Epoch 43/1000] [Batch 41/168] [D loss: 0.000007] [G loss: 13.252126]\n",
      "[Epoch 43/1000] [Batch 42/168] [D loss: 0.000007] [G loss: 12.837008]\n",
      "[Epoch 43/1000] [Batch 43/168] [D loss: 0.000007] [G loss: 12.760093]\n",
      "[Epoch 43/1000] [Batch 44/168] [D loss: 0.000006] [G loss: 13.005122]\n",
      "[Epoch 43/1000] [Batch 45/168] [D loss: 0.000004] [G loss: 13.138583]\n",
      "[Epoch 43/1000] [Batch 46/168] [D loss: 0.000008] [G loss: 12.775823]\n",
      "[Epoch 43/1000] [Batch 47/168] [D loss: 0.000004] [G loss: 13.366585]\n",
      "[Epoch 43/1000] [Batch 48/168] [D loss: 0.000005] [G loss: 13.085833]\n",
      "[Epoch 43/1000] [Batch 49/168] [D loss: 0.000004] [G loss: 12.882504]\n",
      "[Epoch 43/1000] [Batch 50/168] [D loss: 0.000007] [G loss: 12.838099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/1000] [Batch 51/168] [D loss: 0.000006] [G loss: 12.960113]\n",
      "[Epoch 43/1000] [Batch 52/168] [D loss: 0.000006] [G loss: 13.054863]\n",
      "[Epoch 43/1000] [Batch 53/168] [D loss: 0.000007] [G loss: 12.563633]\n",
      "[Epoch 43/1000] [Batch 54/168] [D loss: 0.000006] [G loss: 12.968950]\n",
      "[Epoch 43/1000] [Batch 55/168] [D loss: 0.000006] [G loss: 13.005125]\n",
      "[Epoch 43/1000] [Batch 56/168] [D loss: 0.000004] [G loss: 13.101061]\n",
      "[Epoch 43/1000] [Batch 57/168] [D loss: 0.000012] [G loss: 13.254436]\n",
      "[Epoch 43/1000] [Batch 58/168] [D loss: 0.000005] [G loss: 13.381817]\n",
      "[Epoch 43/1000] [Batch 59/168] [D loss: 0.000007] [G loss: 13.184690]\n",
      "[Epoch 43/1000] [Batch 60/168] [D loss: 0.000004] [G loss: 13.356192]\n",
      "[Epoch 43/1000] [Batch 61/168] [D loss: 0.000007] [G loss: 13.015277]\n",
      "[Epoch 43/1000] [Batch 62/168] [D loss: 0.000005] [G loss: 12.990396]\n",
      "[Epoch 43/1000] [Batch 63/168] [D loss: 0.000007] [G loss: 13.418588]\n",
      "[Epoch 43/1000] [Batch 64/168] [D loss: 0.000009] [G loss: 12.959692]\n",
      "[Epoch 43/1000] [Batch 65/168] [D loss: 0.000007] [G loss: 13.201164]\n",
      "[Epoch 43/1000] [Batch 66/168] [D loss: 0.000006] [G loss: 12.760409]\n",
      "[Epoch 43/1000] [Batch 67/168] [D loss: 0.000007] [G loss: 13.307403]\n",
      "[Epoch 43/1000] [Batch 68/168] [D loss: 0.000006] [G loss: 13.170835]\n",
      "[Epoch 43/1000] [Batch 69/168] [D loss: 0.000005] [G loss: 13.141010]\n",
      "[Epoch 43/1000] [Batch 70/168] [D loss: 0.000005] [G loss: 13.058104]\n",
      "[Epoch 43/1000] [Batch 71/168] [D loss: 0.000007] [G loss: 12.758009]\n",
      "[Epoch 43/1000] [Batch 72/168] [D loss: 0.000005] [G loss: 13.365126]\n",
      "[Epoch 43/1000] [Batch 73/168] [D loss: 0.000007] [G loss: 13.087898]\n",
      "[Epoch 43/1000] [Batch 74/168] [D loss: 0.000005] [G loss: 13.228650]\n",
      "[Epoch 43/1000] [Batch 75/168] [D loss: 0.000005] [G loss: 13.105984]\n",
      "[Epoch 43/1000] [Batch 76/168] [D loss: 0.000007] [G loss: 13.113020]\n",
      "[Epoch 43/1000] [Batch 77/168] [D loss: 0.000005] [G loss: 12.892812]\n",
      "[Epoch 43/1000] [Batch 78/168] [D loss: 0.000008] [G loss: 12.946692]\n",
      "[Epoch 43/1000] [Batch 79/168] [D loss: 0.000006] [G loss: 13.137682]\n",
      "[Epoch 43/1000] [Batch 80/168] [D loss: 0.000005] [G loss: 13.068128]\n",
      "[Epoch 43/1000] [Batch 81/168] [D loss: 0.000004] [G loss: 12.971038]\n",
      "[Epoch 43/1000] [Batch 82/168] [D loss: 0.000005] [G loss: 12.867052]\n",
      "[Epoch 43/1000] [Batch 83/168] [D loss: 0.000008] [G loss: 13.077034]\n",
      "[Epoch 43/1000] [Batch 84/168] [D loss: 0.000005] [G loss: 13.097325]\n",
      "[Epoch 43/1000] [Batch 85/168] [D loss: 0.000005] [G loss: 13.377445]\n",
      "[Epoch 43/1000] [Batch 86/168] [D loss: 0.000009] [G loss: 13.020601]\n",
      "[Epoch 43/1000] [Batch 87/168] [D loss: 0.000007] [G loss: 13.203910]\n",
      "[Epoch 43/1000] [Batch 88/168] [D loss: 0.000005] [G loss: 13.041968]\n",
      "[Epoch 43/1000] [Batch 89/168] [D loss: 0.000009] [G loss: 12.695226]\n",
      "[Epoch 43/1000] [Batch 90/168] [D loss: 0.000005] [G loss: 13.103171]\n",
      "[Epoch 43/1000] [Batch 91/168] [D loss: 0.000005] [G loss: 13.605831]\n",
      "[Epoch 43/1000] [Batch 92/168] [D loss: 0.000006] [G loss: 13.420799]\n",
      "[Epoch 43/1000] [Batch 93/168] [D loss: 0.000006] [G loss: 13.233858]\n",
      "[Epoch 43/1000] [Batch 94/168] [D loss: 0.000007] [G loss: 13.296412]\n",
      "[Epoch 43/1000] [Batch 95/168] [D loss: 0.000006] [G loss: 13.295193]\n",
      "[Epoch 43/1000] [Batch 96/168] [D loss: 0.000005] [G loss: 12.862772]\n",
      "[Epoch 43/1000] [Batch 97/168] [D loss: 0.000005] [G loss: 13.232734]\n",
      "[Epoch 43/1000] [Batch 98/168] [D loss: 0.000005] [G loss: 13.379894]\n",
      "[Epoch 43/1000] [Batch 99/168] [D loss: 0.000007] [G loss: 12.952242]\n",
      "[Epoch 43/1000] [Batch 100/168] [D loss: 0.000004] [G loss: 13.382582]\n",
      "[Epoch 43/1000] [Batch 101/168] [D loss: 0.000008] [G loss: 13.166506]\n",
      "[Epoch 43/1000] [Batch 102/168] [D loss: 0.000005] [G loss: 13.160788]\n",
      "[Epoch 43/1000] [Batch 103/168] [D loss: 0.000004] [G loss: 13.335460]\n",
      "[Epoch 43/1000] [Batch 104/168] [D loss: 0.000004] [G loss: 13.378136]\n",
      "[Epoch 43/1000] [Batch 105/168] [D loss: 0.000004] [G loss: 13.228827]\n",
      "[Epoch 43/1000] [Batch 106/168] [D loss: 0.000008] [G loss: 12.885123]\n",
      "[Epoch 43/1000] [Batch 107/168] [D loss: 0.000004] [G loss: 13.426188]\n",
      "[Epoch 43/1000] [Batch 108/168] [D loss: 0.000008] [G loss: 13.255579]\n",
      "[Epoch 43/1000] [Batch 109/168] [D loss: 0.000004] [G loss: 13.125513]\n",
      "[Epoch 43/1000] [Batch 110/168] [D loss: 0.000006] [G loss: 12.806408]\n",
      "[Epoch 43/1000] [Batch 111/168] [D loss: 0.000006] [G loss: 13.257843]\n",
      "[Epoch 43/1000] [Batch 112/168] [D loss: 0.000005] [G loss: 13.352312]\n",
      "[Epoch 43/1000] [Batch 113/168] [D loss: 0.000004] [G loss: 13.345989]\n",
      "[Epoch 43/1000] [Batch 114/168] [D loss: 0.000004] [G loss: 13.207896]\n",
      "[Epoch 43/1000] [Batch 115/168] [D loss: 0.000005] [G loss: 13.486532]\n",
      "[Epoch 43/1000] [Batch 116/168] [D loss: 0.000008] [G loss: 13.023915]\n",
      "[Epoch 43/1000] [Batch 117/168] [D loss: 0.000008] [G loss: 13.151595]\n",
      "[Epoch 43/1000] [Batch 118/168] [D loss: 0.000004] [G loss: 13.464464]\n",
      "[Epoch 43/1000] [Batch 119/168] [D loss: 0.000005] [G loss: 13.235574]\n",
      "[Epoch 43/1000] [Batch 120/168] [D loss: 0.000007] [G loss: 13.032316]\n",
      "[Epoch 43/1000] [Batch 121/168] [D loss: 0.000006] [G loss: 13.496732]\n",
      "[Epoch 43/1000] [Batch 122/168] [D loss: 0.000005] [G loss: 12.934626]\n",
      "[Epoch 43/1000] [Batch 123/168] [D loss: 0.000004] [G loss: 12.932695]\n",
      "[Epoch 43/1000] [Batch 124/168] [D loss: 0.000007] [G loss: 12.782622]\n",
      "[Epoch 43/1000] [Batch 125/168] [D loss: 0.000006] [G loss: 13.262106]\n",
      "[Epoch 43/1000] [Batch 126/168] [D loss: 0.000005] [G loss: 13.323406]\n",
      "[Epoch 43/1000] [Batch 127/168] [D loss: 0.000007] [G loss: 12.925456]\n",
      "[Epoch 43/1000] [Batch 128/168] [D loss: 0.000006] [G loss: 13.044620]\n",
      "[Epoch 43/1000] [Batch 129/168] [D loss: 0.000005] [G loss: 13.361283]\n",
      "[Epoch 43/1000] [Batch 130/168] [D loss: 0.000005] [G loss: 13.412648]\n",
      "[Epoch 43/1000] [Batch 131/168] [D loss: 0.000008] [G loss: 13.313277]\n",
      "[Epoch 43/1000] [Batch 132/168] [D loss: 0.000006] [G loss: 13.422815]\n",
      "[Epoch 43/1000] [Batch 133/168] [D loss: 0.000004] [G loss: 13.360932]\n",
      "[Epoch 43/1000] [Batch 134/168] [D loss: 0.000006] [G loss: 13.067264]\n",
      "[Epoch 43/1000] [Batch 135/168] [D loss: 0.000008] [G loss: 13.314831]\n",
      "[Epoch 43/1000] [Batch 136/168] [D loss: 0.000004] [G loss: 13.191133]\n",
      "[Epoch 43/1000] [Batch 137/168] [D loss: 0.000003] [G loss: 13.348540]\n",
      "[Epoch 43/1000] [Batch 138/168] [D loss: 0.000006] [G loss: 13.044163]\n",
      "[Epoch 43/1000] [Batch 139/168] [D loss: 0.000010] [G loss: 13.140303]\n",
      "[Epoch 43/1000] [Batch 140/168] [D loss: 0.000005] [G loss: 13.175787]\n",
      "[Epoch 43/1000] [Batch 141/168] [D loss: 0.000005] [G loss: 13.383099]\n",
      "[Epoch 43/1000] [Batch 142/168] [D loss: 0.000005] [G loss: 12.664730]\n",
      "[Epoch 43/1000] [Batch 143/168] [D loss: 0.000006] [G loss: 13.244358]\n",
      "[Epoch 43/1000] [Batch 144/168] [D loss: 0.000004] [G loss: 13.249361]\n",
      "[Epoch 43/1000] [Batch 145/168] [D loss: 0.000009] [G loss: 13.392741]\n",
      "[Epoch 43/1000] [Batch 146/168] [D loss: 0.000004] [G loss: 13.721409]\n",
      "[Epoch 43/1000] [Batch 147/168] [D loss: 0.000005] [G loss: 13.228559]\n",
      "[Epoch 43/1000] [Batch 148/168] [D loss: 0.000005] [G loss: 12.982431]\n",
      "[Epoch 43/1000] [Batch 149/168] [D loss: 0.000004] [G loss: 13.258972]\n",
      "[Epoch 43/1000] [Batch 150/168] [D loss: 0.000006] [G loss: 13.052854]\n",
      "[Epoch 43/1000] [Batch 151/168] [D loss: 0.000009] [G loss: 13.127605]\n",
      "[Epoch 43/1000] [Batch 152/168] [D loss: 0.000004] [G loss: 13.161204]\n",
      "[Epoch 43/1000] [Batch 153/168] [D loss: 0.000010] [G loss: 13.246440]\n",
      "[Epoch 43/1000] [Batch 154/168] [D loss: 0.000006] [G loss: 13.406212]\n",
      "[Epoch 43/1000] [Batch 155/168] [D loss: 0.000005] [G loss: 13.395505]\n",
      "[Epoch 43/1000] [Batch 156/168] [D loss: 0.000005] [G loss: 13.266546]\n",
      "[Epoch 43/1000] [Batch 157/168] [D loss: 0.000005] [G loss: 13.195267]\n",
      "[Epoch 43/1000] [Batch 158/168] [D loss: 0.000006] [G loss: 13.416386]\n",
      "[Epoch 43/1000] [Batch 159/168] [D loss: 0.000005] [G loss: 13.348152]\n",
      "[Epoch 43/1000] [Batch 160/168] [D loss: 0.000005] [G loss: 13.298662]\n",
      "[Epoch 43/1000] [Batch 161/168] [D loss: 0.000005] [G loss: 13.166939]\n",
      "[Epoch 43/1000] [Batch 162/168] [D loss: 0.000004] [G loss: 13.443587]\n",
      "[Epoch 43/1000] [Batch 163/168] [D loss: 0.000004] [G loss: 13.100506]\n",
      "[Epoch 43/1000] [Batch 164/168] [D loss: 0.000005] [G loss: 13.063211]\n",
      "[Epoch 43/1000] [Batch 165/168] [D loss: 0.000006] [G loss: 13.566529]\n",
      "[Epoch 43/1000] [Batch 166/168] [D loss: 0.000005] [G loss: 13.310400]\n",
      "[Epoch 43/1000] [Batch 167/168] [D loss: 0.000005] [G loss: 13.333412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/1000] [Batch 168/168] [D loss: 0.000005] [G loss: 13.234578]\n",
      "[Epoch 44/1000] [Batch 1/168] [D loss: 0.000006] [G loss: 13.195644]\n",
      "[Epoch 44/1000] [Batch 2/168] [D loss: 0.000005] [G loss: 13.058657]\n",
      "[Epoch 44/1000] [Batch 3/168] [D loss: 0.000003] [G loss: 13.579140]\n",
      "[Epoch 44/1000] [Batch 4/168] [D loss: 0.000006] [G loss: 13.023288]\n",
      "[Epoch 44/1000] [Batch 5/168] [D loss: 0.000004] [G loss: 13.568090]\n",
      "[Epoch 44/1000] [Batch 6/168] [D loss: 0.000005] [G loss: 13.540535]\n",
      "[Epoch 44/1000] [Batch 7/168] [D loss: 0.000004] [G loss: 13.331835]\n",
      "[Epoch 44/1000] [Batch 8/168] [D loss: 0.000005] [G loss: 13.369103]\n",
      "[Epoch 44/1000] [Batch 9/168] [D loss: 0.000005] [G loss: 13.129287]\n",
      "[Epoch 44/1000] [Batch 10/168] [D loss: 0.000004] [G loss: 13.578571]\n",
      "[Epoch 44/1000] [Batch 11/168] [D loss: 0.000006] [G loss: 12.818628]\n",
      "[Epoch 44/1000] [Batch 12/168] [D loss: 0.000006] [G loss: 12.960464]\n",
      "[Epoch 44/1000] [Batch 13/168] [D loss: 0.000004] [G loss: 13.417415]\n",
      "[Epoch 44/1000] [Batch 14/168] [D loss: 0.000006] [G loss: 13.179162]\n",
      "[Epoch 44/1000] [Batch 15/168] [D loss: 0.000005] [G loss: 13.493973]\n",
      "[Epoch 44/1000] [Batch 16/168] [D loss: 0.000003] [G loss: 13.500336]\n",
      "[Epoch 44/1000] [Batch 17/168] [D loss: 0.000004] [G loss: 13.135674]\n",
      "[Epoch 44/1000] [Batch 18/168] [D loss: 0.000006] [G loss: 13.543145]\n",
      "[Epoch 44/1000] [Batch 19/168] [D loss: 0.000005] [G loss: 13.418448]\n",
      "[Epoch 44/1000] [Batch 20/168] [D loss: 0.000004] [G loss: 13.274464]\n",
      "[Epoch 44/1000] [Batch 21/168] [D loss: 0.000004] [G loss: 13.333628]\n",
      "[Epoch 44/1000] [Batch 22/168] [D loss: 0.000007] [G loss: 13.216700]\n",
      "[Epoch 44/1000] [Batch 23/168] [D loss: 0.000003] [G loss: 13.280540]\n",
      "[Epoch 44/1000] [Batch 24/168] [D loss: 0.000006] [G loss: 13.350533]\n",
      "[Epoch 44/1000] [Batch 25/168] [D loss: 0.000003] [G loss: 13.547878]\n",
      "[Epoch 44/1000] [Batch 26/168] [D loss: 0.000005] [G loss: 13.241873]\n",
      "[Epoch 44/1000] [Batch 27/168] [D loss: 0.000003] [G loss: 13.287231]\n",
      "[Epoch 44/1000] [Batch 28/168] [D loss: 0.000003] [G loss: 13.458841]\n",
      "[Epoch 44/1000] [Batch 29/168] [D loss: 0.000004] [G loss: 13.419578]\n",
      "[Epoch 44/1000] [Batch 30/168] [D loss: 0.000006] [G loss: 13.518924]\n",
      "[Epoch 44/1000] [Batch 31/168] [D loss: 0.000003] [G loss: 13.065088]\n",
      "[Epoch 44/1000] [Batch 32/168] [D loss: 0.000004] [G loss: 13.528621]\n",
      "[Epoch 44/1000] [Batch 33/168] [D loss: 0.000007] [G loss: 13.482779]\n",
      "[Epoch 44/1000] [Batch 34/168] [D loss: 0.000006] [G loss: 13.864731]\n",
      "[Epoch 44/1000] [Batch 35/168] [D loss: 0.000006] [G loss: 12.853798]\n",
      "[Epoch 44/1000] [Batch 36/168] [D loss: 0.000004] [G loss: 13.511615]\n",
      "[Epoch 44/1000] [Batch 37/168] [D loss: 0.000006] [G loss: 12.969482]\n",
      "[Epoch 44/1000] [Batch 38/168] [D loss: 0.000003] [G loss: 13.481635]\n",
      "[Epoch 44/1000] [Batch 39/168] [D loss: 0.000003] [G loss: 13.351296]\n",
      "[Epoch 44/1000] [Batch 40/168] [D loss: 0.000006] [G loss: 13.443499]\n",
      "[Epoch 44/1000] [Batch 41/168] [D loss: 0.000006] [G loss: 13.385027]\n",
      "[Epoch 44/1000] [Batch 42/168] [D loss: 0.000005] [G loss: 13.093758]\n",
      "[Epoch 44/1000] [Batch 43/168] [D loss: 0.000005] [G loss: 13.626722]\n",
      "[Epoch 44/1000] [Batch 44/168] [D loss: 0.000005] [G loss: 13.270920]\n",
      "[Epoch 44/1000] [Batch 45/168] [D loss: 0.000005] [G loss: 13.131309]\n",
      "[Epoch 44/1000] [Batch 46/168] [D loss: 0.000007] [G loss: 13.111917]\n",
      "[Epoch 44/1000] [Batch 47/168] [D loss: 0.000005] [G loss: 13.193447]\n",
      "[Epoch 44/1000] [Batch 48/168] [D loss: 0.000006] [G loss: 13.366303]\n",
      "[Epoch 44/1000] [Batch 49/168] [D loss: 0.000008] [G loss: 13.383579]\n",
      "[Epoch 44/1000] [Batch 50/168] [D loss: 0.000005] [G loss: 13.065057]\n",
      "[Epoch 44/1000] [Batch 51/168] [D loss: 0.000004] [G loss: 13.669616]\n",
      "[Epoch 44/1000] [Batch 52/168] [D loss: 0.000003] [G loss: 13.529468]\n",
      "[Epoch 44/1000] [Batch 53/168] [D loss: 0.000005] [G loss: 13.528368]\n",
      "[Epoch 44/1000] [Batch 54/168] [D loss: 0.000006] [G loss: 13.097788]\n",
      "[Epoch 44/1000] [Batch 55/168] [D loss: 0.000006] [G loss: 13.406772]\n",
      "[Epoch 44/1000] [Batch 56/168] [D loss: 0.000007] [G loss: 13.017425]\n",
      "[Epoch 44/1000] [Batch 57/168] [D loss: 0.000004] [G loss: 13.170638]\n",
      "[Epoch 44/1000] [Batch 58/168] [D loss: 0.000004] [G loss: 13.346303]\n",
      "[Epoch 44/1000] [Batch 59/168] [D loss: 0.000006] [G loss: 13.299550]\n",
      "[Epoch 44/1000] [Batch 60/168] [D loss: 0.000003] [G loss: 13.362876]\n",
      "[Epoch 44/1000] [Batch 61/168] [D loss: 0.000004] [G loss: 13.565713]\n",
      "[Epoch 44/1000] [Batch 62/168] [D loss: 0.000007] [G loss: 13.292930]\n",
      "[Epoch 44/1000] [Batch 63/168] [D loss: 0.000003] [G loss: 13.703530]\n",
      "[Epoch 44/1000] [Batch 64/168] [D loss: 0.000005] [G loss: 13.648538]\n",
      "[Epoch 44/1000] [Batch 65/168] [D loss: 0.000005] [G loss: 13.759485]\n",
      "[Epoch 44/1000] [Batch 66/168] [D loss: 0.000004] [G loss: 13.271800]\n",
      "[Epoch 44/1000] [Batch 67/168] [D loss: 0.000005] [G loss: 13.471239]\n",
      "[Epoch 44/1000] [Batch 68/168] [D loss: 0.000005] [G loss: 13.135296]\n",
      "[Epoch 44/1000] [Batch 69/168] [D loss: 0.000004] [G loss: 13.366719]\n",
      "[Epoch 44/1000] [Batch 70/168] [D loss: 0.000004] [G loss: 13.337591]\n",
      "[Epoch 44/1000] [Batch 71/168] [D loss: 0.000004] [G loss: 13.193867]\n",
      "[Epoch 44/1000] [Batch 72/168] [D loss: 0.000008] [G loss: 13.532798]\n",
      "[Epoch 44/1000] [Batch 73/168] [D loss: 0.000004] [G loss: 13.624760]\n",
      "[Epoch 44/1000] [Batch 74/168] [D loss: 0.000006] [G loss: 13.501933]\n",
      "[Epoch 44/1000] [Batch 75/168] [D loss: 0.000005] [G loss: 13.641986]\n",
      "[Epoch 44/1000] [Batch 76/168] [D loss: 0.000005] [G loss: 13.299470]\n",
      "[Epoch 44/1000] [Batch 77/168] [D loss: 0.000009] [G loss: 13.327823]\n",
      "[Epoch 44/1000] [Batch 78/168] [D loss: 0.000004] [G loss: 13.296179]\n",
      "[Epoch 44/1000] [Batch 79/168] [D loss: 0.000004] [G loss: 13.538195]\n",
      "[Epoch 44/1000] [Batch 80/168] [D loss: 0.000005] [G loss: 13.823289]\n",
      "[Epoch 44/1000] [Batch 81/168] [D loss: 0.000004] [G loss: 13.365986]\n",
      "[Epoch 44/1000] [Batch 82/168] [D loss: 0.000003] [G loss: 13.377835]\n",
      "[Epoch 44/1000] [Batch 83/168] [D loss: 0.000007] [G loss: 13.068429]\n",
      "[Epoch 44/1000] [Batch 84/168] [D loss: 0.000006] [G loss: 13.493623]\n",
      "[Epoch 44/1000] [Batch 85/168] [D loss: 0.000004] [G loss: 13.446512]\n",
      "[Epoch 44/1000] [Batch 86/168] [D loss: 0.000004] [G loss: 13.182152]\n",
      "[Epoch 44/1000] [Batch 87/168] [D loss: 0.000007] [G loss: 13.341717]\n",
      "[Epoch 44/1000] [Batch 88/168] [D loss: 0.000006] [G loss: 13.154331]\n",
      "[Epoch 44/1000] [Batch 89/168] [D loss: 0.000004] [G loss: 13.589309]\n",
      "[Epoch 44/1000] [Batch 90/168] [D loss: 0.000006] [G loss: 13.618808]\n",
      "[Epoch 44/1000] [Batch 91/168] [D loss: 0.000006] [G loss: 13.183623]\n",
      "[Epoch 44/1000] [Batch 92/168] [D loss: 0.000003] [G loss: 13.438200]\n",
      "[Epoch 44/1000] [Batch 93/168] [D loss: 0.000007] [G loss: 13.244370]\n",
      "[Epoch 44/1000] [Batch 94/168] [D loss: 0.000005] [G loss: 13.193898]\n",
      "[Epoch 44/1000] [Batch 95/168] [D loss: 0.000006] [G loss: 13.476996]\n",
      "[Epoch 44/1000] [Batch 96/168] [D loss: 0.000003] [G loss: 13.374597]\n",
      "[Epoch 44/1000] [Batch 97/168] [D loss: 0.000004] [G loss: 13.567282]\n",
      "[Epoch 44/1000] [Batch 98/168] [D loss: 0.000004] [G loss: 13.411892]\n",
      "[Epoch 44/1000] [Batch 99/168] [D loss: 0.000008] [G loss: 13.194497]\n",
      "[Epoch 44/1000] [Batch 100/168] [D loss: 0.000005] [G loss: 13.223049]\n",
      "[Epoch 44/1000] [Batch 101/168] [D loss: 0.000005] [G loss: 13.444559]\n",
      "[Epoch 44/1000] [Batch 102/168] [D loss: 0.000005] [G loss: 13.028400]\n",
      "[Epoch 44/1000] [Batch 103/168] [D loss: 0.000006] [G loss: 13.543644]\n",
      "[Epoch 44/1000] [Batch 104/168] [D loss: 0.000006] [G loss: 13.050327]\n",
      "[Epoch 44/1000] [Batch 105/168] [D loss: 0.000006] [G loss: 13.873293]\n",
      "[Epoch 44/1000] [Batch 106/168] [D loss: 0.000005] [G loss: 13.086812]\n",
      "[Epoch 44/1000] [Batch 107/168] [D loss: 0.000004] [G loss: 13.266059]\n",
      "[Epoch 44/1000] [Batch 108/168] [D loss: 0.000004] [G loss: 13.621205]\n",
      "[Epoch 44/1000] [Batch 109/168] [D loss: 0.000004] [G loss: 13.153493]\n",
      "[Epoch 44/1000] [Batch 110/168] [D loss: 0.000005] [G loss: 13.439363]\n",
      "[Epoch 44/1000] [Batch 111/168] [D loss: 0.000004] [G loss: 13.328415]\n",
      "[Epoch 44/1000] [Batch 112/168] [D loss: 0.000004] [G loss: 13.228977]\n",
      "[Epoch 44/1000] [Batch 113/168] [D loss: 0.000003] [G loss: 13.534811]\n",
      "[Epoch 44/1000] [Batch 114/168] [D loss: 0.000003] [G loss: 13.518145]\n",
      "[Epoch 44/1000] [Batch 115/168] [D loss: 0.000006] [G loss: 13.530403]\n",
      "[Epoch 44/1000] [Batch 116/168] [D loss: 0.000004] [G loss: 13.543849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/1000] [Batch 117/168] [D loss: 0.000004] [G loss: 13.275285]\n",
      "[Epoch 44/1000] [Batch 118/168] [D loss: 0.000009] [G loss: 12.803897]\n",
      "[Epoch 44/1000] [Batch 119/168] [D loss: 0.000005] [G loss: 13.502335]\n",
      "[Epoch 44/1000] [Batch 120/168] [D loss: 0.000003] [G loss: 13.505038]\n",
      "[Epoch 44/1000] [Batch 121/168] [D loss: 0.000003] [G loss: 13.543287]\n",
      "[Epoch 44/1000] [Batch 122/168] [D loss: 0.000004] [G loss: 13.439061]\n",
      "[Epoch 44/1000] [Batch 123/168] [D loss: 0.000004] [G loss: 13.413388]\n",
      "[Epoch 44/1000] [Batch 124/168] [D loss: 0.000003] [G loss: 13.625240]\n",
      "[Epoch 44/1000] [Batch 125/168] [D loss: 0.000003] [G loss: 13.135724]\n",
      "[Epoch 44/1000] [Batch 126/168] [D loss: 0.000004] [G loss: 13.523484]\n",
      "[Epoch 44/1000] [Batch 127/168] [D loss: 0.000004] [G loss: 13.711255]\n",
      "[Epoch 44/1000] [Batch 128/168] [D loss: 0.000004] [G loss: 13.220388]\n",
      "[Epoch 44/1000] [Batch 129/168] [D loss: 0.000006] [G loss: 12.957761]\n",
      "[Epoch 44/1000] [Batch 130/168] [D loss: 0.000005] [G loss: 13.557362]\n",
      "[Epoch 44/1000] [Batch 131/168] [D loss: 0.000005] [G loss: 13.192750]\n",
      "[Epoch 44/1000] [Batch 132/168] [D loss: 0.000005] [G loss: 13.208775]\n",
      "[Epoch 44/1000] [Batch 133/168] [D loss: 0.000004] [G loss: 13.389178]\n",
      "[Epoch 44/1000] [Batch 134/168] [D loss: 0.000008] [G loss: 13.582584]\n",
      "[Epoch 44/1000] [Batch 135/168] [D loss: 0.000006] [G loss: 13.353972]\n",
      "[Epoch 44/1000] [Batch 136/168] [D loss: 0.000004] [G loss: 13.687959]\n",
      "[Epoch 44/1000] [Batch 137/168] [D loss: 0.000003] [G loss: 13.733482]\n",
      "[Epoch 44/1000] [Batch 138/168] [D loss: 0.000003] [G loss: 13.366630]\n",
      "[Epoch 44/1000] [Batch 139/168] [D loss: 0.000004] [G loss: 13.184220]\n",
      "[Epoch 44/1000] [Batch 140/168] [D loss: 0.000004] [G loss: 13.616509]\n",
      "[Epoch 44/1000] [Batch 141/168] [D loss: 0.000004] [G loss: 13.440925]\n",
      "[Epoch 44/1000] [Batch 142/168] [D loss: 0.000003] [G loss: 13.168364]\n",
      "[Epoch 44/1000] [Batch 143/168] [D loss: 0.000005] [G loss: 13.542012]\n",
      "[Epoch 44/1000] [Batch 144/168] [D loss: 0.000006] [G loss: 13.678918]\n",
      "[Epoch 44/1000] [Batch 145/168] [D loss: 0.000005] [G loss: 13.358428]\n",
      "[Epoch 44/1000] [Batch 146/168] [D loss: 0.000003] [G loss: 13.571168]\n",
      "[Epoch 44/1000] [Batch 147/168] [D loss: 0.000003] [G loss: 13.347672]\n",
      "[Epoch 44/1000] [Batch 148/168] [D loss: 0.000004] [G loss: 13.472637]\n",
      "[Epoch 44/1000] [Batch 149/168] [D loss: 0.000004] [G loss: 13.663214]\n",
      "[Epoch 44/1000] [Batch 150/168] [D loss: 0.000006] [G loss: 13.429097]\n",
      "[Epoch 44/1000] [Batch 151/168] [D loss: 0.000004] [G loss: 13.295925]\n",
      "[Epoch 44/1000] [Batch 152/168] [D loss: 0.000006] [G loss: 13.095671]\n",
      "[Epoch 44/1000] [Batch 153/168] [D loss: 0.000003] [G loss: 13.933658]\n",
      "[Epoch 44/1000] [Batch 154/168] [D loss: 0.000003] [G loss: 13.532253]\n",
      "[Epoch 44/1000] [Batch 155/168] [D loss: 0.000005] [G loss: 13.881863]\n",
      "[Epoch 44/1000] [Batch 156/168] [D loss: 0.000004] [G loss: 13.115584]\n",
      "[Epoch 44/1000] [Batch 157/168] [D loss: 0.000005] [G loss: 13.941599]\n",
      "[Epoch 44/1000] [Batch 158/168] [D loss: 0.000003] [G loss: 13.452015]\n",
      "[Epoch 44/1000] [Batch 159/168] [D loss: 0.000003] [G loss: 13.744791]\n",
      "[Epoch 44/1000] [Batch 160/168] [D loss: 0.000004] [G loss: 13.376007]\n",
      "[Epoch 44/1000] [Batch 161/168] [D loss: 0.000005] [G loss: 13.432350]\n",
      "[Epoch 44/1000] [Batch 162/168] [D loss: 0.000003] [G loss: 13.528094]\n",
      "[Epoch 44/1000] [Batch 163/168] [D loss: 0.000003] [G loss: 13.741231]\n",
      "[Epoch 44/1000] [Batch 164/168] [D loss: 0.000003] [G loss: 13.389759]\n",
      "[Epoch 44/1000] [Batch 165/168] [D loss: 0.000004] [G loss: 13.290119]\n",
      "[Epoch 44/1000] [Batch 166/168] [D loss: 0.000006] [G loss: 13.301509]\n",
      "[Epoch 44/1000] [Batch 167/168] [D loss: 0.000007] [G loss: 13.193313]\n",
      "[Epoch 44/1000] [Batch 168/168] [D loss: 0.000004] [G loss: 13.522193]\n",
      "[Epoch 45/1000] [Batch 1/168] [D loss: 0.000004] [G loss: 13.785141]\n",
      "[Epoch 45/1000] [Batch 2/168] [D loss: 0.000004] [G loss: 13.364800]\n",
      "[Epoch 45/1000] [Batch 3/168] [D loss: 0.000003] [G loss: 13.339893]\n",
      "[Epoch 45/1000] [Batch 4/168] [D loss: 0.000004] [G loss: 13.494238]\n",
      "[Epoch 45/1000] [Batch 5/168] [D loss: 0.000005] [G loss: 13.281554]\n",
      "[Epoch 45/1000] [Batch 6/168] [D loss: 0.000003] [G loss: 13.213571]\n",
      "[Epoch 45/1000] [Batch 7/168] [D loss: 0.000004] [G loss: 13.135782]\n",
      "[Epoch 45/1000] [Batch 8/168] [D loss: 0.000009] [G loss: 13.355784]\n",
      "[Epoch 45/1000] [Batch 9/168] [D loss: 0.000003] [G loss: 13.583959]\n",
      "[Epoch 45/1000] [Batch 10/168] [D loss: 0.000004] [G loss: 13.594954]\n",
      "[Epoch 45/1000] [Batch 11/168] [D loss: 0.000004] [G loss: 13.700690]\n",
      "[Epoch 45/1000] [Batch 12/168] [D loss: 0.000003] [G loss: 13.771616]\n",
      "[Epoch 45/1000] [Batch 13/168] [D loss: 0.000004] [G loss: 13.764035]\n",
      "[Epoch 45/1000] [Batch 14/168] [D loss: 0.000004] [G loss: 13.393264]\n",
      "[Epoch 45/1000] [Batch 15/168] [D loss: 0.000002] [G loss: 13.489473]\n",
      "[Epoch 45/1000] [Batch 16/168] [D loss: 0.000003] [G loss: 13.927193]\n",
      "[Epoch 45/1000] [Batch 17/168] [D loss: 0.000004] [G loss: 13.538550]\n",
      "[Epoch 45/1000] [Batch 18/168] [D loss: 0.000005] [G loss: 13.561491]\n",
      "[Epoch 45/1000] [Batch 19/168] [D loss: 0.000004] [G loss: 13.464334]\n",
      "[Epoch 45/1000] [Batch 20/168] [D loss: 0.000005] [G loss: 13.568902]\n",
      "[Epoch 45/1000] [Batch 21/168] [D loss: 0.000002] [G loss: 13.567518]\n",
      "[Epoch 45/1000] [Batch 22/168] [D loss: 0.000004] [G loss: 13.546598]\n",
      "[Epoch 45/1000] [Batch 23/168] [D loss: 0.000003] [G loss: 13.536908]\n",
      "[Epoch 45/1000] [Batch 24/168] [D loss: 0.000003] [G loss: 13.792064]\n",
      "[Epoch 45/1000] [Batch 25/168] [D loss: 0.000004] [G loss: 13.462308]\n",
      "[Epoch 45/1000] [Batch 26/168] [D loss: 0.000004] [G loss: 13.757082]\n",
      "[Epoch 45/1000] [Batch 27/168] [D loss: 0.000005] [G loss: 13.448934]\n",
      "[Epoch 45/1000] [Batch 28/168] [D loss: 0.000005] [G loss: 13.757431]\n",
      "[Epoch 45/1000] [Batch 29/168] [D loss: 0.000004] [G loss: 13.626076]\n",
      "[Epoch 45/1000] [Batch 30/168] [D loss: 0.000005] [G loss: 13.341413]\n",
      "[Epoch 45/1000] [Batch 31/168] [D loss: 0.000004] [G loss: 13.495295]\n",
      "[Epoch 45/1000] [Batch 32/168] [D loss: 0.000003] [G loss: 14.024729]\n",
      "[Epoch 45/1000] [Batch 33/168] [D loss: 0.000003] [G loss: 13.130322]\n",
      "[Epoch 45/1000] [Batch 34/168] [D loss: 0.000005] [G loss: 13.802610]\n",
      "[Epoch 45/1000] [Batch 35/168] [D loss: 0.000006] [G loss: 14.036435]\n",
      "[Epoch 45/1000] [Batch 36/168] [D loss: 0.000004] [G loss: 13.091659]\n",
      "[Epoch 45/1000] [Batch 37/168] [D loss: 0.000004] [G loss: 13.593184]\n",
      "[Epoch 45/1000] [Batch 38/168] [D loss: 0.000003] [G loss: 13.907757]\n",
      "[Epoch 45/1000] [Batch 39/168] [D loss: 0.000002] [G loss: 13.624702]\n",
      "[Epoch 45/1000] [Batch 40/168] [D loss: 0.000004] [G loss: 13.315550]\n",
      "[Epoch 45/1000] [Batch 41/168] [D loss: 0.000003] [G loss: 13.728512]\n",
      "[Epoch 45/1000] [Batch 42/168] [D loss: 0.000005] [G loss: 13.783243]\n",
      "[Epoch 45/1000] [Batch 43/168] [D loss: 0.000003] [G loss: 13.505301]\n",
      "[Epoch 45/1000] [Batch 44/168] [D loss: 0.000008] [G loss: 13.425230]\n",
      "[Epoch 45/1000] [Batch 45/168] [D loss: 0.000006] [G loss: 13.754982]\n",
      "[Epoch 45/1000] [Batch 46/168] [D loss: 0.000003] [G loss: 13.315379]\n",
      "[Epoch 45/1000] [Batch 47/168] [D loss: 0.000005] [G loss: 13.434603]\n",
      "[Epoch 45/1000] [Batch 48/168] [D loss: 0.000004] [G loss: 13.940386]\n",
      "[Epoch 45/1000] [Batch 49/168] [D loss: 0.000004] [G loss: 13.571323]\n",
      "[Epoch 45/1000] [Batch 50/168] [D loss: 0.000005] [G loss: 13.111130]\n",
      "[Epoch 45/1000] [Batch 51/168] [D loss: 0.000004] [G loss: 13.056214]\n",
      "[Epoch 45/1000] [Batch 52/168] [D loss: 0.000005] [G loss: 13.923164]\n",
      "[Epoch 45/1000] [Batch 53/168] [D loss: 0.000004] [G loss: 13.704812]\n",
      "[Epoch 45/1000] [Batch 54/168] [D loss: 0.000004] [G loss: 13.285384]\n",
      "[Epoch 45/1000] [Batch 55/168] [D loss: 0.000003] [G loss: 13.819497]\n",
      "[Epoch 45/1000] [Batch 56/168] [D loss: 0.000004] [G loss: 13.436305]\n",
      "[Epoch 45/1000] [Batch 57/168] [D loss: 0.000003] [G loss: 13.655829]\n",
      "[Epoch 45/1000] [Batch 58/168] [D loss: 0.000003] [G loss: 13.657255]\n",
      "[Epoch 45/1000] [Batch 59/168] [D loss: 0.000004] [G loss: 13.602966]\n",
      "[Epoch 45/1000] [Batch 60/168] [D loss: 0.000004] [G loss: 13.605965]\n",
      "[Epoch 45/1000] [Batch 61/168] [D loss: 0.000003] [G loss: 13.825705]\n",
      "[Epoch 45/1000] [Batch 62/168] [D loss: 0.000003] [G loss: 13.621553]\n",
      "[Epoch 45/1000] [Batch 63/168] [D loss: 0.000005] [G loss: 13.266366]\n",
      "[Epoch 45/1000] [Batch 64/168] [D loss: 0.000005] [G loss: 13.311951]\n",
      "[Epoch 45/1000] [Batch 65/168] [D loss: 0.000005] [G loss: 13.562537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45/1000] [Batch 66/168] [D loss: 0.000005] [G loss: 13.150483]\n",
      "[Epoch 45/1000] [Batch 67/168] [D loss: 0.000003] [G loss: 13.568946]\n",
      "[Epoch 45/1000] [Batch 68/168] [D loss: 0.000003] [G loss: 13.568598]\n",
      "[Epoch 45/1000] [Batch 69/168] [D loss: 0.000004] [G loss: 13.195445]\n",
      "[Epoch 45/1000] [Batch 70/168] [D loss: 0.000002] [G loss: 13.659364]\n",
      "[Epoch 45/1000] [Batch 71/168] [D loss: 0.000004] [G loss: 13.318092]\n",
      "[Epoch 45/1000] [Batch 72/168] [D loss: 0.000003] [G loss: 13.656894]\n",
      "[Epoch 45/1000] [Batch 73/168] [D loss: 0.000003] [G loss: 13.969803]\n",
      "[Epoch 45/1000] [Batch 74/168] [D loss: 0.000003] [G loss: 13.464764]\n",
      "[Epoch 45/1000] [Batch 75/168] [D loss: 0.000004] [G loss: 13.279617]\n",
      "[Epoch 45/1000] [Batch 76/168] [D loss: 0.000003] [G loss: 13.507061]\n",
      "[Epoch 45/1000] [Batch 77/168] [D loss: 0.000005] [G loss: 13.698226]\n",
      "[Epoch 45/1000] [Batch 78/168] [D loss: 0.000004] [G loss: 13.624746]\n",
      "[Epoch 45/1000] [Batch 79/168] [D loss: 0.000004] [G loss: 13.599546]\n",
      "[Epoch 45/1000] [Batch 80/168] [D loss: 0.000005] [G loss: 13.252813]\n",
      "[Epoch 45/1000] [Batch 81/168] [D loss: 0.000003] [G loss: 13.452874]\n",
      "[Epoch 45/1000] [Batch 82/168] [D loss: 0.000006] [G loss: 13.459326]\n",
      "[Epoch 45/1000] [Batch 83/168] [D loss: 0.000002] [G loss: 13.923142]\n",
      "[Epoch 45/1000] [Batch 84/168] [D loss: 0.000005] [G loss: 13.843049]\n",
      "[Epoch 45/1000] [Batch 85/168] [D loss: 0.000003] [G loss: 13.524662]\n",
      "[Epoch 45/1000] [Batch 86/168] [D loss: 0.000003] [G loss: 14.131574]\n",
      "[Epoch 45/1000] [Batch 87/168] [D loss: 0.000004] [G loss: 13.580290]\n",
      "[Epoch 45/1000] [Batch 88/168] [D loss: 0.000003] [G loss: 13.473186]\n",
      "[Epoch 45/1000] [Batch 89/168] [D loss: 0.000004] [G loss: 13.538825]\n",
      "[Epoch 45/1000] [Batch 90/168] [D loss: 0.000004] [G loss: 13.686844]\n",
      "[Epoch 45/1000] [Batch 91/168] [D loss: 0.000004] [G loss: 13.193186]\n",
      "[Epoch 45/1000] [Batch 92/168] [D loss: 0.000003] [G loss: 13.652294]\n",
      "[Epoch 45/1000] [Batch 93/168] [D loss: 0.000003] [G loss: 13.438774]\n",
      "[Epoch 45/1000] [Batch 94/168] [D loss: 0.000003] [G loss: 13.814687]\n",
      "[Epoch 45/1000] [Batch 95/168] [D loss: 0.000004] [G loss: 13.779748]\n",
      "[Epoch 45/1000] [Batch 96/168] [D loss: 0.000003] [G loss: 13.845670]\n",
      "[Epoch 45/1000] [Batch 97/168] [D loss: 0.000003] [G loss: 13.435615]\n",
      "[Epoch 45/1000] [Batch 98/168] [D loss: 0.000002] [G loss: 13.771420]\n",
      "[Epoch 45/1000] [Batch 99/168] [D loss: 0.000003] [G loss: 13.710720]\n",
      "[Epoch 45/1000] [Batch 100/168] [D loss: 0.000003] [G loss: 13.983984]\n",
      "[Epoch 45/1000] [Batch 101/168] [D loss: 0.000003] [G loss: 13.876962]\n",
      "[Epoch 45/1000] [Batch 102/168] [D loss: 0.000005] [G loss: 13.291938]\n",
      "[Epoch 45/1000] [Batch 103/168] [D loss: 0.000003] [G loss: 13.631844]\n",
      "[Epoch 45/1000] [Batch 104/168] [D loss: 0.000003] [G loss: 13.584558]\n",
      "[Epoch 45/1000] [Batch 105/168] [D loss: 0.000003] [G loss: 13.784920]\n",
      "[Epoch 45/1000] [Batch 106/168] [D loss: 0.000003] [G loss: 14.004527]\n",
      "[Epoch 45/1000] [Batch 107/168] [D loss: 0.000004] [G loss: 13.903404]\n",
      "[Epoch 45/1000] [Batch 108/168] [D loss: 0.000003] [G loss: 13.746108]\n",
      "[Epoch 45/1000] [Batch 109/168] [D loss: 0.000003] [G loss: 13.582230]\n",
      "[Epoch 45/1000] [Batch 110/168] [D loss: 0.000003] [G loss: 13.440188]\n",
      "[Epoch 45/1000] [Batch 111/168] [D loss: 0.000004] [G loss: 13.455050]\n",
      "[Epoch 45/1000] [Batch 112/168] [D loss: 0.000003] [G loss: 13.663569]\n",
      "[Epoch 45/1000] [Batch 113/168] [D loss: 0.000004] [G loss: 13.523682]\n",
      "[Epoch 45/1000] [Batch 114/168] [D loss: 0.000003] [G loss: 13.573621]\n",
      "[Epoch 45/1000] [Batch 115/168] [D loss: 0.000003] [G loss: 13.659069]\n",
      "[Epoch 45/1000] [Batch 116/168] [D loss: 0.000003] [G loss: 13.766463]\n",
      "[Epoch 45/1000] [Batch 117/168] [D loss: 0.000004] [G loss: 13.720342]\n",
      "[Epoch 45/1000] [Batch 118/168] [D loss: 0.000006] [G loss: 13.565536]\n",
      "[Epoch 45/1000] [Batch 119/168] [D loss: 0.000006] [G loss: 13.669756]\n",
      "[Epoch 45/1000] [Batch 120/168] [D loss: 0.000003] [G loss: 13.947845]\n",
      "[Epoch 45/1000] [Batch 121/168] [D loss: 0.000003] [G loss: 13.605901]\n",
      "[Epoch 45/1000] [Batch 122/168] [D loss: 0.000004] [G loss: 13.758796]\n",
      "[Epoch 45/1000] [Batch 123/168] [D loss: 0.000009] [G loss: 13.375104]\n",
      "[Epoch 45/1000] [Batch 124/168] [D loss: 0.000004] [G loss: 13.660523]\n",
      "[Epoch 45/1000] [Batch 125/168] [D loss: 0.000003] [G loss: 13.668371]\n",
      "[Epoch 45/1000] [Batch 126/168] [D loss: 0.000005] [G loss: 13.674390]\n",
      "[Epoch 45/1000] [Batch 127/168] [D loss: 0.000003] [G loss: 14.173022]\n",
      "[Epoch 45/1000] [Batch 128/168] [D loss: 0.000003] [G loss: 13.642134]\n",
      "[Epoch 45/1000] [Batch 129/168] [D loss: 0.000006] [G loss: 13.879916]\n",
      "[Epoch 45/1000] [Batch 130/168] [D loss: 0.000003] [G loss: 13.501739]\n",
      "[Epoch 45/1000] [Batch 131/168] [D loss: 0.000007] [G loss: 13.504707]\n",
      "[Epoch 45/1000] [Batch 132/168] [D loss: 0.000004] [G loss: 13.588640]\n",
      "[Epoch 45/1000] [Batch 133/168] [D loss: 0.000003] [G loss: 13.685339]\n",
      "[Epoch 45/1000] [Batch 134/168] [D loss: 0.000004] [G loss: 13.362617]\n",
      "[Epoch 45/1000] [Batch 135/168] [D loss: 0.000004] [G loss: 13.818279]\n",
      "[Epoch 45/1000] [Batch 136/168] [D loss: 0.000006] [G loss: 13.535769]\n",
      "[Epoch 45/1000] [Batch 137/168] [D loss: 0.000004] [G loss: 13.649083]\n",
      "[Epoch 45/1000] [Batch 138/168] [D loss: 0.000003] [G loss: 13.730534]\n",
      "[Epoch 45/1000] [Batch 139/168] [D loss: 0.000004] [G loss: 13.155702]\n",
      "[Epoch 45/1000] [Batch 140/168] [D loss: 0.000004] [G loss: 13.620741]\n",
      "[Epoch 45/1000] [Batch 141/168] [D loss: 0.000007] [G loss: 13.953344]\n",
      "[Epoch 45/1000] [Batch 142/168] [D loss: 0.000002] [G loss: 13.834419]\n",
      "[Epoch 45/1000] [Batch 143/168] [D loss: 0.000004] [G loss: 13.193179]\n",
      "[Epoch 45/1000] [Batch 144/168] [D loss: 0.000003] [G loss: 13.525259]\n",
      "[Epoch 45/1000] [Batch 145/168] [D loss: 0.000003] [G loss: 13.638676]\n",
      "[Epoch 45/1000] [Batch 146/168] [D loss: 0.000003] [G loss: 13.749136]\n",
      "[Epoch 45/1000] [Batch 147/168] [D loss: 0.000003] [G loss: 13.659446]\n",
      "[Epoch 45/1000] [Batch 148/168] [D loss: 0.000004] [G loss: 13.596054]\n",
      "[Epoch 45/1000] [Batch 149/168] [D loss: 0.000004] [G loss: 13.842554]\n",
      "[Epoch 45/1000] [Batch 150/168] [D loss: 0.000005] [G loss: 13.742735]\n",
      "[Epoch 45/1000] [Batch 151/168] [D loss: 0.000005] [G loss: 13.468225]\n",
      "[Epoch 45/1000] [Batch 152/168] [D loss: 0.000004] [G loss: 13.714375]\n",
      "[Epoch 45/1000] [Batch 153/168] [D loss: 0.000002] [G loss: 13.595597]\n",
      "[Epoch 45/1000] [Batch 154/168] [D loss: 0.000003] [G loss: 13.514022]\n",
      "[Epoch 45/1000] [Batch 155/168] [D loss: 0.000003] [G loss: 13.578922]\n",
      "[Epoch 45/1000] [Batch 156/168] [D loss: 0.000006] [G loss: 13.476135]\n",
      "[Epoch 45/1000] [Batch 157/168] [D loss: 0.000003] [G loss: 13.655602]\n",
      "[Epoch 45/1000] [Batch 158/168] [D loss: 0.000003] [G loss: 13.740130]\n",
      "[Epoch 45/1000] [Batch 159/168] [D loss: 0.000004] [G loss: 13.587717]\n",
      "[Epoch 45/1000] [Batch 160/168] [D loss: 0.000003] [G loss: 13.647968]\n",
      "[Epoch 45/1000] [Batch 161/168] [D loss: 0.000004] [G loss: 13.888215]\n",
      "[Epoch 45/1000] [Batch 162/168] [D loss: 0.000002] [G loss: 13.865628]\n",
      "[Epoch 45/1000] [Batch 163/168] [D loss: 0.000003] [G loss: 13.624998]\n",
      "[Epoch 45/1000] [Batch 164/168] [D loss: 0.000002] [G loss: 14.140259]\n",
      "[Epoch 45/1000] [Batch 165/168] [D loss: 0.000003] [G loss: 13.767367]\n",
      "[Epoch 45/1000] [Batch 166/168] [D loss: 0.000004] [G loss: 13.747030]\n",
      "[Epoch 45/1000] [Batch 167/168] [D loss: 0.000003] [G loss: 13.630226]\n",
      "[Epoch 45/1000] [Batch 168/168] [D loss: 0.000004] [G loss: 13.690372]\n",
      "[Epoch 46/1000] [Batch 1/168] [D loss: 0.000003] [G loss: 13.510086]\n",
      "[Epoch 46/1000] [Batch 2/168] [D loss: 0.000005] [G loss: 13.642529]\n",
      "[Epoch 46/1000] [Batch 3/168] [D loss: 0.000004] [G loss: 13.808582]\n",
      "[Epoch 46/1000] [Batch 4/168] [D loss: 0.000003] [G loss: 13.916334]\n",
      "[Epoch 46/1000] [Batch 5/168] [D loss: 0.000004] [G loss: 13.928863]\n",
      "[Epoch 46/1000] [Batch 6/168] [D loss: 0.000005] [G loss: 14.006272]\n",
      "[Epoch 46/1000] [Batch 7/168] [D loss: 0.000003] [G loss: 13.647976]\n",
      "[Epoch 46/1000] [Batch 8/168] [D loss: 0.000003] [G loss: 13.763567]\n",
      "[Epoch 46/1000] [Batch 9/168] [D loss: 0.000007] [G loss: 13.667969]\n",
      "[Epoch 46/1000] [Batch 10/168] [D loss: 0.000003] [G loss: 13.700954]\n",
      "[Epoch 46/1000] [Batch 11/168] [D loss: 0.000003] [G loss: 13.778391]\n",
      "[Epoch 46/1000] [Batch 12/168] [D loss: 0.000004] [G loss: 13.646375]\n",
      "[Epoch 46/1000] [Batch 13/168] [D loss: 0.000003] [G loss: 13.534460]\n",
      "[Epoch 46/1000] [Batch 14/168] [D loss: 0.000003] [G loss: 13.547681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46/1000] [Batch 15/168] [D loss: 0.000003] [G loss: 13.677511]\n",
      "[Epoch 46/1000] [Batch 16/168] [D loss: 0.000003] [G loss: 13.765826]\n",
      "[Epoch 46/1000] [Batch 17/168] [D loss: 0.000003] [G loss: 13.839895]\n",
      "[Epoch 46/1000] [Batch 18/168] [D loss: 0.000004] [G loss: 13.720105]\n",
      "[Epoch 46/1000] [Batch 19/168] [D loss: 0.000004] [G loss: 13.696962]\n",
      "[Epoch 46/1000] [Batch 20/168] [D loss: 0.000002] [G loss: 13.902764]\n",
      "[Epoch 46/1000] [Batch 21/168] [D loss: 0.000004] [G loss: 13.614762]\n",
      "[Epoch 46/1000] [Batch 22/168] [D loss: 0.000004] [G loss: 13.698174]\n",
      "[Epoch 46/1000] [Batch 23/168] [D loss: 0.000007] [G loss: 13.614027]\n",
      "[Epoch 46/1000] [Batch 24/168] [D loss: 0.000002] [G loss: 14.029978]\n",
      "[Epoch 46/1000] [Batch 25/168] [D loss: 0.000003] [G loss: 13.284481]\n",
      "[Epoch 46/1000] [Batch 26/168] [D loss: 0.000003] [G loss: 13.821029]\n",
      "[Epoch 46/1000] [Batch 27/168] [D loss: 0.000003] [G loss: 13.697580]\n",
      "[Epoch 46/1000] [Batch 28/168] [D loss: 0.000004] [G loss: 13.686769]\n",
      "[Epoch 46/1000] [Batch 29/168] [D loss: 0.000004] [G loss: 13.257570]\n",
      "[Epoch 46/1000] [Batch 30/168] [D loss: 0.000003] [G loss: 13.797490]\n",
      "[Epoch 46/1000] [Batch 31/168] [D loss: 0.000004] [G loss: 13.524775]\n",
      "[Epoch 46/1000] [Batch 32/168] [D loss: 0.000006] [G loss: 13.546477]\n",
      "[Epoch 46/1000] [Batch 33/168] [D loss: 0.000002] [G loss: 13.791342]\n",
      "[Epoch 46/1000] [Batch 34/168] [D loss: 0.000005] [G loss: 13.789657]\n",
      "[Epoch 46/1000] [Batch 35/168] [D loss: 0.000003] [G loss: 13.764940]\n",
      "[Epoch 46/1000] [Batch 36/168] [D loss: 0.000008] [G loss: 13.225583]\n",
      "[Epoch 46/1000] [Batch 37/168] [D loss: 0.000003] [G loss: 13.768674]\n",
      "[Epoch 46/1000] [Batch 38/168] [D loss: 0.000007] [G loss: 13.410800]\n",
      "[Epoch 46/1000] [Batch 39/168] [D loss: 0.000002] [G loss: 14.049335]\n",
      "[Epoch 46/1000] [Batch 40/168] [D loss: 0.000002] [G loss: 13.872579]\n",
      "[Epoch 46/1000] [Batch 41/168] [D loss: 0.000003] [G loss: 13.884519]\n",
      "[Epoch 46/1000] [Batch 42/168] [D loss: 0.000003] [G loss: 13.476513]\n",
      "[Epoch 46/1000] [Batch 43/168] [D loss: 0.000004] [G loss: 13.591824]\n",
      "[Epoch 46/1000] [Batch 44/168] [D loss: 0.000003] [G loss: 13.760768]\n",
      "[Epoch 46/1000] [Batch 45/168] [D loss: 0.000002] [G loss: 13.835901]\n",
      "[Epoch 46/1000] [Batch 46/168] [D loss: 0.000003] [G loss: 13.906866]\n",
      "[Epoch 46/1000] [Batch 47/168] [D loss: 0.000004] [G loss: 13.719948]\n",
      "[Epoch 46/1000] [Batch 48/168] [D loss: 0.000004] [G loss: 13.767146]\n",
      "[Epoch 46/1000] [Batch 49/168] [D loss: 0.000003] [G loss: 14.310806]\n",
      "[Epoch 46/1000] [Batch 50/168] [D loss: 0.000003] [G loss: 13.588273]\n",
      "[Epoch 46/1000] [Batch 51/168] [D loss: 0.000003] [G loss: 13.612089]\n",
      "[Epoch 46/1000] [Batch 52/168] [D loss: 0.000003] [G loss: 14.204167]\n",
      "[Epoch 46/1000] [Batch 53/168] [D loss: 0.000003] [G loss: 13.799080]\n",
      "[Epoch 46/1000] [Batch 54/168] [D loss: 0.000002] [G loss: 13.629251]\n",
      "[Epoch 46/1000] [Batch 55/168] [D loss: 0.000003] [G loss: 13.842052]\n",
      "[Epoch 46/1000] [Batch 56/168] [D loss: 0.000005] [G loss: 13.693706]\n",
      "[Epoch 46/1000] [Batch 57/168] [D loss: 0.000002] [G loss: 14.171009]\n",
      "[Epoch 46/1000] [Batch 58/168] [D loss: 0.000005] [G loss: 13.300605]\n",
      "[Epoch 46/1000] [Batch 59/168] [D loss: 0.000003] [G loss: 13.677979]\n",
      "[Epoch 46/1000] [Batch 60/168] [D loss: 0.000002] [G loss: 13.735078]\n",
      "[Epoch 46/1000] [Batch 61/168] [D loss: 0.000003] [G loss: 13.530495]\n",
      "[Epoch 46/1000] [Batch 62/168] [D loss: 0.000004] [G loss: 13.612705]\n",
      "[Epoch 46/1000] [Batch 63/168] [D loss: 0.000004] [G loss: 13.664845]\n",
      "[Epoch 46/1000] [Batch 64/168] [D loss: 0.000007] [G loss: 13.704031]\n",
      "[Epoch 46/1000] [Batch 65/168] [D loss: 0.000003] [G loss: 13.910016]\n",
      "[Epoch 46/1000] [Batch 66/168] [D loss: 0.000003] [G loss: 13.608986]\n",
      "[Epoch 46/1000] [Batch 67/168] [D loss: 0.000002] [G loss: 14.074280]\n",
      "[Epoch 46/1000] [Batch 68/168] [D loss: 0.000002] [G loss: 14.042190]\n",
      "[Epoch 46/1000] [Batch 69/168] [D loss: 0.000002] [G loss: 13.631169]\n",
      "[Epoch 46/1000] [Batch 70/168] [D loss: 0.000003] [G loss: 13.902567]\n",
      "[Epoch 46/1000] [Batch 71/168] [D loss: 0.000003] [G loss: 13.793482]\n",
      "[Epoch 46/1000] [Batch 72/168] [D loss: 0.000002] [G loss: 13.938699]\n",
      "[Epoch 46/1000] [Batch 73/168] [D loss: 0.000003] [G loss: 13.824051]\n",
      "[Epoch 46/1000] [Batch 74/168] [D loss: 0.000003] [G loss: 14.085421]\n",
      "[Epoch 46/1000] [Batch 75/168] [D loss: 0.000002] [G loss: 14.280426]\n",
      "[Epoch 46/1000] [Batch 76/168] [D loss: 0.000004] [G loss: 13.750839]\n",
      "[Epoch 46/1000] [Batch 77/168] [D loss: 0.000008] [G loss: 13.555140]\n",
      "[Epoch 46/1000] [Batch 78/168] [D loss: 0.000002] [G loss: 13.844298]\n",
      "[Epoch 46/1000] [Batch 79/168] [D loss: 0.000003] [G loss: 13.934330]\n",
      "[Epoch 46/1000] [Batch 80/168] [D loss: 0.000003] [G loss: 13.779428]\n",
      "[Epoch 46/1000] [Batch 81/168] [D loss: 0.000003] [G loss: 13.812089]\n",
      "[Epoch 46/1000] [Batch 82/168] [D loss: 0.000004] [G loss: 13.487568]\n",
      "[Epoch 46/1000] [Batch 83/168] [D loss: 0.000003] [G loss: 13.714178]\n",
      "[Epoch 46/1000] [Batch 84/168] [D loss: 0.000005] [G loss: 13.583757]\n",
      "[Epoch 46/1000] [Batch 85/168] [D loss: 0.000003] [G loss: 13.935905]\n",
      "[Epoch 46/1000] [Batch 86/168] [D loss: 0.000003] [G loss: 13.907610]\n",
      "[Epoch 46/1000] [Batch 87/168] [D loss: 0.000003] [G loss: 13.740854]\n",
      "[Epoch 46/1000] [Batch 88/168] [D loss: 0.000002] [G loss: 13.985999]\n",
      "[Epoch 46/1000] [Batch 89/168] [D loss: 0.000003] [G loss: 13.820947]\n",
      "[Epoch 46/1000] [Batch 90/168] [D loss: 0.000003] [G loss: 13.951412]\n",
      "[Epoch 46/1000] [Batch 91/168] [D loss: 0.000004] [G loss: 13.714634]\n",
      "[Epoch 46/1000] [Batch 92/168] [D loss: 0.000004] [G loss: 13.337051]\n",
      "[Epoch 46/1000] [Batch 93/168] [D loss: 0.000003] [G loss: 13.693369]\n",
      "[Epoch 46/1000] [Batch 94/168] [D loss: 0.000004] [G loss: 13.686221]\n",
      "[Epoch 46/1000] [Batch 95/168] [D loss: 0.000006] [G loss: 13.304985]\n",
      "[Epoch 46/1000] [Batch 96/168] [D loss: 0.000003] [G loss: 13.847379]\n",
      "[Epoch 46/1000] [Batch 97/168] [D loss: 0.000003] [G loss: 13.475576]\n",
      "[Epoch 46/1000] [Batch 98/168] [D loss: 0.000003] [G loss: 13.963580]\n",
      "[Epoch 46/1000] [Batch 99/168] [D loss: 0.000004] [G loss: 13.367134]\n",
      "[Epoch 46/1000] [Batch 100/168] [D loss: 0.000004] [G loss: 13.942319]\n",
      "[Epoch 46/1000] [Batch 101/168] [D loss: 0.000003] [G loss: 13.740312]\n",
      "[Epoch 46/1000] [Batch 102/168] [D loss: 0.000002] [G loss: 13.987164]\n",
      "[Epoch 46/1000] [Batch 103/168] [D loss: 0.000003] [G loss: 13.983867]\n",
      "[Epoch 46/1000] [Batch 104/168] [D loss: 0.000003] [G loss: 13.672752]\n",
      "[Epoch 46/1000] [Batch 105/168] [D loss: 0.000003] [G loss: 13.778906]\n",
      "[Epoch 46/1000] [Batch 106/168] [D loss: 0.000002] [G loss: 14.237148]\n",
      "[Epoch 46/1000] [Batch 107/168] [D loss: 0.000004] [G loss: 13.722143]\n",
      "[Epoch 46/1000] [Batch 108/168] [D loss: 0.000002] [G loss: 13.999472]\n",
      "[Epoch 46/1000] [Batch 109/168] [D loss: 0.000003] [G loss: 13.613094]\n",
      "[Epoch 46/1000] [Batch 110/168] [D loss: 0.000002] [G loss: 13.506607]\n",
      "[Epoch 46/1000] [Batch 111/168] [D loss: 0.000004] [G loss: 13.648618]\n",
      "[Epoch 46/1000] [Batch 112/168] [D loss: 0.000003] [G loss: 13.911251]\n",
      "[Epoch 46/1000] [Batch 113/168] [D loss: 0.000003] [G loss: 13.797404]\n",
      "[Epoch 46/1000] [Batch 114/168] [D loss: 0.000003] [G loss: 14.079062]\n",
      "[Epoch 46/1000] [Batch 115/168] [D loss: 0.000005] [G loss: 13.579260]\n",
      "[Epoch 46/1000] [Batch 116/168] [D loss: 0.000002] [G loss: 14.017181]\n",
      "[Epoch 46/1000] [Batch 117/168] [D loss: 0.000003] [G loss: 13.677761]\n",
      "[Epoch 46/1000] [Batch 118/168] [D loss: 0.000003] [G loss: 13.731565]\n",
      "[Epoch 46/1000] [Batch 119/168] [D loss: 0.000004] [G loss: 14.025684]\n",
      "[Epoch 46/1000] [Batch 120/168] [D loss: 0.000003] [G loss: 13.418660]\n",
      "[Epoch 46/1000] [Batch 121/168] [D loss: 0.000002] [G loss: 13.863802]\n",
      "[Epoch 46/1000] [Batch 122/168] [D loss: 0.000003] [G loss: 13.728260]\n",
      "[Epoch 46/1000] [Batch 123/168] [D loss: 0.000005] [G loss: 13.310597]\n",
      "[Epoch 46/1000] [Batch 124/168] [D loss: 0.000004] [G loss: 14.058935]\n",
      "[Epoch 46/1000] [Batch 125/168] [D loss: 0.000003] [G loss: 13.858394]\n",
      "[Epoch 46/1000] [Batch 126/168] [D loss: 0.000003] [G loss: 13.715014]\n",
      "[Epoch 46/1000] [Batch 127/168] [D loss: 0.000005] [G loss: 13.239940]\n",
      "[Epoch 46/1000] [Batch 128/168] [D loss: 0.000003] [G loss: 13.494856]\n",
      "[Epoch 46/1000] [Batch 129/168] [D loss: 0.000004] [G loss: 13.648968]\n",
      "[Epoch 46/1000] [Batch 130/168] [D loss: 0.000004] [G loss: 13.657719]\n",
      "[Epoch 46/1000] [Batch 131/168] [D loss: 0.000002] [G loss: 14.129545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46/1000] [Batch 132/168] [D loss: 0.000003] [G loss: 13.881242]\n",
      "[Epoch 46/1000] [Batch 133/168] [D loss: 0.000002] [G loss: 13.905369]\n",
      "[Epoch 46/1000] [Batch 134/168] [D loss: 0.000003] [G loss: 13.712445]\n",
      "[Epoch 46/1000] [Batch 135/168] [D loss: 0.000003] [G loss: 13.829493]\n",
      "[Epoch 46/1000] [Batch 136/168] [D loss: 0.000003] [G loss: 13.748468]\n",
      "[Epoch 46/1000] [Batch 137/168] [D loss: 0.000002] [G loss: 13.884336]\n",
      "[Epoch 46/1000] [Batch 138/168] [D loss: 0.000002] [G loss: 13.683131]\n",
      "[Epoch 46/1000] [Batch 139/168] [D loss: 0.000003] [G loss: 13.963493]\n",
      "[Epoch 46/1000] [Batch 140/168] [D loss: 0.000003] [G loss: 13.994663]\n",
      "[Epoch 46/1000] [Batch 141/168] [D loss: 0.000003] [G loss: 13.971423]\n",
      "[Epoch 46/1000] [Batch 142/168] [D loss: 0.000003] [G loss: 13.758397]\n",
      "[Epoch 46/1000] [Batch 143/168] [D loss: 0.000004] [G loss: 13.716180]\n",
      "[Epoch 46/1000] [Batch 144/168] [D loss: 0.000006] [G loss: 13.598530]\n",
      "[Epoch 46/1000] [Batch 145/168] [D loss: 0.000003] [G loss: 14.159495]\n",
      "[Epoch 46/1000] [Batch 146/168] [D loss: 0.000003] [G loss: 13.761916]\n",
      "[Epoch 46/1000] [Batch 147/168] [D loss: 0.000003] [G loss: 13.864335]\n",
      "[Epoch 46/1000] [Batch 148/168] [D loss: 0.000003] [G loss: 13.617811]\n",
      "[Epoch 46/1000] [Batch 149/168] [D loss: 0.000004] [G loss: 13.751841]\n",
      "[Epoch 46/1000] [Batch 150/168] [D loss: 0.000002] [G loss: 14.013353]\n",
      "[Epoch 46/1000] [Batch 151/168] [D loss: 0.000003] [G loss: 13.916113]\n",
      "[Epoch 46/1000] [Batch 152/168] [D loss: 0.000003] [G loss: 13.703178]\n",
      "[Epoch 46/1000] [Batch 153/168] [D loss: 0.000002] [G loss: 14.073082]\n",
      "[Epoch 46/1000] [Batch 154/168] [D loss: 0.000004] [G loss: 14.013672]\n",
      "[Epoch 46/1000] [Batch 155/168] [D loss: 0.000003] [G loss: 14.060572]\n",
      "[Epoch 46/1000] [Batch 156/168] [D loss: 0.000005] [G loss: 14.238575]\n",
      "[Epoch 46/1000] [Batch 157/168] [D loss: 0.000003] [G loss: 13.870736]\n",
      "[Epoch 46/1000] [Batch 158/168] [D loss: 0.000002] [G loss: 13.950357]\n",
      "[Epoch 46/1000] [Batch 159/168] [D loss: 0.000002] [G loss: 13.767462]\n",
      "[Epoch 46/1000] [Batch 160/168] [D loss: 0.000002] [G loss: 14.143954]\n",
      "[Epoch 46/1000] [Batch 161/168] [D loss: 0.000003] [G loss: 13.963589]\n",
      "[Epoch 46/1000] [Batch 162/168] [D loss: 0.000004] [G loss: 13.762941]\n",
      "[Epoch 46/1000] [Batch 163/168] [D loss: 0.000003] [G loss: 13.837568]\n",
      "[Epoch 46/1000] [Batch 164/168] [D loss: 0.000002] [G loss: 14.512867]\n",
      "[Epoch 46/1000] [Batch 165/168] [D loss: 0.000003] [G loss: 14.219344]\n",
      "[Epoch 46/1000] [Batch 166/168] [D loss: 0.000005] [G loss: 14.044742]\n",
      "[Epoch 46/1000] [Batch 167/168] [D loss: 0.000003] [G loss: 13.984123]\n",
      "[Epoch 46/1000] [Batch 168/168] [D loss: 0.000003] [G loss: 13.632245]\n",
      "[Epoch 47/1000] [Batch 1/168] [D loss: 0.000002] [G loss: 14.120825]\n",
      "[Epoch 47/1000] [Batch 2/168] [D loss: 0.000004] [G loss: 14.043628]\n",
      "[Epoch 47/1000] [Batch 3/168] [D loss: 0.000002] [G loss: 13.996502]\n",
      "[Epoch 47/1000] [Batch 4/168] [D loss: 0.000004] [G loss: 13.757512]\n",
      "[Epoch 47/1000] [Batch 5/168] [D loss: 0.000003] [G loss: 13.747363]\n",
      "[Epoch 47/1000] [Batch 6/168] [D loss: 0.000004] [G loss: 14.081903]\n",
      "[Epoch 47/1000] [Batch 7/168] [D loss: 0.000004] [G loss: 13.457017]\n",
      "[Epoch 47/1000] [Batch 8/168] [D loss: 0.000002] [G loss: 14.016221]\n",
      "[Epoch 47/1000] [Batch 9/168] [D loss: 0.000002] [G loss: 14.319713]\n",
      "[Epoch 47/1000] [Batch 10/168] [D loss: 0.000002] [G loss: 14.042310]\n",
      "[Epoch 47/1000] [Batch 11/168] [D loss: 0.000002] [G loss: 13.632481]\n",
      "[Epoch 47/1000] [Batch 12/168] [D loss: 0.000002] [G loss: 13.901580]\n",
      "[Epoch 47/1000] [Batch 13/168] [D loss: 0.000003] [G loss: 14.298374]\n",
      "[Epoch 47/1000] [Batch 14/168] [D loss: 0.000004] [G loss: 13.618228]\n",
      "[Epoch 47/1000] [Batch 15/168] [D loss: 0.000003] [G loss: 13.749785]\n",
      "[Epoch 47/1000] [Batch 16/168] [D loss: 0.000002] [G loss: 13.819767]\n",
      "[Epoch 47/1000] [Batch 17/168] [D loss: 0.000005] [G loss: 13.680952]\n",
      "[Epoch 47/1000] [Batch 18/168] [D loss: 0.000002] [G loss: 13.757546]\n",
      "[Epoch 47/1000] [Batch 19/168] [D loss: 0.000004] [G loss: 13.760172]\n",
      "[Epoch 47/1000] [Batch 20/168] [D loss: 0.000002] [G loss: 13.904432]\n",
      "[Epoch 47/1000] [Batch 21/168] [D loss: 0.000003] [G loss: 13.840716]\n",
      "[Epoch 47/1000] [Batch 22/168] [D loss: 0.000002] [G loss: 14.075094]\n",
      "[Epoch 47/1000] [Batch 23/168] [D loss: 0.000002] [G loss: 13.947595]\n",
      "[Epoch 47/1000] [Batch 24/168] [D loss: 0.000002] [G loss: 13.820454]\n",
      "[Epoch 47/1000] [Batch 25/168] [D loss: 0.000004] [G loss: 13.638993]\n",
      "[Epoch 47/1000] [Batch 26/168] [D loss: 0.000002] [G loss: 14.073912]\n",
      "[Epoch 47/1000] [Batch 27/168] [D loss: 0.000002] [G loss: 13.803135]\n",
      "[Epoch 47/1000] [Batch 28/168] [D loss: 0.000002] [G loss: 13.732279]\n",
      "[Epoch 47/1000] [Batch 29/168] [D loss: 0.000004] [G loss: 13.759211]\n",
      "[Epoch 47/1000] [Batch 30/168] [D loss: 0.000002] [G loss: 13.753230]\n",
      "[Epoch 47/1000] [Batch 31/168] [D loss: 0.000002] [G loss: 14.007936]\n",
      "[Epoch 47/1000] [Batch 32/168] [D loss: 0.000003] [G loss: 13.995374]\n",
      "[Epoch 47/1000] [Batch 33/168] [D loss: 0.000003] [G loss: 13.825242]\n",
      "[Epoch 47/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 13.959730]\n",
      "[Epoch 47/1000] [Batch 35/168] [D loss: 0.000004] [G loss: 13.734499]\n",
      "[Epoch 47/1000] [Batch 36/168] [D loss: 0.000002] [G loss: 14.148352]\n",
      "[Epoch 47/1000] [Batch 37/168] [D loss: 0.000003] [G loss: 13.835338]\n",
      "[Epoch 47/1000] [Batch 38/168] [D loss: 0.000004] [G loss: 13.954005]\n",
      "[Epoch 47/1000] [Batch 39/168] [D loss: 0.000004] [G loss: 13.832208]\n",
      "[Epoch 47/1000] [Batch 40/168] [D loss: 0.000002] [G loss: 14.255470]\n",
      "[Epoch 47/1000] [Batch 41/168] [D loss: 0.000006] [G loss: 14.144098]\n",
      "[Epoch 47/1000] [Batch 42/168] [D loss: 0.000003] [G loss: 13.711599]\n",
      "[Epoch 47/1000] [Batch 43/168] [D loss: 0.000005] [G loss: 13.918962]\n",
      "[Epoch 47/1000] [Batch 44/168] [D loss: 0.000004] [G loss: 13.807837]\n",
      "[Epoch 47/1000] [Batch 45/168] [D loss: 0.000003] [G loss: 14.069622]\n",
      "[Epoch 47/1000] [Batch 46/168] [D loss: 0.000005] [G loss: 13.600945]\n",
      "[Epoch 47/1000] [Batch 47/168] [D loss: 0.000002] [G loss: 13.891746]\n",
      "[Epoch 47/1000] [Batch 48/168] [D loss: 0.000006] [G loss: 14.107130]\n",
      "[Epoch 47/1000] [Batch 49/168] [D loss: 0.000003] [G loss: 14.052031]\n",
      "[Epoch 47/1000] [Batch 50/168] [D loss: 0.000003] [G loss: 14.105910]\n",
      "[Epoch 47/1000] [Batch 51/168] [D loss: 0.000003] [G loss: 14.133036]\n",
      "[Epoch 47/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 14.259803]\n",
      "[Epoch 47/1000] [Batch 53/168] [D loss: 0.000003] [G loss: 14.167064]\n",
      "[Epoch 47/1000] [Batch 54/168] [D loss: 0.000003] [G loss: 14.005365]\n",
      "[Epoch 47/1000] [Batch 55/168] [D loss: 0.000002] [G loss: 13.947738]\n",
      "[Epoch 47/1000] [Batch 56/168] [D loss: 0.000002] [G loss: 14.408163]\n",
      "[Epoch 47/1000] [Batch 57/168] [D loss: 0.000002] [G loss: 14.018316]\n",
      "[Epoch 47/1000] [Batch 58/168] [D loss: 0.000003] [G loss: 13.890646]\n",
      "[Epoch 47/1000] [Batch 59/168] [D loss: 0.000004] [G loss: 13.926079]\n",
      "[Epoch 47/1000] [Batch 60/168] [D loss: 0.000003] [G loss: 14.112967]\n",
      "[Epoch 47/1000] [Batch 61/168] [D loss: 0.000003] [G loss: 14.260903]\n",
      "[Epoch 47/1000] [Batch 62/168] [D loss: 0.000005] [G loss: 13.708220]\n",
      "[Epoch 47/1000] [Batch 63/168] [D loss: 0.000003] [G loss: 14.025822]\n",
      "[Epoch 47/1000] [Batch 64/168] [D loss: 0.000002] [G loss: 13.864196]\n",
      "[Epoch 47/1000] [Batch 65/168] [D loss: 0.000002] [G loss: 14.004558]\n",
      "[Epoch 47/1000] [Batch 66/168] [D loss: 0.000003] [G loss: 14.099800]\n",
      "[Epoch 47/1000] [Batch 67/168] [D loss: 0.000002] [G loss: 14.152817]\n",
      "[Epoch 47/1000] [Batch 68/168] [D loss: 0.000002] [G loss: 13.695858]\n",
      "[Epoch 47/1000] [Batch 69/168] [D loss: 0.000002] [G loss: 13.865137]\n",
      "[Epoch 47/1000] [Batch 70/168] [D loss: 0.000003] [G loss: 13.759654]\n",
      "[Epoch 47/1000] [Batch 71/168] [D loss: 0.000002] [G loss: 13.781464]\n",
      "[Epoch 47/1000] [Batch 72/168] [D loss: 0.000005] [G loss: 13.920021]\n",
      "[Epoch 47/1000] [Batch 73/168] [D loss: 0.000003] [G loss: 13.913309]\n",
      "[Epoch 47/1000] [Batch 74/168] [D loss: 0.000002] [G loss: 14.101957]\n",
      "[Epoch 47/1000] [Batch 75/168] [D loss: 0.000004] [G loss: 13.987146]\n",
      "[Epoch 47/1000] [Batch 76/168] [D loss: 0.000005] [G loss: 14.148889]\n",
      "[Epoch 47/1000] [Batch 77/168] [D loss: 0.000002] [G loss: 13.908796]\n",
      "[Epoch 47/1000] [Batch 78/168] [D loss: 0.000002] [G loss: 14.159176]\n",
      "[Epoch 47/1000] [Batch 79/168] [D loss: 0.000003] [G loss: 13.561984]\n",
      "[Epoch 47/1000] [Batch 80/168] [D loss: 0.000004] [G loss: 13.654428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47/1000] [Batch 81/168] [D loss: 0.000003] [G loss: 13.942012]\n",
      "[Epoch 47/1000] [Batch 82/168] [D loss: 0.000003] [G loss: 13.640698]\n",
      "[Epoch 47/1000] [Batch 83/168] [D loss: 0.000002] [G loss: 14.013556]\n",
      "[Epoch 47/1000] [Batch 84/168] [D loss: 0.000004] [G loss: 13.845114]\n",
      "[Epoch 47/1000] [Batch 85/168] [D loss: 0.000003] [G loss: 13.735782]\n",
      "[Epoch 47/1000] [Batch 86/168] [D loss: 0.000003] [G loss: 13.679800]\n",
      "[Epoch 47/1000] [Batch 87/168] [D loss: 0.000003] [G loss: 13.871813]\n",
      "[Epoch 47/1000] [Batch 88/168] [D loss: 0.000003] [G loss: 13.886350]\n",
      "[Epoch 47/1000] [Batch 89/168] [D loss: 0.000002] [G loss: 14.183342]\n",
      "[Epoch 47/1000] [Batch 90/168] [D loss: 0.000002] [G loss: 13.809186]\n",
      "[Epoch 47/1000] [Batch 91/168] [D loss: 0.000002] [G loss: 14.013876]\n",
      "[Epoch 47/1000] [Batch 92/168] [D loss: 0.000003] [G loss: 13.928564]\n",
      "[Epoch 47/1000] [Batch 93/168] [D loss: 0.000003] [G loss: 13.880472]\n",
      "[Epoch 47/1000] [Batch 94/168] [D loss: 0.000005] [G loss: 13.872208]\n",
      "[Epoch 47/1000] [Batch 95/168] [D loss: 0.000002] [G loss: 13.863573]\n",
      "[Epoch 47/1000] [Batch 96/168] [D loss: 0.000002] [G loss: 13.980374]\n",
      "[Epoch 47/1000] [Batch 97/168] [D loss: 0.000002] [G loss: 13.795620]\n",
      "[Epoch 47/1000] [Batch 98/168] [D loss: 0.000002] [G loss: 13.931964]\n",
      "[Epoch 47/1000] [Batch 99/168] [D loss: 0.000004] [G loss: 14.096822]\n",
      "[Epoch 47/1000] [Batch 100/168] [D loss: 0.000002] [G loss: 14.053381]\n",
      "[Epoch 47/1000] [Batch 101/168] [D loss: 0.000003] [G loss: 13.930851]\n",
      "[Epoch 47/1000] [Batch 102/168] [D loss: 0.000003] [G loss: 13.820608]\n",
      "[Epoch 47/1000] [Batch 103/168] [D loss: 0.000003] [G loss: 14.275225]\n",
      "[Epoch 47/1000] [Batch 104/168] [D loss: 0.000002] [G loss: 14.212668]\n",
      "[Epoch 47/1000] [Batch 105/168] [D loss: 0.000002] [G loss: 14.012514]\n",
      "[Epoch 47/1000] [Batch 106/168] [D loss: 0.000003] [G loss: 13.649137]\n",
      "[Epoch 47/1000] [Batch 107/168] [D loss: 0.000002] [G loss: 14.070675]\n",
      "[Epoch 47/1000] [Batch 108/168] [D loss: 0.000003] [G loss: 13.746917]\n",
      "[Epoch 47/1000] [Batch 109/168] [D loss: 0.000002] [G loss: 14.196508]\n",
      "[Epoch 47/1000] [Batch 110/168] [D loss: 0.000003] [G loss: 14.280692]\n",
      "[Epoch 47/1000] [Batch 111/168] [D loss: 0.000003] [G loss: 14.093703]\n",
      "[Epoch 47/1000] [Batch 112/168] [D loss: 0.000003] [G loss: 13.994456]\n",
      "[Epoch 47/1000] [Batch 113/168] [D loss: 0.000002] [G loss: 14.073793]\n",
      "[Epoch 47/1000] [Batch 114/168] [D loss: 0.000003] [G loss: 13.840414]\n",
      "[Epoch 47/1000] [Batch 115/168] [D loss: 0.000003] [G loss: 13.646550]\n",
      "[Epoch 47/1000] [Batch 116/168] [D loss: 0.000003] [G loss: 13.684040]\n",
      "[Epoch 47/1000] [Batch 117/168] [D loss: 0.000003] [G loss: 13.696302]\n",
      "[Epoch 47/1000] [Batch 118/168] [D loss: 0.000004] [G loss: 13.780906]\n",
      "[Epoch 47/1000] [Batch 119/168] [D loss: 0.000004] [G loss: 14.023197]\n",
      "[Epoch 47/1000] [Batch 120/168] [D loss: 0.000002] [G loss: 14.010742]\n",
      "[Epoch 47/1000] [Batch 121/168] [D loss: 0.000003] [G loss: 14.054100]\n",
      "[Epoch 47/1000] [Batch 122/168] [D loss: 0.000002] [G loss: 13.824480]\n",
      "[Epoch 47/1000] [Batch 123/168] [D loss: 0.000003] [G loss: 14.189997]\n",
      "[Epoch 47/1000] [Batch 124/168] [D loss: 0.000003] [G loss: 13.825118]\n",
      "[Epoch 47/1000] [Batch 125/168] [D loss: 0.000002] [G loss: 14.025510]\n",
      "[Epoch 47/1000] [Batch 126/168] [D loss: 0.000002] [G loss: 13.961207]\n",
      "[Epoch 47/1000] [Batch 127/168] [D loss: 0.000002] [G loss: 14.252834]\n",
      "[Epoch 47/1000] [Batch 128/168] [D loss: 0.000002] [G loss: 13.943372]\n",
      "[Epoch 47/1000] [Batch 129/168] [D loss: 0.000003] [G loss: 13.854389]\n",
      "[Epoch 47/1000] [Batch 130/168] [D loss: 0.000003] [G loss: 13.740539]\n",
      "[Epoch 47/1000] [Batch 131/168] [D loss: 0.000002] [G loss: 14.227768]\n",
      "[Epoch 47/1000] [Batch 132/168] [D loss: 0.000001] [G loss: 14.316159]\n",
      "[Epoch 47/1000] [Batch 133/168] [D loss: 0.000003] [G loss: 14.145556]\n",
      "[Epoch 47/1000] [Batch 134/168] [D loss: 0.000002] [G loss: 14.235844]\n",
      "[Epoch 47/1000] [Batch 135/168] [D loss: 0.000003] [G loss: 13.901509]\n",
      "[Epoch 47/1000] [Batch 136/168] [D loss: 0.000002] [G loss: 13.902134]\n",
      "[Epoch 47/1000] [Batch 137/168] [D loss: 0.000003] [G loss: 14.102802]\n",
      "[Epoch 47/1000] [Batch 138/168] [D loss: 0.000005] [G loss: 13.657600]\n",
      "[Epoch 47/1000] [Batch 139/168] [D loss: 0.000002] [G loss: 13.628436]\n",
      "[Epoch 47/1000] [Batch 140/168] [D loss: 0.000003] [G loss: 13.777060]\n",
      "[Epoch 47/1000] [Batch 141/168] [D loss: 0.000003] [G loss: 14.136242]\n",
      "[Epoch 47/1000] [Batch 142/168] [D loss: 0.000003] [G loss: 13.859487]\n",
      "[Epoch 47/1000] [Batch 143/168] [D loss: 0.000003] [G loss: 14.040637]\n",
      "[Epoch 47/1000] [Batch 144/168] [D loss: 0.000003] [G loss: 14.081170]\n",
      "[Epoch 47/1000] [Batch 145/168] [D loss: 0.000004] [G loss: 13.771387]\n",
      "[Epoch 47/1000] [Batch 146/168] [D loss: 0.000003] [G loss: 13.783780]\n",
      "[Epoch 47/1000] [Batch 147/168] [D loss: 0.000002] [G loss: 14.010626]\n",
      "[Epoch 47/1000] [Batch 148/168] [D loss: 0.000003] [G loss: 13.852044]\n",
      "[Epoch 47/1000] [Batch 149/168] [D loss: 0.000003] [G loss: 13.686921]\n",
      "[Epoch 47/1000] [Batch 150/168] [D loss: 0.000002] [G loss: 14.362477]\n",
      "[Epoch 47/1000] [Batch 151/168] [D loss: 0.000004] [G loss: 14.105726]\n",
      "[Epoch 47/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 14.202247]\n",
      "[Epoch 47/1000] [Batch 153/168] [D loss: 0.000002] [G loss: 14.051576]\n",
      "[Epoch 47/1000] [Batch 154/168] [D loss: 0.000003] [G loss: 14.020873]\n",
      "[Epoch 47/1000] [Batch 155/168] [D loss: 0.000002] [G loss: 14.207676]\n",
      "[Epoch 47/1000] [Batch 156/168] [D loss: 0.000002] [G loss: 13.954248]\n",
      "[Epoch 47/1000] [Batch 157/168] [D loss: 0.000003] [G loss: 13.733171]\n",
      "[Epoch 47/1000] [Batch 158/168] [D loss: 0.000002] [G loss: 13.874119]\n",
      "[Epoch 47/1000] [Batch 159/168] [D loss: 0.000002] [G loss: 14.043409]\n",
      "[Epoch 47/1000] [Batch 160/168] [D loss: 0.000003] [G loss: 14.075826]\n",
      "[Epoch 47/1000] [Batch 161/168] [D loss: 0.000002] [G loss: 14.126917]\n",
      "[Epoch 47/1000] [Batch 162/168] [D loss: 0.000005] [G loss: 13.959426]\n",
      "[Epoch 47/1000] [Batch 163/168] [D loss: 0.000002] [G loss: 14.020063]\n",
      "[Epoch 47/1000] [Batch 164/168] [D loss: 0.000002] [G loss: 13.904231]\n",
      "[Epoch 47/1000] [Batch 165/168] [D loss: 0.000002] [G loss: 13.864719]\n",
      "[Epoch 47/1000] [Batch 166/168] [D loss: 0.000002] [G loss: 14.184577]\n",
      "[Epoch 47/1000] [Batch 167/168] [D loss: 0.000002] [G loss: 14.338571]\n",
      "[Epoch 47/1000] [Batch 168/168] [D loss: 0.000003] [G loss: 14.234388]\n",
      "[Epoch 48/1000] [Batch 1/168] [D loss: 0.000002] [G loss: 13.930831]\n",
      "[Epoch 48/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 14.138565]\n",
      "[Epoch 48/1000] [Batch 3/168] [D loss: 0.000003] [G loss: 13.997850]\n",
      "[Epoch 48/1000] [Batch 4/168] [D loss: 0.000002] [G loss: 14.315496]\n",
      "[Epoch 48/1000] [Batch 5/168] [D loss: 0.000002] [G loss: 13.858903]\n",
      "[Epoch 48/1000] [Batch 6/168] [D loss: 0.000002] [G loss: 14.492414]\n",
      "[Epoch 48/1000] [Batch 7/168] [D loss: 0.000003] [G loss: 13.802844]\n",
      "[Epoch 48/1000] [Batch 8/168] [D loss: 0.000003] [G loss: 13.916603]\n",
      "[Epoch 48/1000] [Batch 9/168] [D loss: 0.000002] [G loss: 13.831177]\n",
      "[Epoch 48/1000] [Batch 10/168] [D loss: 0.000002] [G loss: 13.993488]\n",
      "[Epoch 48/1000] [Batch 11/168] [D loss: 0.000003] [G loss: 14.162192]\n",
      "[Epoch 48/1000] [Batch 12/168] [D loss: 0.000002] [G loss: 13.994435]\n",
      "[Epoch 48/1000] [Batch 13/168] [D loss: 0.000005] [G loss: 14.110096]\n",
      "[Epoch 48/1000] [Batch 14/168] [D loss: 0.000003] [G loss: 14.039244]\n",
      "[Epoch 48/1000] [Batch 15/168] [D loss: 0.000002] [G loss: 14.159252]\n",
      "[Epoch 48/1000] [Batch 16/168] [D loss: 0.000002] [G loss: 13.838052]\n",
      "[Epoch 48/1000] [Batch 17/168] [D loss: 0.000003] [G loss: 13.749419]\n",
      "[Epoch 48/1000] [Batch 18/168] [D loss: 0.000002] [G loss: 14.253983]\n",
      "[Epoch 48/1000] [Batch 19/168] [D loss: 0.000003] [G loss: 14.057719]\n",
      "[Epoch 48/1000] [Batch 20/168] [D loss: 0.000003] [G loss: 14.093843]\n",
      "[Epoch 48/1000] [Batch 21/168] [D loss: 0.000003] [G loss: 13.940538]\n",
      "[Epoch 48/1000] [Batch 22/168] [D loss: 0.000002] [G loss: 13.896267]\n",
      "[Epoch 48/1000] [Batch 23/168] [D loss: 0.000003] [G loss: 13.900418]\n",
      "[Epoch 48/1000] [Batch 24/168] [D loss: 0.000003] [G loss: 13.959273]\n",
      "[Epoch 48/1000] [Batch 25/168] [D loss: 0.000002] [G loss: 14.205159]\n",
      "[Epoch 48/1000] [Batch 26/168] [D loss: 0.000003] [G loss: 14.162033]\n",
      "[Epoch 48/1000] [Batch 27/168] [D loss: 0.000003] [G loss: 13.746331]\n",
      "[Epoch 48/1000] [Batch 28/168] [D loss: 0.000003] [G loss: 14.059892]\n",
      "[Epoch 48/1000] [Batch 29/168] [D loss: 0.000002] [G loss: 13.976224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/1000] [Batch 30/168] [D loss: 0.000002] [G loss: 14.080497]\n",
      "[Epoch 48/1000] [Batch 31/168] [D loss: 0.000003] [G loss: 13.818132]\n",
      "[Epoch 48/1000] [Batch 32/168] [D loss: 0.000003] [G loss: 14.063368]\n",
      "[Epoch 48/1000] [Batch 33/168] [D loss: 0.000003] [G loss: 14.113550]\n",
      "[Epoch 48/1000] [Batch 34/168] [D loss: 0.000003] [G loss: 14.152923]\n",
      "[Epoch 48/1000] [Batch 35/168] [D loss: 0.000002] [G loss: 13.986820]\n",
      "[Epoch 48/1000] [Batch 36/168] [D loss: 0.000002] [G loss: 14.044930]\n",
      "[Epoch 48/1000] [Batch 37/168] [D loss: 0.000003] [G loss: 14.236073]\n",
      "[Epoch 48/1000] [Batch 38/168] [D loss: 0.000002] [G loss: 14.247702]\n",
      "[Epoch 48/1000] [Batch 39/168] [D loss: 0.000002] [G loss: 14.298616]\n",
      "[Epoch 48/1000] [Batch 40/168] [D loss: 0.000003] [G loss: 14.050257]\n",
      "[Epoch 48/1000] [Batch 41/168] [D loss: 0.000004] [G loss: 13.942429]\n",
      "[Epoch 48/1000] [Batch 42/168] [D loss: 0.000003] [G loss: 13.713974]\n",
      "[Epoch 48/1000] [Batch 43/168] [D loss: 0.000002] [G loss: 14.003550]\n",
      "[Epoch 48/1000] [Batch 44/168] [D loss: 0.000002] [G loss: 14.138761]\n",
      "[Epoch 48/1000] [Batch 45/168] [D loss: 0.000003] [G loss: 13.901938]\n",
      "[Epoch 48/1000] [Batch 46/168] [D loss: 0.000003] [G loss: 14.043288]\n",
      "[Epoch 48/1000] [Batch 47/168] [D loss: 0.000002] [G loss: 13.979983]\n",
      "[Epoch 48/1000] [Batch 48/168] [D loss: 0.000002] [G loss: 14.037153]\n",
      "[Epoch 48/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 14.251781]\n",
      "[Epoch 48/1000] [Batch 50/168] [D loss: 0.000003] [G loss: 13.757751]\n",
      "[Epoch 48/1000] [Batch 51/168] [D loss: 0.000002] [G loss: 14.072821]\n",
      "[Epoch 48/1000] [Batch 52/168] [D loss: 0.000004] [G loss: 14.160921]\n",
      "[Epoch 48/1000] [Batch 53/168] [D loss: 0.000003] [G loss: 14.141850]\n",
      "[Epoch 48/1000] [Batch 54/168] [D loss: 0.000004] [G loss: 14.002554]\n",
      "[Epoch 48/1000] [Batch 55/168] [D loss: 0.000003] [G loss: 13.794257]\n",
      "[Epoch 48/1000] [Batch 56/168] [D loss: 0.000002] [G loss: 14.053265]\n",
      "[Epoch 48/1000] [Batch 57/168] [D loss: 0.000002] [G loss: 14.082556]\n",
      "[Epoch 48/1000] [Batch 58/168] [D loss: 0.000002] [G loss: 13.822357]\n",
      "[Epoch 48/1000] [Batch 59/168] [D loss: 0.000003] [G loss: 14.165613]\n",
      "[Epoch 48/1000] [Batch 60/168] [D loss: 0.000004] [G loss: 14.000380]\n",
      "[Epoch 48/1000] [Batch 61/168] [D loss: 0.000003] [G loss: 13.730913]\n",
      "[Epoch 48/1000] [Batch 62/168] [D loss: 0.000003] [G loss: 14.090125]\n",
      "[Epoch 48/1000] [Batch 63/168] [D loss: 0.000003] [G loss: 13.989357]\n",
      "[Epoch 48/1000] [Batch 64/168] [D loss: 0.000002] [G loss: 14.043424]\n",
      "[Epoch 48/1000] [Batch 65/168] [D loss: 0.000002] [G loss: 14.321156]\n",
      "[Epoch 48/1000] [Batch 66/168] [D loss: 0.000003] [G loss: 14.174742]\n",
      "[Epoch 48/1000] [Batch 67/168] [D loss: 0.000002] [G loss: 13.821880]\n",
      "[Epoch 48/1000] [Batch 68/168] [D loss: 0.000002] [G loss: 14.211196]\n",
      "[Epoch 48/1000] [Batch 69/168] [D loss: 0.000002] [G loss: 13.991780]\n",
      "[Epoch 48/1000] [Batch 70/168] [D loss: 0.000002] [G loss: 14.176492]\n",
      "[Epoch 48/1000] [Batch 71/168] [D loss: 0.000002] [G loss: 13.964769]\n",
      "[Epoch 48/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 14.181519]\n",
      "[Epoch 48/1000] [Batch 73/168] [D loss: 0.000002] [G loss: 14.013669]\n",
      "[Epoch 48/1000] [Batch 74/168] [D loss: 0.000002] [G loss: 14.241371]\n",
      "[Epoch 48/1000] [Batch 75/168] [D loss: 0.000002] [G loss: 14.053189]\n",
      "[Epoch 48/1000] [Batch 76/168] [D loss: 0.000002] [G loss: 13.821001]\n",
      "[Epoch 48/1000] [Batch 77/168] [D loss: 0.000002] [G loss: 14.119849]\n",
      "[Epoch 48/1000] [Batch 78/168] [D loss: 0.000002] [G loss: 13.969460]\n",
      "[Epoch 48/1000] [Batch 79/168] [D loss: 0.000002] [G loss: 14.057730]\n",
      "[Epoch 48/1000] [Batch 80/168] [D loss: 0.000003] [G loss: 13.949717]\n",
      "[Epoch 48/1000] [Batch 81/168] [D loss: 0.000002] [G loss: 14.286275]\n",
      "[Epoch 48/1000] [Batch 82/168] [D loss: 0.000002] [G loss: 13.715972]\n",
      "[Epoch 48/1000] [Batch 83/168] [D loss: 0.000002] [G loss: 13.917994]\n",
      "[Epoch 48/1000] [Batch 84/168] [D loss: 0.000002] [G loss: 13.807201]\n",
      "[Epoch 48/1000] [Batch 85/168] [D loss: 0.000003] [G loss: 13.982019]\n",
      "[Epoch 48/1000] [Batch 86/168] [D loss: 0.000002] [G loss: 13.770233]\n",
      "[Epoch 48/1000] [Batch 87/168] [D loss: 0.000002] [G loss: 13.925984]\n",
      "[Epoch 48/1000] [Batch 88/168] [D loss: 0.000002] [G loss: 13.542781]\n",
      "[Epoch 48/1000] [Batch 89/168] [D loss: 0.000003] [G loss: 13.940516]\n",
      "[Epoch 48/1000] [Batch 90/168] [D loss: 0.000002] [G loss: 14.193860]\n",
      "[Epoch 48/1000] [Batch 91/168] [D loss: 0.000002] [G loss: 14.333361]\n",
      "[Epoch 48/1000] [Batch 92/168] [D loss: 0.000003] [G loss: 14.208960]\n",
      "[Epoch 48/1000] [Batch 93/168] [D loss: 0.000003] [G loss: 14.079735]\n",
      "[Epoch 48/1000] [Batch 94/168] [D loss: 0.000003] [G loss: 14.387806]\n",
      "[Epoch 48/1000] [Batch 95/168] [D loss: 0.000002] [G loss: 14.052507]\n",
      "[Epoch 48/1000] [Batch 96/168] [D loss: 0.000002] [G loss: 13.987590]\n",
      "[Epoch 48/1000] [Batch 97/168] [D loss: 0.000003] [G loss: 14.020303]\n",
      "[Epoch 48/1000] [Batch 98/168] [D loss: 0.000002] [G loss: 14.220060]\n",
      "[Epoch 48/1000] [Batch 99/168] [D loss: 0.000002] [G loss: 14.026270]\n",
      "[Epoch 48/1000] [Batch 100/168] [D loss: 0.000004] [G loss: 13.830481]\n",
      "[Epoch 48/1000] [Batch 101/168] [D loss: 0.000002] [G loss: 14.024626]\n",
      "[Epoch 48/1000] [Batch 102/168] [D loss: 0.000002] [G loss: 13.775023]\n",
      "[Epoch 48/1000] [Batch 103/168] [D loss: 0.000002] [G loss: 13.980973]\n",
      "[Epoch 48/1000] [Batch 104/168] [D loss: 0.000002] [G loss: 13.974426]\n",
      "[Epoch 48/1000] [Batch 105/168] [D loss: 0.000002] [G loss: 14.106248]\n",
      "[Epoch 48/1000] [Batch 106/168] [D loss: 0.000002] [G loss: 14.144258]\n",
      "[Epoch 48/1000] [Batch 107/168] [D loss: 0.000002] [G loss: 14.422035]\n",
      "[Epoch 48/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 14.321788]\n",
      "[Epoch 48/1000] [Batch 109/168] [D loss: 0.000002] [G loss: 14.069289]\n",
      "[Epoch 48/1000] [Batch 110/168] [D loss: 0.000002] [G loss: 14.120477]\n",
      "[Epoch 48/1000] [Batch 111/168] [D loss: 0.000002] [G loss: 13.886890]\n",
      "[Epoch 48/1000] [Batch 112/168] [D loss: 0.000002] [G loss: 14.176417]\n",
      "[Epoch 48/1000] [Batch 113/168] [D loss: 0.000003] [G loss: 14.169394]\n",
      "[Epoch 48/1000] [Batch 114/168] [D loss: 0.000002] [G loss: 14.027124]\n",
      "[Epoch 48/1000] [Batch 115/168] [D loss: 0.000003] [G loss: 14.020889]\n",
      "[Epoch 48/1000] [Batch 116/168] [D loss: 0.000003] [G loss: 14.302576]\n",
      "[Epoch 48/1000] [Batch 117/168] [D loss: 0.000002] [G loss: 13.942891]\n",
      "[Epoch 48/1000] [Batch 118/168] [D loss: 0.000002] [G loss: 14.431009]\n",
      "[Epoch 48/1000] [Batch 119/168] [D loss: 0.000003] [G loss: 14.025416]\n",
      "[Epoch 48/1000] [Batch 120/168] [D loss: 0.000002] [G loss: 13.945045]\n",
      "[Epoch 48/1000] [Batch 121/168] [D loss: 0.000002] [G loss: 14.203266]\n",
      "[Epoch 48/1000] [Batch 122/168] [D loss: 0.000002] [G loss: 14.359133]\n",
      "[Epoch 48/1000] [Batch 123/168] [D loss: 0.000004] [G loss: 13.974870]\n",
      "[Epoch 48/1000] [Batch 124/168] [D loss: 0.000003] [G loss: 13.954800]\n",
      "[Epoch 48/1000] [Batch 125/168] [D loss: 0.000003] [G loss: 14.470770]\n",
      "[Epoch 48/1000] [Batch 126/168] [D loss: 0.000002] [G loss: 13.881499]\n",
      "[Epoch 48/1000] [Batch 127/168] [D loss: 0.000004] [G loss: 14.093680]\n",
      "[Epoch 48/1000] [Batch 128/168] [D loss: 0.000002] [G loss: 14.321884]\n",
      "[Epoch 48/1000] [Batch 129/168] [D loss: 0.000002] [G loss: 14.146716]\n",
      "[Epoch 48/1000] [Batch 130/168] [D loss: 0.000002] [G loss: 14.226406]\n",
      "[Epoch 48/1000] [Batch 131/168] [D loss: 0.000003] [G loss: 14.080578]\n",
      "[Epoch 48/1000] [Batch 132/168] [D loss: 0.000002] [G loss: 13.607540]\n",
      "[Epoch 48/1000] [Batch 133/168] [D loss: 0.000002] [G loss: 14.237507]\n",
      "[Epoch 48/1000] [Batch 134/168] [D loss: 0.000003] [G loss: 14.066300]\n",
      "[Epoch 48/1000] [Batch 135/168] [D loss: 0.000002] [G loss: 14.235106]\n",
      "[Epoch 48/1000] [Batch 136/168] [D loss: 0.000003] [G loss: 14.287491]\n",
      "[Epoch 48/1000] [Batch 137/168] [D loss: 0.000002] [G loss: 13.954971]\n",
      "[Epoch 48/1000] [Batch 138/168] [D loss: 0.000002] [G loss: 14.131041]\n",
      "[Epoch 48/1000] [Batch 139/168] [D loss: 0.000002] [G loss: 13.950395]\n",
      "[Epoch 48/1000] [Batch 140/168] [D loss: 0.000002] [G loss: 14.212156]\n",
      "[Epoch 48/1000] [Batch 141/168] [D loss: 0.000002] [G loss: 14.162991]\n",
      "[Epoch 48/1000] [Batch 142/168] [D loss: 0.000002] [G loss: 14.398752]\n",
      "[Epoch 48/1000] [Batch 143/168] [D loss: 0.000002] [G loss: 14.045834]\n",
      "[Epoch 48/1000] [Batch 144/168] [D loss: 0.000002] [G loss: 14.138972]\n",
      "[Epoch 48/1000] [Batch 145/168] [D loss: 0.000002] [G loss: 14.119574]\n",
      "[Epoch 48/1000] [Batch 146/168] [D loss: 0.000002] [G loss: 14.193796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/1000] [Batch 147/168] [D loss: 0.000002] [G loss: 14.204517]\n",
      "[Epoch 48/1000] [Batch 148/168] [D loss: 0.000003] [G loss: 14.379633]\n",
      "[Epoch 48/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 14.540896]\n",
      "[Epoch 48/1000] [Batch 150/168] [D loss: 0.000002] [G loss: 13.987002]\n",
      "[Epoch 48/1000] [Batch 151/168] [D loss: 0.000002] [G loss: 14.294156]\n",
      "[Epoch 48/1000] [Batch 152/168] [D loss: 0.000003] [G loss: 13.900689]\n",
      "[Epoch 48/1000] [Batch 153/168] [D loss: 0.000005] [G loss: 13.977131]\n",
      "[Epoch 48/1000] [Batch 154/168] [D loss: 0.000002] [G loss: 14.394240]\n",
      "[Epoch 48/1000] [Batch 155/168] [D loss: 0.000002] [G loss: 14.203938]\n",
      "[Epoch 48/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 14.489497]\n",
      "[Epoch 48/1000] [Batch 157/168] [D loss: 0.000002] [G loss: 14.210037]\n",
      "[Epoch 48/1000] [Batch 158/168] [D loss: 0.000002] [G loss: 14.022257]\n",
      "[Epoch 48/1000] [Batch 159/168] [D loss: 0.000005] [G loss: 13.698332]\n",
      "[Epoch 48/1000] [Batch 160/168] [D loss: 0.000002] [G loss: 14.124894]\n",
      "[Epoch 48/1000] [Batch 161/168] [D loss: 0.000003] [G loss: 14.327862]\n",
      "[Epoch 48/1000] [Batch 162/168] [D loss: 0.000003] [G loss: 14.076777]\n",
      "[Epoch 48/1000] [Batch 163/168] [D loss: 0.000003] [G loss: 14.136853]\n",
      "[Epoch 48/1000] [Batch 164/168] [D loss: 0.000003] [G loss: 14.285563]\n",
      "[Epoch 48/1000] [Batch 165/168] [D loss: 0.000003] [G loss: 13.792074]\n",
      "[Epoch 48/1000] [Batch 166/168] [D loss: 0.000002] [G loss: 14.293003]\n",
      "[Epoch 48/1000] [Batch 167/168] [D loss: 0.000003] [G loss: 14.206158]\n",
      "[Epoch 48/1000] [Batch 168/168] [D loss: 0.000002] [G loss: 14.544374]\n",
      "[Epoch 49/1000] [Batch 1/168] [D loss: 0.000003] [G loss: 14.054017]\n",
      "[Epoch 49/1000] [Batch 2/168] [D loss: 0.000003] [G loss: 14.267261]\n",
      "[Epoch 49/1000] [Batch 3/168] [D loss: 0.000002] [G loss: 14.315514]\n",
      "[Epoch 49/1000] [Batch 4/168] [D loss: 0.000003] [G loss: 14.106739]\n",
      "[Epoch 49/1000] [Batch 5/168] [D loss: 0.000002] [G loss: 14.142858]\n",
      "[Epoch 49/1000] [Batch 6/168] [D loss: 0.000003] [G loss: 14.388741]\n",
      "[Epoch 49/1000] [Batch 7/168] [D loss: 0.000002] [G loss: 14.036497]\n",
      "[Epoch 49/1000] [Batch 8/168] [D loss: 0.000002] [G loss: 14.153916]\n",
      "[Epoch 49/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 14.405756]\n",
      "[Epoch 49/1000] [Batch 10/168] [D loss: 0.000002] [G loss: 14.234534]\n",
      "[Epoch 49/1000] [Batch 11/168] [D loss: 0.000001] [G loss: 14.227709]\n",
      "[Epoch 49/1000] [Batch 12/168] [D loss: 0.000004] [G loss: 13.691792]\n",
      "[Epoch 49/1000] [Batch 13/168] [D loss: 0.000003] [G loss: 13.852084]\n",
      "[Epoch 49/1000] [Batch 14/168] [D loss: 0.000002] [G loss: 14.816384]\n",
      "[Epoch 49/1000] [Batch 15/168] [D loss: 0.000002] [G loss: 14.476495]\n",
      "[Epoch 49/1000] [Batch 16/168] [D loss: 0.000002] [G loss: 14.034364]\n",
      "[Epoch 49/1000] [Batch 17/168] [D loss: 0.000003] [G loss: 14.121937]\n",
      "[Epoch 49/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 14.386577]\n",
      "[Epoch 49/1000] [Batch 19/168] [D loss: 0.000002] [G loss: 14.107335]\n",
      "[Epoch 49/1000] [Batch 20/168] [D loss: 0.000003] [G loss: 13.924541]\n",
      "[Epoch 49/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 14.287937]\n",
      "[Epoch 49/1000] [Batch 22/168] [D loss: 0.000003] [G loss: 13.863680]\n",
      "[Epoch 49/1000] [Batch 23/168] [D loss: 0.000004] [G loss: 14.317740]\n",
      "[Epoch 49/1000] [Batch 24/168] [D loss: 0.000003] [G loss: 14.211559]\n",
      "[Epoch 49/1000] [Batch 25/168] [D loss: 0.000003] [G loss: 14.136911]\n",
      "[Epoch 49/1000] [Batch 26/168] [D loss: 0.000002] [G loss: 13.866004]\n",
      "[Epoch 49/1000] [Batch 27/168] [D loss: 0.000003] [G loss: 14.439320]\n",
      "[Epoch 49/1000] [Batch 28/168] [D loss: 0.000002] [G loss: 14.203210]\n",
      "[Epoch 49/1000] [Batch 29/168] [D loss: 0.000003] [G loss: 13.863211]\n",
      "[Epoch 49/1000] [Batch 30/168] [D loss: 0.000003] [G loss: 13.826942]\n",
      "[Epoch 49/1000] [Batch 31/168] [D loss: 0.000002] [G loss: 14.313533]\n",
      "[Epoch 49/1000] [Batch 32/168] [D loss: 0.000003] [G loss: 14.355244]\n",
      "[Epoch 49/1000] [Batch 33/168] [D loss: 0.000002] [G loss: 13.972683]\n",
      "[Epoch 49/1000] [Batch 34/168] [D loss: 0.000002] [G loss: 14.235259]\n",
      "[Epoch 49/1000] [Batch 35/168] [D loss: 0.000003] [G loss: 14.089949]\n",
      "[Epoch 49/1000] [Batch 36/168] [D loss: 0.000003] [G loss: 14.392590]\n",
      "[Epoch 49/1000] [Batch 37/168] [D loss: 0.000003] [G loss: 13.968857]\n",
      "[Epoch 49/1000] [Batch 38/168] [D loss: 0.000002] [G loss: 14.182030]\n",
      "[Epoch 49/1000] [Batch 39/168] [D loss: 0.000003] [G loss: 13.950477]\n",
      "[Epoch 49/1000] [Batch 40/168] [D loss: 0.000002] [G loss: 14.037628]\n",
      "[Epoch 49/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 14.448552]\n",
      "[Epoch 49/1000] [Batch 42/168] [D loss: 0.000002] [G loss: 14.239470]\n",
      "[Epoch 49/1000] [Batch 43/168] [D loss: 0.000003] [G loss: 14.118147]\n",
      "[Epoch 49/1000] [Batch 44/168] [D loss: 0.000002] [G loss: 14.357153]\n",
      "[Epoch 49/1000] [Batch 45/168] [D loss: 0.000002] [G loss: 14.232593]\n",
      "[Epoch 49/1000] [Batch 46/168] [D loss: 0.000003] [G loss: 14.490323]\n",
      "[Epoch 49/1000] [Batch 47/168] [D loss: 0.000002] [G loss: 14.474075]\n",
      "[Epoch 49/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 14.434484]\n",
      "[Epoch 49/1000] [Batch 49/168] [D loss: 0.000002] [G loss: 13.963892]\n",
      "[Epoch 49/1000] [Batch 50/168] [D loss: 0.000002] [G loss: 14.376305]\n",
      "[Epoch 49/1000] [Batch 51/168] [D loss: 0.000003] [G loss: 14.231128]\n",
      "[Epoch 49/1000] [Batch 52/168] [D loss: 0.000002] [G loss: 14.675104]\n",
      "[Epoch 49/1000] [Batch 53/168] [D loss: 0.000002] [G loss: 14.382266]\n",
      "[Epoch 49/1000] [Batch 54/168] [D loss: 0.000002] [G loss: 14.209537]\n",
      "[Epoch 49/1000] [Batch 55/168] [D loss: 0.000002] [G loss: 14.462086]\n",
      "[Epoch 49/1000] [Batch 56/168] [D loss: 0.000003] [G loss: 14.270400]\n",
      "[Epoch 49/1000] [Batch 57/168] [D loss: 0.000001] [G loss: 14.526896]\n",
      "[Epoch 49/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 14.119096]\n",
      "[Epoch 49/1000] [Batch 59/168] [D loss: 0.000005] [G loss: 14.314699]\n",
      "[Epoch 49/1000] [Batch 60/168] [D loss: 0.000002] [G loss: 14.334178]\n",
      "[Epoch 49/1000] [Batch 61/168] [D loss: 0.000002] [G loss: 14.010907]\n",
      "[Epoch 49/1000] [Batch 62/168] [D loss: 0.000002] [G loss: 14.747201]\n",
      "[Epoch 49/1000] [Batch 63/168] [D loss: 0.000002] [G loss: 14.110395]\n",
      "[Epoch 49/1000] [Batch 64/168] [D loss: 0.000002] [G loss: 14.217133]\n",
      "[Epoch 49/1000] [Batch 65/168] [D loss: 0.000003] [G loss: 14.286703]\n",
      "[Epoch 49/1000] [Batch 66/168] [D loss: 0.000002] [G loss: 14.435482]\n",
      "[Epoch 49/1000] [Batch 67/168] [D loss: 0.000002] [G loss: 14.424296]\n",
      "[Epoch 49/1000] [Batch 68/168] [D loss: 0.000003] [G loss: 14.017467]\n",
      "[Epoch 49/1000] [Batch 69/168] [D loss: 0.000002] [G loss: 14.333059]\n",
      "[Epoch 49/1000] [Batch 70/168] [D loss: 0.000002] [G loss: 14.047467]\n",
      "[Epoch 49/1000] [Batch 71/168] [D loss: 0.000003] [G loss: 13.631289]\n",
      "[Epoch 49/1000] [Batch 72/168] [D loss: 0.000003] [G loss: 14.306735]\n",
      "[Epoch 49/1000] [Batch 73/168] [D loss: 0.000002] [G loss: 14.277264]\n",
      "[Epoch 49/1000] [Batch 74/168] [D loss: 0.000004] [G loss: 14.504627]\n",
      "[Epoch 49/1000] [Batch 75/168] [D loss: 0.000002] [G loss: 13.976348]\n",
      "[Epoch 49/1000] [Batch 76/168] [D loss: 0.000002] [G loss: 14.134232]\n",
      "[Epoch 49/1000] [Batch 77/168] [D loss: 0.000002] [G loss: 14.294270]\n",
      "[Epoch 49/1000] [Batch 78/168] [D loss: 0.000003] [G loss: 13.891805]\n",
      "[Epoch 49/1000] [Batch 79/168] [D loss: 0.000002] [G loss: 14.065947]\n",
      "[Epoch 49/1000] [Batch 80/168] [D loss: 0.000004] [G loss: 14.150887]\n",
      "[Epoch 49/1000] [Batch 81/168] [D loss: 0.000003] [G loss: 13.905331]\n",
      "[Epoch 49/1000] [Batch 82/168] [D loss: 0.000002] [G loss: 14.381733]\n",
      "[Epoch 49/1000] [Batch 83/168] [D loss: 0.000002] [G loss: 14.163242]\n",
      "[Epoch 49/1000] [Batch 84/168] [D loss: 0.000002] [G loss: 14.227462]\n",
      "[Epoch 49/1000] [Batch 85/168] [D loss: 0.000004] [G loss: 14.144499]\n",
      "[Epoch 49/1000] [Batch 86/168] [D loss: 0.000002] [G loss: 14.272771]\n",
      "[Epoch 49/1000] [Batch 87/168] [D loss: 0.000002] [G loss: 14.001122]\n",
      "[Epoch 49/1000] [Batch 88/168] [D loss: 0.000012] [G loss: 14.310212]\n",
      "[Epoch 49/1000] [Batch 89/168] [D loss: 0.000002] [G loss: 14.216817]\n",
      "[Epoch 49/1000] [Batch 90/168] [D loss: 0.000002] [G loss: 14.311199]\n",
      "[Epoch 49/1000] [Batch 91/168] [D loss: 0.000003] [G loss: 13.924982]\n",
      "[Epoch 49/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 14.364258]\n",
      "[Epoch 49/1000] [Batch 93/168] [D loss: 0.000003] [G loss: 14.142109]\n",
      "[Epoch 49/1000] [Batch 94/168] [D loss: 0.000003] [G loss: 14.278081]\n",
      "[Epoch 49/1000] [Batch 95/168] [D loss: 0.000002] [G loss: 14.350906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/1000] [Batch 96/168] [D loss: 0.000002] [G loss: 14.447822]\n",
      "[Epoch 49/1000] [Batch 97/168] [D loss: 0.000002] [G loss: 14.172988]\n",
      "[Epoch 49/1000] [Batch 98/168] [D loss: 0.000002] [G loss: 14.365577]\n",
      "[Epoch 49/1000] [Batch 99/168] [D loss: 0.000002] [G loss: 14.152792]\n",
      "[Epoch 49/1000] [Batch 100/168] [D loss: 0.000003] [G loss: 14.479614]\n",
      "[Epoch 49/1000] [Batch 101/168] [D loss: 0.000002] [G loss: 14.348669]\n",
      "[Epoch 49/1000] [Batch 102/168] [D loss: 0.000002] [G loss: 14.268816]\n",
      "[Epoch 49/1000] [Batch 103/168] [D loss: 0.000002] [G loss: 14.147945]\n",
      "[Epoch 49/1000] [Batch 104/168] [D loss: 0.000003] [G loss: 14.113495]\n",
      "[Epoch 49/1000] [Batch 105/168] [D loss: 0.000004] [G loss: 14.109334]\n",
      "[Epoch 49/1000] [Batch 106/168] [D loss: 0.000001] [G loss: 14.302232]\n",
      "[Epoch 49/1000] [Batch 107/168] [D loss: 0.000002] [G loss: 14.408939]\n",
      "[Epoch 49/1000] [Batch 108/168] [D loss: 0.000002] [G loss: 13.843557]\n",
      "[Epoch 49/1000] [Batch 109/168] [D loss: 0.000003] [G loss: 14.012040]\n",
      "[Epoch 49/1000] [Batch 110/168] [D loss: 0.000002] [G loss: 14.341749]\n",
      "[Epoch 49/1000] [Batch 111/168] [D loss: 0.000003] [G loss: 14.027106]\n",
      "[Epoch 49/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 14.040489]\n",
      "[Epoch 49/1000] [Batch 113/168] [D loss: 0.000002] [G loss: 14.576752]\n",
      "[Epoch 49/1000] [Batch 114/168] [D loss: 0.000002] [G loss: 14.380716]\n",
      "[Epoch 49/1000] [Batch 115/168] [D loss: 0.000003] [G loss: 13.929823]\n",
      "[Epoch 49/1000] [Batch 116/168] [D loss: 0.000002] [G loss: 14.332438]\n",
      "[Epoch 49/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 14.569646]\n",
      "[Epoch 49/1000] [Batch 118/168] [D loss: 0.000002] [G loss: 14.405362]\n",
      "[Epoch 49/1000] [Batch 119/168] [D loss: 0.000003] [G loss: 13.803673]\n",
      "[Epoch 49/1000] [Batch 120/168] [D loss: 0.000002] [G loss: 14.393121]\n",
      "[Epoch 49/1000] [Batch 121/168] [D loss: 0.000003] [G loss: 14.015674]\n",
      "[Epoch 49/1000] [Batch 122/168] [D loss: 0.000002] [G loss: 14.290775]\n",
      "[Epoch 49/1000] [Batch 123/168] [D loss: 0.000002] [G loss: 14.489470]\n",
      "[Epoch 49/1000] [Batch 124/168] [D loss: 0.000002] [G loss: 14.380068]\n",
      "[Epoch 49/1000] [Batch 125/168] [D loss: 0.000002] [G loss: 14.197317]\n",
      "[Epoch 49/1000] [Batch 126/168] [D loss: 0.000003] [G loss: 14.187894]\n",
      "[Epoch 49/1000] [Batch 127/168] [D loss: 0.000002] [G loss: 14.174498]\n",
      "[Epoch 49/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 14.109667]\n",
      "[Epoch 49/1000] [Batch 129/168] [D loss: 0.000002] [G loss: 14.670913]\n",
      "[Epoch 49/1000] [Batch 130/168] [D loss: 0.000002] [G loss: 14.002622]\n",
      "[Epoch 49/1000] [Batch 131/168] [D loss: 0.000003] [G loss: 13.982411]\n",
      "[Epoch 49/1000] [Batch 132/168] [D loss: 0.000001] [G loss: 14.354423]\n",
      "[Epoch 49/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 14.449870]\n",
      "[Epoch 49/1000] [Batch 134/168] [D loss: 0.000002] [G loss: 14.424341]\n",
      "[Epoch 49/1000] [Batch 135/168] [D loss: 0.000002] [G loss: 14.475221]\n",
      "[Epoch 49/1000] [Batch 136/168] [D loss: 0.000002] [G loss: 14.494462]\n",
      "[Epoch 49/1000] [Batch 137/168] [D loss: 0.000002] [G loss: 14.029331]\n",
      "[Epoch 49/1000] [Batch 138/168] [D loss: 0.000002] [G loss: 14.587909]\n",
      "[Epoch 49/1000] [Batch 139/168] [D loss: 0.000002] [G loss: 13.954821]\n",
      "[Epoch 49/1000] [Batch 140/168] [D loss: 0.000002] [G loss: 14.108652]\n",
      "[Epoch 49/1000] [Batch 141/168] [D loss: 0.000002] [G loss: 14.102150]\n",
      "[Epoch 49/1000] [Batch 142/168] [D loss: 0.000002] [G loss: 14.293365]\n",
      "[Epoch 49/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 14.644399]\n",
      "[Epoch 49/1000] [Batch 144/168] [D loss: 0.000003] [G loss: 13.981197]\n",
      "[Epoch 49/1000] [Batch 145/168] [D loss: 0.000002] [G loss: 14.241831]\n",
      "[Epoch 49/1000] [Batch 146/168] [D loss: 0.000002] [G loss: 14.210421]\n",
      "[Epoch 49/1000] [Batch 147/168] [D loss: 0.000001] [G loss: 14.519377]\n",
      "[Epoch 49/1000] [Batch 148/168] [D loss: 0.000002] [G loss: 14.179403]\n",
      "[Epoch 49/1000] [Batch 149/168] [D loss: 0.000002] [G loss: 14.414387]\n",
      "[Epoch 49/1000] [Batch 150/168] [D loss: 0.000002] [G loss: 14.460648]\n",
      "[Epoch 49/1000] [Batch 151/168] [D loss: 0.000002] [G loss: 13.899315]\n",
      "[Epoch 49/1000] [Batch 152/168] [D loss: 0.000002] [G loss: 14.491876]\n",
      "[Epoch 49/1000] [Batch 153/168] [D loss: 0.000002] [G loss: 14.172989]\n",
      "[Epoch 49/1000] [Batch 154/168] [D loss: 0.000002] [G loss: 14.135019]\n",
      "[Epoch 49/1000] [Batch 155/168] [D loss: 0.000001] [G loss: 14.445958]\n",
      "[Epoch 49/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 14.128871]\n",
      "[Epoch 49/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 14.524123]\n",
      "[Epoch 49/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 14.780300]\n",
      "[Epoch 49/1000] [Batch 159/168] [D loss: 0.000002] [G loss: 14.272465]\n",
      "[Epoch 49/1000] [Batch 160/168] [D loss: 0.000002] [G loss: 14.499212]\n",
      "[Epoch 49/1000] [Batch 161/168] [D loss: 0.000002] [G loss: 14.331127]\n",
      "[Epoch 49/1000] [Batch 162/168] [D loss: 0.000002] [G loss: 14.413681]\n",
      "[Epoch 49/1000] [Batch 163/168] [D loss: 0.000002] [G loss: 14.318110]\n",
      "[Epoch 49/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 14.380354]\n",
      "[Epoch 49/1000] [Batch 165/168] [D loss: 0.000002] [G loss: 14.084843]\n",
      "[Epoch 49/1000] [Batch 166/168] [D loss: 0.000002] [G loss: 14.434216]\n",
      "[Epoch 49/1000] [Batch 167/168] [D loss: 0.000002] [G loss: 14.289726]\n",
      "[Epoch 49/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 14.735173]\n",
      "[Epoch 50/1000] [Batch 1/168] [D loss: 0.000003] [G loss: 14.054548]\n",
      "[Epoch 50/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 14.524441]\n",
      "[Epoch 50/1000] [Batch 3/168] [D loss: 0.000002] [G loss: 14.400685]\n",
      "[Epoch 50/1000] [Batch 4/168] [D loss: 0.000003] [G loss: 14.537977]\n",
      "[Epoch 50/1000] [Batch 5/168] [D loss: 0.000003] [G loss: 14.319415]\n",
      "[Epoch 50/1000] [Batch 6/168] [D loss: 0.000002] [G loss: 14.224813]\n",
      "[Epoch 50/1000] [Batch 7/168] [D loss: 0.000002] [G loss: 14.192065]\n",
      "[Epoch 50/1000] [Batch 8/168] [D loss: 0.000002] [G loss: 14.323680]\n",
      "[Epoch 50/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 14.545042]\n",
      "[Epoch 50/1000] [Batch 10/168] [D loss: 0.000002] [G loss: 14.227205]\n",
      "[Epoch 50/1000] [Batch 11/168] [D loss: 0.000002] [G loss: 14.215076]\n",
      "[Epoch 50/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 14.143181]\n",
      "[Epoch 50/1000] [Batch 13/168] [D loss: 0.000002] [G loss: 14.509081]\n",
      "[Epoch 50/1000] [Batch 14/168] [D loss: 0.000003] [G loss: 14.734862]\n",
      "[Epoch 50/1000] [Batch 15/168] [D loss: 0.000002] [G loss: 14.303791]\n",
      "[Epoch 50/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 14.376990]\n",
      "[Epoch 50/1000] [Batch 17/168] [D loss: 0.000002] [G loss: 14.369845]\n",
      "[Epoch 50/1000] [Batch 18/168] [D loss: 0.000002] [G loss: 14.228403]\n",
      "[Epoch 50/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 14.685439]\n",
      "[Epoch 50/1000] [Batch 20/168] [D loss: 0.000001] [G loss: 14.281844]\n",
      "[Epoch 50/1000] [Batch 21/168] [D loss: 0.000002] [G loss: 14.048299]\n",
      "[Epoch 50/1000] [Batch 22/168] [D loss: 0.000002] [G loss: 14.629432]\n",
      "[Epoch 50/1000] [Batch 23/168] [D loss: 0.000002] [G loss: 14.275359]\n",
      "[Epoch 50/1000] [Batch 24/168] [D loss: 0.000005] [G loss: 14.556583]\n",
      "[Epoch 50/1000] [Batch 25/168] [D loss: 0.000003] [G loss: 14.077309]\n",
      "[Epoch 50/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 14.262199]\n",
      "[Epoch 50/1000] [Batch 27/168] [D loss: 0.000003] [G loss: 14.354564]\n",
      "[Epoch 50/1000] [Batch 28/168] [D loss: 0.000002] [G loss: 14.561900]\n",
      "[Epoch 50/1000] [Batch 29/168] [D loss: 0.000002] [G loss: 14.293886]\n",
      "[Epoch 50/1000] [Batch 30/168] [D loss: 0.000003] [G loss: 14.157290]\n",
      "[Epoch 50/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 14.398803]\n",
      "[Epoch 50/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 14.866980]\n",
      "[Epoch 50/1000] [Batch 33/168] [D loss: 0.000002] [G loss: 14.392713]\n",
      "[Epoch 50/1000] [Batch 34/168] [D loss: 0.000002] [G loss: 14.297605]\n",
      "[Epoch 50/1000] [Batch 35/168] [D loss: 0.000002] [G loss: 14.560798]\n",
      "[Epoch 50/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 14.514614]\n",
      "[Epoch 50/1000] [Batch 37/168] [D loss: 0.000002] [G loss: 14.174734]\n",
      "[Epoch 50/1000] [Batch 38/168] [D loss: 0.000002] [G loss: 14.322941]\n",
      "[Epoch 50/1000] [Batch 39/168] [D loss: 0.000002] [G loss: 14.156324]\n",
      "[Epoch 50/1000] [Batch 40/168] [D loss: 0.000002] [G loss: 14.449036]\n",
      "[Epoch 50/1000] [Batch 41/168] [D loss: 0.000002] [G loss: 14.549374]\n",
      "[Epoch 50/1000] [Batch 42/168] [D loss: 0.000002] [G loss: 14.160106]\n",
      "[Epoch 50/1000] [Batch 43/168] [D loss: 0.000002] [G loss: 14.528256]\n",
      "[Epoch 50/1000] [Batch 44/168] [D loss: 0.000002] [G loss: 14.348165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 14.569060]\n",
      "[Epoch 50/1000] [Batch 46/168] [D loss: 0.000003] [G loss: 14.597171]\n",
      "[Epoch 50/1000] [Batch 47/168] [D loss: 0.000002] [G loss: 14.405336]\n",
      "[Epoch 50/1000] [Batch 48/168] [D loss: 0.000002] [G loss: 14.342607]\n",
      "[Epoch 50/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 14.455973]\n",
      "[Epoch 50/1000] [Batch 50/168] [D loss: 0.000002] [G loss: 14.339594]\n",
      "[Epoch 50/1000] [Batch 51/168] [D loss: 0.000002] [G loss: 14.376980]\n",
      "[Epoch 50/1000] [Batch 52/168] [D loss: 0.000002] [G loss: 14.489260]\n",
      "[Epoch 50/1000] [Batch 53/168] [D loss: 0.000003] [G loss: 13.779107]\n",
      "[Epoch 50/1000] [Batch 54/168] [D loss: 0.000002] [G loss: 14.438894]\n",
      "[Epoch 50/1000] [Batch 55/168] [D loss: 0.000003] [G loss: 14.088200]\n",
      "[Epoch 50/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 14.506807]\n",
      "[Epoch 50/1000] [Batch 57/168] [D loss: 0.000003] [G loss: 14.524068]\n",
      "[Epoch 50/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 14.462371]\n",
      "[Epoch 50/1000] [Batch 59/168] [D loss: 0.000002] [G loss: 14.755934]\n",
      "[Epoch 50/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 14.333772]\n",
      "[Epoch 50/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 14.466613]\n",
      "[Epoch 50/1000] [Batch 62/168] [D loss: 0.000002] [G loss: 14.347057]\n",
      "[Epoch 50/1000] [Batch 63/168] [D loss: 0.000002] [G loss: 14.342381]\n",
      "[Epoch 50/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 13.957998]\n",
      "[Epoch 50/1000] [Batch 65/168] [D loss: 0.000002] [G loss: 14.417224]\n",
      "[Epoch 50/1000] [Batch 66/168] [D loss: 0.000002] [G loss: 14.596041]\n",
      "[Epoch 50/1000] [Batch 67/168] [D loss: 0.000002] [G loss: 14.356699]\n",
      "[Epoch 50/1000] [Batch 68/168] [D loss: 0.000002] [G loss: 14.384732]\n",
      "[Epoch 50/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 14.129276]\n",
      "[Epoch 50/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 14.338617]\n",
      "[Epoch 50/1000] [Batch 71/168] [D loss: 0.000002] [G loss: 14.499844]\n",
      "[Epoch 50/1000] [Batch 72/168] [D loss: 0.000002] [G loss: 14.562838]\n",
      "[Epoch 50/1000] [Batch 73/168] [D loss: 0.000002] [G loss: 14.406508]\n",
      "[Epoch 50/1000] [Batch 74/168] [D loss: 0.000002] [G loss: 14.376611]\n",
      "[Epoch 50/1000] [Batch 75/168] [D loss: 0.000002] [G loss: 14.407688]\n",
      "[Epoch 50/1000] [Batch 76/168] [D loss: 0.000003] [G loss: 13.917190]\n",
      "[Epoch 50/1000] [Batch 77/168] [D loss: 0.000002] [G loss: 13.908394]\n",
      "[Epoch 50/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 14.771213]\n",
      "[Epoch 50/1000] [Batch 79/168] [D loss: 0.000003] [G loss: 14.352987]\n",
      "[Epoch 50/1000] [Batch 80/168] [D loss: 0.000002] [G loss: 14.328419]\n",
      "[Epoch 50/1000] [Batch 81/168] [D loss: 0.000002] [G loss: 14.372066]\n",
      "[Epoch 50/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 14.060436]\n",
      "[Epoch 50/1000] [Batch 83/168] [D loss: 0.000002] [G loss: 14.196705]\n",
      "[Epoch 50/1000] [Batch 84/168] [D loss: 0.000002] [G loss: 14.438135]\n",
      "[Epoch 50/1000] [Batch 85/168] [D loss: 0.000002] [G loss: 14.197913]\n",
      "[Epoch 50/1000] [Batch 86/168] [D loss: 0.000003] [G loss: 14.552526]\n",
      "[Epoch 50/1000] [Batch 87/168] [D loss: 0.000004] [G loss: 13.930285]\n",
      "[Epoch 50/1000] [Batch 88/168] [D loss: 0.000002] [G loss: 14.203189]\n",
      "[Epoch 50/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 14.504846]\n",
      "[Epoch 50/1000] [Batch 90/168] [D loss: 0.000002] [G loss: 14.697957]\n",
      "[Epoch 50/1000] [Batch 91/168] [D loss: 0.000002] [G loss: 14.372943]\n",
      "[Epoch 50/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 14.410623]\n",
      "[Epoch 50/1000] [Batch 93/168] [D loss: 0.000002] [G loss: 14.413997]\n",
      "[Epoch 50/1000] [Batch 94/168] [D loss: 0.000002] [G loss: 14.402176]\n",
      "[Epoch 50/1000] [Batch 95/168] [D loss: 0.000002] [G loss: 14.213451]\n",
      "[Epoch 50/1000] [Batch 96/168] [D loss: 0.000003] [G loss: 14.714444]\n",
      "[Epoch 50/1000] [Batch 97/168] [D loss: 0.000002] [G loss: 14.223546]\n",
      "[Epoch 50/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 14.691867]\n",
      "[Epoch 50/1000] [Batch 99/168] [D loss: 0.000002] [G loss: 14.503606]\n",
      "[Epoch 50/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 14.900036]\n",
      "[Epoch 50/1000] [Batch 101/168] [D loss: 0.000002] [G loss: 14.283182]\n",
      "[Epoch 50/1000] [Batch 102/168] [D loss: 0.000003] [G loss: 14.178792]\n",
      "[Epoch 50/1000] [Batch 103/168] [D loss: 0.000001] [G loss: 14.378616]\n",
      "[Epoch 50/1000] [Batch 104/168] [D loss: 0.000001] [G loss: 14.489473]\n",
      "[Epoch 50/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 14.633883]\n",
      "[Epoch 50/1000] [Batch 106/168] [D loss: 0.000002] [G loss: 14.401593]\n",
      "[Epoch 50/1000] [Batch 107/168] [D loss: 0.000002] [G loss: 14.027418]\n",
      "[Epoch 50/1000] [Batch 108/168] [D loss: 0.000003] [G loss: 14.784229]\n",
      "[Epoch 50/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 14.552891]\n",
      "[Epoch 50/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 14.176961]\n",
      "[Epoch 50/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 14.366469]\n",
      "[Epoch 50/1000] [Batch 112/168] [D loss: 0.000002] [G loss: 14.322099]\n",
      "[Epoch 50/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 14.327122]\n",
      "[Epoch 50/1000] [Batch 114/168] [D loss: 0.000003] [G loss: 14.299744]\n",
      "[Epoch 50/1000] [Batch 115/168] [D loss: 0.000002] [G loss: 14.411652]\n",
      "[Epoch 50/1000] [Batch 116/168] [D loss: 0.000002] [G loss: 14.501195]\n",
      "[Epoch 50/1000] [Batch 117/168] [D loss: 0.000002] [G loss: 14.357774]\n",
      "[Epoch 50/1000] [Batch 118/168] [D loss: 0.000002] [G loss: 14.410965]\n",
      "[Epoch 50/1000] [Batch 119/168] [D loss: 0.000003] [G loss: 14.207639]\n",
      "[Epoch 50/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 14.530793]\n",
      "[Epoch 50/1000] [Batch 121/168] [D loss: 0.000002] [G loss: 13.865044]\n",
      "[Epoch 50/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 14.389606]\n",
      "[Epoch 50/1000] [Batch 123/168] [D loss: 0.000002] [G loss: 14.400814]\n",
      "[Epoch 50/1000] [Batch 124/168] [D loss: 0.000002] [G loss: 14.889196]\n",
      "[Epoch 50/1000] [Batch 125/168] [D loss: 0.000002] [G loss: 14.246540]\n",
      "[Epoch 50/1000] [Batch 126/168] [D loss: 0.000002] [G loss: 14.385503]\n",
      "[Epoch 50/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 14.037156]\n",
      "[Epoch 50/1000] [Batch 128/168] [D loss: 0.000002] [G loss: 14.246938]\n",
      "[Epoch 50/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 14.433630]\n",
      "[Epoch 50/1000] [Batch 130/168] [D loss: 0.000002] [G loss: 14.125381]\n",
      "[Epoch 50/1000] [Batch 131/168] [D loss: 0.000002] [G loss: 14.654149]\n",
      "[Epoch 50/1000] [Batch 132/168] [D loss: 0.000002] [G loss: 13.967738]\n",
      "[Epoch 50/1000] [Batch 133/168] [D loss: 0.000002] [G loss: 13.976099]\n",
      "[Epoch 50/1000] [Batch 134/168] [D loss: 0.000002] [G loss: 14.415839]\n",
      "[Epoch 50/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 14.247489]\n",
      "[Epoch 50/1000] [Batch 136/168] [D loss: 0.000002] [G loss: 14.495286]\n",
      "[Epoch 50/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 14.208128]\n",
      "[Epoch 50/1000] [Batch 138/168] [D loss: 0.000002] [G loss: 14.619402]\n",
      "[Epoch 50/1000] [Batch 139/168] [D loss: 0.000003] [G loss: 14.439894]\n",
      "[Epoch 50/1000] [Batch 140/168] [D loss: 0.000001] [G loss: 14.695054]\n",
      "[Epoch 50/1000] [Batch 141/168] [D loss: 0.000003] [G loss: 14.463400]\n",
      "[Epoch 50/1000] [Batch 142/168] [D loss: 0.000002] [G loss: 14.479180]\n",
      "[Epoch 50/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 14.664331]\n",
      "[Epoch 50/1000] [Batch 144/168] [D loss: 0.000002] [G loss: 13.932763]\n",
      "[Epoch 50/1000] [Batch 145/168] [D loss: 0.000002] [G loss: 14.301901]\n",
      "[Epoch 50/1000] [Batch 146/168] [D loss: 0.000002] [G loss: 14.700065]\n",
      "[Epoch 50/1000] [Batch 147/168] [D loss: 0.000002] [G loss: 14.253480]\n",
      "[Epoch 50/1000] [Batch 148/168] [D loss: 0.000002] [G loss: 14.267085]\n",
      "[Epoch 50/1000] [Batch 149/168] [D loss: 0.000002] [G loss: 14.234324]\n",
      "[Epoch 50/1000] [Batch 150/168] [D loss: 0.000002] [G loss: 14.259040]\n",
      "[Epoch 50/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 14.653916]\n",
      "[Epoch 50/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 14.606073]\n",
      "[Epoch 50/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 14.691257]\n",
      "[Epoch 50/1000] [Batch 154/168] [D loss: 0.000001] [G loss: 14.547663]\n",
      "[Epoch 50/1000] [Batch 155/168] [D loss: 0.000002] [G loss: 14.360497]\n",
      "[Epoch 50/1000] [Batch 156/168] [D loss: 0.000002] [G loss: 14.573996]\n",
      "[Epoch 50/1000] [Batch 157/168] [D loss: 0.000002] [G loss: 14.717593]\n",
      "[Epoch 50/1000] [Batch 158/168] [D loss: 0.000002] [G loss: 14.360271]\n",
      "[Epoch 50/1000] [Batch 159/168] [D loss: 0.000003] [G loss: 14.186398]\n",
      "[Epoch 50/1000] [Batch 160/168] [D loss: 0.000002] [G loss: 14.415420]\n",
      "[Epoch 50/1000] [Batch 161/168] [D loss: 0.000002] [G loss: 14.769219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 14.689636]\n",
      "[Epoch 50/1000] [Batch 163/168] [D loss: 0.000004] [G loss: 14.569231]\n",
      "[Epoch 50/1000] [Batch 164/168] [D loss: 0.000002] [G loss: 14.221163]\n",
      "[Epoch 50/1000] [Batch 165/168] [D loss: 0.000003] [G loss: 14.368816]\n",
      "[Epoch 50/1000] [Batch 166/168] [D loss: 0.000002] [G loss: 14.499852]\n",
      "[Epoch 50/1000] [Batch 167/168] [D loss: 0.000003] [G loss: 14.261259]\n",
      "[Epoch 50/1000] [Batch 168/168] [D loss: 0.000002] [G loss: 14.554662]\n",
      "[Epoch 51/1000] [Batch 1/168] [D loss: 0.000003] [G loss: 14.085547]\n",
      "[Epoch 51/1000] [Batch 2/168] [D loss: 0.000002] [G loss: 14.543341]\n",
      "[Epoch 51/1000] [Batch 3/168] [D loss: 0.000001] [G loss: 14.464706]\n",
      "[Epoch 51/1000] [Batch 4/168] [D loss: 0.000002] [G loss: 14.181084]\n",
      "[Epoch 51/1000] [Batch 5/168] [D loss: 0.000002] [G loss: 14.263774]\n",
      "[Epoch 51/1000] [Batch 6/168] [D loss: 0.000002] [G loss: 14.256086]\n",
      "[Epoch 51/1000] [Batch 7/168] [D loss: 0.000002] [G loss: 14.481107]\n",
      "[Epoch 51/1000] [Batch 8/168] [D loss: 0.000001] [G loss: 14.650943]\n",
      "[Epoch 51/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 14.254894]\n",
      "[Epoch 51/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 14.326675]\n",
      "[Epoch 51/1000] [Batch 11/168] [D loss: 0.000002] [G loss: 14.406834]\n",
      "[Epoch 51/1000] [Batch 12/168] [D loss: 0.000002] [G loss: 14.243885]\n",
      "[Epoch 51/1000] [Batch 13/168] [D loss: 0.000002] [G loss: 14.222320]\n",
      "[Epoch 51/1000] [Batch 14/168] [D loss: 0.000002] [G loss: 14.615092]\n",
      "[Epoch 51/1000] [Batch 15/168] [D loss: 0.000003] [G loss: 14.213032]\n",
      "[Epoch 51/1000] [Batch 16/168] [D loss: 0.000003] [G loss: 14.138693]\n",
      "[Epoch 51/1000] [Batch 17/168] [D loss: 0.000002] [G loss: 13.964285]\n",
      "[Epoch 51/1000] [Batch 18/168] [D loss: 0.000002] [G loss: 14.160910]\n",
      "[Epoch 51/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 14.458618]\n",
      "[Epoch 51/1000] [Batch 20/168] [D loss: 0.000002] [G loss: 14.225142]\n",
      "[Epoch 51/1000] [Batch 21/168] [D loss: 0.000002] [G loss: 14.253277]\n",
      "[Epoch 51/1000] [Batch 22/168] [D loss: 0.000002] [G loss: 14.374715]\n",
      "[Epoch 51/1000] [Batch 23/168] [D loss: 0.000001] [G loss: 14.032022]\n",
      "[Epoch 51/1000] [Batch 24/168] [D loss: 0.000002] [G loss: 14.632386]\n",
      "[Epoch 51/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 14.720119]\n",
      "[Epoch 51/1000] [Batch 26/168] [D loss: 0.000003] [G loss: 14.371925]\n",
      "[Epoch 51/1000] [Batch 27/168] [D loss: 0.000001] [G loss: 14.434093]\n",
      "[Epoch 51/1000] [Batch 28/168] [D loss: 0.000002] [G loss: 14.530622]\n",
      "[Epoch 51/1000] [Batch 29/168] [D loss: 0.000002] [G loss: 14.320643]\n",
      "[Epoch 51/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 14.712424]\n",
      "[Epoch 51/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 14.428147]\n",
      "[Epoch 51/1000] [Batch 32/168] [D loss: 0.000002] [G loss: 14.143559]\n",
      "[Epoch 51/1000] [Batch 33/168] [D loss: 0.000002] [G loss: 14.485694]\n",
      "[Epoch 51/1000] [Batch 34/168] [D loss: 0.000002] [G loss: 14.769250]\n",
      "[Epoch 51/1000] [Batch 35/168] [D loss: 0.000002] [G loss: 14.320573]\n",
      "[Epoch 51/1000] [Batch 36/168] [D loss: 0.000002] [G loss: 14.313783]\n",
      "[Epoch 51/1000] [Batch 37/168] [D loss: 0.000003] [G loss: 14.397549]\n",
      "[Epoch 51/1000] [Batch 38/168] [D loss: 0.000002] [G loss: 13.910415]\n",
      "[Epoch 51/1000] [Batch 39/168] [D loss: 0.000003] [G loss: 14.152093]\n",
      "[Epoch 51/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 14.082153]\n",
      "[Epoch 51/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 14.951836]\n",
      "[Epoch 51/1000] [Batch 42/168] [D loss: 0.000002] [G loss: 14.565919]\n",
      "[Epoch 51/1000] [Batch 43/168] [D loss: 0.000002] [G loss: 14.345224]\n",
      "[Epoch 51/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 14.735565]\n",
      "[Epoch 51/1000] [Batch 45/168] [D loss: 0.000002] [G loss: 14.564552]\n",
      "[Epoch 51/1000] [Batch 46/168] [D loss: 0.000002] [G loss: 14.592247]\n",
      "[Epoch 51/1000] [Batch 47/168] [D loss: 0.000001] [G loss: 14.642121]\n",
      "[Epoch 51/1000] [Batch 48/168] [D loss: 0.000002] [G loss: 14.554867]\n",
      "[Epoch 51/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 14.548010]\n",
      "[Epoch 51/1000] [Batch 50/168] [D loss: 0.000002] [G loss: 14.794601]\n",
      "[Epoch 51/1000] [Batch 51/168] [D loss: 0.000002] [G loss: 14.633714]\n",
      "[Epoch 51/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 14.579842]\n",
      "[Epoch 51/1000] [Batch 53/168] [D loss: 0.000002] [G loss: 14.649072]\n",
      "[Epoch 51/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 14.689024]\n",
      "[Epoch 51/1000] [Batch 55/168] [D loss: 0.000002] [G loss: 14.158511]\n",
      "[Epoch 51/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 14.726971]\n",
      "[Epoch 51/1000] [Batch 57/168] [D loss: 0.000002] [G loss: 14.735388]\n",
      "[Epoch 51/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 14.549163]\n",
      "[Epoch 51/1000] [Batch 59/168] [D loss: 0.000002] [G loss: 14.738474]\n",
      "[Epoch 51/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 14.776014]\n",
      "[Epoch 51/1000] [Batch 61/168] [D loss: 0.000002] [G loss: 14.527965]\n",
      "[Epoch 51/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 14.905299]\n",
      "[Epoch 51/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 14.342321]\n",
      "[Epoch 51/1000] [Batch 64/168] [D loss: 0.000002] [G loss: 14.374808]\n",
      "[Epoch 51/1000] [Batch 65/168] [D loss: 0.000001] [G loss: 14.382446]\n",
      "[Epoch 51/1000] [Batch 66/168] [D loss: 0.000002] [G loss: 14.450638]\n",
      "[Epoch 51/1000] [Batch 67/168] [D loss: 0.000004] [G loss: 14.320901]\n",
      "[Epoch 51/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 14.674994]\n",
      "[Epoch 51/1000] [Batch 69/168] [D loss: 0.000002] [G loss: 14.411059]\n",
      "[Epoch 51/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 14.599165]\n",
      "[Epoch 51/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 14.406883]\n",
      "[Epoch 51/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 14.333889]\n",
      "[Epoch 51/1000] [Batch 73/168] [D loss: 0.000002] [G loss: 14.746143]\n",
      "[Epoch 51/1000] [Batch 74/168] [D loss: 0.000002] [G loss: 14.650789]\n",
      "[Epoch 51/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 14.521884]\n",
      "[Epoch 51/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 14.631520]\n",
      "[Epoch 51/1000] [Batch 77/168] [D loss: 0.000002] [G loss: 14.214443]\n",
      "[Epoch 51/1000] [Batch 78/168] [D loss: 0.000002] [G loss: 14.606125]\n",
      "[Epoch 51/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 14.462227]\n",
      "[Epoch 51/1000] [Batch 80/168] [D loss: 0.000002] [G loss: 14.478485]\n",
      "[Epoch 51/1000] [Batch 81/168] [D loss: 0.000002] [G loss: 14.699838]\n",
      "[Epoch 51/1000] [Batch 82/168] [D loss: 0.000002] [G loss: 14.339423]\n",
      "[Epoch 51/1000] [Batch 83/168] [D loss: 0.000002] [G loss: 14.390102]\n",
      "[Epoch 51/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 14.546924]\n",
      "[Epoch 51/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 14.732549]\n",
      "[Epoch 51/1000] [Batch 86/168] [D loss: 0.000002] [G loss: 14.831036]\n",
      "[Epoch 51/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 14.824423]\n",
      "[Epoch 51/1000] [Batch 88/168] [D loss: 0.000002] [G loss: 14.472071]\n",
      "[Epoch 51/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 14.774180]\n",
      "[Epoch 51/1000] [Batch 90/168] [D loss: 0.000001] [G loss: 14.324435]\n",
      "[Epoch 51/1000] [Batch 91/168] [D loss: 0.000002] [G loss: 14.748474]\n",
      "[Epoch 51/1000] [Batch 92/168] [D loss: 0.000002] [G loss: 14.772024]\n",
      "[Epoch 51/1000] [Batch 93/168] [D loss: 0.000002] [G loss: 14.878881]\n",
      "[Epoch 51/1000] [Batch 94/168] [D loss: 0.000001] [G loss: 14.349673]\n",
      "[Epoch 51/1000] [Batch 95/168] [D loss: 0.000002] [G loss: 14.400074]\n",
      "[Epoch 51/1000] [Batch 96/168] [D loss: 0.000002] [G loss: 14.296640]\n",
      "[Epoch 51/1000] [Batch 97/168] [D loss: 0.000002] [G loss: 14.808522]\n",
      "[Epoch 51/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 14.742962]\n",
      "[Epoch 51/1000] [Batch 99/168] [D loss: 0.000002] [G loss: 14.787353]\n",
      "[Epoch 51/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 14.564739]\n",
      "[Epoch 51/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 14.142797]\n",
      "[Epoch 51/1000] [Batch 102/168] [D loss: 0.000002] [G loss: 14.655373]\n",
      "[Epoch 51/1000] [Batch 103/168] [D loss: 0.000001] [G loss: 14.741259]\n",
      "[Epoch 51/1000] [Batch 104/168] [D loss: 0.000002] [G loss: 14.703604]\n",
      "[Epoch 51/1000] [Batch 105/168] [D loss: 0.000002] [G loss: 14.272563]\n",
      "[Epoch 51/1000] [Batch 106/168] [D loss: 0.000002] [G loss: 14.972682]\n",
      "[Epoch 51/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 14.641797]\n",
      "[Epoch 51/1000] [Batch 108/168] [D loss: 0.000002] [G loss: 14.695889]\n",
      "[Epoch 51/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 14.656833]\n",
      "[Epoch 51/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 14.695454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 14.613939]\n",
      "[Epoch 51/1000] [Batch 112/168] [D loss: 0.000002] [G loss: 14.801683]\n",
      "[Epoch 51/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 14.680572]\n",
      "[Epoch 51/1000] [Batch 114/168] [D loss: 0.000002] [G loss: 14.610738]\n",
      "[Epoch 51/1000] [Batch 115/168] [D loss: 0.000002] [G loss: 14.402198]\n",
      "[Epoch 51/1000] [Batch 116/168] [D loss: 0.000002] [G loss: 14.608350]\n",
      "[Epoch 51/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 14.788658]\n",
      "[Epoch 51/1000] [Batch 118/168] [D loss: 0.000004] [G loss: 14.210878]\n",
      "[Epoch 51/1000] [Batch 119/168] [D loss: 0.000002] [G loss: 14.428411]\n",
      "[Epoch 51/1000] [Batch 120/168] [D loss: 0.000003] [G loss: 14.788465]\n",
      "[Epoch 51/1000] [Batch 121/168] [D loss: 0.000003] [G loss: 14.409430]\n",
      "[Epoch 51/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 14.790572]\n",
      "[Epoch 51/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 14.726532]\n",
      "[Epoch 51/1000] [Batch 124/168] [D loss: 0.000003] [G loss: 14.384042]\n",
      "[Epoch 51/1000] [Batch 125/168] [D loss: 0.000001] [G loss: 14.672194]\n",
      "[Epoch 51/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 14.748670]\n",
      "[Epoch 51/1000] [Batch 127/168] [D loss: 0.000002] [G loss: 14.823458]\n",
      "[Epoch 51/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 14.687592]\n",
      "[Epoch 51/1000] [Batch 129/168] [D loss: 0.000002] [G loss: 14.436914]\n",
      "[Epoch 51/1000] [Batch 130/168] [D loss: 0.000003] [G loss: 14.628201]\n",
      "[Epoch 51/1000] [Batch 131/168] [D loss: 0.000002] [G loss: 14.642740]\n",
      "[Epoch 51/1000] [Batch 132/168] [D loss: 0.000002] [G loss: 14.273196]\n",
      "[Epoch 51/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 14.768297]\n",
      "[Epoch 51/1000] [Batch 134/168] [D loss: 0.000002] [G loss: 14.561202]\n",
      "[Epoch 51/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 14.931734]\n",
      "[Epoch 51/1000] [Batch 136/168] [D loss: 0.000002] [G loss: 14.309732]\n",
      "[Epoch 51/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 14.898804]\n",
      "[Epoch 51/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 14.680810]\n",
      "[Epoch 51/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 14.789765]\n",
      "[Epoch 51/1000] [Batch 140/168] [D loss: 0.000001] [G loss: 14.592973]\n",
      "[Epoch 51/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 14.457126]\n",
      "[Epoch 51/1000] [Batch 142/168] [D loss: 0.000003] [G loss: 14.080042]\n",
      "[Epoch 51/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 14.898870]\n",
      "[Epoch 51/1000] [Batch 144/168] [D loss: 0.000002] [G loss: 14.508484]\n",
      "[Epoch 51/1000] [Batch 145/168] [D loss: 0.000003] [G loss: 14.668672]\n",
      "[Epoch 51/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 14.595092]\n",
      "[Epoch 51/1000] [Batch 147/168] [D loss: 0.000002] [G loss: 14.439040]\n",
      "[Epoch 51/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 14.255792]\n",
      "[Epoch 51/1000] [Batch 149/168] [D loss: 0.000002] [G loss: 14.885899]\n",
      "[Epoch 51/1000] [Batch 150/168] [D loss: 0.000002] [G loss: 14.624949]\n",
      "[Epoch 51/1000] [Batch 151/168] [D loss: 0.000002] [G loss: 14.587104]\n",
      "[Epoch 51/1000] [Batch 152/168] [D loss: 0.000002] [G loss: 14.547978]\n",
      "[Epoch 51/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 14.511124]\n",
      "[Epoch 51/1000] [Batch 154/168] [D loss: 0.000002] [G loss: 14.491316]\n",
      "[Epoch 51/1000] [Batch 155/168] [D loss: 0.000002] [G loss: 14.512653]\n",
      "[Epoch 51/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 14.480493]\n",
      "[Epoch 51/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 14.731521]\n",
      "[Epoch 51/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 14.469741]\n",
      "[Epoch 51/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 14.463839]\n",
      "[Epoch 51/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 14.617958]\n",
      "[Epoch 51/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 14.597991]\n",
      "[Epoch 51/1000] [Batch 162/168] [D loss: 0.000002] [G loss: 14.744311]\n",
      "[Epoch 51/1000] [Batch 163/168] [D loss: 0.000002] [G loss: 14.233652]\n",
      "[Epoch 51/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 14.860046]\n",
      "[Epoch 51/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 14.563338]\n",
      "[Epoch 51/1000] [Batch 166/168] [D loss: 0.000002] [G loss: 14.359699]\n",
      "[Epoch 51/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 14.610638]\n",
      "[Epoch 51/1000] [Batch 168/168] [D loss: 0.000002] [G loss: 14.301062]\n",
      "[Epoch 52/1000] [Batch 1/168] [D loss: 0.000001] [G loss: 14.461757]\n",
      "[Epoch 52/1000] [Batch 2/168] [D loss: 0.000002] [G loss: 14.575475]\n",
      "[Epoch 52/1000] [Batch 3/168] [D loss: 0.000002] [G loss: 14.857670]\n",
      "[Epoch 52/1000] [Batch 4/168] [D loss: 0.000001] [G loss: 14.555662]\n",
      "[Epoch 52/1000] [Batch 5/168] [D loss: 0.000001] [G loss: 14.440271]\n",
      "[Epoch 52/1000] [Batch 6/168] [D loss: 0.000001] [G loss: 14.663445]\n",
      "[Epoch 52/1000] [Batch 7/168] [D loss: 0.000002] [G loss: 14.566997]\n",
      "[Epoch 52/1000] [Batch 8/168] [D loss: 0.000001] [G loss: 14.722349]\n",
      "[Epoch 52/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 14.613433]\n",
      "[Epoch 52/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 14.618495]\n",
      "[Epoch 52/1000] [Batch 11/168] [D loss: 0.000002] [G loss: 14.685266]\n",
      "[Epoch 52/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 14.865437]\n",
      "[Epoch 52/1000] [Batch 13/168] [D loss: 0.000003] [G loss: 14.621849]\n",
      "[Epoch 52/1000] [Batch 14/168] [D loss: 0.000001] [G loss: 14.776914]\n",
      "[Epoch 52/1000] [Batch 15/168] [D loss: 0.000001] [G loss: 14.767543]\n",
      "[Epoch 52/1000] [Batch 16/168] [D loss: 0.000003] [G loss: 14.362448]\n",
      "[Epoch 52/1000] [Batch 17/168] [D loss: 0.000002] [G loss: 14.253054]\n",
      "[Epoch 52/1000] [Batch 18/168] [D loss: 0.000002] [G loss: 14.385214]\n",
      "[Epoch 52/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 14.355931]\n",
      "[Epoch 52/1000] [Batch 20/168] [D loss: 0.000002] [G loss: 14.064101]\n",
      "[Epoch 52/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 14.674124]\n",
      "[Epoch 52/1000] [Batch 22/168] [D loss: 0.000002] [G loss: 14.423220]\n",
      "[Epoch 52/1000] [Batch 23/168] [D loss: 0.000002] [G loss: 14.766727]\n",
      "[Epoch 52/1000] [Batch 24/168] [D loss: 0.000002] [G loss: 14.403100]\n",
      "[Epoch 52/1000] [Batch 25/168] [D loss: 0.000002] [G loss: 14.291366]\n",
      "[Epoch 52/1000] [Batch 26/168] [D loss: 0.000002] [G loss: 14.551586]\n",
      "[Epoch 52/1000] [Batch 27/168] [D loss: 0.000002] [G loss: 14.554743]\n",
      "[Epoch 52/1000] [Batch 28/168] [D loss: 0.000002] [G loss: 14.761837]\n",
      "[Epoch 52/1000] [Batch 29/168] [D loss: 0.000004] [G loss: 14.640186]\n",
      "[Epoch 52/1000] [Batch 30/168] [D loss: 0.000002] [G loss: 14.534620]\n",
      "[Epoch 52/1000] [Batch 31/168] [D loss: 0.000002] [G loss: 14.857366]\n",
      "[Epoch 52/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 14.600160]\n",
      "[Epoch 52/1000] [Batch 33/168] [D loss: 0.000001] [G loss: 14.932239]\n",
      "[Epoch 52/1000] [Batch 34/168] [D loss: 0.000002] [G loss: 14.438943]\n",
      "[Epoch 52/1000] [Batch 35/168] [D loss: 0.000002] [G loss: 14.855864]\n",
      "[Epoch 52/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 14.325565]\n",
      "[Epoch 52/1000] [Batch 37/168] [D loss: 0.000001] [G loss: 14.806106]\n",
      "[Epoch 52/1000] [Batch 38/168] [D loss: 0.000002] [G loss: 14.364712]\n",
      "[Epoch 52/1000] [Batch 39/168] [D loss: 0.000002] [G loss: 14.987397]\n",
      "[Epoch 52/1000] [Batch 40/168] [D loss: 0.000002] [G loss: 14.932709]\n",
      "[Epoch 52/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 15.128660]\n",
      "[Epoch 52/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 14.339667]\n",
      "[Epoch 52/1000] [Batch 43/168] [D loss: 0.000001] [G loss: 14.536311]\n",
      "[Epoch 52/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 14.444069]\n",
      "[Epoch 52/1000] [Batch 45/168] [D loss: 0.000002] [G loss: 14.678432]\n",
      "[Epoch 52/1000] [Batch 46/168] [D loss: 0.000002] [G loss: 14.080210]\n",
      "[Epoch 52/1000] [Batch 47/168] [D loss: 0.000001] [G loss: 14.767415]\n",
      "[Epoch 52/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 14.361830]\n",
      "[Epoch 52/1000] [Batch 49/168] [D loss: 0.000002] [G loss: 14.803842]\n",
      "[Epoch 52/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 14.676640]\n",
      "[Epoch 52/1000] [Batch 51/168] [D loss: 0.000001] [G loss: 14.465863]\n",
      "[Epoch 52/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 14.465971]\n",
      "[Epoch 52/1000] [Batch 53/168] [D loss: 0.000002] [G loss: 14.614870]\n",
      "[Epoch 52/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 14.600960]\n",
      "[Epoch 52/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 15.059006]\n",
      "[Epoch 52/1000] [Batch 56/168] [D loss: 0.000002] [G loss: 14.451103]\n",
      "[Epoch 52/1000] [Batch 57/168] [D loss: 0.000002] [G loss: 14.887817]\n",
      "[Epoch 52/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 14.699703]\n",
      "[Epoch 52/1000] [Batch 59/168] [D loss: 0.000001] [G loss: 14.642681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/1000] [Batch 60/168] [D loss: 0.000002] [G loss: 14.238749]\n",
      "[Epoch 52/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 14.933301]\n",
      "[Epoch 52/1000] [Batch 62/168] [D loss: 0.000003] [G loss: 14.674918]\n",
      "[Epoch 52/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 15.174945]\n",
      "[Epoch 52/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 14.412872]\n",
      "[Epoch 52/1000] [Batch 65/168] [D loss: 0.000002] [G loss: 14.425048]\n",
      "[Epoch 52/1000] [Batch 66/168] [D loss: 0.000002] [G loss: 14.910398]\n",
      "[Epoch 52/1000] [Batch 67/168] [D loss: 0.000002] [G loss: 14.415018]\n",
      "[Epoch 52/1000] [Batch 68/168] [D loss: 0.000002] [G loss: 14.663460]\n",
      "[Epoch 52/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 14.523155]\n",
      "[Epoch 52/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 14.505531]\n",
      "[Epoch 52/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 14.576283]\n",
      "[Epoch 52/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 14.563477]\n",
      "[Epoch 52/1000] [Batch 73/168] [D loss: 0.000001] [G loss: 14.774679]\n",
      "[Epoch 52/1000] [Batch 74/168] [D loss: 0.000003] [G loss: 14.486879]\n",
      "[Epoch 52/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 14.610420]\n",
      "[Epoch 52/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 14.651770]\n",
      "[Epoch 52/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 14.525266]\n",
      "[Epoch 52/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 14.823402]\n",
      "[Epoch 52/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 14.638455]\n",
      "[Epoch 52/1000] [Batch 80/168] [D loss: 0.000001] [G loss: 14.831059]\n",
      "[Epoch 52/1000] [Batch 81/168] [D loss: 0.000002] [G loss: 14.812233]\n",
      "[Epoch 52/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 14.997241]\n",
      "[Epoch 52/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 14.721256]\n",
      "[Epoch 52/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 15.160372]\n",
      "[Epoch 52/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 14.834944]\n",
      "[Epoch 52/1000] [Batch 86/168] [D loss: 0.000001] [G loss: 14.866668]\n",
      "[Epoch 52/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 14.892592]\n",
      "[Epoch 52/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 14.713160]\n",
      "[Epoch 52/1000] [Batch 89/168] [D loss: 0.000002] [G loss: 14.792535]\n",
      "[Epoch 52/1000] [Batch 90/168] [D loss: 0.000001] [G loss: 14.451636]\n",
      "[Epoch 52/1000] [Batch 91/168] [D loss: 0.000002] [G loss: 14.736165]\n",
      "[Epoch 52/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 14.652393]\n",
      "[Epoch 52/1000] [Batch 93/168] [D loss: 0.000001] [G loss: 14.936885]\n",
      "[Epoch 52/1000] [Batch 94/168] [D loss: 0.000003] [G loss: 14.550595]\n",
      "[Epoch 52/1000] [Batch 95/168] [D loss: 0.000001] [G loss: 14.806673]\n",
      "[Epoch 52/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 14.671296]\n",
      "[Epoch 52/1000] [Batch 97/168] [D loss: 0.000002] [G loss: 14.572314]\n",
      "[Epoch 52/1000] [Batch 98/168] [D loss: 0.000002] [G loss: 14.789083]\n",
      "[Epoch 52/1000] [Batch 99/168] [D loss: 0.000001] [G loss: 14.713322]\n",
      "[Epoch 52/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 14.778234]\n",
      "[Epoch 52/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 15.095117]\n",
      "[Epoch 52/1000] [Batch 102/168] [D loss: 0.000001] [G loss: 14.909877]\n",
      "[Epoch 52/1000] [Batch 103/168] [D loss: 0.000002] [G loss: 14.829985]\n",
      "[Epoch 52/1000] [Batch 104/168] [D loss: 0.000002] [G loss: 14.313519]\n",
      "[Epoch 52/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 14.870405]\n",
      "[Epoch 52/1000] [Batch 106/168] [D loss: 0.000002] [G loss: 14.477503]\n",
      "[Epoch 52/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 14.936877]\n",
      "[Epoch 52/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 14.780493]\n",
      "[Epoch 52/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 14.766259]\n",
      "[Epoch 52/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 14.712172]\n",
      "[Epoch 52/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 14.518265]\n",
      "[Epoch 52/1000] [Batch 112/168] [D loss: 0.000002] [G loss: 14.668525]\n",
      "[Epoch 52/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 14.556632]\n",
      "[Epoch 52/1000] [Batch 114/168] [D loss: 0.000001] [G loss: 14.745365]\n",
      "[Epoch 52/1000] [Batch 115/168] [D loss: 0.000001] [G loss: 14.859605]\n",
      "[Epoch 52/1000] [Batch 116/168] [D loss: 0.000001] [G loss: 15.263913]\n",
      "[Epoch 52/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 15.144300]\n",
      "[Epoch 52/1000] [Batch 118/168] [D loss: 0.000002] [G loss: 14.834041]\n",
      "[Epoch 52/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 14.720283]\n",
      "[Epoch 52/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 14.869349]\n",
      "[Epoch 52/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 14.828991]\n",
      "[Epoch 52/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 14.811316]\n",
      "[Epoch 52/1000] [Batch 123/168] [D loss: 0.000002] [G loss: 14.697092]\n",
      "[Epoch 52/1000] [Batch 124/168] [D loss: 0.000002] [G loss: 14.794176]\n",
      "[Epoch 52/1000] [Batch 125/168] [D loss: 0.000001] [G loss: 14.979648]\n",
      "[Epoch 52/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 14.719075]\n",
      "[Epoch 52/1000] [Batch 127/168] [D loss: 0.000002] [G loss: 14.533721]\n",
      "[Epoch 52/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 14.712384]\n",
      "[Epoch 52/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 14.701505]\n",
      "[Epoch 52/1000] [Batch 130/168] [D loss: 0.000002] [G loss: 14.350381]\n",
      "[Epoch 52/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 14.931306]\n",
      "[Epoch 52/1000] [Batch 132/168] [D loss: 0.000002] [G loss: 14.924017]\n",
      "[Epoch 52/1000] [Batch 133/168] [D loss: 0.000002] [G loss: 14.646843]\n",
      "[Epoch 52/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.167002]\n",
      "[Epoch 52/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 15.072158]\n",
      "[Epoch 52/1000] [Batch 136/168] [D loss: 0.000002] [G loss: 14.457259]\n",
      "[Epoch 52/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 14.550049]\n",
      "[Epoch 52/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 14.903347]\n",
      "[Epoch 52/1000] [Batch 139/168] [D loss: 0.000002] [G loss: 14.634648]\n",
      "[Epoch 52/1000] [Batch 140/168] [D loss: 0.000002] [G loss: 14.636388]\n",
      "[Epoch 52/1000] [Batch 141/168] [D loss: 0.000002] [G loss: 14.420396]\n",
      "[Epoch 52/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 14.826953]\n",
      "[Epoch 52/1000] [Batch 143/168] [D loss: 0.000002] [G loss: 14.859705]\n",
      "[Epoch 52/1000] [Batch 144/168] [D loss: 0.000003] [G loss: 14.852747]\n",
      "[Epoch 52/1000] [Batch 145/168] [D loss: 0.000001] [G loss: 14.896069]\n",
      "[Epoch 52/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 14.579819]\n",
      "[Epoch 52/1000] [Batch 147/168] [D loss: 0.000002] [G loss: 14.409483]\n",
      "[Epoch 52/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 14.852494]\n",
      "[Epoch 52/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 14.966137]\n",
      "[Epoch 52/1000] [Batch 150/168] [D loss: 0.000001] [G loss: 14.423876]\n",
      "[Epoch 52/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 15.113331]\n",
      "[Epoch 52/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 14.788713]\n",
      "[Epoch 52/1000] [Batch 153/168] [D loss: 0.000002] [G loss: 14.639306]\n",
      "[Epoch 52/1000] [Batch 154/168] [D loss: 0.000001] [G loss: 15.061340]\n",
      "[Epoch 52/1000] [Batch 155/168] [D loss: 0.000002] [G loss: 15.122138]\n",
      "[Epoch 52/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 14.647474]\n",
      "[Epoch 52/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 14.910374]\n",
      "[Epoch 52/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 14.986200]\n",
      "[Epoch 52/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 14.837416]\n",
      "[Epoch 52/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 14.523091]\n",
      "[Epoch 52/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 14.701097]\n",
      "[Epoch 52/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 14.965376]\n",
      "[Epoch 52/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 14.816709]\n",
      "[Epoch 52/1000] [Batch 164/168] [D loss: 0.000002] [G loss: 14.497595]\n",
      "[Epoch 52/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 14.800536]\n",
      "[Epoch 52/1000] [Batch 166/168] [D loss: 0.000001] [G loss: 15.065682]\n",
      "[Epoch 52/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 15.345307]\n",
      "[Epoch 52/1000] [Batch 168/168] [D loss: 0.000002] [G loss: 14.753873]\n",
      "[Epoch 53/1000] [Batch 1/168] [D loss: 0.000001] [G loss: 15.095767]\n",
      "[Epoch 53/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 14.557587]\n",
      "[Epoch 53/1000] [Batch 3/168] [D loss: 0.000002] [G loss: 15.100027]\n",
      "[Epoch 53/1000] [Batch 4/168] [D loss: 0.000002] [G loss: 14.533383]\n",
      "[Epoch 53/1000] [Batch 5/168] [D loss: 0.000001] [G loss: 14.749961]\n",
      "[Epoch 53/1000] [Batch 6/168] [D loss: 0.000001] [G loss: 15.079345]\n",
      "[Epoch 53/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 14.753154]\n",
      "[Epoch 53/1000] [Batch 8/168] [D loss: 0.000001] [G loss: 14.961076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/1000] [Batch 9/168] [D loss: 0.000002] [G loss: 14.775694]\n",
      "[Epoch 53/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 14.588652]\n",
      "[Epoch 53/1000] [Batch 11/168] [D loss: 0.000002] [G loss: 14.481807]\n",
      "[Epoch 53/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 14.664890]\n",
      "[Epoch 53/1000] [Batch 13/168] [D loss: 0.000001] [G loss: 14.699731]\n",
      "[Epoch 53/1000] [Batch 14/168] [D loss: 0.000001] [G loss: 14.703406]\n",
      "[Epoch 53/1000] [Batch 15/168] [D loss: 0.000002] [G loss: 14.971330]\n",
      "[Epoch 53/1000] [Batch 16/168] [D loss: 0.000002] [G loss: 14.671475]\n",
      "[Epoch 53/1000] [Batch 17/168] [D loss: 0.000002] [G loss: 14.939222]\n",
      "[Epoch 53/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.021261]\n",
      "[Epoch 53/1000] [Batch 19/168] [D loss: 0.000003] [G loss: 14.694919]\n",
      "[Epoch 53/1000] [Batch 20/168] [D loss: 0.000001] [G loss: 14.707100]\n",
      "[Epoch 53/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 14.899754]\n",
      "[Epoch 53/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 14.648606]\n",
      "[Epoch 53/1000] [Batch 23/168] [D loss: 0.000001] [G loss: 14.664264]\n",
      "[Epoch 53/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 14.956597]\n",
      "[Epoch 53/1000] [Batch 25/168] [D loss: 0.000003] [G loss: 14.629061]\n",
      "[Epoch 53/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 14.610638]\n",
      "[Epoch 53/1000] [Batch 27/168] [D loss: 0.000001] [G loss: 14.934050]\n",
      "[Epoch 53/1000] [Batch 28/168] [D loss: 0.000002] [G loss: 14.046892]\n",
      "[Epoch 53/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 14.675307]\n",
      "[Epoch 53/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 14.736069]\n",
      "[Epoch 53/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 14.583627]\n",
      "[Epoch 53/1000] [Batch 32/168] [D loss: 0.000002] [G loss: 14.466021]\n",
      "[Epoch 53/1000] [Batch 33/168] [D loss: 0.000001] [G loss: 14.840363]\n",
      "[Epoch 53/1000] [Batch 34/168] [D loss: 0.000002] [G loss: 14.706316]\n",
      "[Epoch 53/1000] [Batch 35/168] [D loss: 0.000001] [G loss: 14.569867]\n",
      "[Epoch 53/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 14.715216]\n",
      "[Epoch 53/1000] [Batch 37/168] [D loss: 0.000001] [G loss: 15.150384]\n",
      "[Epoch 53/1000] [Batch 38/168] [D loss: 0.000001] [G loss: 14.760748]\n",
      "[Epoch 53/1000] [Batch 39/168] [D loss: 0.000001] [G loss: 14.702347]\n",
      "[Epoch 53/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 14.634832]\n",
      "[Epoch 53/1000] [Batch 41/168] [D loss: 0.000002] [G loss: 14.662209]\n",
      "[Epoch 53/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 14.777292]\n",
      "[Epoch 53/1000] [Batch 43/168] [D loss: 0.000002] [G loss: 14.831861]\n",
      "[Epoch 53/1000] [Batch 44/168] [D loss: 0.000002] [G loss: 15.030506]\n",
      "[Epoch 53/1000] [Batch 45/168] [D loss: 0.000002] [G loss: 14.686098]\n",
      "[Epoch 53/1000] [Batch 46/168] [D loss: 0.000001] [G loss: 14.966119]\n",
      "[Epoch 53/1000] [Batch 47/168] [D loss: 0.000002] [G loss: 14.724112]\n",
      "[Epoch 53/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 14.594290]\n",
      "[Epoch 53/1000] [Batch 49/168] [D loss: 0.000002] [G loss: 14.647317]\n",
      "[Epoch 53/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 15.124877]\n",
      "[Epoch 53/1000] [Batch 51/168] [D loss: 0.000001] [G loss: 14.650504]\n",
      "[Epoch 53/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.012981]\n",
      "[Epoch 53/1000] [Batch 53/168] [D loss: 0.000001] [G loss: 14.804137]\n",
      "[Epoch 53/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 14.917312]\n",
      "[Epoch 53/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 14.610497]\n",
      "[Epoch 53/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 15.230503]\n",
      "[Epoch 53/1000] [Batch 57/168] [D loss: 0.000001] [G loss: 14.845850]\n",
      "[Epoch 53/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 14.695751]\n",
      "[Epoch 53/1000] [Batch 59/168] [D loss: 0.000001] [G loss: 14.811867]\n",
      "[Epoch 53/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 14.759841]\n",
      "[Epoch 53/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 14.931092]\n",
      "[Epoch 53/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 14.948594]\n",
      "[Epoch 53/1000] [Batch 63/168] [D loss: 0.000002] [G loss: 14.644971]\n",
      "[Epoch 53/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 14.774138]\n",
      "[Epoch 53/1000] [Batch 65/168] [D loss: 0.000001] [G loss: 14.536333]\n",
      "[Epoch 53/1000] [Batch 66/168] [D loss: 0.000001] [G loss: 14.519064]\n",
      "[Epoch 53/1000] [Batch 67/168] [D loss: 0.000002] [G loss: 14.294590]\n",
      "[Epoch 53/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 14.867517]\n",
      "[Epoch 53/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 14.899521]\n",
      "[Epoch 53/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 14.921355]\n",
      "[Epoch 53/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 14.579747]\n",
      "[Epoch 53/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 15.273685]\n",
      "[Epoch 53/1000] [Batch 73/168] [D loss: 0.000001] [G loss: 15.001116]\n",
      "[Epoch 53/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 14.929188]\n",
      "[Epoch 53/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 14.465328]\n",
      "[Epoch 53/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 14.964981]\n",
      "[Epoch 53/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 14.847891]\n",
      "[Epoch 53/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 14.971132]\n",
      "[Epoch 53/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 14.984511]\n",
      "[Epoch 53/1000] [Batch 80/168] [D loss: 0.000001] [G loss: 15.028483]\n",
      "[Epoch 53/1000] [Batch 81/168] [D loss: 0.000002] [G loss: 14.941325]\n",
      "[Epoch 53/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 14.835679]\n",
      "[Epoch 53/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 14.812585]\n",
      "[Epoch 53/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 14.954252]\n",
      "[Epoch 53/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 14.912459]\n",
      "[Epoch 53/1000] [Batch 86/168] [D loss: 0.000001] [G loss: 14.942091]\n",
      "[Epoch 53/1000] [Batch 87/168] [D loss: 0.000002] [G loss: 14.783150]\n",
      "[Epoch 53/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 15.098934]\n",
      "[Epoch 53/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 14.905800]\n",
      "[Epoch 53/1000] [Batch 90/168] [D loss: 0.000002] [G loss: 14.734543]\n",
      "[Epoch 53/1000] [Batch 91/168] [D loss: 0.000002] [G loss: 14.746547]\n",
      "[Epoch 53/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 14.554216]\n",
      "[Epoch 53/1000] [Batch 93/168] [D loss: 0.000001] [G loss: 14.600702]\n",
      "[Epoch 53/1000] [Batch 94/168] [D loss: 0.000002] [G loss: 15.013260]\n",
      "[Epoch 53/1000] [Batch 95/168] [D loss: 0.000001] [G loss: 15.011972]\n",
      "[Epoch 53/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 14.738666]\n",
      "[Epoch 53/1000] [Batch 97/168] [D loss: 0.000001] [G loss: 14.777936]\n",
      "[Epoch 53/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 14.862776]\n",
      "[Epoch 53/1000] [Batch 99/168] [D loss: 0.000001] [G loss: 14.891769]\n",
      "[Epoch 53/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 15.144217]\n",
      "[Epoch 53/1000] [Batch 101/168] [D loss: 0.000002] [G loss: 14.278503]\n",
      "[Epoch 53/1000] [Batch 102/168] [D loss: 0.000001] [G loss: 14.843143]\n",
      "[Epoch 53/1000] [Batch 103/168] [D loss: 0.000002] [G loss: 15.108140]\n",
      "[Epoch 53/1000] [Batch 104/168] [D loss: 0.000001] [G loss: 14.623787]\n",
      "[Epoch 53/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 14.765499]\n",
      "[Epoch 53/1000] [Batch 106/168] [D loss: 0.000002] [G loss: 14.686415]\n",
      "[Epoch 53/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 14.885535]\n",
      "[Epoch 53/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 14.909493]\n",
      "[Epoch 53/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 14.640018]\n",
      "[Epoch 53/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 14.981892]\n",
      "[Epoch 53/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 14.970551]\n",
      "[Epoch 53/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 14.764067]\n",
      "[Epoch 53/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 14.636332]\n",
      "[Epoch 53/1000] [Batch 114/168] [D loss: 0.000001] [G loss: 14.694069]\n",
      "[Epoch 53/1000] [Batch 115/168] [D loss: 0.000001] [G loss: 14.553638]\n",
      "[Epoch 53/1000] [Batch 116/168] [D loss: 0.000001] [G loss: 14.957535]\n",
      "[Epoch 53/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 14.942712]\n",
      "[Epoch 53/1000] [Batch 118/168] [D loss: 0.000001] [G loss: 14.975733]\n",
      "[Epoch 53/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 14.580713]\n",
      "[Epoch 53/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 15.105812]\n",
      "[Epoch 53/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 14.872320]\n",
      "[Epoch 53/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 15.083942]\n",
      "[Epoch 53/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 15.335753]\n",
      "[Epoch 53/1000] [Batch 124/168] [D loss: 0.000001] [G loss: 14.946507]\n",
      "[Epoch 53/1000] [Batch 125/168] [D loss: 0.000001] [G loss: 14.885679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 14.949680]\n",
      "[Epoch 53/1000] [Batch 127/168] [D loss: 0.000002] [G loss: 14.646760]\n",
      "[Epoch 53/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 14.421614]\n",
      "[Epoch 53/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 14.661684]\n",
      "[Epoch 53/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 14.503865]\n",
      "[Epoch 53/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 14.811085]\n",
      "[Epoch 53/1000] [Batch 132/168] [D loss: 0.000001] [G loss: 14.866642]\n",
      "[Epoch 53/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 14.897306]\n",
      "[Epoch 53/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 14.885761]\n",
      "[Epoch 53/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 14.632441]\n",
      "[Epoch 53/1000] [Batch 136/168] [D loss: 0.000001] [G loss: 14.995319]\n",
      "[Epoch 53/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 14.370727]\n",
      "[Epoch 53/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 14.981997]\n",
      "[Epoch 53/1000] [Batch 139/168] [D loss: 0.000002] [G loss: 15.086324]\n",
      "[Epoch 53/1000] [Batch 140/168] [D loss: 0.000001] [G loss: 14.762390]\n",
      "[Epoch 53/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 14.567906]\n",
      "[Epoch 53/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 15.026680]\n",
      "[Epoch 53/1000] [Batch 143/168] [D loss: 0.000002] [G loss: 14.806746]\n",
      "[Epoch 53/1000] [Batch 144/168] [D loss: 0.000001] [G loss: 15.157333]\n",
      "[Epoch 53/1000] [Batch 145/168] [D loss: 0.000001] [G loss: 14.945789]\n",
      "[Epoch 53/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 14.961099]\n",
      "[Epoch 53/1000] [Batch 147/168] [D loss: 0.000001] [G loss: 15.204494]\n",
      "[Epoch 53/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 14.925613]\n",
      "[Epoch 53/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 14.814778]\n",
      "[Epoch 53/1000] [Batch 150/168] [D loss: 0.000001] [G loss: 14.985899]\n",
      "[Epoch 53/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 14.734327]\n",
      "[Epoch 53/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 15.488256]\n",
      "[Epoch 53/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 15.065862]\n",
      "[Epoch 53/1000] [Batch 154/168] [D loss: 0.000002] [G loss: 14.976375]\n",
      "[Epoch 53/1000] [Batch 155/168] [D loss: 0.000001] [G loss: 14.566056]\n",
      "[Epoch 53/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 15.102579]\n",
      "[Epoch 53/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 15.112364]\n",
      "[Epoch 53/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 14.626903]\n",
      "[Epoch 53/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 15.119344]\n",
      "[Epoch 53/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 15.139441]\n",
      "[Epoch 53/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 14.809994]\n",
      "[Epoch 53/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 15.028272]\n",
      "[Epoch 53/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 14.868488]\n",
      "[Epoch 53/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 15.041351]\n",
      "[Epoch 53/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 14.710313]\n",
      "[Epoch 53/1000] [Batch 166/168] [D loss: 0.000002] [G loss: 15.134079]\n",
      "[Epoch 53/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 14.974577]\n",
      "[Epoch 53/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 14.800856]\n",
      "[Epoch 54/1000] [Batch 1/168] [D loss: 0.000001] [G loss: 14.894472]\n",
      "[Epoch 54/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 15.199065]\n",
      "[Epoch 54/1000] [Batch 3/168] [D loss: 0.000001] [G loss: 15.152430]\n",
      "[Epoch 54/1000] [Batch 4/168] [D loss: 0.000001] [G loss: 15.140619]\n",
      "[Epoch 54/1000] [Batch 5/168] [D loss: 0.000002] [G loss: 14.715693]\n",
      "[Epoch 54/1000] [Batch 6/168] [D loss: 0.000001] [G loss: 14.935473]\n",
      "[Epoch 54/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 14.923292]\n",
      "[Epoch 54/1000] [Batch 8/168] [D loss: 0.000001] [G loss: 14.812037]\n",
      "[Epoch 54/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 14.900105]\n",
      "[Epoch 54/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 15.014216]\n",
      "[Epoch 54/1000] [Batch 11/168] [D loss: 0.000001] [G loss: 14.966198]\n",
      "[Epoch 54/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 15.072811]\n",
      "[Epoch 54/1000] [Batch 13/168] [D loss: 0.000001] [G loss: 14.705156]\n",
      "[Epoch 54/1000] [Batch 14/168] [D loss: 0.000002] [G loss: 14.891644]\n",
      "[Epoch 54/1000] [Batch 15/168] [D loss: 0.000001] [G loss: 14.889219]\n",
      "[Epoch 54/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 14.501040]\n",
      "[Epoch 54/1000] [Batch 17/168] [D loss: 0.000001] [G loss: 14.900900]\n",
      "[Epoch 54/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.223811]\n",
      "[Epoch 54/1000] [Batch 19/168] [D loss: 0.000002] [G loss: 14.926346]\n",
      "[Epoch 54/1000] [Batch 20/168] [D loss: 0.000001] [G loss: 15.192095]\n",
      "[Epoch 54/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 15.141870]\n",
      "[Epoch 54/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 14.853176]\n",
      "[Epoch 54/1000] [Batch 23/168] [D loss: 0.000001] [G loss: 15.010457]\n",
      "[Epoch 54/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 14.984587]\n",
      "[Epoch 54/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 14.937458]\n",
      "[Epoch 54/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 15.260768]\n",
      "[Epoch 54/1000] [Batch 27/168] [D loss: 0.000001] [G loss: 14.811508]\n",
      "[Epoch 54/1000] [Batch 28/168] [D loss: 0.000001] [G loss: 14.812206]\n",
      "[Epoch 54/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 15.246694]\n",
      "[Epoch 54/1000] [Batch 30/168] [D loss: 0.000002] [G loss: 14.894580]\n",
      "[Epoch 54/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 14.584513]\n",
      "[Epoch 54/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 15.149931]\n",
      "[Epoch 54/1000] [Batch 33/168] [D loss: 0.000001] [G loss: 15.375742]\n",
      "[Epoch 54/1000] [Batch 34/168] [D loss: 0.000002] [G loss: 14.802527]\n",
      "[Epoch 54/1000] [Batch 35/168] [D loss: 0.000001] [G loss: 14.972417]\n",
      "[Epoch 54/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 14.774481]\n",
      "[Epoch 54/1000] [Batch 37/168] [D loss: 0.000001] [G loss: 14.845785]\n",
      "[Epoch 54/1000] [Batch 38/168] [D loss: 0.000001] [G loss: 14.931518]\n",
      "[Epoch 54/1000] [Batch 39/168] [D loss: 0.000001] [G loss: 15.213057]\n",
      "[Epoch 54/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 15.009626]\n",
      "[Epoch 54/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 14.761352]\n",
      "[Epoch 54/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 14.969967]\n",
      "[Epoch 54/1000] [Batch 43/168] [D loss: 0.000001] [G loss: 15.350420]\n",
      "[Epoch 54/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 15.166525]\n",
      "[Epoch 54/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 14.775868]\n",
      "[Epoch 54/1000] [Batch 46/168] [D loss: 0.000001] [G loss: 15.190248]\n",
      "[Epoch 54/1000] [Batch 47/168] [D loss: 0.000001] [G loss: 15.030741]\n",
      "[Epoch 54/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 14.889570]\n",
      "[Epoch 54/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 14.993761]\n",
      "[Epoch 54/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 15.180818]\n",
      "[Epoch 54/1000] [Batch 51/168] [D loss: 0.000001] [G loss: 14.948522]\n",
      "[Epoch 54/1000] [Batch 52/168] [D loss: 0.000002] [G loss: 14.972861]\n",
      "[Epoch 54/1000] [Batch 53/168] [D loss: 0.000001] [G loss: 15.189198]\n",
      "[Epoch 54/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 14.535059]\n",
      "[Epoch 54/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 14.632167]\n",
      "[Epoch 54/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 14.995168]\n",
      "[Epoch 54/1000] [Batch 57/168] [D loss: 0.000001] [G loss: 15.428905]\n",
      "[Epoch 54/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 14.942700]\n",
      "[Epoch 54/1000] [Batch 59/168] [D loss: 0.000001] [G loss: 14.876979]\n",
      "[Epoch 54/1000] [Batch 60/168] [D loss: 0.000002] [G loss: 15.081986]\n",
      "[Epoch 54/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 14.972884]\n",
      "[Epoch 54/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 15.170973]\n",
      "[Epoch 54/1000] [Batch 63/168] [D loss: 0.000002] [G loss: 15.085557]\n",
      "[Epoch 54/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 14.491464]\n",
      "[Epoch 54/1000] [Batch 65/168] [D loss: 0.000001] [G loss: 14.862645]\n",
      "[Epoch 54/1000] [Batch 66/168] [D loss: 0.000002] [G loss: 14.996750]\n",
      "[Epoch 54/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 14.944849]\n",
      "[Epoch 54/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 14.748337]\n",
      "[Epoch 54/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 14.709751]\n",
      "[Epoch 54/1000] [Batch 70/168] [D loss: 0.000002] [G loss: 15.381767]\n",
      "[Epoch 54/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 14.948877]\n",
      "[Epoch 54/1000] [Batch 72/168] [D loss: 0.000002] [G loss: 15.029202]\n",
      "[Epoch 54/1000] [Batch 73/168] [D loss: 0.000001] [G loss: 15.089887]\n",
      "[Epoch 54/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 14.706896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 15.259480]\n",
      "[Epoch 54/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 15.035451]\n",
      "[Epoch 54/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 15.222939]\n",
      "[Epoch 54/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 14.993149]\n",
      "[Epoch 54/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 14.802127]\n",
      "[Epoch 54/1000] [Batch 80/168] [D loss: 0.000001] [G loss: 14.588657]\n",
      "[Epoch 54/1000] [Batch 81/168] [D loss: 0.000001] [G loss: 15.454507]\n",
      "[Epoch 54/1000] [Batch 82/168] [D loss: 0.000002] [G loss: 15.038569]\n",
      "[Epoch 54/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 14.937197]\n",
      "[Epoch 54/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 14.889347]\n",
      "[Epoch 54/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 14.550035]\n",
      "[Epoch 54/1000] [Batch 86/168] [D loss: 0.000001] [G loss: 14.792885]\n",
      "[Epoch 54/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.253553]\n",
      "[Epoch 54/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 14.892704]\n",
      "[Epoch 54/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 14.873534]\n",
      "[Epoch 54/1000] [Batch 90/168] [D loss: 0.000001] [G loss: 15.207097]\n",
      "[Epoch 54/1000] [Batch 91/168] [D loss: 0.000001] [G loss: 15.227382]\n",
      "[Epoch 54/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 15.046182]\n",
      "[Epoch 54/1000] [Batch 93/168] [D loss: 0.000001] [G loss: 14.832565]\n",
      "[Epoch 54/1000] [Batch 94/168] [D loss: 0.000001] [G loss: 15.263390]\n",
      "[Epoch 54/1000] [Batch 95/168] [D loss: 0.000001] [G loss: 14.778346]\n",
      "[Epoch 54/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 15.450306]\n",
      "[Epoch 54/1000] [Batch 97/168] [D loss: 0.000001] [G loss: 14.849442]\n",
      "[Epoch 54/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 14.796059]\n",
      "[Epoch 54/1000] [Batch 99/168] [D loss: 0.000001] [G loss: 15.111683]\n",
      "[Epoch 54/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 14.974997]\n",
      "[Epoch 54/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 15.261147]\n",
      "[Epoch 54/1000] [Batch 102/168] [D loss: 0.000001] [G loss: 15.105747]\n",
      "[Epoch 54/1000] [Batch 103/168] [D loss: 0.000001] [G loss: 14.869856]\n",
      "[Epoch 54/1000] [Batch 104/168] [D loss: 0.000001] [G loss: 15.050095]\n",
      "[Epoch 54/1000] [Batch 105/168] [D loss: 0.000002] [G loss: 15.243924]\n",
      "[Epoch 54/1000] [Batch 106/168] [D loss: 0.000001] [G loss: 14.764884]\n",
      "[Epoch 54/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 15.318609]\n",
      "[Epoch 54/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 15.435468]\n",
      "[Epoch 54/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 14.973847]\n",
      "[Epoch 54/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 15.077839]\n",
      "[Epoch 54/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 14.920420]\n",
      "[Epoch 54/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 15.157443]\n",
      "[Epoch 54/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 15.144262]\n",
      "[Epoch 54/1000] [Batch 114/168] [D loss: 0.000001] [G loss: 15.027927]\n",
      "[Epoch 54/1000] [Batch 115/168] [D loss: 0.000002] [G loss: 14.735018]\n",
      "[Epoch 54/1000] [Batch 116/168] [D loss: 0.000001] [G loss: 15.015124]\n",
      "[Epoch 54/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 15.318832]\n",
      "[Epoch 54/1000] [Batch 118/168] [D loss: 0.000001] [G loss: 15.060115]\n",
      "[Epoch 54/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 15.300249]\n",
      "[Epoch 54/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 14.923920]\n",
      "[Epoch 54/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 14.667639]\n",
      "[Epoch 54/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 14.665142]\n",
      "[Epoch 54/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 15.100177]\n",
      "[Epoch 54/1000] [Batch 124/168] [D loss: 0.000001] [G loss: 14.849295]\n",
      "[Epoch 54/1000] [Batch 125/168] [D loss: 0.000002] [G loss: 14.950214]\n",
      "[Epoch 54/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 14.918910]\n",
      "[Epoch 54/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 15.153990]\n",
      "[Epoch 54/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 14.843373]\n",
      "[Epoch 54/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 14.928219]\n",
      "[Epoch 54/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 14.914827]\n",
      "[Epoch 54/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 15.491376]\n",
      "[Epoch 54/1000] [Batch 132/168] [D loss: 0.000001] [G loss: 15.009828]\n",
      "[Epoch 54/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 15.310983]\n",
      "[Epoch 54/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 14.880944]\n",
      "[Epoch 54/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 14.709772]\n",
      "[Epoch 54/1000] [Batch 136/168] [D loss: 0.000002] [G loss: 14.827450]\n",
      "[Epoch 54/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 15.242647]\n",
      "[Epoch 54/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 15.043027]\n",
      "[Epoch 54/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 15.065435]\n",
      "[Epoch 54/1000] [Batch 140/168] [D loss: 0.000002] [G loss: 15.204482]\n",
      "[Epoch 54/1000] [Batch 141/168] [D loss: 0.000002] [G loss: 14.933592]\n",
      "[Epoch 54/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 15.085629]\n",
      "[Epoch 54/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 14.804694]\n",
      "[Epoch 54/1000] [Batch 144/168] [D loss: 0.000001] [G loss: 15.343052]\n",
      "[Epoch 54/1000] [Batch 145/168] [D loss: 0.000001] [G loss: 15.174156]\n",
      "[Epoch 54/1000] [Batch 146/168] [D loss: 0.000002] [G loss: 14.898905]\n",
      "[Epoch 54/1000] [Batch 147/168] [D loss: 0.000001] [G loss: 14.806514]\n",
      "[Epoch 54/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 15.175502]\n",
      "[Epoch 54/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 15.057206]\n",
      "[Epoch 54/1000] [Batch 150/168] [D loss: 0.000001] [G loss: 14.860268]\n",
      "[Epoch 54/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 15.017009]\n",
      "[Epoch 54/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 14.977354]\n",
      "[Epoch 54/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 15.162110]\n",
      "[Epoch 54/1000] [Batch 154/168] [D loss: 0.000001] [G loss: 15.344329]\n",
      "[Epoch 54/1000] [Batch 155/168] [D loss: 0.000001] [G loss: 14.860528]\n",
      "[Epoch 54/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 15.008331]\n",
      "[Epoch 54/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 15.093683]\n",
      "[Epoch 54/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 14.985922]\n",
      "[Epoch 54/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 15.252481]\n",
      "[Epoch 54/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 15.202437]\n",
      "[Epoch 54/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 14.718512]\n",
      "[Epoch 54/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 14.943740]\n",
      "[Epoch 54/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 15.330983]\n",
      "[Epoch 54/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 14.991874]\n",
      "[Epoch 54/1000] [Batch 165/168] [D loss: 0.000002] [G loss: 14.935639]\n",
      "[Epoch 54/1000] [Batch 166/168] [D loss: 0.000002] [G loss: 14.964938]\n",
      "[Epoch 54/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 15.042880]\n",
      "[Epoch 54/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 15.006931]\n",
      "[Epoch 55/1000] [Batch 1/168] [D loss: 0.000002] [G loss: 15.301323]\n",
      "[Epoch 55/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 14.852182]\n",
      "[Epoch 55/1000] [Batch 3/168] [D loss: 0.000001] [G loss: 14.648670]\n",
      "[Epoch 55/1000] [Batch 4/168] [D loss: 0.000001] [G loss: 15.051239]\n",
      "[Epoch 55/1000] [Batch 5/168] [D loss: 0.000001] [G loss: 14.952199]\n",
      "[Epoch 55/1000] [Batch 6/168] [D loss: 0.000001] [G loss: 14.646618]\n",
      "[Epoch 55/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 15.148548]\n",
      "[Epoch 55/1000] [Batch 8/168] [D loss: 0.000001] [G loss: 15.100956]\n",
      "[Epoch 55/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 14.942746]\n",
      "[Epoch 55/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 14.917382]\n",
      "[Epoch 55/1000] [Batch 11/168] [D loss: 0.000001] [G loss: 14.925625]\n",
      "[Epoch 55/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 15.484327]\n",
      "[Epoch 55/1000] [Batch 13/168] [D loss: 0.000002] [G loss: 15.017389]\n",
      "[Epoch 55/1000] [Batch 14/168] [D loss: 0.000001] [G loss: 14.876753]\n",
      "[Epoch 55/1000] [Batch 15/168] [D loss: 0.000001] [G loss: 14.936234]\n",
      "[Epoch 55/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 14.935225]\n",
      "[Epoch 55/1000] [Batch 17/168] [D loss: 0.000001] [G loss: 15.186878]\n",
      "[Epoch 55/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.109659]\n",
      "[Epoch 55/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 15.285547]\n",
      "[Epoch 55/1000] [Batch 20/168] [D loss: 0.000002] [G loss: 14.869815]\n",
      "[Epoch 55/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 15.094984]\n",
      "[Epoch 55/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 14.821536]\n",
      "[Epoch 55/1000] [Batch 23/168] [D loss: 0.000001] [G loss: 14.954276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 15.238645]\n",
      "[Epoch 55/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 15.231400]\n",
      "[Epoch 55/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 15.133035]\n",
      "[Epoch 55/1000] [Batch 27/168] [D loss: 0.000001] [G loss: 14.994989]\n",
      "[Epoch 55/1000] [Batch 28/168] [D loss: 0.000001] [G loss: 15.152727]\n",
      "[Epoch 55/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 15.248848]\n",
      "[Epoch 55/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 14.873654]\n",
      "[Epoch 55/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 14.951186]\n",
      "[Epoch 55/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 14.705988]\n",
      "[Epoch 55/1000] [Batch 33/168] [D loss: 0.000001] [G loss: 15.360524]\n",
      "[Epoch 55/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 15.061961]\n",
      "[Epoch 55/1000] [Batch 35/168] [D loss: 0.000001] [G loss: 15.056122]\n",
      "[Epoch 55/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 14.894190]\n",
      "[Epoch 55/1000] [Batch 37/168] [D loss: 0.000001] [G loss: 14.992392]\n",
      "[Epoch 55/1000] [Batch 38/168] [D loss: 0.000001] [G loss: 15.174637]\n",
      "[Epoch 55/1000] [Batch 39/168] [D loss: 0.000001] [G loss: 15.095694]\n",
      "[Epoch 55/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 15.154158]\n",
      "[Epoch 55/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 15.281624]\n",
      "[Epoch 55/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 15.291182]\n",
      "[Epoch 55/1000] [Batch 43/168] [D loss: 0.000001] [G loss: 14.624788]\n",
      "[Epoch 55/1000] [Batch 44/168] [D loss: 0.000002] [G loss: 14.994109]\n",
      "[Epoch 55/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 14.868452]\n",
      "[Epoch 55/1000] [Batch 46/168] [D loss: 0.000001] [G loss: 15.167603]\n",
      "[Epoch 55/1000] [Batch 47/168] [D loss: 0.000001] [G loss: 15.417152]\n",
      "[Epoch 55/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 14.894937]\n",
      "[Epoch 55/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 15.076105]\n",
      "[Epoch 55/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 15.019196]\n",
      "[Epoch 55/1000] [Batch 51/168] [D loss: 0.000001] [G loss: 15.232198]\n",
      "[Epoch 55/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.026365]\n",
      "[Epoch 55/1000] [Batch 53/168] [D loss: 0.000001] [G loss: 15.378181]\n",
      "[Epoch 55/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 15.367563]\n",
      "[Epoch 55/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 15.047132]\n",
      "[Epoch 55/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 15.275311]\n",
      "[Epoch 55/1000] [Batch 57/168] [D loss: 0.000002] [G loss: 15.156924]\n",
      "[Epoch 55/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 14.828798]\n",
      "[Epoch 55/1000] [Batch 59/168] [D loss: 0.000001] [G loss: 15.070494]\n",
      "[Epoch 55/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 14.847109]\n",
      "[Epoch 55/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 15.262025]\n",
      "[Epoch 55/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 15.494617]\n",
      "[Epoch 55/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 15.089757]\n",
      "[Epoch 55/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 15.000749]\n",
      "[Epoch 55/1000] [Batch 65/168] [D loss: 0.000001] [G loss: 14.996318]\n",
      "[Epoch 55/1000] [Batch 66/168] [D loss: 0.000001] [G loss: 14.777817]\n",
      "[Epoch 55/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 15.292903]\n",
      "[Epoch 55/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 14.924013]\n",
      "[Epoch 55/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 15.026489]\n",
      "[Epoch 55/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 15.433561]\n",
      "[Epoch 55/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 15.095733]\n",
      "[Epoch 55/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 14.892403]\n",
      "[Epoch 55/1000] [Batch 73/168] [D loss: 0.000001] [G loss: 15.081626]\n",
      "[Epoch 55/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 15.131063]\n",
      "[Epoch 55/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 15.160681]\n",
      "[Epoch 55/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 15.164392]\n",
      "[Epoch 55/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 14.949638]\n",
      "[Epoch 55/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 14.973177]\n",
      "[Epoch 55/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 15.408741]\n",
      "[Epoch 55/1000] [Batch 80/168] [D loss: 0.000001] [G loss: 15.188099]\n",
      "[Epoch 55/1000] [Batch 81/168] [D loss: 0.000001] [G loss: 15.051746]\n",
      "[Epoch 55/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 14.660359]\n",
      "[Epoch 55/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 14.851974]\n",
      "[Epoch 55/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 14.738266]\n",
      "[Epoch 55/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 15.370093]\n",
      "[Epoch 55/1000] [Batch 86/168] [D loss: 0.000001] [G loss: 15.395502]\n",
      "[Epoch 55/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.112835]\n",
      "[Epoch 55/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 14.940825]\n",
      "[Epoch 55/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 15.666164]\n",
      "[Epoch 55/1000] [Batch 90/168] [D loss: 0.000001] [G loss: 15.122845]\n",
      "[Epoch 55/1000] [Batch 91/168] [D loss: 0.000001] [G loss: 15.091957]\n",
      "[Epoch 55/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 14.818684]\n",
      "[Epoch 55/1000] [Batch 93/168] [D loss: 0.000001] [G loss: 15.358509]\n",
      "[Epoch 55/1000] [Batch 94/168] [D loss: 0.000001] [G loss: 14.895355]\n",
      "[Epoch 55/1000] [Batch 95/168] [D loss: 0.000003] [G loss: 15.220697]\n",
      "[Epoch 55/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 15.113434]\n",
      "[Epoch 55/1000] [Batch 97/168] [D loss: 0.000002] [G loss: 15.501975]\n",
      "[Epoch 55/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 14.943338]\n",
      "[Epoch 55/1000] [Batch 99/168] [D loss: 0.000002] [G loss: 15.083192]\n",
      "[Epoch 55/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 15.303920]\n",
      "[Epoch 55/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 15.399063]\n",
      "[Epoch 55/1000] [Batch 102/168] [D loss: 0.000001] [G loss: 15.089823]\n",
      "[Epoch 55/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 15.029788]\n",
      "[Epoch 55/1000] [Batch 104/168] [D loss: 0.000001] [G loss: 15.163483]\n",
      "[Epoch 55/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 15.387127]\n",
      "[Epoch 55/1000] [Batch 106/168] [D loss: 0.000001] [G loss: 14.875509]\n",
      "[Epoch 55/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 15.122067]\n",
      "[Epoch 55/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 15.167622]\n",
      "[Epoch 55/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 14.797409]\n",
      "[Epoch 55/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 15.195019]\n",
      "[Epoch 55/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 14.983464]\n",
      "[Epoch 55/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 15.041868]\n",
      "[Epoch 55/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 15.433773]\n",
      "[Epoch 55/1000] [Batch 114/168] [D loss: 0.000001] [G loss: 15.161508]\n",
      "[Epoch 55/1000] [Batch 115/168] [D loss: 0.000001] [G loss: 15.203844]\n",
      "[Epoch 55/1000] [Batch 116/168] [D loss: 0.000001] [G loss: 15.240366]\n",
      "[Epoch 55/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 15.565078]\n",
      "[Epoch 55/1000] [Batch 118/168] [D loss: 0.000001] [G loss: 15.391470]\n",
      "[Epoch 55/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 15.156403]\n",
      "[Epoch 55/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 15.085608]\n",
      "[Epoch 55/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 15.024273]\n",
      "[Epoch 55/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 15.298783]\n",
      "[Epoch 55/1000] [Batch 123/168] [D loss: 0.000002] [G loss: 14.498381]\n",
      "[Epoch 55/1000] [Batch 124/168] [D loss: 0.000001] [G loss: 15.381433]\n",
      "[Epoch 55/1000] [Batch 125/168] [D loss: 0.000001] [G loss: 15.392494]\n",
      "[Epoch 55/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 15.373134]\n",
      "[Epoch 55/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 15.076979]\n",
      "[Epoch 55/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 15.148388]\n",
      "[Epoch 55/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 15.082336]\n",
      "[Epoch 55/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 15.236009]\n",
      "[Epoch 55/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 14.961319]\n",
      "[Epoch 55/1000] [Batch 132/168] [D loss: 0.000003] [G loss: 15.104989]\n",
      "[Epoch 55/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 14.952511]\n",
      "[Epoch 55/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.062897]\n",
      "[Epoch 55/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 15.285583]\n",
      "[Epoch 55/1000] [Batch 136/168] [D loss: 0.000001] [G loss: 15.325889]\n",
      "[Epoch 55/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 15.114194]\n",
      "[Epoch 55/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 15.297169]\n",
      "[Epoch 55/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 15.191073]\n",
      "[Epoch 55/1000] [Batch 140/168] [D loss: 0.000001] [G loss: 15.356584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 15.629599]\n",
      "[Epoch 55/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 15.292392]\n",
      "[Epoch 55/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 15.222639]\n",
      "[Epoch 55/1000] [Batch 144/168] [D loss: 0.000001] [G loss: 15.231606]\n",
      "[Epoch 55/1000] [Batch 145/168] [D loss: 0.000001] [G loss: 15.489923]\n",
      "[Epoch 55/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 15.254930]\n",
      "[Epoch 55/1000] [Batch 147/168] [D loss: 0.000001] [G loss: 14.742357]\n",
      "[Epoch 55/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 15.400855]\n",
      "[Epoch 55/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 15.019457]\n",
      "[Epoch 55/1000] [Batch 150/168] [D loss: 0.000003] [G loss: 15.043271]\n",
      "[Epoch 55/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 15.355899]\n",
      "[Epoch 55/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 15.306372]\n",
      "[Epoch 55/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 15.241499]\n",
      "[Epoch 55/1000] [Batch 154/168] [D loss: 0.000001] [G loss: 15.288355]\n",
      "[Epoch 55/1000] [Batch 155/168] [D loss: 0.000001] [G loss: 15.293336]\n",
      "[Epoch 55/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 15.022496]\n",
      "[Epoch 55/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 15.391203]\n",
      "[Epoch 55/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 15.382957]\n",
      "[Epoch 55/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 14.896553]\n",
      "[Epoch 55/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 15.057867]\n",
      "[Epoch 55/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 15.536582]\n",
      "[Epoch 55/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 15.042570]\n",
      "[Epoch 55/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 15.159929]\n",
      "[Epoch 55/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 15.454441]\n",
      "[Epoch 55/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 15.012021]\n",
      "[Epoch 55/1000] [Batch 166/168] [D loss: 0.000001] [G loss: 15.245673]\n",
      "[Epoch 55/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 15.235979]\n",
      "[Epoch 55/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 14.935647]\n",
      "[Epoch 56/1000] [Batch 1/168] [D loss: 0.000001] [G loss: 15.338253]\n",
      "[Epoch 56/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 15.358021]\n",
      "[Epoch 56/1000] [Batch 3/168] [D loss: 0.000002] [G loss: 14.877667]\n",
      "[Epoch 56/1000] [Batch 4/168] [D loss: 0.000001] [G loss: 15.371803]\n",
      "[Epoch 56/1000] [Batch 5/168] [D loss: 0.000001] [G loss: 15.245739]\n",
      "[Epoch 56/1000] [Batch 6/168] [D loss: 0.000001] [G loss: 15.279966]\n",
      "[Epoch 56/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 15.018380]\n",
      "[Epoch 56/1000] [Batch 8/168] [D loss: 0.000001] [G loss: 15.117743]\n",
      "[Epoch 56/1000] [Batch 9/168] [D loss: 0.000002] [G loss: 15.014690]\n",
      "[Epoch 56/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 15.234907]\n",
      "[Epoch 56/1000] [Batch 11/168] [D loss: 0.000001] [G loss: 15.165086]\n",
      "[Epoch 56/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 15.239897]\n",
      "[Epoch 56/1000] [Batch 13/168] [D loss: 0.000004] [G loss: 15.328993]\n",
      "[Epoch 56/1000] [Batch 14/168] [D loss: 0.000001] [G loss: 15.175840]\n",
      "[Epoch 56/1000] [Batch 15/168] [D loss: 0.000001] [G loss: 15.018847]\n",
      "[Epoch 56/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 15.381791]\n",
      "[Epoch 56/1000] [Batch 17/168] [D loss: 0.000001] [G loss: 14.872085]\n",
      "[Epoch 56/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.593836]\n",
      "[Epoch 56/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 15.170956]\n",
      "[Epoch 56/1000] [Batch 20/168] [D loss: 0.000001] [G loss: 15.298190]\n",
      "[Epoch 56/1000] [Batch 21/168] [D loss: 0.000002] [G loss: 15.150182]\n",
      "[Epoch 56/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 14.969708]\n",
      "[Epoch 56/1000] [Batch 23/168] [D loss: 0.000002] [G loss: 15.209300]\n",
      "[Epoch 56/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 15.677147]\n",
      "[Epoch 56/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 15.277565]\n",
      "[Epoch 56/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 15.471432]\n",
      "[Epoch 56/1000] [Batch 27/168] [D loss: 0.000002] [G loss: 15.075994]\n",
      "[Epoch 56/1000] [Batch 28/168] [D loss: 0.000001] [G loss: 15.148350]\n",
      "[Epoch 56/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 15.092671]\n",
      "[Epoch 56/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 15.247607]\n",
      "[Epoch 56/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 15.309895]\n",
      "[Epoch 56/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 15.165669]\n",
      "[Epoch 56/1000] [Batch 33/168] [D loss: 0.000001] [G loss: 15.449287]\n",
      "[Epoch 56/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 15.294020]\n",
      "[Epoch 56/1000] [Batch 35/168] [D loss: 0.000001] [G loss: 15.417211]\n",
      "[Epoch 56/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 15.018166]\n",
      "[Epoch 56/1000] [Batch 37/168] [D loss: 0.000001] [G loss: 14.665334]\n",
      "[Epoch 56/1000] [Batch 38/168] [D loss: 0.000001] [G loss: 15.440219]\n",
      "[Epoch 56/1000] [Batch 39/168] [D loss: 0.000001] [G loss: 15.378647]\n",
      "[Epoch 56/1000] [Batch 40/168] [D loss: 0.000002] [G loss: 15.156208]\n",
      "[Epoch 56/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 15.429968]\n",
      "[Epoch 56/1000] [Batch 42/168] [D loss: 0.000002] [G loss: 15.444300]\n",
      "[Epoch 56/1000] [Batch 43/168] [D loss: 0.000001] [G loss: 15.263287]\n",
      "[Epoch 56/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 15.002794]\n",
      "[Epoch 56/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 15.211950]\n",
      "[Epoch 56/1000] [Batch 46/168] [D loss: 0.000001] [G loss: 15.265942]\n",
      "[Epoch 56/1000] [Batch 47/168] [D loss: 0.000003] [G loss: 14.881354]\n",
      "[Epoch 56/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 15.773552]\n",
      "[Epoch 56/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 14.989364]\n",
      "[Epoch 56/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 15.679476]\n",
      "[Epoch 56/1000] [Batch 51/168] [D loss: 0.000001] [G loss: 15.244838]\n",
      "[Epoch 56/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.344883]\n",
      "[Epoch 56/1000] [Batch 53/168] [D loss: 0.000001] [G loss: 15.031851]\n",
      "[Epoch 56/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 15.254690]\n",
      "[Epoch 56/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 15.168782]\n",
      "[Epoch 56/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 15.510138]\n",
      "[Epoch 56/1000] [Batch 57/168] [D loss: 0.000001] [G loss: 15.249270]\n",
      "[Epoch 56/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 15.230960]\n",
      "[Epoch 56/1000] [Batch 59/168] [D loss: 0.000001] [G loss: 14.812142]\n",
      "[Epoch 56/1000] [Batch 60/168] [D loss: 0.000002] [G loss: 14.965456]\n",
      "[Epoch 56/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 15.594234]\n",
      "[Epoch 56/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 15.294677]\n",
      "[Epoch 56/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 14.967705]\n",
      "[Epoch 56/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 14.879809]\n",
      "[Epoch 56/1000] [Batch 65/168] [D loss: 0.000001] [G loss: 15.047170]\n",
      "[Epoch 56/1000] [Batch 66/168] [D loss: 0.000001] [G loss: 14.739293]\n",
      "[Epoch 56/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 15.098313]\n",
      "[Epoch 56/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 15.442421]\n",
      "[Epoch 56/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 15.063592]\n",
      "[Epoch 56/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 14.898218]\n",
      "[Epoch 56/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 15.377251]\n",
      "[Epoch 56/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 15.448370]\n",
      "[Epoch 56/1000] [Batch 73/168] [D loss: 0.000001] [G loss: 15.173032]\n",
      "[Epoch 56/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 15.361720]\n",
      "[Epoch 56/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 15.364698]\n",
      "[Epoch 56/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 15.220263]\n",
      "[Epoch 56/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 15.280445]\n",
      "[Epoch 56/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 15.100096]\n",
      "[Epoch 56/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 15.458520]\n",
      "[Epoch 56/1000] [Batch 80/168] [D loss: 0.000001] [G loss: 15.210325]\n",
      "[Epoch 56/1000] [Batch 81/168] [D loss: 0.000001] [G loss: 15.291457]\n",
      "[Epoch 56/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 15.093008]\n",
      "[Epoch 56/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 15.003645]\n",
      "[Epoch 56/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 15.662028]\n",
      "[Epoch 56/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 15.049807]\n",
      "[Epoch 56/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 15.354291]\n",
      "[Epoch 56/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.269855]\n",
      "[Epoch 56/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 15.297301]\n",
      "[Epoch 56/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 15.284746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56/1000] [Batch 90/168] [D loss: 0.000001] [G loss: 15.210285]\n",
      "[Epoch 56/1000] [Batch 91/168] [D loss: 0.000001] [G loss: 15.092964]\n",
      "[Epoch 56/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 14.688706]\n",
      "[Epoch 56/1000] [Batch 93/168] [D loss: 0.000001] [G loss: 15.355027]\n",
      "[Epoch 56/1000] [Batch 94/168] [D loss: 0.000001] [G loss: 15.157404]\n",
      "[Epoch 56/1000] [Batch 95/168] [D loss: 0.000001] [G loss: 14.967383]\n",
      "[Epoch 56/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 15.472529]\n",
      "[Epoch 56/1000] [Batch 97/168] [D loss: 0.000001] [G loss: 15.184965]\n",
      "[Epoch 56/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 15.404480]\n",
      "[Epoch 56/1000] [Batch 99/168] [D loss: 0.000001] [G loss: 15.197481]\n",
      "[Epoch 56/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 15.194956]\n",
      "[Epoch 56/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 15.418718]\n",
      "[Epoch 56/1000] [Batch 102/168] [D loss: 0.000001] [G loss: 15.031647]\n",
      "[Epoch 56/1000] [Batch 103/168] [D loss: 0.000001] [G loss: 15.301721]\n",
      "[Epoch 56/1000] [Batch 104/168] [D loss: 0.000001] [G loss: 15.547353]\n",
      "[Epoch 56/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 15.284010]\n",
      "[Epoch 56/1000] [Batch 106/168] [D loss: 0.000001] [G loss: 14.930387]\n",
      "[Epoch 56/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 15.216238]\n",
      "[Epoch 56/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 15.298746]\n",
      "[Epoch 56/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 15.143190]\n",
      "[Epoch 56/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 15.161280]\n",
      "[Epoch 56/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 15.432645]\n",
      "[Epoch 56/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 15.141510]\n",
      "[Epoch 56/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 15.297224]\n",
      "[Epoch 56/1000] [Batch 114/168] [D loss: 0.000001] [G loss: 15.095952]\n",
      "[Epoch 56/1000] [Batch 115/168] [D loss: 0.000001] [G loss: 15.236895]\n",
      "[Epoch 56/1000] [Batch 116/168] [D loss: 0.000001] [G loss: 15.076507]\n",
      "[Epoch 56/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 15.133299]\n",
      "[Epoch 56/1000] [Batch 118/168] [D loss: 0.000001] [G loss: 15.245686]\n",
      "[Epoch 56/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 15.262808]\n",
      "[Epoch 56/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 15.251608]\n",
      "[Epoch 56/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 15.420264]\n",
      "[Epoch 56/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 14.887785]\n",
      "[Epoch 56/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 15.054444]\n",
      "[Epoch 56/1000] [Batch 124/168] [D loss: 0.000001] [G loss: 15.527328]\n",
      "[Epoch 56/1000] [Batch 125/168] [D loss: 0.000001] [G loss: 15.492984]\n",
      "[Epoch 56/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 15.049417]\n",
      "[Epoch 56/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 15.189575]\n",
      "[Epoch 56/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 15.047573]\n",
      "[Epoch 56/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 15.027970]\n",
      "[Epoch 56/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 15.243284]\n",
      "[Epoch 56/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 15.416685]\n",
      "[Epoch 56/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 15.332155]\n",
      "[Epoch 56/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 15.384418]\n",
      "[Epoch 56/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.630460]\n",
      "[Epoch 56/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 15.225807]\n",
      "[Epoch 56/1000] [Batch 136/168] [D loss: 0.000001] [G loss: 15.403975]\n",
      "[Epoch 56/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 15.040950]\n",
      "[Epoch 56/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 15.250839]\n",
      "[Epoch 56/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 15.460705]\n",
      "[Epoch 56/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 15.430742]\n",
      "[Epoch 56/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 15.507024]\n",
      "[Epoch 56/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 15.608377]\n",
      "[Epoch 56/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 15.118328]\n",
      "[Epoch 56/1000] [Batch 144/168] [D loss: 0.000001] [G loss: 15.391836]\n",
      "[Epoch 56/1000] [Batch 145/168] [D loss: 0.000001] [G loss: 15.597525]\n",
      "[Epoch 56/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 15.359671]\n",
      "[Epoch 56/1000] [Batch 147/168] [D loss: 0.000001] [G loss: 15.336156]\n",
      "[Epoch 56/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 15.460882]\n",
      "[Epoch 56/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 15.402439]\n",
      "[Epoch 56/1000] [Batch 150/168] [D loss: 0.000001] [G loss: 15.530266]\n",
      "[Epoch 56/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 14.836214]\n",
      "[Epoch 56/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 15.534245]\n",
      "[Epoch 56/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 15.004255]\n",
      "[Epoch 56/1000] [Batch 154/168] [D loss: 0.000001] [G loss: 15.308343]\n",
      "[Epoch 56/1000] [Batch 155/168] [D loss: 0.000001] [G loss: 15.418845]\n",
      "[Epoch 56/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 14.877694]\n",
      "[Epoch 56/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 15.670414]\n",
      "[Epoch 56/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 15.253753]\n",
      "[Epoch 56/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 15.565607]\n",
      "[Epoch 56/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 15.138418]\n",
      "[Epoch 56/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 15.333444]\n",
      "[Epoch 56/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 15.467268]\n",
      "[Epoch 56/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 15.169141]\n",
      "[Epoch 56/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 15.253948]\n",
      "[Epoch 56/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 15.171218]\n",
      "[Epoch 56/1000] [Batch 166/168] [D loss: 0.000001] [G loss: 15.478575]\n",
      "[Epoch 56/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 15.569298]\n",
      "[Epoch 56/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 15.284261]\n",
      "[Epoch 57/1000] [Batch 1/168] [D loss: 0.000001] [G loss: 14.893145]\n",
      "[Epoch 57/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 15.473948]\n",
      "[Epoch 57/1000] [Batch 3/168] [D loss: 0.000001] [G loss: 15.375948]\n",
      "[Epoch 57/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 15.376828]\n",
      "[Epoch 57/1000] [Batch 5/168] [D loss: 0.000001] [G loss: 15.182096]\n",
      "[Epoch 57/1000] [Batch 6/168] [D loss: 0.000001] [G loss: 15.529177]\n",
      "[Epoch 57/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 15.206651]\n",
      "[Epoch 57/1000] [Batch 8/168] [D loss: 0.000001] [G loss: 15.766989]\n",
      "[Epoch 57/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 15.227884]\n",
      "[Epoch 57/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 15.707971]\n",
      "[Epoch 57/1000] [Batch 11/168] [D loss: 0.000001] [G loss: 15.432337]\n",
      "[Epoch 57/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 15.424581]\n",
      "[Epoch 57/1000] [Batch 13/168] [D loss: 0.000001] [G loss: 15.521473]\n",
      "[Epoch 57/1000] [Batch 14/168] [D loss: 0.000001] [G loss: 14.995857]\n",
      "[Epoch 57/1000] [Batch 15/168] [D loss: 0.000001] [G loss: 15.358112]\n",
      "[Epoch 57/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 15.422739]\n",
      "[Epoch 57/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 15.274014]\n",
      "[Epoch 57/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.728477]\n",
      "[Epoch 57/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 15.370443]\n",
      "[Epoch 57/1000] [Batch 20/168] [D loss: 0.000001] [G loss: 15.253099]\n",
      "[Epoch 57/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 15.326831]\n",
      "[Epoch 57/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 15.515262]\n",
      "[Epoch 57/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 15.720785]\n",
      "[Epoch 57/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 15.258009]\n",
      "[Epoch 57/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 15.807375]\n",
      "[Epoch 57/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 15.332815]\n",
      "[Epoch 57/1000] [Batch 27/168] [D loss: 0.000001] [G loss: 15.199421]\n",
      "[Epoch 57/1000] [Batch 28/168] [D loss: 0.000001] [G loss: 15.185856]\n",
      "[Epoch 57/1000] [Batch 29/168] [D loss: 0.000002] [G loss: 15.744452]\n",
      "[Epoch 57/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 15.128428]\n",
      "[Epoch 57/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 15.712355]\n",
      "[Epoch 57/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 15.227142]\n",
      "[Epoch 57/1000] [Batch 33/168] [D loss: 0.000001] [G loss: 15.555255]\n",
      "[Epoch 57/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 15.321184]\n",
      "[Epoch 57/1000] [Batch 35/168] [D loss: 0.000001] [G loss: 15.356602]\n",
      "[Epoch 57/1000] [Batch 36/168] [D loss: 0.000002] [G loss: 15.056623]\n",
      "[Epoch 57/1000] [Batch 37/168] [D loss: 0.000001] [G loss: 15.528708]\n",
      "[Epoch 57/1000] [Batch 38/168] [D loss: 0.000001] [G loss: 15.460281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/1000] [Batch 39/168] [D loss: 0.000001] [G loss: 15.458447]\n",
      "[Epoch 57/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 15.364098]\n",
      "[Epoch 57/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 15.326337]\n",
      "[Epoch 57/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 15.170193]\n",
      "[Epoch 57/1000] [Batch 43/168] [D loss: 0.000001] [G loss: 15.271946]\n",
      "[Epoch 57/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 15.358213]\n",
      "[Epoch 57/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 15.450322]\n",
      "[Epoch 57/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 15.415733]\n",
      "[Epoch 57/1000] [Batch 47/168] [D loss: 0.000001] [G loss: 15.116835]\n",
      "[Epoch 57/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 15.256735]\n",
      "[Epoch 57/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 15.382655]\n",
      "[Epoch 57/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 15.089815]\n",
      "[Epoch 57/1000] [Batch 51/168] [D loss: 0.000002] [G loss: 15.302303]\n",
      "[Epoch 57/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.492741]\n",
      "[Epoch 57/1000] [Batch 53/168] [D loss: 0.000001] [G loss: 15.124717]\n",
      "[Epoch 57/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 15.473676]\n",
      "[Epoch 57/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 15.256750]\n",
      "[Epoch 57/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 15.450753]\n",
      "[Epoch 57/1000] [Batch 57/168] [D loss: 0.000002] [G loss: 14.899597]\n",
      "[Epoch 57/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 15.617124]\n",
      "[Epoch 57/1000] [Batch 59/168] [D loss: 0.000001] [G loss: 15.437074]\n",
      "[Epoch 57/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 15.498402]\n",
      "[Epoch 57/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 15.385129]\n",
      "[Epoch 57/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 15.095997]\n",
      "[Epoch 57/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 15.225112]\n",
      "[Epoch 57/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 16.015884]\n",
      "[Epoch 57/1000] [Batch 65/168] [D loss: 0.000001] [G loss: 15.484473]\n",
      "[Epoch 57/1000] [Batch 66/168] [D loss: 0.000001] [G loss: 15.558105]\n",
      "[Epoch 57/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 15.547263]\n",
      "[Epoch 57/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 15.327712]\n",
      "[Epoch 57/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 15.394896]\n",
      "[Epoch 57/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 15.484834]\n",
      "[Epoch 57/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 15.226787]\n",
      "[Epoch 57/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 15.249448]\n",
      "[Epoch 57/1000] [Batch 73/168] [D loss: 0.000001] [G loss: 15.361279]\n",
      "[Epoch 57/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 15.301886]\n",
      "[Epoch 57/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 15.367907]\n",
      "[Epoch 57/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 15.720288]\n",
      "[Epoch 57/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 15.466167]\n",
      "[Epoch 57/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 15.328588]\n",
      "[Epoch 57/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 15.343529]\n",
      "[Epoch 57/1000] [Batch 80/168] [D loss: 0.000001] [G loss: 15.326912]\n",
      "[Epoch 57/1000] [Batch 81/168] [D loss: 0.000001] [G loss: 15.260345]\n",
      "[Epoch 57/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 15.513601]\n",
      "[Epoch 57/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 15.352211]\n",
      "[Epoch 57/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 15.358349]\n",
      "[Epoch 57/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 15.679752]\n",
      "[Epoch 57/1000] [Batch 86/168] [D loss: 0.000001] [G loss: 15.493840]\n",
      "[Epoch 57/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.459343]\n",
      "[Epoch 57/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 15.702393]\n",
      "[Epoch 57/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 15.647442]\n",
      "[Epoch 57/1000] [Batch 90/168] [D loss: 0.000001] [G loss: 15.370824]\n",
      "[Epoch 57/1000] [Batch 91/168] [D loss: 0.000001] [G loss: 15.874730]\n",
      "[Epoch 57/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 15.554567]\n",
      "[Epoch 57/1000] [Batch 93/168] [D loss: 0.000001] [G loss: 15.555756]\n",
      "[Epoch 57/1000] [Batch 94/168] [D loss: 0.000001] [G loss: 15.013108]\n",
      "[Epoch 57/1000] [Batch 95/168] [D loss: 0.000001] [G loss: 15.265181]\n",
      "[Epoch 57/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 15.053318]\n",
      "[Epoch 57/1000] [Batch 97/168] [D loss: 0.000001] [G loss: 15.760634]\n",
      "[Epoch 57/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 15.460309]\n",
      "[Epoch 57/1000] [Batch 99/168] [D loss: 0.000001] [G loss: 15.591377]\n",
      "[Epoch 57/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 15.505015]\n",
      "[Epoch 57/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 15.446511]\n",
      "[Epoch 57/1000] [Batch 102/168] [D loss: 0.000001] [G loss: 14.931658]\n",
      "[Epoch 57/1000] [Batch 103/168] [D loss: 0.000001] [G loss: 15.338646]\n",
      "[Epoch 57/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 15.702921]\n",
      "[Epoch 57/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 15.041917]\n",
      "[Epoch 57/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 15.642815]\n",
      "[Epoch 57/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 15.385489]\n",
      "[Epoch 57/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 15.408578]\n",
      "[Epoch 57/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 15.804673]\n",
      "[Epoch 57/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 15.067286]\n",
      "[Epoch 57/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 15.166808]\n",
      "[Epoch 57/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 15.562609]\n",
      "[Epoch 57/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 15.387320]\n",
      "[Epoch 57/1000] [Batch 114/168] [D loss: 0.000001] [G loss: 15.640406]\n",
      "[Epoch 57/1000] [Batch 115/168] [D loss: 0.000001] [G loss: 15.476389]\n",
      "[Epoch 57/1000] [Batch 116/168] [D loss: 0.000001] [G loss: 15.410167]\n",
      "[Epoch 57/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 15.441484]\n",
      "[Epoch 57/1000] [Batch 118/168] [D loss: 0.000001] [G loss: 15.738859]\n",
      "[Epoch 57/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 15.333918]\n",
      "[Epoch 57/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 15.105455]\n",
      "[Epoch 57/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 15.922707]\n",
      "[Epoch 57/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 15.181981]\n",
      "[Epoch 57/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 15.496195]\n",
      "[Epoch 57/1000] [Batch 124/168] [D loss: 0.000001] [G loss: 15.713632]\n",
      "[Epoch 57/1000] [Batch 125/168] [D loss: 0.000001] [G loss: 15.427193]\n",
      "[Epoch 57/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 15.594798]\n",
      "[Epoch 57/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 15.344505]\n",
      "[Epoch 57/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 15.610163]\n",
      "[Epoch 57/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 15.005382]\n",
      "[Epoch 57/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 15.593572]\n",
      "[Epoch 57/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 15.386105]\n",
      "[Epoch 57/1000] [Batch 132/168] [D loss: 0.000001] [G loss: 15.884837]\n",
      "[Epoch 57/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 15.625076]\n",
      "[Epoch 57/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.397978]\n",
      "[Epoch 57/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 15.290197]\n",
      "[Epoch 57/1000] [Batch 136/168] [D loss: 0.000001] [G loss: 15.483672]\n",
      "[Epoch 57/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 15.683734]\n",
      "[Epoch 57/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 15.381407]\n",
      "[Epoch 57/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 15.823104]\n",
      "[Epoch 57/1000] [Batch 140/168] [D loss: 0.000001] [G loss: 15.157376]\n",
      "[Epoch 57/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 15.382078]\n",
      "[Epoch 57/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 15.383459]\n",
      "[Epoch 57/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 15.807495]\n",
      "[Epoch 57/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 15.945079]\n",
      "[Epoch 57/1000] [Batch 145/168] [D loss: 0.000001] [G loss: 15.921423]\n",
      "[Epoch 57/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 15.427742]\n",
      "[Epoch 57/1000] [Batch 147/168] [D loss: 0.000001] [G loss: 15.611855]\n",
      "[Epoch 57/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 15.460268]\n",
      "[Epoch 57/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 15.291686]\n",
      "[Epoch 57/1000] [Batch 150/168] [D loss: 0.000001] [G loss: 15.408130]\n",
      "[Epoch 57/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 15.494122]\n",
      "[Epoch 57/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 15.050679]\n",
      "[Epoch 57/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 15.403378]\n",
      "[Epoch 57/1000] [Batch 154/168] [D loss: 0.000001] [G loss: 15.168694]\n",
      "[Epoch 57/1000] [Batch 155/168] [D loss: 0.000001] [G loss: 15.642247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 15.657780]\n",
      "[Epoch 57/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 15.373270]\n",
      "[Epoch 57/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 15.322716]\n",
      "[Epoch 57/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 15.467143]\n",
      "[Epoch 57/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 15.357025]\n",
      "[Epoch 57/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 15.676305]\n",
      "[Epoch 57/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 15.731104]\n",
      "[Epoch 57/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 15.529444]\n",
      "[Epoch 57/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 15.788862]\n",
      "[Epoch 57/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 15.279238]\n",
      "[Epoch 57/1000] [Batch 166/168] [D loss: 0.000001] [G loss: 15.272305]\n",
      "[Epoch 57/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.007685]\n",
      "[Epoch 57/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 15.323184]\n",
      "[Epoch 58/1000] [Batch 1/168] [D loss: 0.000001] [G loss: 15.583355]\n",
      "[Epoch 58/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 15.656586]\n",
      "[Epoch 58/1000] [Batch 3/168] [D loss: 0.000001] [G loss: 15.490062]\n",
      "[Epoch 58/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 15.396621]\n",
      "[Epoch 58/1000] [Batch 5/168] [D loss: 0.000001] [G loss: 15.829949]\n",
      "[Epoch 58/1000] [Batch 6/168] [D loss: 0.000001] [G loss: 15.454964]\n",
      "[Epoch 58/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 15.540078]\n",
      "[Epoch 58/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 15.502940]\n",
      "[Epoch 58/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 15.484984]\n",
      "[Epoch 58/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 15.648238]\n",
      "[Epoch 58/1000] [Batch 11/168] [D loss: 0.000001] [G loss: 15.257874]\n",
      "[Epoch 58/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 15.396036]\n",
      "[Epoch 58/1000] [Batch 13/168] [D loss: 0.000001] [G loss: 15.554157]\n",
      "[Epoch 58/1000] [Batch 14/168] [D loss: 0.000001] [G loss: 15.153520]\n",
      "[Epoch 58/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 15.363019]\n",
      "[Epoch 58/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 15.680674]\n",
      "[Epoch 58/1000] [Batch 17/168] [D loss: 0.000001] [G loss: 15.597911]\n",
      "[Epoch 58/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 15.736241]\n",
      "[Epoch 58/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 15.968182]\n",
      "[Epoch 58/1000] [Batch 20/168] [D loss: 0.000001] [G loss: 15.570399]\n",
      "[Epoch 58/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 15.715592]\n",
      "[Epoch 58/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 15.387935]\n",
      "[Epoch 58/1000] [Batch 23/168] [D loss: 0.000001] [G loss: 15.786582]\n",
      "[Epoch 58/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 15.437501]\n",
      "[Epoch 58/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 15.405350]\n",
      "[Epoch 58/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 15.482340]\n",
      "[Epoch 58/1000] [Batch 27/168] [D loss: 0.000001] [G loss: 15.390482]\n",
      "[Epoch 58/1000] [Batch 28/168] [D loss: 0.000001] [G loss: 15.411079]\n",
      "[Epoch 58/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 15.271335]\n",
      "[Epoch 58/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 15.373425]\n",
      "[Epoch 58/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 15.678310]\n",
      "[Epoch 58/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 15.610149]\n",
      "[Epoch 58/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 15.803145]\n",
      "[Epoch 58/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 15.619794]\n",
      "[Epoch 58/1000] [Batch 35/168] [D loss: 0.000001] [G loss: 15.211267]\n",
      "[Epoch 58/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 15.593932]\n",
      "[Epoch 58/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 15.681267]\n",
      "[Epoch 58/1000] [Batch 38/168] [D loss: 0.000001] [G loss: 15.690910]\n",
      "[Epoch 58/1000] [Batch 39/168] [D loss: 0.000002] [G loss: 15.227259]\n",
      "[Epoch 58/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 15.734680]\n",
      "[Epoch 58/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 15.261553]\n",
      "[Epoch 58/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 15.733654]\n",
      "[Epoch 58/1000] [Batch 43/168] [D loss: 0.000001] [G loss: 15.566298]\n",
      "[Epoch 58/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 15.358438]\n",
      "[Epoch 58/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.003124]\n",
      "[Epoch 58/1000] [Batch 46/168] [D loss: 0.000001] [G loss: 15.549421]\n",
      "[Epoch 58/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 15.713998]\n",
      "[Epoch 58/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 15.572065]\n",
      "[Epoch 58/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 15.264835]\n",
      "[Epoch 58/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 15.670238]\n",
      "[Epoch 58/1000] [Batch 51/168] [D loss: 0.000001] [G loss: 15.379941]\n",
      "[Epoch 58/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.584097]\n",
      "[Epoch 58/1000] [Batch 53/168] [D loss: 0.000001] [G loss: 15.411448]\n",
      "[Epoch 58/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 15.507278]\n",
      "[Epoch 58/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 15.453243]\n",
      "[Epoch 58/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 15.538188]\n",
      "[Epoch 58/1000] [Batch 57/168] [D loss: 0.000001] [G loss: 15.753291]\n",
      "[Epoch 58/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 15.828292]\n",
      "[Epoch 58/1000] [Batch 59/168] [D loss: 0.000001] [G loss: 15.405594]\n",
      "[Epoch 58/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 15.303102]\n",
      "[Epoch 58/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 15.484431]\n",
      "[Epoch 58/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 15.540231]\n",
      "[Epoch 58/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 15.508507]\n",
      "[Epoch 58/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 15.317298]\n",
      "[Epoch 58/1000] [Batch 65/168] [D loss: 0.000001] [G loss: 15.512310]\n",
      "[Epoch 58/1000] [Batch 66/168] [D loss: 0.000001] [G loss: 15.528130]\n",
      "[Epoch 58/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 15.422685]\n",
      "[Epoch 58/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 15.483411]\n",
      "[Epoch 58/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 15.444556]\n",
      "[Epoch 58/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 15.595613]\n",
      "[Epoch 58/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 15.560286]\n",
      "[Epoch 58/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 15.163686]\n",
      "[Epoch 58/1000] [Batch 73/168] [D loss: 0.000001] [G loss: 15.236479]\n",
      "[Epoch 58/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 15.457770]\n",
      "[Epoch 58/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 15.635249]\n",
      "[Epoch 58/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 15.436634]\n",
      "[Epoch 58/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 15.213407]\n",
      "[Epoch 58/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 15.604033]\n",
      "[Epoch 58/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 15.639837]\n",
      "[Epoch 58/1000] [Batch 80/168] [D loss: 0.000001] [G loss: 15.645533]\n",
      "[Epoch 58/1000] [Batch 81/168] [D loss: 0.000001] [G loss: 15.026591]\n",
      "[Epoch 58/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 15.712589]\n",
      "[Epoch 58/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 15.510429]\n",
      "[Epoch 58/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 15.649757]\n",
      "[Epoch 58/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 15.453515]\n",
      "[Epoch 58/1000] [Batch 86/168] [D loss: 0.000001] [G loss: 15.192075]\n",
      "[Epoch 58/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.492705]\n",
      "[Epoch 58/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 15.585292]\n",
      "[Epoch 58/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 15.643455]\n",
      "[Epoch 58/1000] [Batch 90/168] [D loss: 0.000001] [G loss: 15.667336]\n",
      "[Epoch 58/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 15.685476]\n",
      "[Epoch 58/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 15.621540]\n",
      "[Epoch 58/1000] [Batch 93/168] [D loss: 0.000001] [G loss: 15.453650]\n",
      "[Epoch 58/1000] [Batch 94/168] [D loss: 0.000001] [G loss: 15.342262]\n",
      "[Epoch 58/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.211979]\n",
      "[Epoch 58/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 15.583851]\n",
      "[Epoch 58/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.088799]\n",
      "[Epoch 58/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 15.617882]\n",
      "[Epoch 58/1000] [Batch 99/168] [D loss: 0.000001] [G loss: 15.057962]\n",
      "[Epoch 58/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 15.470803]\n",
      "[Epoch 58/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 15.576855]\n",
      "[Epoch 58/1000] [Batch 102/168] [D loss: 0.000001] [G loss: 15.479644]\n",
      "[Epoch 58/1000] [Batch 103/168] [D loss: 0.000001] [G loss: 15.485584]\n",
      "[Epoch 58/1000] [Batch 104/168] [D loss: 0.000001] [G loss: 15.266139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 15.102225]\n",
      "[Epoch 58/1000] [Batch 106/168] [D loss: 0.000001] [G loss: 15.355481]\n",
      "[Epoch 58/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 15.627763]\n",
      "[Epoch 58/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 15.650284]\n",
      "[Epoch 58/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 15.215766]\n",
      "[Epoch 58/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 15.317473]\n",
      "[Epoch 58/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 15.718673]\n",
      "[Epoch 58/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 15.410168]\n",
      "[Epoch 58/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 15.103422]\n",
      "[Epoch 58/1000] [Batch 114/168] [D loss: 0.000001] [G loss: 15.663577]\n",
      "[Epoch 58/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 15.390627]\n",
      "[Epoch 58/1000] [Batch 116/168] [D loss: 0.000001] [G loss: 15.446358]\n",
      "[Epoch 58/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 15.100307]\n",
      "[Epoch 58/1000] [Batch 118/168] [D loss: 0.000001] [G loss: 15.618471]\n",
      "[Epoch 58/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 15.300784]\n",
      "[Epoch 58/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 15.737198]\n",
      "[Epoch 58/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 15.622375]\n",
      "[Epoch 58/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 15.685724]\n",
      "[Epoch 58/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 15.706968]\n",
      "[Epoch 58/1000] [Batch 124/168] [D loss: 0.000001] [G loss: 15.528749]\n",
      "[Epoch 58/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 15.655863]\n",
      "[Epoch 58/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 15.234884]\n",
      "[Epoch 58/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 15.520781]\n",
      "[Epoch 58/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 15.852886]\n",
      "[Epoch 58/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 15.555179]\n",
      "[Epoch 58/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 15.497745]\n",
      "[Epoch 58/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 15.511653]\n",
      "[Epoch 58/1000] [Batch 132/168] [D loss: 0.000001] [G loss: 15.539818]\n",
      "[Epoch 58/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 15.276952]\n",
      "[Epoch 58/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.684265]\n",
      "[Epoch 58/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 15.298179]\n",
      "[Epoch 58/1000] [Batch 136/168] [D loss: 0.000001] [G loss: 15.325575]\n",
      "[Epoch 58/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 15.729336]\n",
      "[Epoch 58/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 15.760601]\n",
      "[Epoch 58/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 15.321267]\n",
      "[Epoch 58/1000] [Batch 140/168] [D loss: 0.000001] [G loss: 15.443797]\n",
      "[Epoch 58/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 15.525041]\n",
      "[Epoch 58/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 15.729378]\n",
      "[Epoch 58/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 15.528325]\n",
      "[Epoch 58/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 15.758707]\n",
      "[Epoch 58/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 15.609051]\n",
      "[Epoch 58/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 15.371823]\n",
      "[Epoch 58/1000] [Batch 147/168] [D loss: 0.000001] [G loss: 15.676214]\n",
      "[Epoch 58/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 15.500978]\n",
      "[Epoch 58/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 15.546058]\n",
      "[Epoch 58/1000] [Batch 150/168] [D loss: 0.000001] [G loss: 15.818860]\n",
      "[Epoch 58/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 15.840992]\n",
      "[Epoch 58/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 15.652467]\n",
      "[Epoch 58/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 15.680254]\n",
      "[Epoch 58/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 15.550303]\n",
      "[Epoch 58/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 15.540154]\n",
      "[Epoch 58/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 15.625038]\n",
      "[Epoch 58/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 15.481483]\n",
      "[Epoch 58/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 15.563031]\n",
      "[Epoch 58/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 15.824515]\n",
      "[Epoch 58/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 15.540326]\n",
      "[Epoch 58/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 15.352177]\n",
      "[Epoch 58/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 15.637640]\n",
      "[Epoch 58/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 15.558543]\n",
      "[Epoch 58/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 15.156384]\n",
      "[Epoch 58/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 15.589910]\n",
      "[Epoch 58/1000] [Batch 166/168] [D loss: 0.000001] [G loss: 15.690577]\n",
      "[Epoch 58/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 15.595608]\n",
      "[Epoch 58/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 15.800075]\n",
      "[Epoch 59/1000] [Batch 1/168] [D loss: 0.000001] [G loss: 15.675336]\n",
      "[Epoch 59/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 15.736381]\n",
      "[Epoch 59/1000] [Batch 3/168] [D loss: 0.000001] [G loss: 15.593178]\n",
      "[Epoch 59/1000] [Batch 4/168] [D loss: 0.000001] [G loss: 15.711814]\n",
      "[Epoch 59/1000] [Batch 5/168] [D loss: 0.000001] [G loss: 15.473355]\n",
      "[Epoch 59/1000] [Batch 6/168] [D loss: 0.000001] [G loss: 15.814842]\n",
      "[Epoch 59/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 15.449950]\n",
      "[Epoch 59/1000] [Batch 8/168] [D loss: 0.000001] [G loss: 15.466928]\n",
      "[Epoch 59/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 15.438138]\n",
      "[Epoch 59/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 15.411335]\n",
      "[Epoch 59/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 15.482943]\n",
      "[Epoch 59/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 15.587255]\n",
      "[Epoch 59/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 15.577088]\n",
      "[Epoch 59/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 15.480711]\n",
      "[Epoch 59/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 15.595864]\n",
      "[Epoch 59/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 15.475965]\n",
      "[Epoch 59/1000] [Batch 17/168] [D loss: 0.000001] [G loss: 15.751585]\n",
      "[Epoch 59/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.320951]\n",
      "[Epoch 59/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 15.584534]\n",
      "[Epoch 59/1000] [Batch 20/168] [D loss: 0.000001] [G loss: 15.773621]\n",
      "[Epoch 59/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 15.719777]\n",
      "[Epoch 59/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 15.174278]\n",
      "[Epoch 59/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.207256]\n",
      "[Epoch 59/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 15.140635]\n",
      "[Epoch 59/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 15.759848]\n",
      "[Epoch 59/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 15.600257]\n",
      "[Epoch 59/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 15.385090]\n",
      "[Epoch 59/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 15.554933]\n",
      "[Epoch 59/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 15.361559]\n",
      "[Epoch 59/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 15.368620]\n",
      "[Epoch 59/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.283678]\n",
      "[Epoch 59/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 15.528883]\n",
      "[Epoch 59/1000] [Batch 33/168] [D loss: 0.000001] [G loss: 15.681268]\n",
      "[Epoch 59/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 15.789218]\n",
      "[Epoch 59/1000] [Batch 35/168] [D loss: 0.000001] [G loss: 15.671905]\n",
      "[Epoch 59/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 15.507237]\n",
      "[Epoch 59/1000] [Batch 37/168] [D loss: 0.000001] [G loss: 15.380023]\n",
      "[Epoch 59/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 15.755219]\n",
      "[Epoch 59/1000] [Batch 39/168] [D loss: 0.000001] [G loss: 15.672779]\n",
      "[Epoch 59/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 14.975625]\n",
      "[Epoch 59/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 15.535819]\n",
      "[Epoch 59/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 15.820264]\n",
      "[Epoch 59/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 15.941132]\n",
      "[Epoch 59/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 15.760822]\n",
      "[Epoch 59/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 15.691722]\n",
      "[Epoch 59/1000] [Batch 46/168] [D loss: 0.000001] [G loss: 15.903861]\n",
      "[Epoch 59/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 15.641328]\n",
      "[Epoch 59/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 16.151058]\n",
      "[Epoch 59/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 15.583542]\n",
      "[Epoch 59/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 15.510014]\n",
      "[Epoch 59/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 15.424432]\n",
      "[Epoch 59/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.779633]\n",
      "[Epoch 59/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 15.552277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 15.919904]\n",
      "[Epoch 59/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 15.495451]\n",
      "[Epoch 59/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 15.884589]\n",
      "[Epoch 59/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 15.398871]\n",
      "[Epoch 59/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 15.794413]\n",
      "[Epoch 59/1000] [Batch 59/168] [D loss: 0.000001] [G loss: 15.652581]\n",
      "[Epoch 59/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 15.853947]\n",
      "[Epoch 59/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 15.286439]\n",
      "[Epoch 59/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 15.229679]\n",
      "[Epoch 59/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 15.526812]\n",
      "[Epoch 59/1000] [Batch 64/168] [D loss: 0.000001] [G loss: 15.866209]\n",
      "[Epoch 59/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 15.608952]\n",
      "[Epoch 59/1000] [Batch 66/168] [D loss: 0.000001] [G loss: 15.390934]\n",
      "[Epoch 59/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 15.158295]\n",
      "[Epoch 59/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 15.702591]\n",
      "[Epoch 59/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 15.677438]\n",
      "[Epoch 59/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 15.444284]\n",
      "[Epoch 59/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 15.785971]\n",
      "[Epoch 59/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 15.717942]\n",
      "[Epoch 59/1000] [Batch 73/168] [D loss: 0.000001] [G loss: 15.894322]\n",
      "[Epoch 59/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 15.646379]\n",
      "[Epoch 59/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 15.421235]\n",
      "[Epoch 59/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 15.512222]\n",
      "[Epoch 59/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 15.632725]\n",
      "[Epoch 59/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 15.243361]\n",
      "[Epoch 59/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 15.650391]\n",
      "[Epoch 59/1000] [Batch 80/168] [D loss: 0.000001] [G loss: 15.387986]\n",
      "[Epoch 59/1000] [Batch 81/168] [D loss: 0.000001] [G loss: 15.878441]\n",
      "[Epoch 59/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 15.737558]\n",
      "[Epoch 59/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 15.468843]\n",
      "[Epoch 59/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 15.590687]\n",
      "[Epoch 59/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 15.781119]\n",
      "[Epoch 59/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 15.665793]\n",
      "[Epoch 59/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.543710]\n",
      "[Epoch 59/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 15.784828]\n",
      "[Epoch 59/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 15.680566]\n",
      "[Epoch 59/1000] [Batch 90/168] [D loss: 0.000001] [G loss: 15.485809]\n",
      "[Epoch 59/1000] [Batch 91/168] [D loss: 0.000001] [G loss: 15.159554]\n",
      "[Epoch 59/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 15.624623]\n",
      "[Epoch 59/1000] [Batch 93/168] [D loss: 0.000001] [G loss: 15.661902]\n",
      "[Epoch 59/1000] [Batch 94/168] [D loss: 0.000003] [G loss: 15.573498]\n",
      "[Epoch 59/1000] [Batch 95/168] [D loss: 0.000001] [G loss: 15.803740]\n",
      "[Epoch 59/1000] [Batch 96/168] [D loss: 0.000002] [G loss: 15.500864]\n",
      "[Epoch 59/1000] [Batch 97/168] [D loss: 0.000001] [G loss: 15.836283]\n",
      "[Epoch 59/1000] [Batch 98/168] [D loss: 0.000001] [G loss: 15.553904]\n",
      "[Epoch 59/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 15.796679]\n",
      "[Epoch 59/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 15.876537]\n",
      "[Epoch 59/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 15.225294]\n",
      "[Epoch 59/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 15.948597]\n",
      "[Epoch 59/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 15.471830]\n",
      "[Epoch 59/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 15.938427]\n",
      "[Epoch 59/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 15.428519]\n",
      "[Epoch 59/1000] [Batch 106/168] [D loss: 0.000001] [G loss: 15.674618]\n",
      "[Epoch 59/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 15.736966]\n",
      "[Epoch 59/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 15.542627]\n",
      "[Epoch 59/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 15.482005]\n",
      "[Epoch 59/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 15.626581]\n",
      "[Epoch 59/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 15.825942]\n",
      "[Epoch 59/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 15.545121]\n",
      "[Epoch 59/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 15.775995]\n",
      "[Epoch 59/1000] [Batch 114/168] [D loss: 0.000001] [G loss: 15.726641]\n",
      "[Epoch 59/1000] [Batch 115/168] [D loss: 0.000001] [G loss: 15.350985]\n",
      "[Epoch 59/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 15.691209]\n",
      "[Epoch 59/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 15.944372]\n",
      "[Epoch 59/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 15.677029]\n",
      "[Epoch 59/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 15.612946]\n",
      "[Epoch 59/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 15.577441]\n",
      "[Epoch 59/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 15.664792]\n",
      "[Epoch 59/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 15.606315]\n",
      "[Epoch 59/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 15.826656]\n",
      "[Epoch 59/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.060591]\n",
      "[Epoch 59/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.081127]\n",
      "[Epoch 59/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 15.858413]\n",
      "[Epoch 59/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 15.558331]\n",
      "[Epoch 59/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 15.982930]\n",
      "[Epoch 59/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 15.269650]\n",
      "[Epoch 59/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 15.512646]\n",
      "[Epoch 59/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 15.825510]\n",
      "[Epoch 59/1000] [Batch 132/168] [D loss: 0.000001] [G loss: 15.458645]\n",
      "[Epoch 59/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 15.721531]\n",
      "[Epoch 59/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.582392]\n",
      "[Epoch 59/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 15.472502]\n",
      "[Epoch 59/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 15.725727]\n",
      "[Epoch 59/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 15.424421]\n",
      "[Epoch 59/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 15.537518]\n",
      "[Epoch 59/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 15.555995]\n",
      "[Epoch 59/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 15.811132]\n",
      "[Epoch 59/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 15.552213]\n",
      "[Epoch 59/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 15.731964]\n",
      "[Epoch 59/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 15.663408]\n",
      "[Epoch 59/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 15.639323]\n",
      "[Epoch 59/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 15.840273]\n",
      "[Epoch 59/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 15.315876]\n",
      "[Epoch 59/1000] [Batch 147/168] [D loss: 0.000001] [G loss: 15.361945]\n",
      "[Epoch 59/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 15.684155]\n",
      "[Epoch 59/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 15.862222]\n",
      "[Epoch 59/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 15.649118]\n",
      "[Epoch 59/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 15.796232]\n",
      "[Epoch 59/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 15.895279]\n",
      "[Epoch 59/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 15.391690]\n",
      "[Epoch 59/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 15.923779]\n",
      "[Epoch 59/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 15.580273]\n",
      "[Epoch 59/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 15.330737]\n",
      "[Epoch 59/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 15.602592]\n",
      "[Epoch 59/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 15.918624]\n",
      "[Epoch 59/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 15.895426]\n",
      "[Epoch 59/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 15.602029]\n",
      "[Epoch 59/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 15.843165]\n",
      "[Epoch 59/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 15.666397]\n",
      "[Epoch 59/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 15.798604]\n",
      "[Epoch 59/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 15.611723]\n",
      "[Epoch 59/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 15.521410]\n",
      "[Epoch 59/1000] [Batch 166/168] [D loss: 0.000001] [G loss: 15.713432]\n",
      "[Epoch 59/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 15.223982]\n",
      "[Epoch 59/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 15.807169]\n",
      "[Epoch 60/1000] [Batch 1/168] [D loss: 0.000001] [G loss: 15.838985]\n",
      "[Epoch 60/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 15.891340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 15.854550]\n",
      "[Epoch 60/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 15.819109]\n",
      "[Epoch 60/1000] [Batch 5/168] [D loss: 0.000001] [G loss: 15.592591]\n",
      "[Epoch 60/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 15.595066]\n",
      "[Epoch 60/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 15.461355]\n",
      "[Epoch 60/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 15.664583]\n",
      "[Epoch 60/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 15.489032]\n",
      "[Epoch 60/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 15.887592]\n",
      "[Epoch 60/1000] [Batch 11/168] [D loss: 0.000001] [G loss: 15.479141]\n",
      "[Epoch 60/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 15.929873]\n",
      "[Epoch 60/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 15.872589]\n",
      "[Epoch 60/1000] [Batch 14/168] [D loss: 0.000001] [G loss: 15.665558]\n",
      "[Epoch 60/1000] [Batch 15/168] [D loss: 0.000001] [G loss: 15.760777]\n",
      "[Epoch 60/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 15.856606]\n",
      "[Epoch 60/1000] [Batch 17/168] [D loss: 0.000001] [G loss: 15.701326]\n",
      "[Epoch 60/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.905649]\n",
      "[Epoch 60/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 15.721759]\n",
      "[Epoch 60/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 15.861429]\n",
      "[Epoch 60/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 15.571585]\n",
      "[Epoch 60/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 15.851922]\n",
      "[Epoch 60/1000] [Batch 23/168] [D loss: 0.000001] [G loss: 15.531675]\n",
      "[Epoch 60/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 15.450086]\n",
      "[Epoch 60/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 15.389248]\n",
      "[Epoch 60/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 16.107262]\n",
      "[Epoch 60/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 15.826282]\n",
      "[Epoch 60/1000] [Batch 28/168] [D loss: 0.000001] [G loss: 15.523241]\n",
      "[Epoch 60/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 15.526895]\n",
      "[Epoch 60/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 15.689462]\n",
      "[Epoch 60/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.081741]\n",
      "[Epoch 60/1000] [Batch 32/168] [D loss: 0.000001] [G loss: 15.629667]\n",
      "[Epoch 60/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 15.728797]\n",
      "[Epoch 60/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 15.867066]\n",
      "[Epoch 60/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 15.995959]\n",
      "[Epoch 60/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 15.729082]\n",
      "[Epoch 60/1000] [Batch 37/168] [D loss: 0.000001] [G loss: 16.166981]\n",
      "[Epoch 60/1000] [Batch 38/168] [D loss: 0.000001] [G loss: 15.526706]\n",
      "[Epoch 60/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 15.867660]\n",
      "[Epoch 60/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.075415]\n",
      "[Epoch 60/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 15.483188]\n",
      "[Epoch 60/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 15.745880]\n",
      "[Epoch 60/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 15.837298]\n",
      "[Epoch 60/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 16.057196]\n",
      "[Epoch 60/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 15.537927]\n",
      "[Epoch 60/1000] [Batch 46/168] [D loss: 0.000001] [G loss: 15.723018]\n",
      "[Epoch 60/1000] [Batch 47/168] [D loss: 0.000001] [G loss: 15.726350]\n",
      "[Epoch 60/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 16.172333]\n",
      "[Epoch 60/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 16.057173]\n",
      "[Epoch 60/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 15.721266]\n",
      "[Epoch 60/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 15.881510]\n",
      "[Epoch 60/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.740438]\n",
      "[Epoch 60/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 15.729848]\n",
      "[Epoch 60/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 15.422567]\n",
      "[Epoch 60/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 15.703397]\n",
      "[Epoch 60/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 15.541098]\n",
      "[Epoch 60/1000] [Batch 57/168] [D loss: 0.000001] [G loss: 15.763232]\n",
      "[Epoch 60/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 15.593746]\n",
      "[Epoch 60/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 15.965551]\n",
      "[Epoch 60/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 16.063267]\n",
      "[Epoch 60/1000] [Batch 61/168] [D loss: 0.000001] [G loss: 15.303817]\n",
      "[Epoch 60/1000] [Batch 62/168] [D loss: 0.000001] [G loss: 15.546703]\n",
      "[Epoch 60/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 15.622464]\n",
      "[Epoch 60/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 15.610492]\n",
      "[Epoch 60/1000] [Batch 65/168] [D loss: 0.000001] [G loss: 15.616463]\n",
      "[Epoch 60/1000] [Batch 66/168] [D loss: 0.000001] [G loss: 15.631668]\n",
      "[Epoch 60/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 15.944327]\n",
      "[Epoch 60/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 15.878050]\n",
      "[Epoch 60/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 15.731152]\n",
      "[Epoch 60/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.133644]\n",
      "[Epoch 60/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 15.903266]\n",
      "[Epoch 60/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 15.749720]\n",
      "[Epoch 60/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 15.759563]\n",
      "[Epoch 60/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 15.629322]\n",
      "[Epoch 60/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.038677]\n",
      "[Epoch 60/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 16.011263]\n",
      "[Epoch 60/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 15.867703]\n",
      "[Epoch 60/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 15.912909]\n",
      "[Epoch 60/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 15.644972]\n",
      "[Epoch 60/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 15.475660]\n",
      "[Epoch 60/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 15.668770]\n",
      "[Epoch 60/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 15.787155]\n",
      "[Epoch 60/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 15.613823]\n",
      "[Epoch 60/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 15.776529]\n",
      "[Epoch 60/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 15.299313]\n",
      "[Epoch 60/1000] [Batch 86/168] [D loss: 0.000001] [G loss: 15.517002]\n",
      "[Epoch 60/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.495390]\n",
      "[Epoch 60/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.029701]\n",
      "[Epoch 60/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 15.748837]\n",
      "[Epoch 60/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 15.708948]\n",
      "[Epoch 60/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 15.829052]\n",
      "[Epoch 60/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 15.306041]\n",
      "[Epoch 60/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 15.939159]\n",
      "[Epoch 60/1000] [Batch 94/168] [D loss: 0.000001] [G loss: 15.638159]\n",
      "[Epoch 60/1000] [Batch 95/168] [D loss: 0.000001] [G loss: 15.969820]\n",
      "[Epoch 60/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 16.043463]\n",
      "[Epoch 60/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 15.724910]\n",
      "[Epoch 60/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.108149]\n",
      "[Epoch 60/1000] [Batch 99/168] [D loss: 0.000001] [G loss: 15.549066]\n",
      "[Epoch 60/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 15.455176]\n",
      "[Epoch 60/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 15.880260]\n",
      "[Epoch 60/1000] [Batch 102/168] [D loss: 0.000001] [G loss: 15.558159]\n",
      "[Epoch 60/1000] [Batch 103/168] [D loss: 0.000001] [G loss: 15.464015]\n",
      "[Epoch 60/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 15.656193]\n",
      "[Epoch 60/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 15.788790]\n",
      "[Epoch 60/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 15.844000]\n",
      "[Epoch 60/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 15.824460]\n",
      "[Epoch 60/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 15.675064]\n",
      "[Epoch 60/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 15.461281]\n",
      "[Epoch 60/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 15.956431]\n",
      "[Epoch 60/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 15.901891]\n",
      "[Epoch 60/1000] [Batch 112/168] [D loss: 0.000001] [G loss: 15.717744]\n",
      "[Epoch 60/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.032942]\n",
      "[Epoch 60/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 15.463932]\n",
      "[Epoch 60/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 15.701962]\n",
      "[Epoch 60/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.128614]\n",
      "[Epoch 60/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 15.758364]\n",
      "[Epoch 60/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 15.594692]\n",
      "[Epoch 60/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 15.799521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 15.794415]\n",
      "[Epoch 60/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 15.545353]\n",
      "[Epoch 60/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 15.823720]\n",
      "[Epoch 60/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 15.678064]\n",
      "[Epoch 60/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.011280]\n",
      "[Epoch 60/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 15.832502]\n",
      "[Epoch 60/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.123993]\n",
      "[Epoch 60/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 15.841867]\n",
      "[Epoch 60/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 15.981496]\n",
      "[Epoch 60/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 15.879742]\n",
      "[Epoch 60/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 15.888841]\n",
      "[Epoch 60/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 15.769629]\n",
      "[Epoch 60/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 15.620342]\n",
      "[Epoch 60/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 15.849467]\n",
      "[Epoch 60/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.798561]\n",
      "[Epoch 60/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 15.982904]\n",
      "[Epoch 60/1000] [Batch 136/168] [D loss: 0.000001] [G loss: 15.761849]\n",
      "[Epoch 60/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 15.950733]\n",
      "[Epoch 60/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 15.693176]\n",
      "[Epoch 60/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 15.807705]\n",
      "[Epoch 60/1000] [Batch 140/168] [D loss: 0.000001] [G loss: 15.643410]\n",
      "[Epoch 60/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 15.629271]\n",
      "[Epoch 60/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 15.894782]\n",
      "[Epoch 60/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 16.042114]\n",
      "[Epoch 60/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 15.836383]\n",
      "[Epoch 60/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.023027]\n",
      "[Epoch 60/1000] [Batch 146/168] [D loss: 0.000001] [G loss: 15.989202]\n",
      "[Epoch 60/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 15.309703]\n",
      "[Epoch 60/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 15.772430]\n",
      "[Epoch 60/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 15.414056]\n",
      "[Epoch 60/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.212326]\n",
      "[Epoch 60/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 15.772321]\n",
      "[Epoch 60/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 15.449400]\n",
      "[Epoch 60/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 15.851421]\n",
      "[Epoch 60/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 15.831763]\n",
      "[Epoch 60/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 15.707313]\n",
      "[Epoch 60/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 15.814242]\n",
      "[Epoch 60/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 15.818055]\n",
      "[Epoch 60/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 15.487931]\n",
      "[Epoch 60/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 15.443385]\n",
      "[Epoch 60/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 15.523722]\n",
      "[Epoch 60/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 15.773335]\n",
      "[Epoch 60/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 16.058784]\n",
      "[Epoch 60/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 15.662387]\n",
      "[Epoch 60/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 15.956838]\n",
      "[Epoch 60/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 15.989610]\n",
      "[Epoch 60/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 15.571391]\n",
      "[Epoch 60/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 15.852673]\n",
      "[Epoch 60/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 15.581878]\n",
      "[Epoch 61/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 15.961457]\n",
      "[Epoch 61/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 15.499166]\n",
      "[Epoch 61/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 15.824173]\n",
      "[Epoch 61/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 15.757796]\n",
      "[Epoch 61/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.003025]\n",
      "[Epoch 61/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 15.951012]\n",
      "[Epoch 61/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 15.984091]\n",
      "[Epoch 61/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.003328]\n",
      "[Epoch 61/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 15.711454]\n",
      "[Epoch 61/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.058849]\n",
      "[Epoch 61/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 15.963514]\n",
      "[Epoch 61/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 16.063173]\n",
      "[Epoch 61/1000] [Batch 13/168] [D loss: 0.000001] [G loss: 16.070482]\n",
      "[Epoch 61/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 15.983783]\n",
      "[Epoch 61/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 15.791513]\n",
      "[Epoch 61/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 16.189568]\n",
      "[Epoch 61/1000] [Batch 17/168] [D loss: 0.000001] [G loss: 15.780278]\n",
      "[Epoch 61/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.808060]\n",
      "[Epoch 61/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 15.605910]\n",
      "[Epoch 61/1000] [Batch 20/168] [D loss: 0.000001] [G loss: 15.663886]\n",
      "[Epoch 61/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 15.731400]\n",
      "[Epoch 61/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 16.041458]\n",
      "[Epoch 61/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 15.804589]\n",
      "[Epoch 61/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 15.591591]\n",
      "[Epoch 61/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 16.089592]\n",
      "[Epoch 61/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 15.796676]\n",
      "[Epoch 61/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 16.142736]\n",
      "[Epoch 61/1000] [Batch 28/168] [D loss: 0.000001] [G loss: 15.613938]\n",
      "[Epoch 61/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 15.787338]\n",
      "[Epoch 61/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 15.748652]\n",
      "[Epoch 61/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 15.694721]\n",
      "[Epoch 61/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 15.900597]\n",
      "[Epoch 61/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 15.836302]\n",
      "[Epoch 61/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 15.828955]\n",
      "[Epoch 61/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 15.947294]\n",
      "[Epoch 61/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 15.631714]\n",
      "[Epoch 61/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.071529]\n",
      "[Epoch 61/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 15.817241]\n",
      "[Epoch 61/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 15.679358]\n",
      "[Epoch 61/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.285631]\n",
      "[Epoch 61/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 15.789936]\n",
      "[Epoch 61/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 16.008661]\n",
      "[Epoch 61/1000] [Batch 43/168] [D loss: 0.000001] [G loss: 15.533989]\n",
      "[Epoch 61/1000] [Batch 44/168] [D loss: 0.000001] [G loss: 15.860093]\n",
      "[Epoch 61/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.049255]\n",
      "[Epoch 61/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 15.529953]\n",
      "[Epoch 61/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 15.658658]\n",
      "[Epoch 61/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 15.323515]\n",
      "[Epoch 61/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 15.667299]\n",
      "[Epoch 61/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 16.113081]\n",
      "[Epoch 61/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 16.008965]\n",
      "[Epoch 61/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.613222]\n",
      "[Epoch 61/1000] [Batch 53/168] [D loss: 0.000001] [G loss: 15.807920]\n",
      "[Epoch 61/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.170649]\n",
      "[Epoch 61/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 15.679330]\n",
      "[Epoch 61/1000] [Batch 56/168] [D loss: 0.000001] [G loss: 15.569115]\n",
      "[Epoch 61/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 15.836874]\n",
      "[Epoch 61/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.109289]\n",
      "[Epoch 61/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.141201]\n",
      "[Epoch 61/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 16.070215]\n",
      "[Epoch 61/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 15.676657]\n",
      "[Epoch 61/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 15.738635]\n",
      "[Epoch 61/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 15.613602]\n",
      "[Epoch 61/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 15.973883]\n",
      "[Epoch 61/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 15.988881]\n",
      "[Epoch 61/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 15.853985]\n",
      "[Epoch 61/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 16.108109]\n",
      "[Epoch 61/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 15.981287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 61/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 15.740205]\n",
      "[Epoch 61/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 15.640715]\n",
      "[Epoch 61/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 15.818645]\n",
      "[Epoch 61/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 15.731042]\n",
      "[Epoch 61/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 15.676704]\n",
      "[Epoch 61/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 15.851432]\n",
      "[Epoch 61/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 15.923359]\n",
      "[Epoch 61/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 15.883352]\n",
      "[Epoch 61/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.007360]\n",
      "[Epoch 61/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 15.941525]\n",
      "[Epoch 61/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 15.689161]\n",
      "[Epoch 61/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 15.971887]\n",
      "[Epoch 61/1000] [Batch 81/168] [D loss: 0.000001] [G loss: 15.833075]\n",
      "[Epoch 61/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 16.062431]\n",
      "[Epoch 61/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 15.777600]\n",
      "[Epoch 61/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 15.749016]\n",
      "[Epoch 61/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 15.376404]\n",
      "[Epoch 61/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 15.965618]\n",
      "[Epoch 61/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 15.744457]\n",
      "[Epoch 61/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 15.931573]\n",
      "[Epoch 61/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 15.777926]\n",
      "[Epoch 61/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.173466]\n",
      "[Epoch 61/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 15.746992]\n",
      "[Epoch 61/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 15.846376]\n",
      "[Epoch 61/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 15.747665]\n",
      "[Epoch 61/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 15.864836]\n",
      "[Epoch 61/1000] [Batch 95/168] [D loss: 0.000001] [G loss: 16.033686]\n",
      "[Epoch 61/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 16.047264]\n",
      "[Epoch 61/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.099953]\n",
      "[Epoch 61/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 15.579650]\n",
      "[Epoch 61/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.037977]\n",
      "[Epoch 61/1000] [Batch 100/168] [D loss: 0.000001] [G loss: 15.481762]\n",
      "[Epoch 61/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 15.848702]\n",
      "[Epoch 61/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 15.930101]\n",
      "[Epoch 61/1000] [Batch 103/168] [D loss: 0.000001] [G loss: 15.512380]\n",
      "[Epoch 61/1000] [Batch 104/168] [D loss: 0.000001] [G loss: 16.107819]\n",
      "[Epoch 61/1000] [Batch 105/168] [D loss: 0.000001] [G loss: 15.885027]\n",
      "[Epoch 61/1000] [Batch 106/168] [D loss: 0.000001] [G loss: 15.850854]\n",
      "[Epoch 61/1000] [Batch 107/168] [D loss: 0.000001] [G loss: 16.178593]\n",
      "[Epoch 61/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 16.157558]\n",
      "[Epoch 61/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 15.996921]\n",
      "[Epoch 61/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 15.638199]\n",
      "[Epoch 61/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 15.633542]\n",
      "[Epoch 61/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 15.459765]\n",
      "[Epoch 61/1000] [Batch 113/168] [D loss: 0.000001] [G loss: 15.883525]\n",
      "[Epoch 61/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 15.696931]\n",
      "[Epoch 61/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.036947]\n",
      "[Epoch 61/1000] [Batch 116/168] [D loss: 0.000001] [G loss: 15.689222]\n",
      "[Epoch 61/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 15.820046]\n",
      "[Epoch 61/1000] [Batch 118/168] [D loss: 0.000001] [G loss: 15.778022]\n",
      "[Epoch 61/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 15.985356]\n",
      "[Epoch 61/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 15.634346]\n",
      "[Epoch 61/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 16.256275]\n",
      "[Epoch 61/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.204388]\n",
      "[Epoch 61/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 16.162163]\n",
      "[Epoch 61/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 15.780088]\n",
      "[Epoch 61/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.135948]\n",
      "[Epoch 61/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 15.811149]\n",
      "[Epoch 61/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 15.879138]\n",
      "[Epoch 61/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 16.109070]\n",
      "[Epoch 61/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 15.808983]\n",
      "[Epoch 61/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 15.755222]\n",
      "[Epoch 61/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 16.078350]\n",
      "[Epoch 61/1000] [Batch 132/168] [D loss: 0.000001] [G loss: 16.251320]\n",
      "[Epoch 61/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 15.972113]\n",
      "[Epoch 61/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.917482]\n",
      "[Epoch 61/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 15.921624]\n",
      "[Epoch 61/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 15.886848]\n",
      "[Epoch 61/1000] [Batch 137/168] [D loss: 0.000001] [G loss: 15.886869]\n",
      "[Epoch 61/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 15.763005]\n",
      "[Epoch 61/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.005283]\n",
      "[Epoch 61/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 15.772406]\n",
      "[Epoch 61/1000] [Batch 141/168] [D loss: 0.000001] [G loss: 15.955111]\n",
      "[Epoch 61/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 15.834503]\n",
      "[Epoch 61/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 15.892841]\n",
      "[Epoch 61/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.026249]\n",
      "[Epoch 61/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 15.891812]\n",
      "[Epoch 61/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 15.717857]\n",
      "[Epoch 61/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 15.959782]\n",
      "[Epoch 61/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 15.729650]\n",
      "[Epoch 61/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 15.748145]\n",
      "[Epoch 61/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.071779]\n",
      "[Epoch 61/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.080132]\n",
      "[Epoch 61/1000] [Batch 152/168] [D loss: 0.000001] [G loss: 16.017839]\n",
      "[Epoch 61/1000] [Batch 153/168] [D loss: 0.000001] [G loss: 15.831598]\n",
      "[Epoch 61/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.039368]\n",
      "[Epoch 61/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.607683]\n",
      "[Epoch 61/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 15.670684]\n",
      "[Epoch 61/1000] [Batch 157/168] [D loss: 0.000001] [G loss: 16.202799]\n",
      "[Epoch 61/1000] [Batch 158/168] [D loss: 0.000001] [G loss: 15.712271]\n",
      "[Epoch 61/1000] [Batch 159/168] [D loss: 0.000001] [G loss: 15.609915]\n",
      "[Epoch 61/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 15.729548]\n",
      "[Epoch 61/1000] [Batch 161/168] [D loss: 0.000001] [G loss: 15.767657]\n",
      "[Epoch 61/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 15.779711]\n",
      "[Epoch 61/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 15.818872]\n",
      "[Epoch 61/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 16.028374]\n",
      "[Epoch 61/1000] [Batch 165/168] [D loss: 0.000001] [G loss: 15.948181]\n",
      "[Epoch 61/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.049110]\n",
      "[Epoch 61/1000] [Batch 167/168] [D loss: 0.000001] [G loss: 16.017212]\n",
      "[Epoch 61/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 15.930458]\n",
      "[Epoch 62/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 15.862432]\n",
      "[Epoch 62/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.056580]\n",
      "[Epoch 62/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 15.827223]\n",
      "[Epoch 62/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 16.104929]\n",
      "[Epoch 62/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.245052]\n",
      "[Epoch 62/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.104292]\n",
      "[Epoch 62/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.021467]\n",
      "[Epoch 62/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 15.607988]\n",
      "[Epoch 62/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 15.876677]\n",
      "[Epoch 62/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 15.893824]\n",
      "[Epoch 62/1000] [Batch 11/168] [D loss: 0.000001] [G loss: 16.244556]\n",
      "[Epoch 62/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 15.781828]\n",
      "[Epoch 62/1000] [Batch 13/168] [D loss: 0.000001] [G loss: 15.874437]\n",
      "[Epoch 62/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 16.074005]\n",
      "[Epoch 62/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 15.743240]\n",
      "[Epoch 62/1000] [Batch 16/168] [D loss: 0.000001] [G loss: 15.372559]\n",
      "[Epoch 62/1000] [Batch 17/168] [D loss: 0.000001] [G loss: 15.762859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.090992]\n",
      "[Epoch 62/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 15.828295]\n",
      "[Epoch 62/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 15.861865]\n",
      "[Epoch 62/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 15.673848]\n",
      "[Epoch 62/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.178774]\n",
      "[Epoch 62/1000] [Batch 23/168] [D loss: 0.000001] [G loss: 16.222475]\n",
      "[Epoch 62/1000] [Batch 24/168] [D loss: 0.000001] [G loss: 15.598543]\n",
      "[Epoch 62/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 15.830345]\n",
      "[Epoch 62/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 15.718302]\n",
      "[Epoch 62/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 15.702454]\n",
      "[Epoch 62/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 15.802850]\n",
      "[Epoch 62/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 15.498264]\n",
      "[Epoch 62/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.390808]\n",
      "[Epoch 62/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 15.939322]\n",
      "[Epoch 62/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 15.780777]\n",
      "[Epoch 62/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.037453]\n",
      "[Epoch 62/1000] [Batch 34/168] [D loss: 0.000001] [G loss: 15.808510]\n",
      "[Epoch 62/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 15.972464]\n",
      "[Epoch 62/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 15.844098]\n",
      "[Epoch 62/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 15.912384]\n",
      "[Epoch 62/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 15.686884]\n",
      "[Epoch 62/1000] [Batch 39/168] [D loss: 0.000001] [G loss: 15.680933]\n",
      "[Epoch 62/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 15.746696]\n",
      "[Epoch 62/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 16.195066]\n",
      "[Epoch 62/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 15.670980]\n",
      "[Epoch 62/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 15.942106]\n",
      "[Epoch 62/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 15.935536]\n",
      "[Epoch 62/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 15.790512]\n",
      "[Epoch 62/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.422867]\n",
      "[Epoch 62/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 16.212051]\n",
      "[Epoch 62/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 16.032351]\n",
      "[Epoch 62/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 15.862828]\n",
      "[Epoch 62/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 15.717527]\n",
      "[Epoch 62/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 16.186342]\n",
      "[Epoch 62/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 16.138206]\n",
      "[Epoch 62/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 15.909889]\n",
      "[Epoch 62/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 15.992145]\n",
      "[Epoch 62/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 15.909159]\n",
      "[Epoch 62/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 15.823591]\n",
      "[Epoch 62/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.281620]\n",
      "[Epoch 62/1000] [Batch 58/168] [D loss: 0.000001] [G loss: 16.022583]\n",
      "[Epoch 62/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.076752]\n",
      "[Epoch 62/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 15.669302]\n",
      "[Epoch 62/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 15.955860]\n",
      "[Epoch 62/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.161312]\n",
      "[Epoch 62/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 15.873656]\n",
      "[Epoch 62/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.065845]\n",
      "[Epoch 62/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 15.631111]\n",
      "[Epoch 62/1000] [Batch 66/168] [D loss: 0.000001] [G loss: 15.675783]\n",
      "[Epoch 62/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 16.033871]\n",
      "[Epoch 62/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.093760]\n",
      "[Epoch 62/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.336327]\n",
      "[Epoch 62/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.044682]\n",
      "[Epoch 62/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.029715]\n",
      "[Epoch 62/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 16.083185]\n",
      "[Epoch 62/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 15.645704]\n",
      "[Epoch 62/1000] [Batch 74/168] [D loss: 0.000001] [G loss: 15.893692]\n",
      "[Epoch 62/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 15.959594]\n",
      "[Epoch 62/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.193493]\n",
      "[Epoch 62/1000] [Batch 77/168] [D loss: 0.000001] [G loss: 16.058847]\n",
      "[Epoch 62/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 15.954043]\n",
      "[Epoch 62/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 15.753613]\n",
      "[Epoch 62/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.065170]\n",
      "[Epoch 62/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.350668]\n",
      "[Epoch 62/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 15.659273]\n",
      "[Epoch 62/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.168177]\n",
      "[Epoch 62/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 16.058456]\n",
      "[Epoch 62/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 15.676121]\n",
      "[Epoch 62/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 16.244589]\n",
      "[Epoch 62/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.930612]\n",
      "[Epoch 62/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 16.189745]\n",
      "[Epoch 62/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.160366]\n",
      "[Epoch 62/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.033813]\n",
      "[Epoch 62/1000] [Batch 91/168] [D loss: 0.000001] [G loss: 15.950449]\n",
      "[Epoch 62/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 16.287411]\n",
      "[Epoch 62/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 15.821928]\n",
      "[Epoch 62/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.096861]\n",
      "[Epoch 62/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.164986]\n",
      "[Epoch 62/1000] [Batch 96/168] [D loss: 0.000001] [G loss: 16.045767]\n",
      "[Epoch 62/1000] [Batch 97/168] [D loss: 0.000001] [G loss: 15.870464]\n",
      "[Epoch 62/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 15.831683]\n",
      "[Epoch 62/1000] [Batch 99/168] [D loss: 0.000001] [G loss: 15.703543]\n",
      "[Epoch 62/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 15.924840]\n",
      "[Epoch 62/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.221754]\n",
      "[Epoch 62/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 15.902111]\n",
      "[Epoch 62/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.027821]\n",
      "[Epoch 62/1000] [Batch 104/168] [D loss: 0.000001] [G loss: 16.323036]\n",
      "[Epoch 62/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 15.843805]\n",
      "[Epoch 62/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 15.825035]\n",
      "[Epoch 62/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 16.230595]\n",
      "[Epoch 62/1000] [Batch 108/168] [D loss: 0.000001] [G loss: 15.943900]\n",
      "[Epoch 62/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 15.833137]\n",
      "[Epoch 62/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.248379]\n",
      "[Epoch 62/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 16.481203]\n",
      "[Epoch 62/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.041948]\n",
      "[Epoch 62/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 15.813611]\n",
      "[Epoch 62/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 15.877248]\n",
      "[Epoch 62/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.008854]\n",
      "[Epoch 62/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 15.945151]\n",
      "[Epoch 62/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 16.238695]\n",
      "[Epoch 62/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 16.293173]\n",
      "[Epoch 62/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 16.023392]\n",
      "[Epoch 62/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 15.847023]\n",
      "[Epoch 62/1000] [Batch 121/168] [D loss: 0.000001] [G loss: 15.575305]\n",
      "[Epoch 62/1000] [Batch 122/168] [D loss: 0.000001] [G loss: 15.835763]\n",
      "[Epoch 62/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 15.846989]\n",
      "[Epoch 62/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 15.862448]\n",
      "[Epoch 62/1000] [Batch 125/168] [D loss: 0.000001] [G loss: 16.169542]\n",
      "[Epoch 62/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 15.815370]\n",
      "[Epoch 62/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 16.146423]\n",
      "[Epoch 62/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 15.897128]\n",
      "[Epoch 62/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 16.094458]\n",
      "[Epoch 62/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 15.802311]\n",
      "[Epoch 62/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 16.005041]\n",
      "[Epoch 62/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 16.012241]\n",
      "[Epoch 62/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 16.277525]\n",
      "[Epoch 62/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.006844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 16.374123]\n",
      "[Epoch 62/1000] [Batch 136/168] [D loss: 0.000001] [G loss: 15.562489]\n",
      "[Epoch 62/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.338242]\n",
      "[Epoch 62/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 15.929915]\n",
      "[Epoch 62/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 15.981386]\n",
      "[Epoch 62/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 15.833483]\n",
      "[Epoch 62/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 15.828360]\n",
      "[Epoch 62/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 15.959694]\n",
      "[Epoch 62/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.070154]\n",
      "[Epoch 62/1000] [Batch 144/168] [D loss: 0.000001] [G loss: 15.793736]\n",
      "[Epoch 62/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.047493]\n",
      "[Epoch 62/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.510622]\n",
      "[Epoch 62/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 15.947695]\n",
      "[Epoch 62/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 15.643044]\n",
      "[Epoch 62/1000] [Batch 149/168] [D loss: 0.000001] [G loss: 15.815885]\n",
      "[Epoch 62/1000] [Batch 150/168] [D loss: 0.000001] [G loss: 15.951921]\n",
      "[Epoch 62/1000] [Batch 151/168] [D loss: 0.000001] [G loss: 15.758753]\n",
      "[Epoch 62/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 16.299038]\n",
      "[Epoch 62/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 16.138323]\n",
      "[Epoch 62/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 15.705375]\n",
      "[Epoch 62/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.015949]\n",
      "[Epoch 62/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.019114]\n",
      "[Epoch 62/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.100582]\n",
      "[Epoch 62/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.163191]\n",
      "[Epoch 62/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.188524]\n",
      "[Epoch 62/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 15.797564]\n",
      "[Epoch 62/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.048550]\n",
      "[Epoch 62/1000] [Batch 162/168] [D loss: 0.000001] [G loss: 15.978552]\n",
      "[Epoch 62/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 16.153296]\n",
      "[Epoch 62/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 15.990763]\n",
      "[Epoch 62/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.289619]\n",
      "[Epoch 62/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 15.797262]\n",
      "[Epoch 62/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.030922]\n",
      "[Epoch 62/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 15.959674]\n",
      "[Epoch 63/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 15.795097]\n",
      "[Epoch 63/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 16.174660]\n",
      "[Epoch 63/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 16.029896]\n",
      "[Epoch 63/1000] [Batch 4/168] [D loss: 0.000001] [G loss: 16.237511]\n",
      "[Epoch 63/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 15.999424]\n",
      "[Epoch 63/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.222754]\n",
      "[Epoch 63/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.081717]\n",
      "[Epoch 63/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.146715]\n",
      "[Epoch 63/1000] [Batch 9/168] [D loss: 0.000001] [G loss: 16.080225]\n",
      "[Epoch 63/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 15.967133]\n",
      "[Epoch 63/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.221992]\n",
      "[Epoch 63/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.307182]\n",
      "[Epoch 63/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 15.899845]\n",
      "[Epoch 63/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 16.016104]\n",
      "[Epoch 63/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.051140]\n",
      "[Epoch 63/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 16.092064]\n",
      "[Epoch 63/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 15.811521]\n",
      "[Epoch 63/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 15.735893]\n",
      "[Epoch 63/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 16.065945]\n",
      "[Epoch 63/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 15.857349]\n",
      "[Epoch 63/1000] [Batch 21/168] [D loss: 0.000001] [G loss: 15.895012]\n",
      "[Epoch 63/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 15.755342]\n",
      "[Epoch 63/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.103771]\n",
      "[Epoch 63/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.168913]\n",
      "[Epoch 63/1000] [Batch 25/168] [D loss: 0.000001] [G loss: 15.848702]\n",
      "[Epoch 63/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 16.044821]\n",
      "[Epoch 63/1000] [Batch 27/168] [D loss: 0.000001] [G loss: 16.139481]\n",
      "[Epoch 63/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.152531]\n",
      "[Epoch 63/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 16.268194]\n",
      "[Epoch 63/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.063503]\n",
      "[Epoch 63/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 15.973482]\n",
      "[Epoch 63/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.074390]\n",
      "[Epoch 63/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.366121]\n",
      "[Epoch 63/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.015541]\n",
      "[Epoch 63/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.042627]\n",
      "[Epoch 63/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 16.046364]\n",
      "[Epoch 63/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.460581]\n",
      "[Epoch 63/1000] [Batch 38/168] [D loss: 0.000001] [G loss: 15.922045]\n",
      "[Epoch 63/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 15.984661]\n",
      "[Epoch 63/1000] [Batch 40/168] [D loss: 0.000001] [G loss: 16.477045]\n",
      "[Epoch 63/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 15.897667]\n",
      "[Epoch 63/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 16.182838]\n",
      "[Epoch 63/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 16.079144]\n",
      "[Epoch 63/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.092306]\n",
      "[Epoch 63/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 15.847169]\n",
      "[Epoch 63/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.153893]\n",
      "[Epoch 63/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 16.000275]\n",
      "[Epoch 63/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 15.929259]\n",
      "[Epoch 63/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 16.168505]\n",
      "[Epoch 63/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 16.155554]\n",
      "[Epoch 63/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 15.713116]\n",
      "[Epoch 63/1000] [Batch 52/168] [D loss: 0.000001] [G loss: 15.894647]\n",
      "[Epoch 63/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 16.043974]\n",
      "[Epoch 63/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.094900]\n",
      "[Epoch 63/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 15.800905]\n",
      "[Epoch 63/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.003725]\n",
      "[Epoch 63/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.345125]\n",
      "[Epoch 63/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.089586]\n",
      "[Epoch 63/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 15.865109]\n",
      "[Epoch 63/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 16.161669]\n",
      "[Epoch 63/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.196609]\n",
      "[Epoch 63/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 15.823046]\n",
      "[Epoch 63/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 16.359766]\n",
      "[Epoch 63/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 15.907209]\n",
      "[Epoch 63/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 15.823420]\n",
      "[Epoch 63/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 15.883122]\n",
      "[Epoch 63/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 15.732703]\n",
      "[Epoch 63/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.201668]\n",
      "[Epoch 63/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.476482]\n",
      "[Epoch 63/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.186455]\n",
      "[Epoch 63/1000] [Batch 71/168] [D loss: 0.000001] [G loss: 15.917626]\n",
      "[Epoch 63/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 16.041174]\n",
      "[Epoch 63/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.207607]\n",
      "[Epoch 63/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 16.306160]\n",
      "[Epoch 63/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 16.041203]\n",
      "[Epoch 63/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.598207]\n",
      "[Epoch 63/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.045546]\n",
      "[Epoch 63/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.163311]\n",
      "[Epoch 63/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 16.035900]\n",
      "[Epoch 63/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.227127]\n",
      "[Epoch 63/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 15.800179]\n",
      "[Epoch 63/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 16.123491]\n",
      "[Epoch 63/1000] [Batch 83/168] [D loss: 0.000001] [G loss: 15.822857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 15.985229]\n",
      "[Epoch 63/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 16.266977]\n",
      "[Epoch 63/1000] [Batch 86/168] [D loss: 0.000001] [G loss: 16.149401]\n",
      "[Epoch 63/1000] [Batch 87/168] [D loss: 0.000001] [G loss: 15.806499]\n",
      "[Epoch 63/1000] [Batch 88/168] [D loss: 0.000001] [G loss: 16.314180]\n",
      "[Epoch 63/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.048109]\n",
      "[Epoch 63/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.246494]\n",
      "[Epoch 63/1000] [Batch 91/168] [D loss: 0.000001] [G loss: 15.868984]\n",
      "[Epoch 63/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 15.956111]\n",
      "[Epoch 63/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.107521]\n",
      "[Epoch 63/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.300753]\n",
      "[Epoch 63/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.275293]\n",
      "[Epoch 63/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 16.076763]\n",
      "[Epoch 63/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.345274]\n",
      "[Epoch 63/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.458519]\n",
      "[Epoch 63/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.202003]\n",
      "[Epoch 63/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.476429]\n",
      "[Epoch 63/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.296440]\n",
      "[Epoch 63/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.010229]\n",
      "[Epoch 63/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.096054]\n",
      "[Epoch 63/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 16.175428]\n",
      "[Epoch 63/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.063667]\n",
      "[Epoch 63/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.037220]\n",
      "[Epoch 63/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 16.022285]\n",
      "[Epoch 63/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 16.021120]\n",
      "[Epoch 63/1000] [Batch 109/168] [D loss: 0.000001] [G loss: 15.765244]\n",
      "[Epoch 63/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 15.859741]\n",
      "[Epoch 63/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 16.485395]\n",
      "[Epoch 63/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 15.870295]\n",
      "[Epoch 63/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.123436]\n",
      "[Epoch 63/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 15.851920]\n",
      "[Epoch 63/1000] [Batch 115/168] [D loss: 0.000001] [G loss: 16.349747]\n",
      "[Epoch 63/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.375648]\n",
      "[Epoch 63/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 16.238865]\n",
      "[Epoch 63/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 15.954856]\n",
      "[Epoch 63/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 15.982534]\n",
      "[Epoch 63/1000] [Batch 120/168] [D loss: 0.000001] [G loss: 16.292110]\n",
      "[Epoch 63/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 16.474108]\n",
      "[Epoch 63/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.389244]\n",
      "[Epoch 63/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 15.998818]\n",
      "[Epoch 63/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.188976]\n",
      "[Epoch 63/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.193346]\n",
      "[Epoch 63/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 16.109375]\n",
      "[Epoch 63/1000] [Batch 127/168] [D loss: 0.000001] [G loss: 15.801612]\n",
      "[Epoch 63/1000] [Batch 128/168] [D loss: 0.000001] [G loss: 15.991728]\n",
      "[Epoch 63/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 16.027214]\n",
      "[Epoch 63/1000] [Batch 130/168] [D loss: 0.000001] [G loss: 15.487516]\n",
      "[Epoch 63/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 16.315941]\n",
      "[Epoch 63/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 15.977070]\n",
      "[Epoch 63/1000] [Batch 133/168] [D loss: 0.000001] [G loss: 16.438606]\n",
      "[Epoch 63/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.003994]\n",
      "[Epoch 63/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 16.084658]\n",
      "[Epoch 63/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 15.866316]\n",
      "[Epoch 63/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 15.761974]\n",
      "[Epoch 63/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 16.032436]\n",
      "[Epoch 63/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 15.955952]\n",
      "[Epoch 63/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 16.279892]\n",
      "[Epoch 63/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.079767]\n",
      "[Epoch 63/1000] [Batch 142/168] [D loss: 0.000001] [G loss: 15.812844]\n",
      "[Epoch 63/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.159971]\n",
      "[Epoch 63/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.286995]\n",
      "[Epoch 63/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 15.949002]\n",
      "[Epoch 63/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.157566]\n",
      "[Epoch 63/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.312458]\n",
      "[Epoch 63/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 16.119055]\n",
      "[Epoch 63/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 16.274042]\n",
      "[Epoch 63/1000] [Batch 150/168] [D loss: 0.000001] [G loss: 15.715209]\n",
      "[Epoch 63/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.146559]\n",
      "[Epoch 63/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 15.964762]\n",
      "[Epoch 63/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 16.100733]\n",
      "[Epoch 63/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.169834]\n",
      "[Epoch 63/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.509157]\n",
      "[Epoch 63/1000] [Batch 156/168] [D loss: 0.000001] [G loss: 16.323444]\n",
      "[Epoch 63/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.419477]\n",
      "[Epoch 63/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.036058]\n",
      "[Epoch 63/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.070595]\n",
      "[Epoch 63/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 16.289965]\n",
      "[Epoch 63/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.349998]\n",
      "[Epoch 63/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.403730]\n",
      "[Epoch 63/1000] [Batch 163/168] [D loss: 0.000001] [G loss: 16.078497]\n",
      "[Epoch 63/1000] [Batch 164/168] [D loss: 0.000001] [G loss: 16.008398]\n",
      "[Epoch 63/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.254120]\n",
      "[Epoch 63/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.492634]\n",
      "[Epoch 63/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.239407]\n",
      "[Epoch 63/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 16.065937]\n",
      "[Epoch 64/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 16.404406]\n",
      "[Epoch 64/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.304754]\n",
      "[Epoch 64/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 16.065910]\n",
      "[Epoch 64/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 16.101269]\n",
      "[Epoch 64/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.043505]\n",
      "[Epoch 64/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 15.847942]\n",
      "[Epoch 64/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.217033]\n",
      "[Epoch 64/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.078598]\n",
      "[Epoch 64/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.090839]\n",
      "[Epoch 64/1000] [Batch 10/168] [D loss: 0.000001] [G loss: 15.978843]\n",
      "[Epoch 64/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.337969]\n",
      "[Epoch 64/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.459644]\n",
      "[Epoch 64/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 16.366081]\n",
      "[Epoch 64/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 16.121422]\n",
      "[Epoch 64/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.275991]\n",
      "[Epoch 64/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 16.521259]\n",
      "[Epoch 64/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 16.214052]\n",
      "[Epoch 64/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.181814]\n",
      "[Epoch 64/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 16.023167]\n",
      "[Epoch 64/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 16.624334]\n",
      "[Epoch 64/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 16.183790]\n",
      "[Epoch 64/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.276403]\n",
      "[Epoch 64/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.581482]\n",
      "[Epoch 64/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.068081]\n",
      "[Epoch 64/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 15.933587]\n",
      "[Epoch 64/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 16.234098]\n",
      "[Epoch 64/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 15.781248]\n",
      "[Epoch 64/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.554228]\n",
      "[Epoch 64/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 16.245039]\n",
      "[Epoch 64/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 16.353203]\n",
      "[Epoch 64/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.418810]\n",
      "[Epoch 64/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.376713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64/1000] [Batch 33/168] [D loss: 0.000001] [G loss: 15.998152]\n",
      "[Epoch 64/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.452549]\n",
      "[Epoch 64/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.308424]\n",
      "[Epoch 64/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 15.994009]\n",
      "[Epoch 64/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.231579]\n",
      "[Epoch 64/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.642933]\n",
      "[Epoch 64/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 16.333492]\n",
      "[Epoch 64/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.112461]\n",
      "[Epoch 64/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 16.239729]\n",
      "[Epoch 64/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 16.096577]\n",
      "[Epoch 64/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 16.023275]\n",
      "[Epoch 64/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.188087]\n",
      "[Epoch 64/1000] [Batch 45/168] [D loss: 0.000001] [G loss: 16.143229]\n",
      "[Epoch 64/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.248634]\n",
      "[Epoch 64/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 16.252102]\n",
      "[Epoch 64/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 16.048239]\n",
      "[Epoch 64/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 16.163645]\n",
      "[Epoch 64/1000] [Batch 50/168] [D loss: 0.000001] [G loss: 16.211502]\n",
      "[Epoch 64/1000] [Batch 51/168] [D loss: 0.000001] [G loss: 16.391342]\n",
      "[Epoch 64/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 16.443007]\n",
      "[Epoch 64/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 15.898140]\n",
      "[Epoch 64/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.292946]\n",
      "[Epoch 64/1000] [Batch 55/168] [D loss: 0.000001] [G loss: 16.068863]\n",
      "[Epoch 64/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.563770]\n",
      "[Epoch 64/1000] [Batch 57/168] [D loss: 0.000001] [G loss: 16.201311]\n",
      "[Epoch 64/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.125984]\n",
      "[Epoch 64/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.192970]\n",
      "[Epoch 64/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 16.678614]\n",
      "[Epoch 64/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.003332]\n",
      "[Epoch 64/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.369343]\n",
      "[Epoch 64/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 16.257023]\n",
      "[Epoch 64/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.086710]\n",
      "[Epoch 64/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 15.970268]\n",
      "[Epoch 64/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.001524]\n",
      "[Epoch 64/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 16.101974]\n",
      "[Epoch 64/1000] [Batch 68/168] [D loss: 0.000001] [G loss: 15.997759]\n",
      "[Epoch 64/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.339006]\n",
      "[Epoch 64/1000] [Batch 70/168] [D loss: 0.000001] [G loss: 15.856474]\n",
      "[Epoch 64/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 15.972486]\n",
      "[Epoch 64/1000] [Batch 72/168] [D loss: 0.000001] [G loss: 16.201950]\n",
      "[Epoch 64/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.436232]\n",
      "[Epoch 64/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 16.052635]\n",
      "[Epoch 64/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.217777]\n",
      "[Epoch 64/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.085218]\n",
      "[Epoch 64/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.475887]\n",
      "[Epoch 64/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.224590]\n",
      "[Epoch 64/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 16.240629]\n",
      "[Epoch 64/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.173561]\n",
      "[Epoch 64/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.167439]\n",
      "[Epoch 64/1000] [Batch 82/168] [D loss: 0.000001] [G loss: 16.155771]\n",
      "[Epoch 64/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.269394]\n",
      "[Epoch 64/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 16.197651]\n",
      "[Epoch 64/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 16.308546]\n",
      "[Epoch 64/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 16.557325]\n",
      "[Epoch 64/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 16.554525]\n",
      "[Epoch 64/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.155531]\n",
      "[Epoch 64/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.177074]\n",
      "[Epoch 64/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.274454]\n",
      "[Epoch 64/1000] [Batch 91/168] [D loss: 0.000002] [G loss: 16.201639]\n",
      "[Epoch 64/1000] [Batch 92/168] [D loss: 0.000001] [G loss: 16.156975]\n",
      "[Epoch 64/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.293406]\n",
      "[Epoch 64/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.197252]\n",
      "[Epoch 64/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.204973]\n",
      "[Epoch 64/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 15.996799]\n",
      "[Epoch 64/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.057629]\n",
      "[Epoch 64/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.255980]\n",
      "[Epoch 64/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.313982]\n",
      "[Epoch 64/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.570206]\n",
      "[Epoch 64/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.397465]\n",
      "[Epoch 64/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.569279]\n",
      "[Epoch 64/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.778072]\n",
      "[Epoch 64/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 16.437178]\n",
      "[Epoch 64/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.169127]\n",
      "[Epoch 64/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.310953]\n",
      "[Epoch 64/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 15.983454]\n",
      "[Epoch 64/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 16.071815]\n",
      "[Epoch 64/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 16.207201]\n",
      "[Epoch 64/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.276331]\n",
      "[Epoch 64/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 15.973042]\n",
      "[Epoch 64/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.306637]\n",
      "[Epoch 64/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.732578]\n",
      "[Epoch 64/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 16.485981]\n",
      "[Epoch 64/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.413698]\n",
      "[Epoch 64/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.289948]\n",
      "[Epoch 64/1000] [Batch 117/168] [D loss: 0.000001] [G loss: 15.972663]\n",
      "[Epoch 64/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 16.399166]\n",
      "[Epoch 64/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 16.342897]\n",
      "[Epoch 64/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 16.496401]\n",
      "[Epoch 64/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 16.210207]\n",
      "[Epoch 64/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.176979]\n",
      "[Epoch 64/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 16.268845]\n",
      "[Epoch 64/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.232723]\n",
      "[Epoch 64/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.144514]\n",
      "[Epoch 64/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.119263]\n",
      "[Epoch 64/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 16.389128]\n",
      "[Epoch 64/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 16.267624]\n",
      "[Epoch 64/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 16.258259]\n",
      "[Epoch 64/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 16.620064]\n",
      "[Epoch 64/1000] [Batch 131/168] [D loss: 0.000001] [G loss: 16.676762]\n",
      "[Epoch 64/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 16.646660]\n",
      "[Epoch 64/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 16.482033]\n",
      "[Epoch 64/1000] [Batch 134/168] [D loss: 0.000001] [G loss: 15.911141]\n",
      "[Epoch 64/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 16.173016]\n",
      "[Epoch 64/1000] [Batch 136/168] [D loss: 0.000001] [G loss: 16.495846]\n",
      "[Epoch 64/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.183750]\n",
      "[Epoch 64/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 16.534927]\n",
      "[Epoch 64/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.083273]\n",
      "[Epoch 64/1000] [Batch 140/168] [D loss: 0.000001] [G loss: 15.932651]\n",
      "[Epoch 64/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.229961]\n",
      "[Epoch 64/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 16.037151]\n",
      "[Epoch 64/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.461504]\n",
      "[Epoch 64/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.057165]\n",
      "[Epoch 64/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.169407]\n",
      "[Epoch 64/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.417763]\n",
      "[Epoch 64/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.489826]\n",
      "[Epoch 64/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 16.475500]\n",
      "[Epoch 64/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 16.020611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.227947]\n",
      "[Epoch 64/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.078671]\n",
      "[Epoch 64/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 16.115778]\n",
      "[Epoch 64/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 16.343157]\n",
      "[Epoch 64/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.037916]\n",
      "[Epoch 64/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.368042]\n",
      "[Epoch 64/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.355701]\n",
      "[Epoch 64/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.347343]\n",
      "[Epoch 64/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 15.909213]\n",
      "[Epoch 64/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.061253]\n",
      "[Epoch 64/1000] [Batch 160/168] [D loss: 0.000001] [G loss: 16.119816]\n",
      "[Epoch 64/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.196695]\n",
      "[Epoch 64/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.441986]\n",
      "[Epoch 64/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 16.276237]\n",
      "[Epoch 64/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 16.185846]\n",
      "[Epoch 64/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.366646]\n",
      "[Epoch 64/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.145094]\n",
      "[Epoch 64/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 15.996828]\n",
      "[Epoch 64/1000] [Batch 168/168] [D loss: 0.000001] [G loss: 16.271353]\n",
      "[Epoch 65/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 16.286694]\n",
      "[Epoch 65/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.445000]\n",
      "[Epoch 65/1000] [Batch 3/168] [D loss: 0.000001] [G loss: 16.611055]\n",
      "[Epoch 65/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 16.289499]\n",
      "[Epoch 65/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.256350]\n",
      "[Epoch 65/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 15.959399]\n",
      "[Epoch 65/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.404881]\n",
      "[Epoch 65/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.546665]\n",
      "[Epoch 65/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.439360]\n",
      "[Epoch 65/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.434774]\n",
      "[Epoch 65/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.025486]\n",
      "[Epoch 65/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.709419]\n",
      "[Epoch 65/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 16.114849]\n",
      "[Epoch 65/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 16.180557]\n",
      "[Epoch 65/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.265118]\n",
      "[Epoch 65/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 16.132460]\n",
      "[Epoch 65/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 16.280174]\n",
      "[Epoch 65/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.089933]\n",
      "[Epoch 65/1000] [Batch 19/168] [D loss: 0.000001] [G loss: 16.225683]\n",
      "[Epoch 65/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 16.299252]\n",
      "[Epoch 65/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 16.241623]\n",
      "[Epoch 65/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.399273]\n",
      "[Epoch 65/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.292992]\n",
      "[Epoch 65/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.254700]\n",
      "[Epoch 65/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 16.204317]\n",
      "[Epoch 65/1000] [Batch 26/168] [D loss: 0.000001] [G loss: 16.215359]\n",
      "[Epoch 65/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 16.027254]\n",
      "[Epoch 65/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.372822]\n",
      "[Epoch 65/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 16.254978]\n",
      "[Epoch 65/1000] [Batch 30/168] [D loss: 0.000001] [G loss: 16.367907]\n",
      "[Epoch 65/1000] [Batch 31/168] [D loss: 0.000001] [G loss: 16.407877]\n",
      "[Epoch 65/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.181761]\n",
      "[Epoch 65/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.333202]\n",
      "[Epoch 65/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.309324]\n",
      "[Epoch 65/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 15.718079]\n",
      "[Epoch 65/1000] [Batch 36/168] [D loss: 0.000001] [G loss: 16.203182]\n",
      "[Epoch 65/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.241440]\n",
      "[Epoch 65/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.210640]\n",
      "[Epoch 65/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 16.426086]\n",
      "[Epoch 65/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.393410]\n",
      "[Epoch 65/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 16.264387]\n",
      "[Epoch 65/1000] [Batch 42/168] [D loss: 0.000001] [G loss: 16.120094]\n",
      "[Epoch 65/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 16.486540]\n",
      "[Epoch 65/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.585140]\n",
      "[Epoch 65/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.427805]\n",
      "[Epoch 65/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.223759]\n",
      "[Epoch 65/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 16.262920]\n",
      "[Epoch 65/1000] [Batch 48/168] [D loss: 0.000001] [G loss: 16.076071]\n",
      "[Epoch 65/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 16.428465]\n",
      "[Epoch 65/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 16.313820]\n",
      "[Epoch 65/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 16.128983]\n",
      "[Epoch 65/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 16.132652]\n",
      "[Epoch 65/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 16.152617]\n",
      "[Epoch 65/1000] [Batch 54/168] [D loss: 0.000001] [G loss: 16.211555]\n",
      "[Epoch 65/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 16.225821]\n",
      "[Epoch 65/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.014269]\n",
      "[Epoch 65/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.104572]\n",
      "[Epoch 65/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.297684]\n",
      "[Epoch 65/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.398720]\n",
      "[Epoch 65/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 16.380659]\n",
      "[Epoch 65/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.593750]\n",
      "[Epoch 65/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.360031]\n",
      "[Epoch 65/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 16.273912]\n",
      "[Epoch 65/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.323380]\n",
      "[Epoch 65/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 16.515938]\n",
      "[Epoch 65/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.259922]\n",
      "[Epoch 65/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 16.560282]\n",
      "[Epoch 65/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.677885]\n",
      "[Epoch 65/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.142868]\n",
      "[Epoch 65/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.182291]\n",
      "[Epoch 65/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.263880]\n",
      "[Epoch 65/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 16.522285]\n",
      "[Epoch 65/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.336226]\n",
      "[Epoch 65/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 16.132744]\n",
      "[Epoch 65/1000] [Batch 75/168] [D loss: 0.000001] [G loss: 16.385288]\n",
      "[Epoch 65/1000] [Batch 76/168] [D loss: 0.000001] [G loss: 16.774948]\n",
      "[Epoch 65/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.116226]\n",
      "[Epoch 65/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.198154]\n",
      "[Epoch 65/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 16.420198]\n",
      "[Epoch 65/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.614058]\n",
      "[Epoch 65/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.262379]\n",
      "[Epoch 65/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 16.130909]\n",
      "[Epoch 65/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.454269]\n",
      "[Epoch 65/1000] [Batch 84/168] [D loss: 0.000001] [G loss: 16.254070]\n",
      "[Epoch 65/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 16.326752]\n",
      "[Epoch 65/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 16.564428]\n",
      "[Epoch 65/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 16.542721]\n",
      "[Epoch 65/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.597195]\n",
      "[Epoch 65/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.634117]\n",
      "[Epoch 65/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.674374]\n",
      "[Epoch 65/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 16.649103]\n",
      "[Epoch 65/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 16.192028]\n",
      "[Epoch 65/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.443031]\n",
      "[Epoch 65/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.375168]\n",
      "[Epoch 65/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.428493]\n",
      "[Epoch 65/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 16.329611]\n",
      "[Epoch 65/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.274904]\n",
      "[Epoch 65/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.169447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.405979]\n",
      "[Epoch 65/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.651413]\n",
      "[Epoch 65/1000] [Batch 101/168] [D loss: 0.000001] [G loss: 16.067991]\n",
      "[Epoch 65/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.446278]\n",
      "[Epoch 65/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.340956]\n",
      "[Epoch 65/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 16.329456]\n",
      "[Epoch 65/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.411425]\n",
      "[Epoch 65/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.556675]\n",
      "[Epoch 65/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 16.206570]\n",
      "[Epoch 65/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 16.204914]\n",
      "[Epoch 65/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 16.508413]\n",
      "[Epoch 65/1000] [Batch 110/168] [D loss: 0.000001] [G loss: 16.121597]\n",
      "[Epoch 65/1000] [Batch 111/168] [D loss: 0.000001] [G loss: 16.367426]\n",
      "[Epoch 65/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.265308]\n",
      "[Epoch 65/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.181032]\n",
      "[Epoch 65/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 16.267120]\n",
      "[Epoch 65/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.235909]\n",
      "[Epoch 65/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.331257]\n",
      "[Epoch 65/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 16.482218]\n",
      "[Epoch 65/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 16.617962]\n",
      "[Epoch 65/1000] [Batch 119/168] [D loss: 0.000001] [G loss: 16.597567]\n",
      "[Epoch 65/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 16.245152]\n",
      "[Epoch 65/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 16.140045]\n",
      "[Epoch 65/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.245075]\n",
      "[Epoch 65/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 16.229017]\n",
      "[Epoch 65/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.415079]\n",
      "[Epoch 65/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.229801]\n",
      "[Epoch 65/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.152166]\n",
      "[Epoch 65/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 16.297920]\n",
      "[Epoch 65/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 16.246708]\n",
      "[Epoch 65/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 16.477577]\n",
      "[Epoch 65/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 16.252661]\n",
      "[Epoch 65/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 16.378012]\n",
      "[Epoch 65/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 16.178928]\n",
      "[Epoch 65/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 16.497753]\n",
      "[Epoch 65/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.227684]\n",
      "[Epoch 65/1000] [Batch 135/168] [D loss: 0.000001] [G loss: 16.440130]\n",
      "[Epoch 65/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 16.281326]\n",
      "[Epoch 65/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.629665]\n",
      "[Epoch 65/1000] [Batch 138/168] [D loss: 0.000001] [G loss: 16.242235]\n",
      "[Epoch 65/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.384346]\n",
      "[Epoch 65/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 16.304977]\n",
      "[Epoch 65/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.539927]\n",
      "[Epoch 65/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 16.274780]\n",
      "[Epoch 65/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.178288]\n",
      "[Epoch 65/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.518166]\n",
      "[Epoch 65/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.552046]\n",
      "[Epoch 65/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.551394]\n",
      "[Epoch 65/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.129164]\n",
      "[Epoch 65/1000] [Batch 148/168] [D loss: 0.000001] [G loss: 16.313417]\n",
      "[Epoch 65/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 16.409445]\n",
      "[Epoch 65/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.760752]\n",
      "[Epoch 65/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.019812]\n",
      "[Epoch 65/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 16.349997]\n",
      "[Epoch 65/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 16.322964]\n",
      "[Epoch 65/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.535519]\n",
      "[Epoch 65/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.085314]\n",
      "[Epoch 65/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.610975]\n",
      "[Epoch 65/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.579435]\n",
      "[Epoch 65/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.209721]\n",
      "[Epoch 65/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.113312]\n",
      "[Epoch 65/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 16.496929]\n",
      "[Epoch 65/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.310667]\n",
      "[Epoch 65/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.324604]\n",
      "[Epoch 65/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 16.374208]\n",
      "[Epoch 65/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 16.328754]\n",
      "[Epoch 65/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.383263]\n",
      "[Epoch 65/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.416035]\n",
      "[Epoch 65/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.151983]\n",
      "[Epoch 65/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 16.673037]\n",
      "[Epoch 66/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 16.399113]\n",
      "[Epoch 66/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.870453]\n",
      "[Epoch 66/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 16.431185]\n",
      "[Epoch 66/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 16.503643]\n",
      "[Epoch 66/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.348539]\n",
      "[Epoch 66/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.567291]\n",
      "[Epoch 66/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.183470]\n",
      "[Epoch 66/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.581850]\n",
      "[Epoch 66/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.492353]\n",
      "[Epoch 66/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.265644]\n",
      "[Epoch 66/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.322149]\n",
      "[Epoch 66/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.558582]\n",
      "[Epoch 66/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 16.346766]\n",
      "[Epoch 66/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 16.488094]\n",
      "[Epoch 66/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.254549]\n",
      "[Epoch 66/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 16.365435]\n",
      "[Epoch 66/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 16.174839]\n",
      "[Epoch 66/1000] [Batch 18/168] [D loss: 0.000001] [G loss: 16.195036]\n",
      "[Epoch 66/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 16.423279]\n",
      "[Epoch 66/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 16.339233]\n",
      "[Epoch 66/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 16.393597]\n",
      "[Epoch 66/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.171017]\n",
      "[Epoch 66/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.529139]\n",
      "[Epoch 66/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.175879]\n",
      "[Epoch 66/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 16.330757]\n",
      "[Epoch 66/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 16.235052]\n",
      "[Epoch 66/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 15.949387]\n",
      "[Epoch 66/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.508528]\n",
      "[Epoch 66/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 16.219229]\n",
      "[Epoch 66/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.421679]\n",
      "[Epoch 66/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.611061]\n",
      "[Epoch 66/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.139936]\n",
      "[Epoch 66/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.247141]\n",
      "[Epoch 66/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.524990]\n",
      "[Epoch 66/1000] [Batch 35/168] [D loss: 0.000001] [G loss: 16.250015]\n",
      "[Epoch 66/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 16.494780]\n",
      "[Epoch 66/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.582630]\n",
      "[Epoch 66/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.418045]\n",
      "[Epoch 66/1000] [Batch 39/168] [D loss: 0.000001] [G loss: 16.456606]\n",
      "[Epoch 66/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.469603]\n",
      "[Epoch 66/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 16.433136]\n",
      "[Epoch 66/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 16.677767]\n",
      "[Epoch 66/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 15.927065]\n",
      "[Epoch 66/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.188631]\n",
      "[Epoch 66/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.625185]\n",
      "[Epoch 66/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.723799]\n",
      "[Epoch 66/1000] [Batch 47/168] [D loss: 0.000001] [G loss: 16.214415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 16.323227]\n",
      "[Epoch 66/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 16.506495]\n",
      "[Epoch 66/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 16.251316]\n",
      "[Epoch 66/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 16.039631]\n",
      "[Epoch 66/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 16.339554]\n",
      "[Epoch 66/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 16.172688]\n",
      "[Epoch 66/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.177259]\n",
      "[Epoch 66/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 16.367744]\n",
      "[Epoch 66/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.473354]\n",
      "[Epoch 66/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.314579]\n",
      "[Epoch 66/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.874043]\n",
      "[Epoch 66/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.759565]\n",
      "[Epoch 66/1000] [Batch 60/168] [D loss: 0.000001] [G loss: 15.803140]\n",
      "[Epoch 66/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.114525]\n",
      "[Epoch 66/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.734371]\n",
      "[Epoch 66/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 16.373825]\n",
      "[Epoch 66/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.410875]\n",
      "[Epoch 66/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 16.395626]\n",
      "[Epoch 66/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.509995]\n",
      "[Epoch 66/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 16.092806]\n",
      "[Epoch 66/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.119654]\n",
      "[Epoch 66/1000] [Batch 69/168] [D loss: 0.000001] [G loss: 15.848258]\n",
      "[Epoch 66/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.773018]\n",
      "[Epoch 66/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.734571]\n",
      "[Epoch 66/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 16.417114]\n",
      "[Epoch 66/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.552374]\n",
      "[Epoch 66/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 16.592384]\n",
      "[Epoch 66/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.724770]\n",
      "[Epoch 66/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.415758]\n",
      "[Epoch 66/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.460976]\n",
      "[Epoch 66/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.240532]\n",
      "[Epoch 66/1000] [Batch 79/168] [D loss: 0.000001] [G loss: 16.485079]\n",
      "[Epoch 66/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.074770]\n",
      "[Epoch 66/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.515675]\n",
      "[Epoch 66/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 16.422955]\n",
      "[Epoch 66/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.470335]\n",
      "[Epoch 66/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 16.047047]\n",
      "[Epoch 66/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 16.156210]\n",
      "[Epoch 66/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 16.429884]\n",
      "[Epoch 66/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 16.154072]\n",
      "[Epoch 66/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.387995]\n",
      "[Epoch 66/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.544245]\n",
      "[Epoch 66/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.610403]\n",
      "[Epoch 66/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 16.477736]\n",
      "[Epoch 66/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 16.418356]\n",
      "[Epoch 66/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.405838]\n",
      "[Epoch 66/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.186298]\n",
      "[Epoch 66/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.555374]\n",
      "[Epoch 66/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 16.368689]\n",
      "[Epoch 66/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.409670]\n",
      "[Epoch 66/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.420433]\n",
      "[Epoch 66/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.430075]\n",
      "[Epoch 66/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.412323]\n",
      "[Epoch 66/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.458406]\n",
      "[Epoch 66/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.736301]\n",
      "[Epoch 66/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.597483]\n",
      "[Epoch 66/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 16.623056]\n",
      "[Epoch 66/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.136965]\n",
      "[Epoch 66/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.392244]\n",
      "[Epoch 66/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 16.453176]\n",
      "[Epoch 66/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 16.208496]\n",
      "[Epoch 66/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 16.630142]\n",
      "[Epoch 66/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.538816]\n",
      "[Epoch 66/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 16.612726]\n",
      "[Epoch 66/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.204077]\n",
      "[Epoch 66/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.652891]\n",
      "[Epoch 66/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 16.276134]\n",
      "[Epoch 66/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.460079]\n",
      "[Epoch 66/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.328382]\n",
      "[Epoch 66/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 16.774305]\n",
      "[Epoch 66/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 16.696239]\n",
      "[Epoch 66/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 16.127686]\n",
      "[Epoch 66/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 16.505720]\n",
      "[Epoch 66/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 16.440502]\n",
      "[Epoch 66/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.502121]\n",
      "[Epoch 66/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 16.305885]\n",
      "[Epoch 66/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.584095]\n",
      "[Epoch 66/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.421230]\n",
      "[Epoch 66/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.364698]\n",
      "[Epoch 66/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 16.400471]\n",
      "[Epoch 66/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 16.462334]\n",
      "[Epoch 66/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 16.262829]\n",
      "[Epoch 66/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 16.575726]\n",
      "[Epoch 66/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 16.539480]\n",
      "[Epoch 66/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 16.721729]\n",
      "[Epoch 66/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 16.448959]\n",
      "[Epoch 66/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.407869]\n",
      "[Epoch 66/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 16.406361]\n",
      "[Epoch 66/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 16.426323]\n",
      "[Epoch 66/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.391239]\n",
      "[Epoch 66/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 16.891260]\n",
      "[Epoch 66/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 16.211735]\n",
      "[Epoch 66/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 16.510180]\n",
      "[Epoch 66/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.659592]\n",
      "[Epoch 66/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 16.753838]\n",
      "[Epoch 66/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.557961]\n",
      "[Epoch 66/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.486816]\n",
      "[Epoch 66/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.366865]\n",
      "[Epoch 66/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.455254]\n",
      "[Epoch 66/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.299427]\n",
      "[Epoch 66/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 16.669897]\n",
      "[Epoch 66/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 16.321764]\n",
      "[Epoch 66/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.371460]\n",
      "[Epoch 66/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.437044]\n",
      "[Epoch 66/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 16.231768]\n",
      "[Epoch 66/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 16.706024]\n",
      "[Epoch 66/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.172802]\n",
      "[Epoch 66/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.392338]\n",
      "[Epoch 66/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.438059]\n",
      "[Epoch 66/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.134867]\n",
      "[Epoch 66/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.295931]\n",
      "[Epoch 66/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.549122]\n",
      "[Epoch 66/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 16.669483]\n",
      "[Epoch 66/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.365271]\n",
      "[Epoch 66/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.453182]\n",
      "[Epoch 66/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 16.307528]\n",
      "[Epoch 66/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 16.734789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.629095]\n",
      "[Epoch 66/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.590019]\n",
      "[Epoch 66/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.327826]\n",
      "[Epoch 66/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 16.336784]\n",
      "[Epoch 67/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 15.863335]\n",
      "[Epoch 67/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.597597]\n",
      "[Epoch 67/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 16.541086]\n",
      "[Epoch 67/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 16.529696]\n",
      "[Epoch 67/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.196550]\n",
      "[Epoch 67/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.658098]\n",
      "[Epoch 67/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.392670]\n",
      "[Epoch 67/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.224131]\n",
      "[Epoch 67/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.356071]\n",
      "[Epoch 67/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.316170]\n",
      "[Epoch 67/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.168968]\n",
      "[Epoch 67/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.368309]\n",
      "[Epoch 67/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 15.950749]\n",
      "[Epoch 67/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 16.772444]\n",
      "[Epoch 67/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.636108]\n",
      "[Epoch 67/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 16.443882]\n",
      "[Epoch 67/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 16.472372]\n",
      "[Epoch 67/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.207455]\n",
      "[Epoch 67/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 16.523552]\n",
      "[Epoch 67/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 16.531389]\n",
      "[Epoch 67/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 16.582296]\n",
      "[Epoch 67/1000] [Batch 22/168] [D loss: 0.000001] [G loss: 16.288313]\n",
      "[Epoch 67/1000] [Batch 23/168] [D loss: 0.000001] [G loss: 16.102282]\n",
      "[Epoch 67/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.771753]\n",
      "[Epoch 67/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 16.543489]\n",
      "[Epoch 67/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 16.749216]\n",
      "[Epoch 67/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 16.550257]\n",
      "[Epoch 67/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.951218]\n",
      "[Epoch 67/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 16.585207]\n",
      "[Epoch 67/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.664165]\n",
      "[Epoch 67/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.282551]\n",
      "[Epoch 67/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.221573]\n",
      "[Epoch 67/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.926918]\n",
      "[Epoch 67/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.436081]\n",
      "[Epoch 67/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.732748]\n",
      "[Epoch 67/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 16.657898]\n",
      "[Epoch 67/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.707994]\n",
      "[Epoch 67/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.410856]\n",
      "[Epoch 67/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 16.528738]\n",
      "[Epoch 67/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.172169]\n",
      "[Epoch 67/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 16.337109]\n",
      "[Epoch 67/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 16.470314]\n",
      "[Epoch 67/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 16.077364]\n",
      "[Epoch 67/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.379848]\n",
      "[Epoch 67/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.420456]\n",
      "[Epoch 67/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.577408]\n",
      "[Epoch 67/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 16.809513]\n",
      "[Epoch 67/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 16.532993]\n",
      "[Epoch 67/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 16.427668]\n",
      "[Epoch 67/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 16.752867]\n",
      "[Epoch 67/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 16.190722]\n",
      "[Epoch 67/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 16.661768]\n",
      "[Epoch 67/1000] [Batch 53/168] [D loss: 0.000001] [G loss: 16.039104]\n",
      "[Epoch 67/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.322166]\n",
      "[Epoch 67/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 16.772295]\n",
      "[Epoch 67/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.720661]\n",
      "[Epoch 67/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.673437]\n",
      "[Epoch 67/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.420425]\n",
      "[Epoch 67/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.251299]\n",
      "[Epoch 67/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 16.168139]\n",
      "[Epoch 67/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.467466]\n",
      "[Epoch 67/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.421993]\n",
      "[Epoch 67/1000] [Batch 63/168] [D loss: 0.000001] [G loss: 16.319874]\n",
      "[Epoch 67/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.404812]\n",
      "[Epoch 67/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 16.486523]\n",
      "[Epoch 67/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.314453]\n",
      "[Epoch 67/1000] [Batch 67/168] [D loss: 0.000001] [G loss: 16.411324]\n",
      "[Epoch 67/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.191181]\n",
      "[Epoch 67/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.628048]\n",
      "[Epoch 67/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.524652]\n",
      "[Epoch 67/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.513458]\n",
      "[Epoch 67/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 16.792587]\n",
      "[Epoch 67/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.574972]\n",
      "[Epoch 67/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 16.025650]\n",
      "[Epoch 67/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.483385]\n",
      "[Epoch 67/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.664625]\n",
      "[Epoch 67/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.412558]\n",
      "[Epoch 67/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.476822]\n",
      "[Epoch 67/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 16.662827]\n",
      "[Epoch 67/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.321976]\n",
      "[Epoch 67/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.477295]\n",
      "[Epoch 67/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 16.727804]\n",
      "[Epoch 67/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.996151]\n",
      "[Epoch 67/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 16.283747]\n",
      "[Epoch 67/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 16.959091]\n",
      "[Epoch 67/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 16.342833]\n",
      "[Epoch 67/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 16.378088]\n",
      "[Epoch 67/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.504414]\n",
      "[Epoch 67/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.523220]\n",
      "[Epoch 67/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.542362]\n",
      "[Epoch 67/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 16.583078]\n",
      "[Epoch 67/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 16.661648]\n",
      "[Epoch 67/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.103952]\n",
      "[Epoch 67/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 17.042168]\n",
      "[Epoch 67/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.587225]\n",
      "[Epoch 67/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 16.413235]\n",
      "[Epoch 67/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.712269]\n",
      "[Epoch 67/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.235973]\n",
      "[Epoch 67/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.446894]\n",
      "[Epoch 67/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.593178]\n",
      "[Epoch 67/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.698515]\n",
      "[Epoch 67/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.435987]\n",
      "[Epoch 67/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.342297]\n",
      "[Epoch 67/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 16.172850]\n",
      "[Epoch 67/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.626585]\n",
      "[Epoch 67/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.619585]\n",
      "[Epoch 67/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 16.291405]\n",
      "[Epoch 67/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 16.636585]\n",
      "[Epoch 67/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 16.821018]\n",
      "[Epoch 67/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.604389]\n",
      "[Epoch 67/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 16.719992]\n",
      "[Epoch 67/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.659990]\n",
      "[Epoch 67/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.556784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 67/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 16.384012]\n",
      "[Epoch 67/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.325003]\n",
      "[Epoch 67/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.636929]\n",
      "[Epoch 67/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 16.368694]\n",
      "[Epoch 67/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 16.370720]\n",
      "[Epoch 67/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 16.640854]\n",
      "[Epoch 67/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 16.331593]\n",
      "[Epoch 67/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 16.563791]\n",
      "[Epoch 67/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.673351]\n",
      "[Epoch 67/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 16.608061]\n",
      "[Epoch 67/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.793102]\n",
      "[Epoch 67/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.650871]\n",
      "[Epoch 67/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.545197]\n",
      "[Epoch 67/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 16.169537]\n",
      "[Epoch 67/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 16.519995]\n",
      "[Epoch 67/1000] [Batch 129/168] [D loss: 0.000001] [G loss: 16.644081]\n",
      "[Epoch 67/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 16.858664]\n",
      "[Epoch 67/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 16.416948]\n",
      "[Epoch 67/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 16.126537]\n",
      "[Epoch 67/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 16.264135]\n",
      "[Epoch 67/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.480656]\n",
      "[Epoch 67/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 16.232418]\n",
      "[Epoch 67/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 16.395447]\n",
      "[Epoch 67/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.559425]\n",
      "[Epoch 67/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 16.688347]\n",
      "[Epoch 67/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.626131]\n",
      "[Epoch 67/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 16.524479]\n",
      "[Epoch 67/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.698702]\n",
      "[Epoch 67/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 16.572468]\n",
      "[Epoch 67/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.685284]\n",
      "[Epoch 67/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.879013]\n",
      "[Epoch 67/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.710560]\n",
      "[Epoch 67/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.454744]\n",
      "[Epoch 67/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.647779]\n",
      "[Epoch 67/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 16.558315]\n",
      "[Epoch 67/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 16.724125]\n",
      "[Epoch 67/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.469540]\n",
      "[Epoch 67/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.721792]\n",
      "[Epoch 67/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 16.510546]\n",
      "[Epoch 67/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 16.249029]\n",
      "[Epoch 67/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.633574]\n",
      "[Epoch 67/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.352310]\n",
      "[Epoch 67/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.435852]\n",
      "[Epoch 67/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.668570]\n",
      "[Epoch 67/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.500153]\n",
      "[Epoch 67/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.851274]\n",
      "[Epoch 67/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 16.231663]\n",
      "[Epoch 67/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.558676]\n",
      "[Epoch 67/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.983656]\n",
      "[Epoch 67/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 16.596426]\n",
      "[Epoch 67/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 16.816854]\n",
      "[Epoch 67/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.574661]\n",
      "[Epoch 67/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.524164]\n",
      "[Epoch 67/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.428574]\n",
      "[Epoch 67/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 16.638515]\n",
      "[Epoch 68/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 16.330484]\n",
      "[Epoch 68/1000] [Batch 2/168] [D loss: 0.000001] [G loss: 16.678154]\n",
      "[Epoch 68/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 16.284584]\n",
      "[Epoch 68/1000] [Batch 4/168] [D loss: 0.000001] [G loss: 16.418289]\n",
      "[Epoch 68/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.945089]\n",
      "[Epoch 68/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.532066]\n",
      "[Epoch 68/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.927612]\n",
      "[Epoch 68/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.832911]\n",
      "[Epoch 68/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.587563]\n",
      "[Epoch 68/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.166651]\n",
      "[Epoch 68/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.823433]\n",
      "[Epoch 68/1000] [Batch 12/168] [D loss: 0.000001] [G loss: 16.550142]\n",
      "[Epoch 68/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 16.281805]\n",
      "[Epoch 68/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 16.564739]\n",
      "[Epoch 68/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.767111]\n",
      "[Epoch 68/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 16.493679]\n",
      "[Epoch 68/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 16.713280]\n",
      "[Epoch 68/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.932249]\n",
      "[Epoch 68/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 16.487507]\n",
      "[Epoch 68/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 16.136402]\n",
      "[Epoch 68/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 16.270309]\n",
      "[Epoch 68/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.559231]\n",
      "[Epoch 68/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.478285]\n",
      "[Epoch 68/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.839695]\n",
      "[Epoch 68/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 16.556660]\n",
      "[Epoch 68/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 16.430273]\n",
      "[Epoch 68/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 16.881601]\n",
      "[Epoch 68/1000] [Batch 28/168] [D loss: 0.000001] [G loss: 16.797657]\n",
      "[Epoch 68/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 16.722073]\n",
      "[Epoch 68/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.473961]\n",
      "[Epoch 68/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.542894]\n",
      "[Epoch 68/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.399208]\n",
      "[Epoch 68/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.623329]\n",
      "[Epoch 68/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.622486]\n",
      "[Epoch 68/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.388609]\n",
      "[Epoch 68/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 16.445896]\n",
      "[Epoch 68/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.362522]\n",
      "[Epoch 68/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.550077]\n",
      "[Epoch 68/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 16.740454]\n",
      "[Epoch 68/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.726789]\n",
      "[Epoch 68/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 16.968195]\n",
      "[Epoch 68/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 16.951803]\n",
      "[Epoch 68/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 16.365980]\n",
      "[Epoch 68/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.632023]\n",
      "[Epoch 68/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.376732]\n",
      "[Epoch 68/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.800869]\n",
      "[Epoch 68/1000] [Batch 47/168] [D loss: 0.000001] [G loss: 16.118223]\n",
      "[Epoch 68/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 16.618902]\n",
      "[Epoch 68/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 16.185490]\n",
      "[Epoch 68/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 16.656889]\n",
      "[Epoch 68/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 16.569382]\n",
      "[Epoch 68/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 17.097252]\n",
      "[Epoch 68/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 16.605793]\n",
      "[Epoch 68/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.599710]\n",
      "[Epoch 68/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 16.615438]\n",
      "[Epoch 68/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.779207]\n",
      "[Epoch 68/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.499222]\n",
      "[Epoch 68/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.636490]\n",
      "[Epoch 68/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.993023]\n",
      "[Epoch 68/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 16.562244]\n",
      "[Epoch 68/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.663719]\n",
      "[Epoch 68/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.572857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 16.128769]\n",
      "[Epoch 68/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.573589]\n",
      "[Epoch 68/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 16.303028]\n",
      "[Epoch 68/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.859558]\n",
      "[Epoch 68/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 16.678139]\n",
      "[Epoch 68/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.306366]\n",
      "[Epoch 68/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.862530]\n",
      "[Epoch 68/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.522692]\n",
      "[Epoch 68/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.635450]\n",
      "[Epoch 68/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 16.615601]\n",
      "[Epoch 68/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.534979]\n",
      "[Epoch 68/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 16.667055]\n",
      "[Epoch 68/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.248234]\n",
      "[Epoch 68/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.500942]\n",
      "[Epoch 68/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.715229]\n",
      "[Epoch 68/1000] [Batch 78/168] [D loss: 0.000001] [G loss: 16.563234]\n",
      "[Epoch 68/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 17.006603]\n",
      "[Epoch 68/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.493849]\n",
      "[Epoch 68/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.506310]\n",
      "[Epoch 68/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 16.449171]\n",
      "[Epoch 68/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.730204]\n",
      "[Epoch 68/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 16.593147]\n",
      "[Epoch 68/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 16.782040]\n",
      "[Epoch 68/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 16.640875]\n",
      "[Epoch 68/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 17.055124]\n",
      "[Epoch 68/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.859997]\n",
      "[Epoch 68/1000] [Batch 89/168] [D loss: 0.000001] [G loss: 16.704006]\n",
      "[Epoch 68/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.794876]\n",
      "[Epoch 68/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 16.892063]\n",
      "[Epoch 68/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 17.099903]\n",
      "[Epoch 68/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.655678]\n",
      "[Epoch 68/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.861259]\n",
      "[Epoch 68/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.600565]\n",
      "[Epoch 68/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 16.911297]\n",
      "[Epoch 68/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.734001]\n",
      "[Epoch 68/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.529728]\n",
      "[Epoch 68/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.664562]\n",
      "[Epoch 68/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.562340]\n",
      "[Epoch 68/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.809822]\n",
      "[Epoch 68/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.672403]\n",
      "[Epoch 68/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.595997]\n",
      "[Epoch 68/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 16.629110]\n",
      "[Epoch 68/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.699818]\n",
      "[Epoch 68/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.574718]\n",
      "[Epoch 68/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 16.813040]\n",
      "[Epoch 68/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 17.041599]\n",
      "[Epoch 68/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 16.821444]\n",
      "[Epoch 68/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.604321]\n",
      "[Epoch 68/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 16.853050]\n",
      "[Epoch 68/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.698906]\n",
      "[Epoch 68/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.348574]\n",
      "[Epoch 68/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 16.594137]\n",
      "[Epoch 68/1000] [Batch 115/168] [D loss: 0.000001] [G loss: 17.027025]\n",
      "[Epoch 68/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.983587]\n",
      "[Epoch 68/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 16.502207]\n",
      "[Epoch 68/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 16.592218]\n",
      "[Epoch 68/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 16.684490]\n",
      "[Epoch 68/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 16.651531]\n",
      "[Epoch 68/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 16.851608]\n",
      "[Epoch 68/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.587605]\n",
      "[Epoch 68/1000] [Batch 123/168] [D loss: 0.000001] [G loss: 16.515472]\n",
      "[Epoch 68/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.313026]\n",
      "[Epoch 68/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.725199]\n",
      "[Epoch 68/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.530167]\n",
      "[Epoch 68/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 16.839100]\n",
      "[Epoch 68/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 16.565866]\n",
      "[Epoch 68/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 17.001318]\n",
      "[Epoch 68/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 16.658855]\n",
      "[Epoch 68/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 16.927519]\n",
      "[Epoch 68/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 16.573547]\n",
      "[Epoch 68/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 16.892298]\n",
      "[Epoch 68/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.589010]\n",
      "[Epoch 68/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 16.752573]\n",
      "[Epoch 68/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 16.480227]\n",
      "[Epoch 68/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.689587]\n",
      "[Epoch 68/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 16.538647]\n",
      "[Epoch 68/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.491400]\n",
      "[Epoch 68/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 16.773573]\n",
      "[Epoch 68/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.772655]\n",
      "[Epoch 68/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 16.868561]\n",
      "[Epoch 68/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.523359]\n",
      "[Epoch 68/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.837914]\n",
      "[Epoch 68/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.569937]\n",
      "[Epoch 68/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.703766]\n",
      "[Epoch 68/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 15.948924]\n",
      "[Epoch 68/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 16.557613]\n",
      "[Epoch 68/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 16.724579]\n",
      "[Epoch 68/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.737921]\n",
      "[Epoch 68/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.509600]\n",
      "[Epoch 68/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 16.774399]\n",
      "[Epoch 68/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 16.629601]\n",
      "[Epoch 68/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.811708]\n",
      "[Epoch 68/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.480467]\n",
      "[Epoch 68/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.558969]\n",
      "[Epoch 68/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.962383]\n",
      "[Epoch 68/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.358356]\n",
      "[Epoch 68/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.636446]\n",
      "[Epoch 68/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 16.800526]\n",
      "[Epoch 68/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.647167]\n",
      "[Epoch 68/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.964466]\n",
      "[Epoch 68/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 16.719158]\n",
      "[Epoch 68/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 16.681328]\n",
      "[Epoch 68/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.618343]\n",
      "[Epoch 68/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.816626]\n",
      "[Epoch 68/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.774553]\n",
      "[Epoch 68/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 17.025251]\n",
      "[Epoch 69/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 16.548416]\n",
      "[Epoch 69/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.783194]\n",
      "[Epoch 69/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 16.702562]\n",
      "[Epoch 69/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 16.945681]\n",
      "[Epoch 69/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.360857]\n",
      "[Epoch 69/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.875563]\n",
      "[Epoch 69/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.698971]\n",
      "[Epoch 69/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.772825]\n",
      "[Epoch 69/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.491667]\n",
      "[Epoch 69/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.511908]\n",
      "[Epoch 69/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.686548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.953323]\n",
      "[Epoch 69/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 16.673733]\n",
      "[Epoch 69/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 17.076546]\n",
      "[Epoch 69/1000] [Batch 15/168] [D loss: 0.000001] [G loss: 16.320738]\n",
      "[Epoch 69/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 16.856535]\n",
      "[Epoch 69/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 16.712929]\n",
      "[Epoch 69/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.782383]\n",
      "[Epoch 69/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 16.794533]\n",
      "[Epoch 69/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 16.802528]\n",
      "[Epoch 69/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 16.580711]\n",
      "[Epoch 69/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.836929]\n",
      "[Epoch 69/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.470144]\n",
      "[Epoch 69/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.556877]\n",
      "[Epoch 69/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 16.757080]\n",
      "[Epoch 69/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 16.658092]\n",
      "[Epoch 69/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 16.704420]\n",
      "[Epoch 69/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.809467]\n",
      "[Epoch 69/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 16.323673]\n",
      "[Epoch 69/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.418644]\n",
      "[Epoch 69/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.870337]\n",
      "[Epoch 69/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.861435]\n",
      "[Epoch 69/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.439308]\n",
      "[Epoch 69/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.707951]\n",
      "[Epoch 69/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.970695]\n",
      "[Epoch 69/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 16.483761]\n",
      "[Epoch 69/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.591183]\n",
      "[Epoch 69/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.954939]\n",
      "[Epoch 69/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 16.540348]\n",
      "[Epoch 69/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.500690]\n",
      "[Epoch 69/1000] [Batch 41/168] [D loss: 0.000001] [G loss: 16.604950]\n",
      "[Epoch 69/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 16.445456]\n",
      "[Epoch 69/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 16.797981]\n",
      "[Epoch 69/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.425173]\n",
      "[Epoch 69/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.704897]\n",
      "[Epoch 69/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.967272]\n",
      "[Epoch 69/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 17.208776]\n",
      "[Epoch 69/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 16.650858]\n",
      "[Epoch 69/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 17.105623]\n",
      "[Epoch 69/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 16.552034]\n",
      "[Epoch 69/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 17.024330]\n",
      "[Epoch 69/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 16.833809]\n",
      "[Epoch 69/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 16.488726]\n",
      "[Epoch 69/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.546591]\n",
      "[Epoch 69/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 16.784571]\n",
      "[Epoch 69/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.641479]\n",
      "[Epoch 69/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.641005]\n",
      "[Epoch 69/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.919666]\n",
      "[Epoch 69/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.939938]\n",
      "[Epoch 69/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 16.851366]\n",
      "[Epoch 69/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.703251]\n",
      "[Epoch 69/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.656496]\n",
      "[Epoch 69/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 17.023029]\n",
      "[Epoch 69/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.611738]\n",
      "[Epoch 69/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 17.177551]\n",
      "[Epoch 69/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.149027]\n",
      "[Epoch 69/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 16.560257]\n",
      "[Epoch 69/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.838980]\n",
      "[Epoch 69/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.585621]\n",
      "[Epoch 69/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.613192]\n",
      "[Epoch 69/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.857162]\n",
      "[Epoch 69/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 17.023760]\n",
      "[Epoch 69/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.620327]\n",
      "[Epoch 69/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 16.465219]\n",
      "[Epoch 69/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.503607]\n",
      "[Epoch 69/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.429337]\n",
      "[Epoch 69/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.758533]\n",
      "[Epoch 69/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.990129]\n",
      "[Epoch 69/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 16.994902]\n",
      "[Epoch 69/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.639740]\n",
      "[Epoch 69/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 17.046198]\n",
      "[Epoch 69/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 16.823299]\n",
      "[Epoch 69/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.949259]\n",
      "[Epoch 69/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 16.576853]\n",
      "[Epoch 69/1000] [Batch 85/168] [D loss: 0.000001] [G loss: 16.753347]\n",
      "[Epoch 69/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 16.470528]\n",
      "[Epoch 69/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 16.740816]\n",
      "[Epoch 69/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.797144]\n",
      "[Epoch 69/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.800417]\n",
      "[Epoch 69/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.970726]\n",
      "[Epoch 69/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 16.891190]\n",
      "[Epoch 69/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 16.704857]\n",
      "[Epoch 69/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.677460]\n",
      "[Epoch 69/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.459099]\n",
      "[Epoch 69/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.660116]\n",
      "[Epoch 69/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 16.863148]\n",
      "[Epoch 69/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.688160]\n",
      "[Epoch 69/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.726620]\n",
      "[Epoch 69/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.702261]\n",
      "[Epoch 69/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.424355]\n",
      "[Epoch 69/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 17.003252]\n",
      "[Epoch 69/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.722084]\n",
      "[Epoch 69/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.733448]\n",
      "[Epoch 69/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 16.568508]\n",
      "[Epoch 69/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.750666]\n",
      "[Epoch 69/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.720381]\n",
      "[Epoch 69/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 16.781902]\n",
      "[Epoch 69/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 16.228199]\n",
      "[Epoch 69/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 16.510569]\n",
      "[Epoch 69/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.714069]\n",
      "[Epoch 69/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 17.109968]\n",
      "[Epoch 69/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.607971]\n",
      "[Epoch 69/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.979923]\n",
      "[Epoch 69/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 16.656876]\n",
      "[Epoch 69/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.821831]\n",
      "[Epoch 69/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.646320]\n",
      "[Epoch 69/1000] [Batch 117/168] [D loss: 0.000002] [G loss: 16.793127]\n",
      "[Epoch 69/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 17.061190]\n",
      "[Epoch 69/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 16.998459]\n",
      "[Epoch 69/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 16.967850]\n",
      "[Epoch 69/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 16.721745]\n",
      "[Epoch 69/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.661715]\n",
      "[Epoch 69/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 17.107334]\n",
      "[Epoch 69/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.722797]\n",
      "[Epoch 69/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.697128]\n",
      "[Epoch 69/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.918716]\n",
      "[Epoch 69/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 16.782177]\n",
      "[Epoch 69/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 16.863926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 16.970070]\n",
      "[Epoch 69/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 17.379793]\n",
      "[Epoch 69/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 16.689043]\n",
      "[Epoch 69/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 17.014090]\n",
      "[Epoch 69/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 17.067631]\n",
      "[Epoch 69/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.895741]\n",
      "[Epoch 69/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 16.990559]\n",
      "[Epoch 69/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 17.097311]\n",
      "[Epoch 69/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.940256]\n",
      "[Epoch 69/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 16.834352]\n",
      "[Epoch 69/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.878677]\n",
      "[Epoch 69/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 16.900826]\n",
      "[Epoch 69/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.561090]\n",
      "[Epoch 69/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 17.475674]\n",
      "[Epoch 69/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.867878]\n",
      "[Epoch 69/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.975983]\n",
      "[Epoch 69/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.648067]\n",
      "[Epoch 69/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.700422]\n",
      "[Epoch 69/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.946085]\n",
      "[Epoch 69/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 17.026384]\n",
      "[Epoch 69/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 16.738144]\n",
      "[Epoch 69/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.803867]\n",
      "[Epoch 69/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.421070]\n",
      "[Epoch 69/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 16.580303]\n",
      "[Epoch 69/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 17.087351]\n",
      "[Epoch 69/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.548626]\n",
      "[Epoch 69/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.991478]\n",
      "[Epoch 69/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.518749]\n",
      "[Epoch 69/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.777704]\n",
      "[Epoch 69/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.661985]\n",
      "[Epoch 69/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.680634]\n",
      "[Epoch 69/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 17.125803]\n",
      "[Epoch 69/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.667768]\n",
      "[Epoch 69/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 17.133270]\n",
      "[Epoch 69/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 16.864090]\n",
      "[Epoch 69/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 16.743914]\n",
      "[Epoch 69/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.963400]\n",
      "[Epoch 69/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.691746]\n",
      "[Epoch 69/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.486834]\n",
      "[Epoch 69/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 17.047537]\n",
      "[Epoch 70/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 16.933210]\n",
      "[Epoch 70/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.840528]\n",
      "[Epoch 70/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 16.788244]\n",
      "[Epoch 70/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 16.657324]\n",
      "[Epoch 70/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.710030]\n",
      "[Epoch 70/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 17.068110]\n",
      "[Epoch 70/1000] [Batch 7/168] [D loss: 0.000001] [G loss: 16.737007]\n",
      "[Epoch 70/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.690201]\n",
      "[Epoch 70/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.775129]\n",
      "[Epoch 70/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.985617]\n",
      "[Epoch 70/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.918816]\n",
      "[Epoch 70/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.930386]\n",
      "[Epoch 70/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 17.060705]\n",
      "[Epoch 70/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 17.022238]\n",
      "[Epoch 70/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.942806]\n",
      "[Epoch 70/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 16.232000]\n",
      "[Epoch 70/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 16.853550]\n",
      "[Epoch 70/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.889271]\n",
      "[Epoch 70/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 16.800264]\n",
      "[Epoch 70/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 16.883125]\n",
      "[Epoch 70/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 16.662624]\n",
      "[Epoch 70/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.685038]\n",
      "[Epoch 70/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.951107]\n",
      "[Epoch 70/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.831926]\n",
      "[Epoch 70/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 16.539467]\n",
      "[Epoch 70/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 16.773411]\n",
      "[Epoch 70/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 16.994194]\n",
      "[Epoch 70/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.665209]\n",
      "[Epoch 70/1000] [Batch 29/168] [D loss: 0.000001] [G loss: 16.973286]\n",
      "[Epoch 70/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.800882]\n",
      "[Epoch 70/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.858294]\n",
      "[Epoch 70/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.517986]\n",
      "[Epoch 70/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.712950]\n",
      "[Epoch 70/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.498831]\n",
      "[Epoch 70/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.829458]\n",
      "[Epoch 70/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 16.348139]\n",
      "[Epoch 70/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 17.044102]\n",
      "[Epoch 70/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.509338]\n",
      "[Epoch 70/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 17.064489]\n",
      "[Epoch 70/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.936983]\n",
      "[Epoch 70/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 17.070805]\n",
      "[Epoch 70/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 16.735456]\n",
      "[Epoch 70/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 17.125385]\n",
      "[Epoch 70/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.983448]\n",
      "[Epoch 70/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.698198]\n",
      "[Epoch 70/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.565895]\n",
      "[Epoch 70/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 17.121925]\n",
      "[Epoch 70/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 16.862654]\n",
      "[Epoch 70/1000] [Batch 49/168] [D loss: 0.000001] [G loss: 16.844997]\n",
      "[Epoch 70/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 16.977428]\n",
      "[Epoch 70/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 17.027414]\n",
      "[Epoch 70/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 16.638170]\n",
      "[Epoch 70/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 17.181952]\n",
      "[Epoch 70/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 17.066746]\n",
      "[Epoch 70/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 16.922058]\n",
      "[Epoch 70/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.942917]\n",
      "[Epoch 70/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.508337]\n",
      "[Epoch 70/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.752947]\n",
      "[Epoch 70/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.796635]\n",
      "[Epoch 70/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 16.838375]\n",
      "[Epoch 70/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.929119]\n",
      "[Epoch 70/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.612349]\n",
      "[Epoch 70/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 17.060741]\n",
      "[Epoch 70/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 17.073015]\n",
      "[Epoch 70/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 16.665100]\n",
      "[Epoch 70/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.832878]\n",
      "[Epoch 70/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 16.774426]\n",
      "[Epoch 70/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.850470]\n",
      "[Epoch 70/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.907579]\n",
      "[Epoch 70/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 17.185938]\n",
      "[Epoch 70/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.902096]\n",
      "[Epoch 70/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 17.053272]\n",
      "[Epoch 70/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.637974]\n",
      "[Epoch 70/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 16.576279]\n",
      "[Epoch 70/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.743031]\n",
      "[Epoch 70/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 17.048622]\n",
      "[Epoch 70/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 16.926035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.858818]\n",
      "[Epoch 70/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 16.720860]\n",
      "[Epoch 70/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.977186]\n",
      "[Epoch 70/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.768127]\n",
      "[Epoch 70/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 16.954842]\n",
      "[Epoch 70/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.907909]\n",
      "[Epoch 70/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 16.622816]\n",
      "[Epoch 70/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 16.687447]\n",
      "[Epoch 70/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 17.052050]\n",
      "[Epoch 70/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 16.920105]\n",
      "[Epoch 70/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.957548]\n",
      "[Epoch 70/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 17.111258]\n",
      "[Epoch 70/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 17.152313]\n",
      "[Epoch 70/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 16.984909]\n",
      "[Epoch 70/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 17.089167]\n",
      "[Epoch 70/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.528627]\n",
      "[Epoch 70/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.804432]\n",
      "[Epoch 70/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.826195]\n",
      "[Epoch 70/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 16.823782]\n",
      "[Epoch 70/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.980587]\n",
      "[Epoch 70/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.961758]\n",
      "[Epoch 70/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.636703]\n",
      "[Epoch 70/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 17.175653]\n",
      "[Epoch 70/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.530943]\n",
      "[Epoch 70/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.635090]\n",
      "[Epoch 70/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.808920]\n",
      "[Epoch 70/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 17.104078]\n",
      "[Epoch 70/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.635431]\n",
      "[Epoch 70/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.917282]\n",
      "[Epoch 70/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 16.990316]\n",
      "[Epoch 70/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 17.071960]\n",
      "[Epoch 70/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 16.877512]\n",
      "[Epoch 70/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.703018]\n",
      "[Epoch 70/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 16.689150]\n",
      "[Epoch 70/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.856693]\n",
      "[Epoch 70/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.992935]\n",
      "[Epoch 70/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 16.539583]\n",
      "[Epoch 70/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.762762]\n",
      "[Epoch 70/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.973543]\n",
      "[Epoch 70/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 17.068504]\n",
      "[Epoch 70/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 16.427010]\n",
      "[Epoch 70/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 16.783646]\n",
      "[Epoch 70/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 16.613945]\n",
      "[Epoch 70/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 17.218285]\n",
      "[Epoch 70/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.844870]\n",
      "[Epoch 70/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 16.779934]\n",
      "[Epoch 70/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.914759]\n",
      "[Epoch 70/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.655514]\n",
      "[Epoch 70/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.507757]\n",
      "[Epoch 70/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 16.959600]\n",
      "[Epoch 70/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 16.927057]\n",
      "[Epoch 70/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 17.177662]\n",
      "[Epoch 70/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 16.911636]\n",
      "[Epoch 70/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 16.926979]\n",
      "[Epoch 70/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 16.978886]\n",
      "[Epoch 70/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 16.397772]\n",
      "[Epoch 70/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 17.239538]\n",
      "[Epoch 70/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 16.680927]\n",
      "[Epoch 70/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 16.649384]\n",
      "[Epoch 70/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.772532]\n",
      "[Epoch 70/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 16.779388]\n",
      "[Epoch 70/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.999327]\n",
      "[Epoch 70/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 16.982468]\n",
      "[Epoch 70/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.861008]\n",
      "[Epoch 70/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 16.954748]\n",
      "[Epoch 70/1000] [Batch 143/168] [D loss: 0.000001] [G loss: 17.063520]\n",
      "[Epoch 70/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 16.540468]\n",
      "[Epoch 70/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.874847]\n",
      "[Epoch 70/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 16.895693]\n",
      "[Epoch 70/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.873569]\n",
      "[Epoch 70/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 17.057537]\n",
      "[Epoch 70/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 17.080601]\n",
      "[Epoch 70/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 17.126284]\n",
      "[Epoch 70/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 17.018429]\n",
      "[Epoch 70/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 16.696777]\n",
      "[Epoch 70/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 16.696478]\n",
      "[Epoch 70/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.614599]\n",
      "[Epoch 70/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 16.846516]\n",
      "[Epoch 70/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.829180]\n",
      "[Epoch 70/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.589752]\n",
      "[Epoch 70/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.715744]\n",
      "[Epoch 70/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.862501]\n",
      "[Epoch 70/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 17.347858]\n",
      "[Epoch 70/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.913509]\n",
      "[Epoch 70/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.587471]\n",
      "[Epoch 70/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 16.700605]\n",
      "[Epoch 70/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 17.013109]\n",
      "[Epoch 70/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.674999]\n",
      "[Epoch 70/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 17.044464]\n",
      "[Epoch 70/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.950098]\n",
      "[Epoch 70/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 16.769033]\n",
      "[Epoch 71/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 16.908371]\n",
      "[Epoch 71/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.961189]\n",
      "[Epoch 71/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 16.440506]\n",
      "[Epoch 71/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 17.126255]\n",
      "[Epoch 71/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 17.044487]\n",
      "[Epoch 71/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 17.228050]\n",
      "[Epoch 71/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.755136]\n",
      "[Epoch 71/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.816229]\n",
      "[Epoch 71/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.526394]\n",
      "[Epoch 71/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.792202]\n",
      "[Epoch 71/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.834444]\n",
      "[Epoch 71/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.498077]\n",
      "[Epoch 71/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 16.956451]\n",
      "[Epoch 71/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 16.993589]\n",
      "[Epoch 71/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.630619]\n",
      "[Epoch 71/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 17.028591]\n",
      "[Epoch 71/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 17.245846]\n",
      "[Epoch 71/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.865520]\n",
      "[Epoch 71/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 16.461237]\n",
      "[Epoch 71/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 17.004177]\n",
      "[Epoch 71/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 17.407764]\n",
      "[Epoch 71/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.992834]\n",
      "[Epoch 71/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 17.216824]\n",
      "[Epoch 71/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 17.195044]\n",
      "[Epoch 71/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 16.587524]\n",
      "[Epoch 71/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 17.008945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 71/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 16.876579]\n",
      "[Epoch 71/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.815180]\n",
      "[Epoch 71/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 16.792130]\n",
      "[Epoch 71/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.957075]\n",
      "[Epoch 71/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.882751]\n",
      "[Epoch 71/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 16.782581]\n",
      "[Epoch 71/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 16.824663]\n",
      "[Epoch 71/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.900101]\n",
      "[Epoch 71/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.842220]\n",
      "[Epoch 71/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 17.009657]\n",
      "[Epoch 71/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 17.105062]\n",
      "[Epoch 71/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.949753]\n",
      "[Epoch 71/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 17.171021]\n",
      "[Epoch 71/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.989655]\n",
      "[Epoch 71/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 16.928005]\n",
      "[Epoch 71/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 17.023613]\n",
      "[Epoch 71/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 16.989819]\n",
      "[Epoch 71/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.792288]\n",
      "[Epoch 71/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 17.325914]\n",
      "[Epoch 71/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 16.949747]\n",
      "[Epoch 71/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 16.549671]\n",
      "[Epoch 71/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 16.749660]\n",
      "[Epoch 71/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 16.813114]\n",
      "[Epoch 71/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 16.609640]\n",
      "[Epoch 71/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 16.911961]\n",
      "[Epoch 71/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 16.824354]\n",
      "[Epoch 71/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 16.965696]\n",
      "[Epoch 71/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 17.102596]\n",
      "[Epoch 71/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 17.101753]\n",
      "[Epoch 71/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.852852]\n",
      "[Epoch 71/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.882105]\n",
      "[Epoch 71/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 17.054016]\n",
      "[Epoch 71/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 17.127464]\n",
      "[Epoch 71/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 17.023033]\n",
      "[Epoch 71/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.868130]\n",
      "[Epoch 71/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 17.063982]\n",
      "[Epoch 71/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 17.226936]\n",
      "[Epoch 71/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.866034]\n",
      "[Epoch 71/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 17.165878]\n",
      "[Epoch 71/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.692507]\n",
      "[Epoch 71/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 17.364435]\n",
      "[Epoch 71/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.521103]\n",
      "[Epoch 71/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.973486]\n",
      "[Epoch 71/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 16.914520]\n",
      "[Epoch 71/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.936531]\n",
      "[Epoch 71/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 17.062086]\n",
      "[Epoch 71/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 16.805550]\n",
      "[Epoch 71/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 17.031393]\n",
      "[Epoch 71/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.711700]\n",
      "[Epoch 71/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.759003]\n",
      "[Epoch 71/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 17.304329]\n",
      "[Epoch 71/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.955074]\n",
      "[Epoch 71/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 16.639030]\n",
      "[Epoch 71/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 16.974117]\n",
      "[Epoch 71/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.855639]\n",
      "[Epoch 71/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 16.801712]\n",
      "[Epoch 71/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.600822]\n",
      "[Epoch 71/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 16.721544]\n",
      "[Epoch 71/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 17.104116]\n",
      "[Epoch 71/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 17.122107]\n",
      "[Epoch 71/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 16.886612]\n",
      "[Epoch 71/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.587477]\n",
      "[Epoch 71/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.495205]\n",
      "[Epoch 71/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 17.099318]\n",
      "[Epoch 71/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 16.614807]\n",
      "[Epoch 71/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 16.689962]\n",
      "[Epoch 71/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 17.043756]\n",
      "[Epoch 71/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.772726]\n",
      "[Epoch 71/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 16.981094]\n",
      "[Epoch 71/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 17.092049]\n",
      "[Epoch 71/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.646557]\n",
      "[Epoch 71/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 16.778360]\n",
      "[Epoch 71/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.798466]\n",
      "[Epoch 71/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.946159]\n",
      "[Epoch 71/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.694885]\n",
      "[Epoch 71/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.468214]\n",
      "[Epoch 71/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 16.863157]\n",
      "[Epoch 71/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 16.682453]\n",
      "[Epoch 71/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.826448]\n",
      "[Epoch 71/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 16.961018]\n",
      "[Epoch 71/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 17.016739]\n",
      "[Epoch 71/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 16.821356]\n",
      "[Epoch 71/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 16.933567]\n",
      "[Epoch 71/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.763294]\n",
      "[Epoch 71/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 16.988760]\n",
      "[Epoch 71/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 16.724207]\n",
      "[Epoch 71/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 16.909302]\n",
      "[Epoch 71/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 17.003849]\n",
      "[Epoch 71/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 17.270655]\n",
      "[Epoch 71/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 16.982225]\n",
      "[Epoch 71/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 16.975679]\n",
      "[Epoch 71/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 16.741861]\n",
      "[Epoch 71/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 17.056156]\n",
      "[Epoch 71/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 16.519369]\n",
      "[Epoch 71/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 16.896326]\n",
      "[Epoch 71/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 17.081675]\n",
      "[Epoch 71/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 17.231695]\n",
      "[Epoch 71/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 17.098583]\n",
      "[Epoch 71/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 16.759302]\n",
      "[Epoch 71/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 16.947460]\n",
      "[Epoch 71/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 16.922073]\n",
      "[Epoch 71/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 16.883209]\n",
      "[Epoch 71/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 16.900852]\n",
      "[Epoch 71/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 17.254507]\n",
      "[Epoch 71/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 17.043430]\n",
      "[Epoch 71/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 16.686602]\n",
      "[Epoch 71/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 16.959820]\n",
      "[Epoch 71/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.503380]\n",
      "[Epoch 71/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 16.920895]\n",
      "[Epoch 71/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 16.902128]\n",
      "[Epoch 71/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 16.583630]\n",
      "[Epoch 71/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 16.995083]\n",
      "[Epoch 71/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.886156]\n",
      "[Epoch 71/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 17.023443]\n",
      "[Epoch 71/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 17.141760]\n",
      "[Epoch 71/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 16.775311]\n",
      "[Epoch 71/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 16.582418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 71/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 17.003513]\n",
      "[Epoch 71/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 16.700279]\n",
      "[Epoch 71/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 17.054453]\n",
      "[Epoch 71/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 17.018099]\n",
      "[Epoch 71/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 16.933041]\n",
      "[Epoch 71/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 16.989611]\n",
      "[Epoch 71/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 17.184446]\n",
      "[Epoch 71/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 16.978249]\n",
      "[Epoch 71/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 17.285257]\n",
      "[Epoch 71/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 17.173346]\n",
      "[Epoch 71/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 16.916759]\n",
      "[Epoch 71/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 17.333353]\n",
      "[Epoch 71/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.801750]\n",
      "[Epoch 71/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.752415]\n",
      "[Epoch 71/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 17.226498]\n",
      "[Epoch 71/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.735664]\n",
      "[Epoch 71/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 16.818134]\n",
      "[Epoch 71/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 16.879473]\n",
      "[Epoch 71/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.884291]\n",
      "[Epoch 71/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 17.174929]\n",
      "[Epoch 71/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 16.748936]\n",
      "[Epoch 71/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 17.041821]\n",
      "[Epoch 71/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 17.150208]\n",
      "[Epoch 71/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 16.758757]\n",
      "[Epoch 71/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 16.705730]\n",
      "[Epoch 72/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 17.048737]\n",
      "[Epoch 72/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 17.115295]\n",
      "[Epoch 72/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 17.078087]\n",
      "[Epoch 72/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 17.094770]\n",
      "[Epoch 72/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.855679]\n",
      "[Epoch 72/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.863241]\n",
      "[Epoch 72/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.854694]\n",
      "[Epoch 72/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 16.636536]\n",
      "[Epoch 72/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 16.971336]\n",
      "[Epoch 72/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.950687]\n",
      "[Epoch 72/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 16.943819]\n",
      "[Epoch 72/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.990610]\n",
      "[Epoch 72/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 16.605040]\n",
      "[Epoch 72/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 17.110378]\n",
      "[Epoch 72/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 16.809452]\n",
      "[Epoch 72/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 17.003635]\n",
      "[Epoch 72/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 17.159594]\n",
      "[Epoch 72/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.657169]\n",
      "[Epoch 72/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 17.169678]\n",
      "[Epoch 72/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 17.398821]\n",
      "[Epoch 72/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 16.604855]\n",
      "[Epoch 72/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 16.904922]\n",
      "[Epoch 72/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 16.995552]\n",
      "[Epoch 72/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 16.951962]\n",
      "[Epoch 72/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 17.020884]\n",
      "[Epoch 72/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 16.727629]\n",
      "[Epoch 72/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 17.113348]\n",
      "[Epoch 72/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.910460]\n",
      "[Epoch 72/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 17.339300]\n",
      "[Epoch 72/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 17.008467]\n",
      "[Epoch 72/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 17.155458]\n",
      "[Epoch 72/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 17.098396]\n",
      "[Epoch 72/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 17.394793]\n",
      "[Epoch 72/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 17.035238]\n",
      "[Epoch 72/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.829702]\n",
      "[Epoch 72/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 16.825720]\n",
      "[Epoch 72/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 17.296280]\n",
      "[Epoch 72/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 17.129984]\n",
      "[Epoch 72/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 17.053154]\n",
      "[Epoch 72/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.919237]\n",
      "[Epoch 72/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 16.768053]\n",
      "[Epoch 72/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 16.868601]\n",
      "[Epoch 72/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 16.879438]\n",
      "[Epoch 72/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 17.060865]\n",
      "[Epoch 72/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 16.148945]\n",
      "[Epoch 72/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 17.133411]\n",
      "[Epoch 72/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 17.073242]\n",
      "[Epoch 72/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 16.838579]\n",
      "[Epoch 72/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 17.314974]\n",
      "[Epoch 72/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 17.127438]\n",
      "[Epoch 72/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 17.009197]\n",
      "[Epoch 72/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 17.118322]\n",
      "[Epoch 72/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 16.955217]\n",
      "[Epoch 72/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.934294]\n",
      "[Epoch 72/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 16.842319]\n",
      "[Epoch 72/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 17.166832]\n",
      "[Epoch 72/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 17.197821]\n",
      "[Epoch 72/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 17.009611]\n",
      "[Epoch 72/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 17.115541]\n",
      "[Epoch 72/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 17.403423]\n",
      "[Epoch 72/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 17.021957]\n",
      "[Epoch 72/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.966385]\n",
      "[Epoch 72/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 16.911785]\n",
      "[Epoch 72/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 17.220703]\n",
      "[Epoch 72/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 16.814892]\n",
      "[Epoch 72/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 17.285919]\n",
      "[Epoch 72/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 17.048159]\n",
      "[Epoch 72/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.778606]\n",
      "[Epoch 72/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 16.858881]\n",
      "[Epoch 72/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 17.180185]\n",
      "[Epoch 72/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.684380]\n",
      "[Epoch 72/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 17.073301]\n",
      "[Epoch 72/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 17.021603]\n",
      "[Epoch 72/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 17.038504]\n",
      "[Epoch 72/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.847670]\n",
      "[Epoch 72/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 16.990269]\n",
      "[Epoch 72/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 17.172352]\n",
      "[Epoch 72/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 17.114620]\n",
      "[Epoch 72/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 17.081095]\n",
      "[Epoch 72/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 17.026825]\n",
      "[Epoch 72/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.918398]\n",
      "[Epoch 72/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 17.262587]\n",
      "[Epoch 72/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.910923]\n",
      "[Epoch 72/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 17.254429]\n",
      "[Epoch 72/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 17.009176]\n",
      "[Epoch 72/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 16.986286]\n",
      "[Epoch 72/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 17.109755]\n",
      "[Epoch 72/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 16.952469]\n",
      "[Epoch 72/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 17.041592]\n",
      "[Epoch 72/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 16.946871]\n",
      "[Epoch 72/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 16.745163]\n",
      "[Epoch 72/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 17.074419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 16.592230]\n",
      "[Epoch 72/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.599731]\n",
      "[Epoch 72/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 17.300417]\n",
      "[Epoch 72/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 17.465738]\n",
      "[Epoch 72/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 17.220308]\n",
      "[Epoch 72/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 17.366842]\n",
      "[Epoch 72/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 17.307144]\n",
      "[Epoch 72/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 16.920435]\n",
      "[Epoch 72/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.835304]\n",
      "[Epoch 72/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 17.536861]\n",
      "[Epoch 72/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 17.229414]\n",
      "[Epoch 72/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 17.022263]\n",
      "[Epoch 72/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.908123]\n",
      "[Epoch 72/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 17.214666]\n",
      "[Epoch 72/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 17.004032]\n",
      "[Epoch 72/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 17.223949]\n",
      "[Epoch 72/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 17.050453]\n",
      "[Epoch 72/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 16.836319]\n",
      "[Epoch 72/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 17.267801]\n",
      "[Epoch 72/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 17.103790]\n",
      "[Epoch 72/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 17.288500]\n",
      "[Epoch 72/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 17.020350]\n",
      "[Epoch 72/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.811453]\n",
      "[Epoch 72/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 17.113903]\n",
      "[Epoch 72/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 16.997337]\n",
      "[Epoch 72/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 17.174589]\n",
      "[Epoch 72/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 16.870649]\n",
      "[Epoch 72/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 17.003487]\n",
      "[Epoch 72/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 17.313257]\n",
      "[Epoch 72/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 16.913305]\n",
      "[Epoch 72/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 17.532423]\n",
      "[Epoch 72/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 16.908556]\n",
      "[Epoch 72/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 17.200994]\n",
      "[Epoch 72/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 17.410915]\n",
      "[Epoch 72/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 17.033245]\n",
      "[Epoch 72/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 17.096111]\n",
      "[Epoch 72/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 16.922384]\n",
      "[Epoch 72/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 16.969513]\n",
      "[Epoch 72/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 17.403692]\n",
      "[Epoch 72/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 17.171511]\n",
      "[Epoch 72/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 17.051462]\n",
      "[Epoch 72/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 16.904856]\n",
      "[Epoch 72/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 16.869455]\n",
      "[Epoch 72/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 17.260361]\n",
      "[Epoch 72/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 17.258682]\n",
      "[Epoch 72/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 17.118399]\n",
      "[Epoch 72/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 17.121153]\n",
      "[Epoch 72/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 17.058685]\n",
      "[Epoch 72/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 16.969099]\n",
      "[Epoch 72/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 16.725281]\n",
      "[Epoch 72/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 17.257378]\n",
      "[Epoch 72/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 17.072674]\n",
      "[Epoch 72/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 17.362833]\n",
      "[Epoch 72/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 17.080278]\n",
      "[Epoch 72/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.896292]\n",
      "[Epoch 72/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 16.819641]\n",
      "[Epoch 72/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 17.091724]\n",
      "[Epoch 72/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 17.095013]\n",
      "[Epoch 72/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 17.529467]\n",
      "[Epoch 72/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 17.015896]\n",
      "[Epoch 72/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 17.258196]\n",
      "[Epoch 72/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 17.398581]\n",
      "[Epoch 72/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 17.198656]\n",
      "[Epoch 72/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 17.219440]\n",
      "[Epoch 72/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 16.753925]\n",
      "[Epoch 72/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 17.089592]\n",
      "[Epoch 72/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 16.892475]\n",
      "[Epoch 72/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 17.148699]\n",
      "[Epoch 72/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 17.068232]\n",
      "[Epoch 72/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 16.995453]\n",
      "[Epoch 72/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 17.208822]\n",
      "[Epoch 72/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 17.299152]\n",
      "[Epoch 72/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 16.908033]\n",
      "[Epoch 72/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 16.900742]\n",
      "[Epoch 72/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 17.148485]\n",
      "[Epoch 72/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 17.043137]\n",
      "[Epoch 73/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 17.184540]\n",
      "[Epoch 73/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 16.922871]\n",
      "[Epoch 73/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 17.049944]\n",
      "[Epoch 73/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 16.983936]\n",
      "[Epoch 73/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 16.913219]\n",
      "[Epoch 73/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.873959]\n",
      "[Epoch 73/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 16.857742]\n",
      "[Epoch 73/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 17.297098]\n",
      "[Epoch 73/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 17.263769]\n",
      "[Epoch 73/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 17.358982]\n",
      "[Epoch 73/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 17.003582]\n",
      "[Epoch 73/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 16.913301]\n",
      "[Epoch 73/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 17.090748]\n",
      "[Epoch 73/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 17.049944]\n",
      "[Epoch 73/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 17.019852]\n",
      "[Epoch 73/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 17.327719]\n",
      "[Epoch 73/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 16.912077]\n",
      "[Epoch 73/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 17.328297]\n",
      "[Epoch 73/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 17.411888]\n",
      "[Epoch 73/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 17.158808]\n",
      "[Epoch 73/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 17.057425]\n",
      "[Epoch 73/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 17.337708]\n",
      "[Epoch 73/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 17.122866]\n",
      "[Epoch 73/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 17.091928]\n",
      "[Epoch 73/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 17.094515]\n",
      "[Epoch 73/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 17.017138]\n",
      "[Epoch 73/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 17.191273]\n",
      "[Epoch 73/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.669279]\n",
      "[Epoch 73/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 16.984535]\n",
      "[Epoch 73/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 16.906502]\n",
      "[Epoch 73/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 16.489403]\n",
      "[Epoch 73/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 17.143791]\n",
      "[Epoch 73/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 17.141003]\n",
      "[Epoch 73/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 17.172691]\n",
      "[Epoch 73/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 16.835913]\n",
      "[Epoch 73/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 17.164413]\n",
      "[Epoch 73/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 16.857967]\n",
      "[Epoch 73/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 16.804234]\n",
      "[Epoch 73/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 17.095116]\n",
      "[Epoch 73/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 16.796795]\n",
      "[Epoch 73/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 16.779427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 17.223660]\n",
      "[Epoch 73/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 17.170328]\n",
      "[Epoch 73/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 16.907230]\n",
      "[Epoch 73/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 17.298716]\n",
      "[Epoch 73/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 17.350130]\n",
      "[Epoch 73/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 17.358393]\n",
      "[Epoch 73/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 17.349682]\n",
      "[Epoch 73/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 17.085886]\n",
      "[Epoch 73/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 17.023659]\n",
      "[Epoch 73/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 17.142834]\n",
      "[Epoch 73/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 17.431866]\n",
      "[Epoch 73/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 16.899734]\n",
      "[Epoch 73/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 17.085659]\n",
      "[Epoch 73/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 17.401562]\n",
      "[Epoch 73/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.909420]\n",
      "[Epoch 73/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 16.808249]\n",
      "[Epoch 73/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 16.832130]\n",
      "[Epoch 73/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.916822]\n",
      "[Epoch 73/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 17.141708]\n",
      "[Epoch 73/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 16.859509]\n",
      "[Epoch 73/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 16.983055]\n",
      "[Epoch 73/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 17.344597]\n",
      "[Epoch 73/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 16.764404]\n",
      "[Epoch 73/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 17.163652]\n",
      "[Epoch 73/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.665241]\n",
      "[Epoch 73/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 17.242569]\n",
      "[Epoch 73/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 16.850620]\n",
      "[Epoch 73/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 17.257410]\n",
      "[Epoch 73/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 17.060268]\n",
      "[Epoch 73/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 16.896618]\n",
      "[Epoch 73/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 17.462858]\n",
      "[Epoch 73/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 17.501228]\n",
      "[Epoch 73/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 17.080591]\n",
      "[Epoch 73/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 16.847799]\n",
      "[Epoch 73/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 17.201263]\n",
      "[Epoch 73/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 17.240089]\n",
      "[Epoch 73/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 17.222004]\n",
      "[Epoch 73/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 17.316513]\n",
      "[Epoch 73/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 17.692335]\n",
      "[Epoch 73/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 16.913685]\n",
      "[Epoch 73/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 17.157896]\n",
      "[Epoch 73/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 16.733313]\n",
      "[Epoch 73/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 17.096630]\n",
      "[Epoch 73/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 17.059608]\n",
      "[Epoch 73/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 17.038996]\n",
      "[Epoch 73/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 16.722250]\n",
      "[Epoch 73/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 17.002975]\n",
      "[Epoch 73/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 16.782721]\n",
      "[Epoch 73/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 17.370506]\n",
      "[Epoch 73/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 17.343090]\n",
      "[Epoch 73/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 17.019951]\n",
      "[Epoch 73/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 17.170742]\n",
      "[Epoch 73/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 16.907816]\n",
      "[Epoch 73/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 17.138336]\n",
      "[Epoch 73/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 17.207233]\n",
      "[Epoch 73/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 16.882486]\n",
      "[Epoch 73/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 17.176901]\n",
      "[Epoch 73/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 16.971096]\n",
      "[Epoch 73/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 17.473993]\n",
      "[Epoch 73/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 16.993763]\n",
      "[Epoch 73/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 16.953728]\n",
      "[Epoch 73/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 17.060324]\n",
      "[Epoch 73/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 17.193624]\n",
      "[Epoch 73/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 17.199572]\n",
      "[Epoch 73/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 17.361210]\n",
      "[Epoch 73/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 17.120819]\n",
      "[Epoch 73/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 17.229136]\n",
      "[Epoch 73/1000] [Batch 109/168] [D loss: 0.000003] [G loss: 16.719976]\n",
      "[Epoch 73/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 17.409456]\n",
      "[Epoch 73/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 17.603533]\n",
      "[Epoch 73/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 17.761562]\n",
      "[Epoch 73/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 17.489231]\n",
      "[Epoch 73/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 17.472019]\n",
      "[Epoch 73/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 17.215878]\n",
      "[Epoch 73/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 17.274256]\n",
      "[Epoch 73/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 17.196859]\n",
      "[Epoch 73/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 17.065372]\n",
      "[Epoch 73/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 17.088556]\n",
      "[Epoch 73/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 17.303062]\n",
      "[Epoch 73/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 17.315819]\n",
      "[Epoch 73/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 17.347349]\n",
      "[Epoch 73/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 17.328053]\n",
      "[Epoch 73/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 17.560261]\n",
      "[Epoch 73/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 17.133307]\n",
      "[Epoch 73/1000] [Batch 126/168] [D loss: 0.000001] [G loss: 16.975140]\n",
      "[Epoch 73/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 17.377892]\n",
      "[Epoch 73/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 17.107777]\n",
      "[Epoch 73/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 17.425602]\n",
      "[Epoch 73/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 17.320795]\n",
      "[Epoch 73/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 17.179012]\n",
      "[Epoch 73/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 17.246279]\n",
      "[Epoch 73/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 17.616558]\n",
      "[Epoch 73/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 17.231544]\n",
      "[Epoch 73/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 17.274811]\n",
      "[Epoch 73/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 17.288141]\n",
      "[Epoch 73/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 17.331583]\n",
      "[Epoch 73/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 17.208046]\n",
      "[Epoch 73/1000] [Batch 139/168] [D loss: 0.000001] [G loss: 17.046917]\n",
      "[Epoch 73/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 17.272085]\n",
      "[Epoch 73/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 17.583212]\n",
      "[Epoch 73/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 17.521130]\n",
      "[Epoch 73/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 17.461092]\n",
      "[Epoch 73/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 17.642693]\n",
      "[Epoch 73/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 17.742010]\n",
      "[Epoch 73/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 17.653831]\n",
      "[Epoch 73/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 17.336676]\n",
      "[Epoch 73/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 17.271492]\n",
      "[Epoch 73/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 17.549427]\n",
      "[Epoch 73/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 16.986387]\n",
      "[Epoch 73/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 17.492714]\n",
      "[Epoch 73/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 17.316833]\n",
      "[Epoch 73/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 17.123060]\n",
      "[Epoch 73/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 17.310841]\n",
      "[Epoch 73/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 17.235168]\n",
      "[Epoch 73/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 17.606953]\n",
      "[Epoch 73/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 17.351656]\n",
      "[Epoch 73/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 16.888636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 17.415419]\n",
      "[Epoch 73/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 17.577301]\n",
      "[Epoch 73/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 17.490051]\n",
      "[Epoch 73/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 17.254272]\n",
      "[Epoch 73/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 17.258036]\n",
      "[Epoch 73/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 17.590313]\n",
      "[Epoch 73/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 17.509748]\n",
      "[Epoch 73/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 17.090433]\n",
      "[Epoch 73/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 17.062378]\n",
      "[Epoch 73/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 17.268610]\n",
      "[Epoch 74/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 17.362736]\n",
      "[Epoch 74/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 17.063364]\n",
      "[Epoch 74/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 17.244944]\n",
      "[Epoch 74/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 17.088232]\n",
      "[Epoch 74/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 17.279234]\n",
      "[Epoch 74/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 16.842707]\n",
      "[Epoch 74/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 17.381020]\n",
      "[Epoch 74/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 17.101377]\n",
      "[Epoch 74/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 17.209187]\n",
      "[Epoch 74/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 16.986162]\n",
      "[Epoch 74/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 17.135002]\n",
      "[Epoch 74/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 17.355524]\n",
      "[Epoch 74/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 17.351570]\n",
      "[Epoch 74/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 17.552837]\n",
      "[Epoch 74/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 17.224684]\n",
      "[Epoch 74/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 17.250277]\n",
      "[Epoch 74/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 17.472168]\n",
      "[Epoch 74/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 17.207096]\n",
      "[Epoch 74/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 17.323112]\n",
      "[Epoch 74/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 17.008633]\n",
      "[Epoch 74/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 17.670649]\n",
      "[Epoch 74/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 17.328024]\n",
      "[Epoch 74/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 17.553232]\n",
      "[Epoch 74/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 17.454123]\n",
      "[Epoch 74/1000] [Batch 25/168] [D loss: 0.000000] [G loss: 17.418797]\n",
      "[Epoch 74/1000] [Batch 26/168] [D loss: 0.000000] [G loss: 17.322241]\n",
      "[Epoch 74/1000] [Batch 27/168] [D loss: 0.000000] [G loss: 17.420776]\n",
      "[Epoch 74/1000] [Batch 28/168] [D loss: 0.000000] [G loss: 16.961847]\n",
      "[Epoch 74/1000] [Batch 29/168] [D loss: 0.000000] [G loss: 17.450981]\n",
      "[Epoch 74/1000] [Batch 30/168] [D loss: 0.000000] [G loss: 17.279966]\n",
      "[Epoch 74/1000] [Batch 31/168] [D loss: 0.000000] [G loss: 17.179926]\n",
      "[Epoch 74/1000] [Batch 32/168] [D loss: 0.000000] [G loss: 17.085403]\n",
      "[Epoch 74/1000] [Batch 33/168] [D loss: 0.000000] [G loss: 17.389921]\n",
      "[Epoch 74/1000] [Batch 34/168] [D loss: 0.000000] [G loss: 16.985516]\n",
      "[Epoch 74/1000] [Batch 35/168] [D loss: 0.000000] [G loss: 17.087889]\n",
      "[Epoch 74/1000] [Batch 36/168] [D loss: 0.000000] [G loss: 16.924036]\n",
      "[Epoch 74/1000] [Batch 37/168] [D loss: 0.000000] [G loss: 17.043230]\n",
      "[Epoch 74/1000] [Batch 38/168] [D loss: 0.000000] [G loss: 17.418982]\n",
      "[Epoch 74/1000] [Batch 39/168] [D loss: 0.000000] [G loss: 17.468010]\n",
      "[Epoch 74/1000] [Batch 40/168] [D loss: 0.000000] [G loss: 17.532524]\n",
      "[Epoch 74/1000] [Batch 41/168] [D loss: 0.000000] [G loss: 17.348585]\n",
      "[Epoch 74/1000] [Batch 42/168] [D loss: 0.000000] [G loss: 17.114109]\n",
      "[Epoch 74/1000] [Batch 43/168] [D loss: 0.000000] [G loss: 17.357161]\n",
      "[Epoch 74/1000] [Batch 44/168] [D loss: 0.000000] [G loss: 17.392353]\n",
      "[Epoch 74/1000] [Batch 45/168] [D loss: 0.000000] [G loss: 17.464964]\n",
      "[Epoch 74/1000] [Batch 46/168] [D loss: 0.000000] [G loss: 17.280300]\n",
      "[Epoch 74/1000] [Batch 47/168] [D loss: 0.000000] [G loss: 17.182110]\n",
      "[Epoch 74/1000] [Batch 48/168] [D loss: 0.000000] [G loss: 17.358078]\n",
      "[Epoch 74/1000] [Batch 49/168] [D loss: 0.000000] [G loss: 17.243355]\n",
      "[Epoch 74/1000] [Batch 50/168] [D loss: 0.000000] [G loss: 17.260801]\n",
      "[Epoch 74/1000] [Batch 51/168] [D loss: 0.000000] [G loss: 17.554661]\n",
      "[Epoch 74/1000] [Batch 52/168] [D loss: 0.000000] [G loss: 17.323200]\n",
      "[Epoch 74/1000] [Batch 53/168] [D loss: 0.000000] [G loss: 17.486057]\n",
      "[Epoch 74/1000] [Batch 54/168] [D loss: 0.000000] [G loss: 16.989452]\n",
      "[Epoch 74/1000] [Batch 55/168] [D loss: 0.000000] [G loss: 17.398634]\n",
      "[Epoch 74/1000] [Batch 56/168] [D loss: 0.000000] [G loss: 16.907127]\n",
      "[Epoch 74/1000] [Batch 57/168] [D loss: 0.000000] [G loss: 17.026373]\n",
      "[Epoch 74/1000] [Batch 58/168] [D loss: 0.000000] [G loss: 17.165321]\n",
      "[Epoch 74/1000] [Batch 59/168] [D loss: 0.000000] [G loss: 16.961914]\n",
      "[Epoch 74/1000] [Batch 60/168] [D loss: 0.000000] [G loss: 17.230728]\n",
      "[Epoch 74/1000] [Batch 61/168] [D loss: 0.000000] [G loss: 17.471037]\n",
      "[Epoch 74/1000] [Batch 62/168] [D loss: 0.000000] [G loss: 17.059561]\n",
      "[Epoch 74/1000] [Batch 63/168] [D loss: 0.000000] [G loss: 17.044243]\n",
      "[Epoch 74/1000] [Batch 64/168] [D loss: 0.000000] [G loss: 17.056704]\n",
      "[Epoch 74/1000] [Batch 65/168] [D loss: 0.000000] [G loss: 17.236536]\n",
      "[Epoch 74/1000] [Batch 66/168] [D loss: 0.000000] [G loss: 16.895370]\n",
      "[Epoch 74/1000] [Batch 67/168] [D loss: 0.000000] [G loss: 17.201950]\n",
      "[Epoch 74/1000] [Batch 68/168] [D loss: 0.000000] [G loss: 17.271856]\n",
      "[Epoch 74/1000] [Batch 69/168] [D loss: 0.000000] [G loss: 17.469744]\n",
      "[Epoch 74/1000] [Batch 70/168] [D loss: 0.000000] [G loss: 17.321678]\n",
      "[Epoch 74/1000] [Batch 71/168] [D loss: 0.000000] [G loss: 17.399008]\n",
      "[Epoch 74/1000] [Batch 72/168] [D loss: 0.000000] [G loss: 17.331532]\n",
      "[Epoch 74/1000] [Batch 73/168] [D loss: 0.000000] [G loss: 17.233555]\n",
      "[Epoch 74/1000] [Batch 74/168] [D loss: 0.000000] [G loss: 17.011587]\n",
      "[Epoch 74/1000] [Batch 75/168] [D loss: 0.000000] [G loss: 17.174501]\n",
      "[Epoch 74/1000] [Batch 76/168] [D loss: 0.000000] [G loss: 17.016678]\n",
      "[Epoch 74/1000] [Batch 77/168] [D loss: 0.000000] [G loss: 17.244829]\n",
      "[Epoch 74/1000] [Batch 78/168] [D loss: 0.000000] [G loss: 16.977959]\n",
      "[Epoch 74/1000] [Batch 79/168] [D loss: 0.000000] [G loss: 17.160679]\n",
      "[Epoch 74/1000] [Batch 80/168] [D loss: 0.000000] [G loss: 17.201927]\n",
      "[Epoch 74/1000] [Batch 81/168] [D loss: 0.000000] [G loss: 17.308550]\n",
      "[Epoch 74/1000] [Batch 82/168] [D loss: 0.000000] [G loss: 17.525440]\n",
      "[Epoch 74/1000] [Batch 83/168] [D loss: 0.000000] [G loss: 17.073708]\n",
      "[Epoch 74/1000] [Batch 84/168] [D loss: 0.000000] [G loss: 17.300619]\n",
      "[Epoch 74/1000] [Batch 85/168] [D loss: 0.000000] [G loss: 17.370522]\n",
      "[Epoch 74/1000] [Batch 86/168] [D loss: 0.000000] [G loss: 17.315596]\n",
      "[Epoch 74/1000] [Batch 87/168] [D loss: 0.000000] [G loss: 17.070980]\n",
      "[Epoch 74/1000] [Batch 88/168] [D loss: 0.000000] [G loss: 17.602627]\n",
      "[Epoch 74/1000] [Batch 89/168] [D loss: 0.000000] [G loss: 17.151726]\n",
      "[Epoch 74/1000] [Batch 90/168] [D loss: 0.000000] [G loss: 17.244255]\n",
      "[Epoch 74/1000] [Batch 91/168] [D loss: 0.000000] [G loss: 17.335310]\n",
      "[Epoch 74/1000] [Batch 92/168] [D loss: 0.000000] [G loss: 17.570475]\n",
      "[Epoch 74/1000] [Batch 93/168] [D loss: 0.000000] [G loss: 17.258739]\n",
      "[Epoch 74/1000] [Batch 94/168] [D loss: 0.000000] [G loss: 17.387888]\n",
      "[Epoch 74/1000] [Batch 95/168] [D loss: 0.000000] [G loss: 17.222414]\n",
      "[Epoch 74/1000] [Batch 96/168] [D loss: 0.000000] [G loss: 17.422935]\n",
      "[Epoch 74/1000] [Batch 97/168] [D loss: 0.000000] [G loss: 17.076136]\n",
      "[Epoch 74/1000] [Batch 98/168] [D loss: 0.000000] [G loss: 17.574039]\n",
      "[Epoch 74/1000] [Batch 99/168] [D loss: 0.000000] [G loss: 17.311701]\n",
      "[Epoch 74/1000] [Batch 100/168] [D loss: 0.000000] [G loss: 17.185160]\n",
      "[Epoch 74/1000] [Batch 101/168] [D loss: 0.000000] [G loss: 17.222107]\n",
      "[Epoch 74/1000] [Batch 102/168] [D loss: 0.000000] [G loss: 17.432119]\n",
      "[Epoch 74/1000] [Batch 103/168] [D loss: 0.000000] [G loss: 17.209658]\n",
      "[Epoch 74/1000] [Batch 104/168] [D loss: 0.000000] [G loss: 17.366611]\n",
      "[Epoch 74/1000] [Batch 105/168] [D loss: 0.000000] [G loss: 16.912760]\n",
      "[Epoch 74/1000] [Batch 106/168] [D loss: 0.000000] [G loss: 17.480064]\n",
      "[Epoch 74/1000] [Batch 107/168] [D loss: 0.000000] [G loss: 17.253536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74/1000] [Batch 108/168] [D loss: 0.000000] [G loss: 17.410679]\n",
      "[Epoch 74/1000] [Batch 109/168] [D loss: 0.000000] [G loss: 17.215620]\n",
      "[Epoch 74/1000] [Batch 110/168] [D loss: 0.000000] [G loss: 17.173422]\n",
      "[Epoch 74/1000] [Batch 111/168] [D loss: 0.000000] [G loss: 17.064852]\n",
      "[Epoch 74/1000] [Batch 112/168] [D loss: 0.000000] [G loss: 17.032907]\n",
      "[Epoch 74/1000] [Batch 113/168] [D loss: 0.000000] [G loss: 17.340525]\n",
      "[Epoch 74/1000] [Batch 114/168] [D loss: 0.000000] [G loss: 17.141285]\n",
      "[Epoch 74/1000] [Batch 115/168] [D loss: 0.000000] [G loss: 16.949188]\n",
      "[Epoch 74/1000] [Batch 116/168] [D loss: 0.000000] [G loss: 17.071381]\n",
      "[Epoch 74/1000] [Batch 117/168] [D loss: 0.000000] [G loss: 17.195908]\n",
      "[Epoch 74/1000] [Batch 118/168] [D loss: 0.000000] [G loss: 17.088795]\n",
      "[Epoch 74/1000] [Batch 119/168] [D loss: 0.000000] [G loss: 17.298904]\n",
      "[Epoch 74/1000] [Batch 120/168] [D loss: 0.000000] [G loss: 17.227541]\n",
      "[Epoch 74/1000] [Batch 121/168] [D loss: 0.000000] [G loss: 17.025307]\n",
      "[Epoch 74/1000] [Batch 122/168] [D loss: 0.000000] [G loss: 17.065702]\n",
      "[Epoch 74/1000] [Batch 123/168] [D loss: 0.000000] [G loss: 17.401051]\n",
      "[Epoch 74/1000] [Batch 124/168] [D loss: 0.000000] [G loss: 17.148794]\n",
      "[Epoch 74/1000] [Batch 125/168] [D loss: 0.000000] [G loss: 17.204144]\n",
      "[Epoch 74/1000] [Batch 126/168] [D loss: 0.000000] [G loss: 17.053751]\n",
      "[Epoch 74/1000] [Batch 127/168] [D loss: 0.000000] [G loss: 17.510454]\n",
      "[Epoch 74/1000] [Batch 128/168] [D loss: 0.000000] [G loss: 17.144403]\n",
      "[Epoch 74/1000] [Batch 129/168] [D loss: 0.000000] [G loss: 17.335751]\n",
      "[Epoch 74/1000] [Batch 130/168] [D loss: 0.000000] [G loss: 17.148575]\n",
      "[Epoch 74/1000] [Batch 131/168] [D loss: 0.000000] [G loss: 17.319347]\n",
      "[Epoch 74/1000] [Batch 132/168] [D loss: 0.000000] [G loss: 17.110477]\n",
      "[Epoch 74/1000] [Batch 133/168] [D loss: 0.000000] [G loss: 17.275307]\n",
      "[Epoch 74/1000] [Batch 134/168] [D loss: 0.000000] [G loss: 17.422558]\n",
      "[Epoch 74/1000] [Batch 135/168] [D loss: 0.000000] [G loss: 17.372175]\n",
      "[Epoch 74/1000] [Batch 136/168] [D loss: 0.000000] [G loss: 17.334015]\n",
      "[Epoch 74/1000] [Batch 137/168] [D loss: 0.000000] [G loss: 17.028036]\n",
      "[Epoch 74/1000] [Batch 138/168] [D loss: 0.000000] [G loss: 17.012377]\n",
      "[Epoch 74/1000] [Batch 139/168] [D loss: 0.000000] [G loss: 16.875481]\n",
      "[Epoch 74/1000] [Batch 140/168] [D loss: 0.000000] [G loss: 17.079002]\n",
      "[Epoch 74/1000] [Batch 141/168] [D loss: 0.000000] [G loss: 17.273705]\n",
      "[Epoch 74/1000] [Batch 142/168] [D loss: 0.000000] [G loss: 17.030542]\n",
      "[Epoch 74/1000] [Batch 143/168] [D loss: 0.000000] [G loss: 17.064224]\n",
      "[Epoch 74/1000] [Batch 144/168] [D loss: 0.000000] [G loss: 17.184061]\n",
      "[Epoch 74/1000] [Batch 145/168] [D loss: 0.000000] [G loss: 17.287983]\n",
      "[Epoch 74/1000] [Batch 146/168] [D loss: 0.000000] [G loss: 17.606344]\n",
      "[Epoch 74/1000] [Batch 147/168] [D loss: 0.000000] [G loss: 16.972878]\n",
      "[Epoch 74/1000] [Batch 148/168] [D loss: 0.000000] [G loss: 16.993534]\n",
      "[Epoch 74/1000] [Batch 149/168] [D loss: 0.000000] [G loss: 17.244833]\n",
      "[Epoch 74/1000] [Batch 150/168] [D loss: 0.000000] [G loss: 17.382627]\n",
      "[Epoch 74/1000] [Batch 151/168] [D loss: 0.000000] [G loss: 17.265644]\n",
      "[Epoch 74/1000] [Batch 152/168] [D loss: 0.000000] [G loss: 17.436449]\n",
      "[Epoch 74/1000] [Batch 153/168] [D loss: 0.000000] [G loss: 17.508915]\n",
      "[Epoch 74/1000] [Batch 154/168] [D loss: 0.000000] [G loss: 17.018404]\n",
      "[Epoch 74/1000] [Batch 155/168] [D loss: 0.000000] [G loss: 17.256929]\n",
      "[Epoch 74/1000] [Batch 156/168] [D loss: 0.000000] [G loss: 16.886784]\n",
      "[Epoch 74/1000] [Batch 157/168] [D loss: 0.000000] [G loss: 17.250452]\n",
      "[Epoch 74/1000] [Batch 158/168] [D loss: 0.000000] [G loss: 17.034678]\n",
      "[Epoch 74/1000] [Batch 159/168] [D loss: 0.000000] [G loss: 17.238745]\n",
      "[Epoch 74/1000] [Batch 160/168] [D loss: 0.000000] [G loss: 17.390194]\n",
      "[Epoch 74/1000] [Batch 161/168] [D loss: 0.000000] [G loss: 17.156330]\n",
      "[Epoch 74/1000] [Batch 162/168] [D loss: 0.000000] [G loss: 17.089613]\n",
      "[Epoch 74/1000] [Batch 163/168] [D loss: 0.000000] [G loss: 17.115715]\n",
      "[Epoch 74/1000] [Batch 164/168] [D loss: 0.000000] [G loss: 17.138159]\n",
      "[Epoch 74/1000] [Batch 165/168] [D loss: 0.000000] [G loss: 17.123541]\n",
      "[Epoch 74/1000] [Batch 166/168] [D loss: 0.000000] [G loss: 17.225109]\n",
      "[Epoch 74/1000] [Batch 167/168] [D loss: 0.000000] [G loss: 17.605928]\n",
      "[Epoch 74/1000] [Batch 168/168] [D loss: 0.000000] [G loss: 17.206200]\n",
      "[Epoch 75/1000] [Batch 1/168] [D loss: 0.000000] [G loss: 17.153843]\n",
      "[Epoch 75/1000] [Batch 2/168] [D loss: 0.000000] [G loss: 17.064640]\n",
      "[Epoch 75/1000] [Batch 3/168] [D loss: 0.000000] [G loss: 17.430109]\n",
      "[Epoch 75/1000] [Batch 4/168] [D loss: 0.000000] [G loss: 17.033962]\n",
      "[Epoch 75/1000] [Batch 5/168] [D loss: 0.000000] [G loss: 17.568953]\n",
      "[Epoch 75/1000] [Batch 6/168] [D loss: 0.000000] [G loss: 17.678303]\n",
      "[Epoch 75/1000] [Batch 7/168] [D loss: 0.000000] [G loss: 17.124035]\n",
      "[Epoch 75/1000] [Batch 8/168] [D loss: 0.000000] [G loss: 17.488226]\n",
      "[Epoch 75/1000] [Batch 9/168] [D loss: 0.000000] [G loss: 17.346443]\n",
      "[Epoch 75/1000] [Batch 10/168] [D loss: 0.000000] [G loss: 17.388514]\n",
      "[Epoch 75/1000] [Batch 11/168] [D loss: 0.000000] [G loss: 17.096245]\n",
      "[Epoch 75/1000] [Batch 12/168] [D loss: 0.000000] [G loss: 17.570919]\n",
      "[Epoch 75/1000] [Batch 13/168] [D loss: 0.000000] [G loss: 17.368835]\n",
      "[Epoch 75/1000] [Batch 14/168] [D loss: 0.000000] [G loss: 17.601540]\n",
      "[Epoch 75/1000] [Batch 15/168] [D loss: 0.000000] [G loss: 17.186104]\n",
      "[Epoch 75/1000] [Batch 16/168] [D loss: 0.000000] [G loss: 17.536472]\n",
      "[Epoch 75/1000] [Batch 17/168] [D loss: 0.000000] [G loss: 17.320724]\n",
      "[Epoch 75/1000] [Batch 18/168] [D loss: 0.000000] [G loss: 16.971863]\n",
      "[Epoch 75/1000] [Batch 19/168] [D loss: 0.000000] [G loss: 17.060297]\n",
      "[Epoch 75/1000] [Batch 20/168] [D loss: 0.000000] [G loss: 17.341234]\n",
      "[Epoch 75/1000] [Batch 21/168] [D loss: 0.000000] [G loss: 17.199383]\n",
      "[Epoch 75/1000] [Batch 22/168] [D loss: 0.000000] [G loss: 17.602215]\n",
      "[Epoch 75/1000] [Batch 23/168] [D loss: 0.000000] [G loss: 17.385332]\n",
      "[Epoch 75/1000] [Batch 24/168] [D loss: 0.000000] [G loss: 17.200302]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-68f9773abd37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IA\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IA\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lists to keep track of progress\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "#Training\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, valid) in enumerate(train_dataloader):\n",
    "        \n",
    "        ##Train Generator\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Sample noise as generator input\n",
    "        \n",
    "        z = torch.randn(size_batch, nz, 1, 1)\n",
    "        \n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "        \n",
    "        d_outputs = discriminator(gen_imgs)\n",
    "        \n",
    "        fake = torch.zeros_like(d_outputs)\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(d_outputs, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        ##Train Discriminator\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch +1, n_epochs, i +1, len(train_dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "        \n",
    "        batches_done = epoch * len(train_dataloader) + i\n",
    "        \n",
    "        if (batches_done % 1000 == 0):\n",
    "            save_image(gen_imgs.data[:25], \"images3/%d.png\" % batches_done , nrow=5, normalize=True)\n",
    "            torch.save(generator.state_dict(), \"generator3.pt\")\n",
    "            torch.save(discriminator.state_dict(), \"discriminator3.pt\")\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    plt.imshow(np.swapaxes(np.swapaxes(gen_imgs[0],0,2), 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
